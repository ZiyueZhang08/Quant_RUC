{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e826037-0f95-4cb3-ac2d-43fc6e4da071",
   "metadata": {},
   "source": [
    "### 海淀苏州街数据爬取"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16b79e8-d344-4461-9e3e-e619b57c8ad8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 0. 一些准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8dd26eb-8b17-4038-a6af-6b8286da6b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import pandas as pd\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4d0b06e-4e69-48c7-a209-e251b66f5a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_haidian_suzhouqiao(url):\n",
    "    \"\"\"点击海淀区和苏州桥片区\"\"\"\n",
    "    try:\n",
    "        # 等待页面加载并点击北京\n",
    "        driver.get(url)\n",
    "        \n",
    "        # 点击海淀区\n",
    "        haidian_link = wait.until(EC.element_to_be_clickable((By.LINK_TEXT, \"海淀\")))\n",
    "        haidian_link.click()\n",
    "        print(\"已点击海淀区\")\n",
    "        \n",
    "        # 点击苏州桥片区\n",
    "        suzhouqiao_link = wait.until(EC.element_to_be_clickable((By.LINK_TEXT, \"苏州桥\")))\n",
    "        suzhouqiao_link.click()\n",
    "        print(\"已点击苏州桥片区\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"点击区域时出错: {e}\")\n",
    "\n",
    "def scrape_listings(element_list, npage_button, func, max_pages=20):\n",
    "    \"\"\"爬取房源列表\"\"\"\n",
    "    all_listings = []\n",
    "    \n",
    "    try:\n",
    "        for page in range(1, max_pages + 1):\n",
    "            print(f\"正在爬取第 {page} 页...\")\n",
    "            \n",
    "            # 获取当前页所有房源元素\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, element_list)))\n",
    "            listing_elements = driver.find_elements(By.CSS_SELECTOR, element_list)\n",
    "            print(f\"找到 {len(listing_elements)} 个房源\")\n",
    "            \n",
    "            page_listings = 0\n",
    "            for i, listing_element in enumerate(listing_elements):\n",
    "                try:\n",
    "                    listing_data = func(listing_element)\n",
    "                    if listing_data:\n",
    "                        all_listings.append(listing_data)\n",
    "                        page_listings += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"处理第 {page} 页第 {i+1} 条房源时出错: {e}\")\n",
    "            \n",
    "            print(f\"第 {page} 页收集完成，共 {page_listings} 条房源\")\n",
    "            \n",
    "            # 尝试翻到下一页\n",
    "            if page < max_pages:\n",
    "                try:\n",
    "                    next_button = driver.find_element(By.CSS_SELECTOR, npage_button)\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    print(\"成功点击下一页\")\n",
    "                    time.sleep(1) # 太快似乎会引起反爬\n",
    "                    \n",
    "                    # 等待新页面加载\n",
    "                    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, element_list)))\n",
    "                    \n",
    "                except NoSuchElementException:\n",
    "                    print(\"没有找到下一页，爬取结束\")\n",
    "                    break     \n",
    "    except Exception as e:\n",
    "        print(f\"爬取过程中出错: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    return all_listings                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf874efc-6977-4db8-a1fe-647792bea016",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 1. 爬取房价数据，存储在'Housing_Price_Suzhouqiao.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a244d7c-0b25-436b-961e-22145c7986e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_PRICE_listing_from_list(listing_element):\n",
    "    \"\"\"从列表页元素直接收集数据\"\"\"\n",
    "    listing_data = {}\n",
    "    \n",
    "    try:\n",
    "        # 标题\n",
    "        try:\n",
    "            title_element = listing_element.find_element(By.CSS_SELECTOR, 'h4 a span.tit_shop')\n",
    "            listing_data['标题'] = title_element.text\n",
    "        except NoSuchElementException:\n",
    "            listing_data['标题'] = ''\n",
    "        \n",
    "        # 总价\n",
    "        try:\n",
    "            total_price_element = listing_element.find_element(By.CSS_SELECTOR, 'dd.price_right span.red b')\n",
    "            listing_data['总价(万元)'] = float(total_price_element.text)\n",
    "        except NoSuchElementException:\n",
    "            listing_data['总价(万元)'] = None\n",
    "        \n",
    "        # 单价\n",
    "        try:\n",
    "            unit_price_element = listing_element.find_element(By.CSS_SELECTOR, 'dd.price_right span:not(.red)')\n",
    "            unit_price_text = unit_price_element.text\n",
    "            cleaned_unit_price_text = re.sub(r'[^\\d.]', '', unit_price_text)\n",
    "            listing_data['单价(元/平方米)'] = float(cleaned_unit_price_text)\n",
    "        except NoSuchElementException:\n",
    "            listing_data['单价(元/平方米)'] = None\n",
    "        \n",
    "        # 户型、面积、楼层、朝向、建成年份\n",
    "        try:\n",
    "            tel_shop_element = listing_element.find_element(By.CSS_SELECTOR, 'p.tel_shop')\n",
    "            tel_shop_text = tel_shop_element.text\n",
    "            parts = [part.strip() for part in tel_shop_text.split('|')]\n",
    "            \n",
    "            # 户型\n",
    "            if len(parts) > 0:\n",
    "                listing_data['户型'] = parts[0]\n",
    "            \n",
    "            # 面积\n",
    "            if len(parts) > 1:\n",
    "                area_text = re.sub(r'[^\\d.]', '', parts[1])\n",
    "                listing_data['面积'] = float(area_text)\n",
    "            \n",
    "            # 楼层\n",
    "            if len(parts) > 2:\n",
    "                listing_data['楼层'] = parts[2]\n",
    "            \n",
    "            # 朝向\n",
    "            if len(parts) > 3:\n",
    "                listing_data['朝向'] = parts[3]\n",
    "            \n",
    "            # 建成年份\n",
    "            if len(parts) > 4:\n",
    "                year_match = re.search(r'(\\d{4})', parts[4])\n",
    "                listing_data['建成年份'] = int(year_match.group(1)) if year_match else None\n",
    "        except NoSuchElementException:\n",
    "            listing_data['户型'] = ''\n",
    "            listing_data['面积'] = None\n",
    "            listing_data['楼层'] = ''\n",
    "            listing_data['朝向'] = ''\n",
    "            listing_data['建成年份'] = None\n",
    "        \n",
    "        # 小区名称\n",
    "        try:\n",
    "            community_element = listing_element.find_element(By.CSS_SELECTOR, 'p.add_shop a')\n",
    "            listing_data['小区名称'] = community_element.text\n",
    "        except NoSuchElementException:\n",
    "            listing_data['小区名称'] = ''\n",
    "        \n",
    "        # 地址\n",
    "        try:\n",
    "            address_element = listing_element.find_element(By.CSS_SELECTOR, 'p.add_shop span')\n",
    "            listing_data['地址'] = address_element.text\n",
    "        except NoSuchElementException:\n",
    "            listing_data['地址'] = ''\n",
    "    \n",
    "\n",
    "        # 房主持有年份和交通信息\n",
    "        try:\n",
    "            label_element = listing_element.find_element(By.CSS_SELECTOR, 'p.clearfix.label')\n",
    "    \n",
    "            # 提取房主持有年份（没有类名的span）\n",
    "            try:\n",
    "                hold_year_span = label_element.find_element(By.CSS_SELECTOR, 'span:not([class])')\n",
    "                listing_data['房主持有年份'] = hold_year_span.text\n",
    "            except NoSuchElementException:\n",
    "                listing_data['房主持有年份'] = ''\n",
    "    \n",
    "            # 提取交通信息\n",
    "            try:\n",
    "                traffic_span = label_element.find_element(By.CSS_SELECTOR, 'span.bg_none.icon_dt')\n",
    "                listing_data['交通信息'] = traffic_span.text\n",
    "            except NoSuchElementException:\n",
    "                listing_data['交通信息'] = ''\n",
    "        \n",
    "        except NoSuchElementException:\n",
    "            listing_data['房主持有年份'] = ''\n",
    "            listing_data['交通信息'] = ''\n",
    "        \n",
    "        # 经纪人\n",
    "        try:\n",
    "            agent_element = listing_element.find_element(By.CSS_SELECTOR, 'span.people_name a')\n",
    "            listing_data['经纪人'] = agent_element.text\n",
    "        except NoSuchElementException:\n",
    "            listing_data['经纪人'] = ''\n",
    "        \n",
    "        # 添加片区信息\n",
    "        listing_data['片区'] = '苏州桥'\n",
    "        \n",
    "        return listing_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"从列表提取房源信息时出错: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c886c85d-34e9-47f1-834d-67c81d0b64ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已点击海淀区\n",
      "已点击苏州桥片区\n",
      "开始爬取房源数据...\n",
      "正在爬取第 1 页...\n",
      "找到 60 个房源\n",
      "第 1 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 2 页...\n",
      "找到 60 个房源\n",
      "第 2 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 3 页...\n",
      "找到 60 个房源\n",
      "第 3 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 4 页...\n",
      "找到 60 个房源\n",
      "第 4 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 5 页...\n",
      "找到 60 个房源\n",
      "第 5 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 6 页...\n",
      "找到 8 个房源\n",
      "第 6 页收集完成，共 8 条房源\n",
      "没有找到下一页，爬取结束\n",
      "数据已保存到 Housing_Price_Suzhouqiao.csv\n",
      "共收集到 308 条房源信息\n",
      "\n",
      "前5条数据预览:\n",
      "                             标题  总价(万元)  单价(元/平方米)    户型      面积         楼层   朝向    建成年份   小区名称            地址 房主持有年份               交通信息  经纪人   片区\n",
      "0  苏州桥·友谊宾馆家属院不临街中间层正规三居室三条地铁环抱   720.0    78878.0  2室2厅   91.28   高层 （共4层）  西北向  1958.0   友谊社区  苏州桥 北三环西路47号         距4号线大兴线人民大学站约867米  张明明  苏州桥\n",
      "1           苏州桥人民大学南侧三线地铁南北通透明厅   480.0    81771.0  2室1厅   58.70   中层 （共6层）  南北向  1990.0  三义庙小区     苏州桥 三义庙小区            距16号线苏州桥站约502米  张明明  苏州桥\n",
      "2            苏州桥·三义庙·理工北门楼层南北两居   398.0    70194.0  2室1厅   56.70   中层 （共6层）  南北向  1985.0  三义庙小区     苏州桥 三义庙小区            距16号线苏州桥站约502米  付晓培  苏州桥\n",
      "3       紫金庄园 254平4居 东西向简装修 拎包入住  1255.0    49409.0  4室2厅  254.00  中层 （共21层）  东西向  1998.0   紫金庄园   苏州桥 万泉河路68号            距16号线苏州桥站约479米   郭欣  苏州桥\n",
      "4            苏州桥·三义庙·理工北门楼层南北两居   398.0    70194.0  2室1厅   56.70   中层 （共6层）  南北向  1985.0  三义庙小区     苏州桥 三义庙小区            距16号线苏州桥站约502米  张明明  苏州桥\n",
      "浏览器已关闭\n"
     ]
    }
   ],
   "source": [
    "# 初始化浏览器\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 10)\n",
    "# 主执行流程\n",
    "try:\n",
    "    # 1. 点击选择区域\n",
    "    url_esf='https://esf.fang.com/'\n",
    "    click_haidian_suzhouqiao(url_esf)\n",
    "    \n",
    "    # 2. 爬取房源数据\n",
    "    print(\"开始爬取房源数据...\")\n",
    "    element_list = 'div.shop_list.shop_list_4 dl.clearfix'\n",
    "    npage_button = 'p.last a'\n",
    "    func = collect_PRICE_listing_from_list\n",
    "    listings_data = scrape_listings(element_list, npage_button, func, max_pages=20)\n",
    "    \n",
    "    # 3. 转换为DataFrame并保存\n",
    "    if listings_data:\n",
    "        df = pd.DataFrame(listings_data)\n",
    "\n",
    "        # 保存到CSV文件\n",
    "        filename = 'Housing_Price_Suzhouqiao.csv'\n",
    "        df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"数据已保存到 {filename}\")\n",
    "        print(f\"共收集到 {len(df)} 条房源信息\")\n",
    "        \n",
    "        # 显示前几行数据\n",
    "        print(\"\\n前5条数据预览:\")\n",
    "        print(df.head().to_string())\n",
    "        \n",
    "    else:\n",
    "        print(\"没有收集到任何数据\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"主程序执行出错: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "finally:\n",
    "    # 关闭浏览器\n",
    "    driver.quit()\n",
    "    print(\"浏览器已关闭\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a95089-b2dc-47b6-bcce-2f212a42fd42",
   "metadata": {},
   "source": [
    "##### 2.  爬取房租数据，存储在'Rent_Suzhouqiao.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "419674d7-329c-4192-b3ca-1506a368ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_RENT_listing_from_list(listing_element):\n",
    "    \"\"\"从列表页元素直接收集数据\"\"\"\n",
    "    listing_data = {}\n",
    "    \n",
    "    try:\n",
    "        # 标题\n",
    "        try:\n",
    "            title_element = listing_element.find_element(By.CSS_SELECTOR, 'dd.info.rel p.title a')\n",
    "            listing_data['标题'] = title_element.text\n",
    "        except NoSuchElementException:\n",
    "            listing_data['标题'] = ''\n",
    "        \n",
    "        # 总价\n",
    "        try:\n",
    "            total_price_element = listing_element.find_element(By.CSS_SELECTOR, 'dd.info.rel div.moreInfo p span.price')\n",
    "            listing_data['总价'] = float(total_price_element.text)\n",
    "        except NoSuchElementException:\n",
    "            listing_data['总价'] = None\n",
    "        \n",
    "        # “租赁方式”“户型”“租赁面积”“朝向”\n",
    "        try:\n",
    "            tel_shop_element = listing_element.find_element(By.CSS_SELECTOR, 'p.font15.mt12.bold')\n",
    "            tel_shop_text = tel_shop_element.text\n",
    "            parts = [part.strip() for part in tel_shop_text.split('|')]\n",
    "            \n",
    "            # 租赁方式\n",
    "            if len(parts) > 0:\n",
    "                listing_data['租赁方式'] = parts[0]\n",
    "            \n",
    "            # 户型\n",
    "            if len(parts) > 1:\n",
    "                listing_data['户型'] = parts[1]\n",
    "            \n",
    "            # 租赁面积\n",
    "            if len(parts) > 2:\n",
    "                area_text = re.sub(r'[^\\d.]', '', parts[2])\n",
    "                listing_data['租赁面积'] = float(area_text)\n",
    "            \n",
    "            # 朝向\n",
    "            if len(parts) > 3:\n",
    "                listing_data['朝向'] = parts[3]\n",
    "            \n",
    "        except NoSuchElementException:\n",
    "            listing_data['户型'] = ''\n",
    "            listing_data['租赁面积'] = None\n",
    "            listing_data['租赁方式'] = ''\n",
    "            listing_data['朝向'] = ''\n",
    "        \n",
    "        # 添加片区信息\n",
    "        listing_data['片区'] = '苏州桥'\n",
    "        \n",
    "        return listing_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"从列表提取房源信息时出错: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bddfe3b-ef92-41d7-89b4-5204ca81187b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已点击海淀区\n",
      "已点击苏州桥片区\n",
      "开始爬取租房房源数据...\n",
      "正在爬取第 1 页...\n",
      "找到 60 个房源\n",
      "第 1 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 2 页...\n",
      "找到 60 个房源\n",
      "第 2 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 3 页...\n",
      "找到 60 个房源\n",
      "第 3 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 4 页...\n",
      "找到 60 个房源\n",
      "第 4 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 5 页...\n",
      "找到 60 个房源\n",
      "第 5 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 6 页...\n",
      "找到 60 个房源\n",
      "第 6 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 7 页...\n",
      "找到 60 个房源\n",
      "第 7 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 8 页...\n",
      "找到 60 个房源\n",
      "第 8 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 9 页...\n",
      "找到 60 个房源\n",
      "第 9 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 10 页...\n",
      "找到 60 个房源\n",
      "第 10 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 11 页...\n",
      "找到 60 个房源\n",
      "第 11 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 12 页...\n",
      "找到 60 个房源\n",
      "第 12 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 13 页...\n",
      "找到 60 个房源\n",
      "第 13 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 14 页...\n",
      "找到 60 个房源\n",
      "第 14 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 15 页...\n",
      "找到 60 个房源\n",
      "第 15 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 16 页...\n",
      "找到 60 个房源\n",
      "第 16 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 17 页...\n",
      "找到 60 个房源\n",
      "第 17 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 18 页...\n",
      "找到 60 个房源\n",
      "第 18 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 19 页...\n",
      "找到 60 个房源\n",
      "第 19 页收集完成，共 60 条房源\n",
      "成功点击下一页\n",
      "正在爬取第 20 页...\n",
      "找到 60 个房源\n",
      "第 20 页收集完成，共 60 条房源\n",
      "数据已保存到 Rent_Suzhouqiao.csv\n",
      "共收集到 1200 条租房房源信息\n",
      "\n",
      "前5条数据预览:\n",
      "                           标题       总价  租赁方式    户型  租赁面积   朝向   片区\n",
      "0  可短签可月付北京大学新东方海淀黄庄经典通透三居随时看  12500.0    整租  3室1厅  85.0  朝西南  苏州桥\n",
      "1      相寓 中关村·人大北路1号院·低楼层·3居室  10200.0    整租  3室1厅  66.0  朝南北  苏州桥\n",
      "2         整租·苏州桥·人民大学静园·3室·1厅  15000.0    整租  3室1厅  74.0  朝南北  苏州桥\n",
      "3         整租·苏州桥·人民大学静园·2室·1厅   9500.0    整租  2室1厅  58.0  朝南北  苏州桥\n",
      "4          苏州桥·三义庙·低楼层·2居室·主卧   4260.0  合租单间  2户合租  18.0   朝南  苏州桥\n",
      "浏览器已关闭\n"
     ]
    }
   ],
   "source": [
    "# 初始化浏览器\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 10)\n",
    "# 主执行流程\n",
    "try:\n",
    "    # 1. 点击选择区域\n",
    "    url_rent = 'https://zu.fang.com/'\n",
    "    click_haidian_suzhouqiao(url_rent)\n",
    "    \n",
    "    # 2. 爬取房源数据\n",
    "    print(\"开始爬取租房房源数据...\")\n",
    "    element_list = 'div.houseList dl.list.hiddenMap.rel'\n",
    "    npage_button = 'a[href*=\"/house-a015277-b02655/i32/\"]'\n",
    "    func = collect_RENT_listing_from_list\n",
    "    listings_data = scrape_listings(element_list, npage_button, func, max_pages=20)\n",
    "    \n",
    "    # 3. 转换为DataFrame并保存\n",
    "    if listings_data:\n",
    "        df = pd.DataFrame(listings_data)\n",
    "\n",
    "        # 保存到CSV文件\n",
    "        filename = 'Rent_Suzhouqiao.csv'\n",
    "        df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"数据已保存到 {filename}\")\n",
    "        print(f\"共收集到 {len(df)} 条租房房源信息\")\n",
    "        \n",
    "        # 显示前几行数据\n",
    "        print(\"\\n前5条数据预览:\")\n",
    "        print(df.head().to_string())\n",
    "        \n",
    "    else:\n",
    "        print(\"没有收集到任何数据\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"主程序执行出错: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "finally:\n",
    "    # 关闭浏览器\n",
    "    driver.quit()\n",
    "    print(\"浏览器已关闭\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
