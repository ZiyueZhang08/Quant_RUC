{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fdc1452-bed0-4625-afb7-01e32ecd7387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 02:09:02.388183: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集形状: (98899, 56), 测试集形状: (9773, 56)\n",
      "使用特征: ['城市', 'lon', 'lat', '年份', '区县', '板块', 'coord_x', 'coord_y', '室数', '厅数', '厨房数', '卫数', '精装修', '是否为底层', '是否为低层', '是否为中层', '是否为高层', '是否为顶层', '总楼层', '建筑面积值', '向南', '向北', '向西', '向东', '交易距今', '季付', '双月付', '月付', '半年付价', '年付', '整租', '合租', '是否有电梯', '租用车位', '免费使用', '是否有燃气', '设施情况', '房屋年份', '总户数', '总楼数', '绿化率', '塔楼', '板楼', '平房', '民水供水', '商水供水', '民电供电', '商电供电', '无供暖', '集中供暖', '自采暖', '很不好', '比较不好', '适中', '比较好', '很好']\n",
      "填充值示例: 城市        4.322157\n",
      "lon     115.752394\n",
      "lat      31.420651\n",
      "年份     2021.643010\n",
      "区县       70.243054\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 02:09:05.474610: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2025-10-29 02:09:05.540224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:b6:00.0 name: Tesla P100-SXM2-16GB computeCapability: 6.0\n",
      "coreClock: 1.4805GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2025-10-29 02:09:05.540289: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2025-10-29 02:09:05.544318: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2025-10-29 02:09:05.544419: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2025-10-29 02:09:05.545780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2025-10-29 02:09:05.546217: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2025-10-29 02:09:05.547228: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2025-10-29 02:09:05.548164: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2025-10-29 02:09:05.548425: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2025-10-29 02:09:05.551192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2025-10-29 02:09:05.551838: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-29 02:09:05.554375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:b6:00.0 name: Tesla P100-SXM2-16GB computeCapability: 6.0\n",
      "coreClock: 1.4805GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2025-10-29 02:09:05.557039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2025-10-29 02:09:05.557100: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2025-10-29 02:09:06.281260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2025-10-29 02:09:06.281316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2025-10-29 02:09:06.281327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2025-10-29 02:09:06.285625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory) -> physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:b6:00.0, compute capability: 6.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练模型...\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 02:09:06.713849: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2025-10-29 02:09:06.727672: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2502935000 Hz\n",
      "2025-10-29 02:09:07.490819: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27/155 [====>.........................] - ETA: 0s - loss: 717524172800.0000 - mae: 582598.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 02:09:07.817719: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 2s 9ms/step - loss: 717234044928.0000 - mae: 581266.3125 - val_loss: 757115191296.0000 - val_mae: 586827.5625\n",
      "Epoch 2/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 695093493760.0000 - mae: 572174.2500 - val_loss: 717315768320.0000 - val_mae: 571873.0625\n",
      "Epoch 3/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 581343576064.0000 - mae: 521502.3125 - val_loss: 549560057856.0000 - val_mae: 499348.3125\n",
      "Epoch 4/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 350147739648.0000 - mae: 391012.7188 - val_loss: 262881280000.0000 - val_mae: 307522.2188\n",
      "Epoch 5/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 167268204544.0000 - mae: 245722.3125 - val_loss: 139687788544.0000 - val_mae: 196052.5625\n",
      "Epoch 6/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 122086260736.0000 - mae: 204252.8906 - val_loss: 122220183552.0000 - val_mae: 182616.0000\n",
      "Epoch 7/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 112075718656.0000 - mae: 194733.3438 - val_loss: 108887924736.0000 - val_mae: 174893.6406\n",
      "Epoch 8/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 106979672064.0000 - mae: 190114.3125 - val_loss: 103857315840.0000 - val_mae: 170436.5781\n",
      "Epoch 9/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 102913523712.0000 - mae: 187178.4062 - val_loss: 98487541760.0000 - val_mae: 164357.4844\n",
      "Epoch 10/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 99735642112.0000 - mae: 184987.0156 - val_loss: 93889495040.0000 - val_mae: 159710.9844\n",
      "Epoch 11/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 97014734848.0000 - mae: 180790.0312 - val_loss: 89032826880.0000 - val_mae: 154863.3125\n",
      "Epoch 12/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 97648820224.0000 - mae: 181113.7031 - val_loss: 90682843136.0000 - val_mae: 163578.0469\n",
      "Epoch 13/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 93292429312.0000 - mae: 176552.6250 - val_loss: 84582719488.0000 - val_mae: 151391.5938\n",
      "Epoch 14/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 92763152384.0000 - mae: 176093.5156 - val_loss: 83645489152.0000 - val_mae: 153082.0781\n",
      "Epoch 15/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 88882372608.0000 - mae: 171933.0938 - val_loss: 80076693504.0000 - val_mae: 147676.6562\n",
      "Epoch 16/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 85430435840.0000 - mae: 169959.9219 - val_loss: 81980940288.0000 - val_mae: 144814.7031\n",
      "Epoch 17/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 84922933248.0000 - mae: 167327.7344 - val_loss: 75979276288.0000 - val_mae: 143609.5000\n",
      "Epoch 18/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 83123822592.0000 - mae: 164393.9844 - val_loss: 73255051264.0000 - val_mae: 140844.2812\n",
      "Epoch 19/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 80942383104.0000 - mae: 161369.1094 - val_loss: 71406682112.0000 - val_mae: 138582.2656\n",
      "Epoch 20/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 78935867392.0000 - mae: 158941.1875 - val_loss: 69225922560.0000 - val_mae: 137712.0781\n",
      "Epoch 21/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 76932046848.0000 - mae: 158548.8594 - val_loss: 68716089344.0000 - val_mae: 140440.8906\n",
      "Epoch 22/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 75066793984.0000 - mae: 156714.0625 - val_loss: 70545702912.0000 - val_mae: 134848.8750\n",
      "Epoch 23/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 74015752192.0000 - mae: 155532.0156 - val_loss: 68535926784.0000 - val_mae: 134507.9688\n",
      "Epoch 24/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 74612654080.0000 - mae: 155366.8281 - val_loss: 66738548736.0000 - val_mae: 132596.0625\n",
      "Epoch 25/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 72360124416.0000 - mae: 153645.5781 - val_loss: 66755305472.0000 - val_mae: 131269.2656\n",
      "Epoch 26/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 72548818944.0000 - mae: 153131.1562 - val_loss: 65360003072.0000 - val_mae: 130984.7656\n",
      "Epoch 27/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 72349204480.0000 - mae: 152193.3750 - val_loss: 65299795968.0000 - val_mae: 133798.8594\n",
      "Epoch 28/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 69259476992.0000 - mae: 150660.2188 - val_loss: 63279222784.0000 - val_mae: 128768.4375\n",
      "Epoch 29/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 68736499712.0000 - mae: 149771.5938 - val_loss: 62539538432.0000 - val_mae: 127626.6016\n",
      "Epoch 30/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 68381011968.0000 - mae: 149190.7969 - val_loss: 60858646528.0000 - val_mae: 129315.3750\n",
      "Epoch 31/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 69742239744.0000 - mae: 149350.7656 - val_loss: 65957330944.0000 - val_mae: 130363.8828\n",
      "Epoch 32/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 66864439296.0000 - mae: 148270.0156 - val_loss: 62786244608.0000 - val_mae: 129609.2188\n",
      "Epoch 33/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 67143172096.0000 - mae: 147370.9688 - val_loss: 66299002880.0000 - val_mae: 131016.5391\n",
      "Epoch 34/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 66876137472.0000 - mae: 147647.5312 - val_loss: 60616642560.0000 - val_mae: 125190.9922\n",
      "Epoch 35/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 63394533376.0000 - mae: 144445.7656 - val_loss: 61185593344.0000 - val_mae: 125845.4844\n",
      "Epoch 36/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 65720066048.0000 - mae: 146183.7031 - val_loss: 61203324928.0000 - val_mae: 125851.9688\n",
      "Epoch 37/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 62769131520.0000 - mae: 144467.2656 - val_loss: 60567310336.0000 - val_mae: 124266.8906\n",
      "Epoch 38/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 64277999616.0000 - mae: 144647.3594 - val_loss: 59026968576.0000 - val_mae: 122859.5547\n",
      "Epoch 39/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 63226814464.0000 - mae: 143231.5781 - val_loss: 59729285120.0000 - val_mae: 123682.8438\n",
      "Epoch 40/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 62725656576.0000 - mae: 143748.9062 - val_loss: 62283673600.0000 - val_mae: 125445.7891\n",
      "Epoch 41/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 62096453632.0000 - mae: 142686.0781 - val_loss: 58897195008.0000 - val_mae: 122183.0000\n",
      "Epoch 42/200\n",
      "155/155 [==============================] - 1s 8ms/step - loss: 63064522752.0000 - mae: 142943.3594 - val_loss: 61165453312.0000 - val_mae: 124280.7266\n",
      "Epoch 43/200\n",
      "155/155 [==============================] - 1s 8ms/step - loss: 62206590976.0000 - mae: 142420.6562 - val_loss: 63317606400.0000 - val_mae: 123574.9297\n",
      "Epoch 44/200\n",
      "155/155 [==============================] - 1s 8ms/step - loss: 59717173248.0000 - mae: 140835.1562 - val_loss: 59425746944.0000 - val_mae: 122960.5547\n",
      "Epoch 45/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 60431327232.0000 - mae: 140874.4062 - val_loss: 58549972992.0000 - val_mae: 124019.0156\n",
      "Epoch 46/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 60893052928.0000 - mae: 141026.4531 - val_loss: 57605931008.0000 - val_mae: 120543.1250\n",
      "Epoch 47/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 59796979712.0000 - mae: 141179.2812 - val_loss: 58220236800.0000 - val_mae: 120133.7188\n",
      "Epoch 48/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 59756236800.0000 - mae: 140848.4062 - val_loss: 57216475136.0000 - val_mae: 120115.1641\n",
      "Epoch 49/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 59611230208.0000 - mae: 140630.1094 - val_loss: 57321353216.0000 - val_mae: 119968.6562\n",
      "Epoch 50/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 59080355840.0000 - mae: 140189.7812 - val_loss: 56910557184.0000 - val_mae: 118516.4531\n",
      "Epoch 51/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 58316976128.0000 - mae: 138978.5156 - val_loss: 57307578368.0000 - val_mae: 120692.1172\n",
      "Epoch 52/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 58449084416.0000 - mae: 138692.3125 - val_loss: 56901722112.0000 - val_mae: 118809.3438\n",
      "Epoch 53/200\n",
      "155/155 [==============================] - 1s 8ms/step - loss: 57932922880.0000 - mae: 139070.4531 - val_loss: 59823808512.0000 - val_mae: 120662.6250\n",
      "Epoch 54/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 59503976448.0000 - mae: 138645.8906 - val_loss: 57116434432.0000 - val_mae: 119377.4609\n",
      "Epoch 55/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 57671475200.0000 - mae: 138338.4219 - val_loss: 58125586432.0000 - val_mae: 119749.6797\n",
      "Epoch 56/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 57573203968.0000 - mae: 137984.1875 - val_loss: 58676318208.0000 - val_mae: 118268.2344\n",
      "Epoch 57/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 57308803072.0000 - mae: 137428.3906 - val_loss: 58308501504.0000 - val_mae: 119191.9531\n",
      "Epoch 58/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 57371942912.0000 - mae: 136986.2344 - val_loss: 57849475072.0000 - val_mae: 118209.0469\n",
      "Epoch 59/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 56711827456.0000 - mae: 137451.5156 - val_loss: 56397737984.0000 - val_mae: 119030.6719\n",
      "Epoch 60/200\n",
      "155/155 [==============================] - 3s 18ms/step - loss: 56761524224.0000 - mae: 136953.7656 - val_loss: 59826159616.0000 - val_mae: 117124.8047\n",
      "Epoch 61/200\n",
      "155/155 [==============================] - 1s 8ms/step - loss: 56952844288.0000 - mae: 136830.7969 - val_loss: 59786526720.0000 - val_mae: 118909.6719\n",
      "Epoch 62/200\n",
      "155/155 [==============================] - 1s 9ms/step - loss: 55903354880.0000 - mae: 136364.8594 - val_loss: 56969318400.0000 - val_mae: 117777.7188\n",
      "Epoch 63/200\n",
      "155/155 [==============================] - 1s 8ms/step - loss: 56365559808.0000 - mae: 136725.4062 - val_loss: 58440740864.0000 - val_mae: 118313.9297\n",
      "Epoch 64/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 57414516736.0000 - mae: 136413.6250 - val_loss: 56611659776.0000 - val_mae: 118419.9922\n",
      "Epoch 65/200\n",
      "155/155 [==============================] - 1s 8ms/step - loss: 57877336064.0000 - mae: 137313.7812 - val_loss: 56383787008.0000 - val_mae: 117507.6875\n",
      "Epoch 66/200\n",
      "155/155 [==============================] - 1s 9ms/step - loss: 58086297600.0000 - mae: 135907.5938 - val_loss: 59316133888.0000 - val_mae: 117824.5469\n",
      "Epoch 67/200\n",
      "155/155 [==============================] - 1s 8ms/step - loss: 55342833664.0000 - mae: 135343.2188 - val_loss: 58603122688.0000 - val_mae: 118091.5938\n",
      "Epoch 68/200\n",
      "155/155 [==============================] - 1s 8ms/step - loss: 55956533248.0000 - mae: 135964.8750 - val_loss: 55875710976.0000 - val_mae: 118181.9844\n",
      "Epoch 69/200\n",
      "155/155 [==============================] - 1s 8ms/step - loss: 56238878720.0000 - mae: 135050.8281 - val_loss: 55894540288.0000 - val_mae: 117465.6484\n",
      "Epoch 70/200\n",
      "155/155 [==============================] - 1s 8ms/step - loss: 55525367808.0000 - mae: 135279.3906 - val_loss: 55747149824.0000 - val_mae: 117123.1094\n",
      "Epoch 71/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 53885902848.0000 - mae: 134667.9375 - val_loss: 56783024128.0000 - val_mae: 116053.9922\n",
      "Epoch 72/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 55090434048.0000 - mae: 135113.9062 - val_loss: 55849213952.0000 - val_mae: 115522.7344\n",
      "Epoch 73/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 53173817344.0000 - mae: 134302.6719 - val_loss: 56376299520.0000 - val_mae: 117059.1094\n",
      "Epoch 74/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 54596071424.0000 - mae: 134654.8750 - val_loss: 55518515200.0000 - val_mae: 115291.6562\n",
      "Epoch 75/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 53759270912.0000 - mae: 133652.7500 - val_loss: 56351457280.0000 - val_mae: 116390.7109\n",
      "Epoch 76/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 54953095168.0000 - mae: 134007.1250 - val_loss: 56844050432.0000 - val_mae: 115589.2969\n",
      "Epoch 77/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 54705594368.0000 - mae: 134175.0156 - val_loss: 54660632576.0000 - val_mae: 115508.1328\n",
      "Epoch 78/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 52879618048.0000 - mae: 133218.2500 - val_loss: 55011631104.0000 - val_mae: 115646.9141\n",
      "Epoch 79/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 55211802624.0000 - mae: 134337.8125 - val_loss: 54354612224.0000 - val_mae: 115488.2891\n",
      "Epoch 80/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 53944913920.0000 - mae: 133871.3906 - val_loss: 55188873216.0000 - val_mae: 116402.6406\n",
      "Epoch 81/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 52554784768.0000 - mae: 132884.7656 - val_loss: 53831725056.0000 - val_mae: 116147.5078\n",
      "Epoch 82/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 54141640704.0000 - mae: 133599.8438 - val_loss: 54456754176.0000 - val_mae: 114478.8750\n",
      "Epoch 83/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 52769316864.0000 - mae: 132703.8125 - val_loss: 54053183488.0000 - val_mae: 116975.5781\n",
      "Epoch 84/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 53006508032.0000 - mae: 132462.2969 - val_loss: 56895086592.0000 - val_mae: 116290.3438\n",
      "Epoch 85/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 53961101312.0000 - mae: 133398.5938 - val_loss: 53425721344.0000 - val_mae: 114289.3516\n",
      "Epoch 86/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 52834852864.0000 - mae: 132565.1406 - val_loss: 56164098048.0000 - val_mae: 116716.6797\n",
      "Epoch 87/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 52291600384.0000 - mae: 132530.4688 - val_loss: 57343873024.0000 - val_mae: 116921.5781\n",
      "Epoch 88/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 52738334720.0000 - mae: 133065.4062 - val_loss: 56713949184.0000 - val_mae: 115503.0703\n",
      "Epoch 89/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 51472146432.0000 - mae: 131416.6406 - val_loss: 57711423488.0000 - val_mae: 115315.0547\n",
      "Epoch 90/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 52758372352.0000 - mae: 132855.4688 - val_loss: 54794850304.0000 - val_mae: 114815.8672\n",
      "Epoch 91/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 52320894976.0000 - mae: 132748.0625 - val_loss: 54095761408.0000 - val_mae: 114014.2344\n",
      "Epoch 92/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 52734816256.0000 - mae: 132691.1719 - val_loss: 54540640256.0000 - val_mae: 113562.6094\n",
      "Epoch 93/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 50874036224.0000 - mae: 131698.7812 - val_loss: 55456591872.0000 - val_mae: 114110.1641\n",
      "Epoch 94/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 51683123200.0000 - mae: 132044.2500 - val_loss: 55102259200.0000 - val_mae: 115027.0234\n",
      "Epoch 95/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 51065765888.0000 - mae: 131639.2500 - val_loss: 55193198592.0000 - val_mae: 114898.8828\n",
      "Epoch 96/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 51217760256.0000 - mae: 131347.4688 - val_loss: 55249338368.0000 - val_mae: 113050.8438\n",
      "Epoch 97/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 50982141952.0000 - mae: 130411.4531 - val_loss: 55899340800.0000 - val_mae: 115076.3984\n",
      "Epoch 98/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 52448722944.0000 - mae: 131741.2500 - val_loss: 55371132928.0000 - val_mae: 113402.4766\n",
      "Epoch 99/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 51580088320.0000 - mae: 131300.7188 - val_loss: 53290524672.0000 - val_mae: 113786.6016\n",
      "Epoch 100/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 52123570176.0000 - mae: 131557.8125 - val_loss: 54459813888.0000 - val_mae: 113069.7266\n",
      "Epoch 101/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 50268250112.0000 - mae: 130788.2891 - val_loss: 55081189376.0000 - val_mae: 114340.1250\n",
      "Epoch 102/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 51768152064.0000 - mae: 131273.6562 - val_loss: 52518105088.0000 - val_mae: 111937.2656\n",
      "Epoch 103/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 50313420800.0000 - mae: 130064.5547 - val_loss: 53733203968.0000 - val_mae: 112663.8750\n",
      "Epoch 104/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 49122365440.0000 - mae: 129634.3047 - val_loss: 56388468736.0000 - val_mae: 113448.3906\n",
      "Epoch 105/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 49156034560.0000 - mae: 129539.7109 - val_loss: 57492516864.0000 - val_mae: 115170.4375\n",
      "Epoch 106/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 49297428480.0000 - mae: 129754.0000 - val_loss: 57003225088.0000 - val_mae: 114311.1797\n",
      "Epoch 107/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 49571123200.0000 - mae: 129623.5234 - val_loss: 54637150208.0000 - val_mae: 113584.0156\n",
      "Epoch 108/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 49498316800.0000 - mae: 128885.9844 - val_loss: 52215013376.0000 - val_mae: 111221.6094\n",
      "Epoch 109/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 49131098112.0000 - mae: 129071.1016 - val_loss: 56278016000.0000 - val_mae: 113179.3203\n",
      "Epoch 110/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 50536935424.0000 - mae: 130105.8047 - val_loss: 54461693952.0000 - val_mae: 112867.0078\n",
      "Epoch 111/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 50321965056.0000 - mae: 130100.8672 - val_loss: 55022931968.0000 - val_mae: 113107.2734\n",
      "Epoch 112/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 49056120832.0000 - mae: 129654.7031 - val_loss: 52400173056.0000 - val_mae: 111616.6484\n",
      "Epoch 113/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 50107125760.0000 - mae: 129333.8984 - val_loss: 51230498816.0000 - val_mae: 111708.9297\n",
      "Epoch 114/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 49839144960.0000 - mae: 129398.7266 - val_loss: 54507253760.0000 - val_mae: 111992.4453\n",
      "Epoch 115/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 50221408256.0000 - mae: 130597.3438 - val_loss: 57295249408.0000 - val_mae: 114125.1484\n",
      "Epoch 116/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 50131984384.0000 - mae: 129233.6172 - val_loss: 51511914496.0000 - val_mae: 111114.1875\n",
      "Epoch 117/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 48992837632.0000 - mae: 128407.8828 - val_loss: 53918097408.0000 - val_mae: 111771.7969\n",
      "Epoch 118/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 49538494464.0000 - mae: 128526.3203 - val_loss: 56257208320.0000 - val_mae: 112547.9375\n",
      "Epoch 119/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 49808494592.0000 - mae: 128458.5156 - val_loss: 52783144960.0000 - val_mae: 111831.5781\n",
      "Epoch 120/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 49469140992.0000 - mae: 129177.3203 - val_loss: 52043415552.0000 - val_mae: 111816.4141\n",
      "Epoch 121/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 47913181184.0000 - mae: 128501.7969 - val_loss: 54330884096.0000 - val_mae: 112134.8203\n",
      "Epoch 122/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 47985139712.0000 - mae: 127910.3438 - val_loss: 53440524288.0000 - val_mae: 110760.6094\n",
      "Epoch 123/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 48116932608.0000 - mae: 127982.1797 - val_loss: 53879283712.0000 - val_mae: 112780.9688\n",
      "Epoch 124/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 49919807488.0000 - mae: 129472.1641 - val_loss: 53913821184.0000 - val_mae: 112118.3672\n",
      "Epoch 125/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 49370767360.0000 - mae: 128119.5781 - val_loss: 53062332416.0000 - val_mae: 111216.2734\n",
      "Epoch 126/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 46896918528.0000 - mae: 127017.5547 - val_loss: 53801943040.0000 - val_mae: 111279.3438\n",
      "Epoch 127/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 46168322048.0000 - mae: 126354.6328 - val_loss: 54972760064.0000 - val_mae: 111006.8438\n",
      "Epoch 128/200\n",
      "155/155 [==============================] - 1s 7ms/step - loss: 49032966144.0000 - mae: 128153.4688 - val_loss: 52935946240.0000 - val_mae: 111523.3359\n",
      "验证集损失: 51230494720.0000, MAE: 111708.8594\n",
      "进行预测...\n",
      "预测结果已保存到: NeuralNetwork_predict_rent.csv\n",
      "文件前5行预览:\n",
      "        ID  predict_price\n",
      "0  2000000   1.532208e+05\n",
      "1  2000001   5.073150e+05\n",
      "2  2000002   3.399020e+05\n",
      "3  2000003   1.568997e+06\n",
      "4  2000004   1.230396e+06\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import os\n",
    "\n",
    "# 1. 更健壮的文件读取与列名检查\n",
    "def load_and_validate_data(train_path, test_path):\n",
    "    # 检查文件是否存在\n",
    "    if not os.path.exists(train_path):\n",
    "        raise FileNotFoundError(f\"训练集文件不存在: {train_path}\")\n",
    "    if not os.path.exists(test_path):\n",
    "        raise FileNotFoundError(f\"测试集文件不存在: {test_path}\")\n",
    "    \n",
    "    # 读取数据\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    \n",
    "    # 检查训练集是否有Price列\n",
    "    if 'Price' not in train_df.columns:\n",
    "        # 尝试查找可能的目标列\n",
    "        price_candidates = [col for col in train_df.columns if 'price' in col.lower()]\n",
    "        if price_candidates:\n",
    "            print(f\"警告: 未找到'Price'列, 使用替代列: {price_candidates[0]}\")\n",
    "            train_df = train_df.rename(columns={price_candidates[0]: 'Price'})\n",
    "        else:\n",
    "            # 尝试使用最后一列作为目标列\n",
    "            last_col = train_df.columns[-1]\n",
    "            print(f\"警告: 未找到'Price'列, 使用最后一列作为目标列: {last_col}\")\n",
    "            train_df = train_df.rename(columns={last_col: 'Price'})\n",
    "    \n",
    "    # 检查测试集是否有ID列\n",
    "    if 'ID' not in test_df.columns:\n",
    "        # 尝试查找可能的ID列\n",
    "        id_candidates = [col for col in test_df.columns if 'id' in col.lower()]\n",
    "        if id_candidates:\n",
    "            print(f\"警告: 未找到'ID'列, 使用替代列: {id_candidates[0]}\")\n",
    "            test_df = test_df.rename(columns={id_candidates[0]: 'ID'})\n",
    "        else:\n",
    "            # 尝试使用第一列作为ID列\n",
    "            first_col = test_df.columns[0]\n",
    "            print(f\"警告: 未找到'ID'列, 使用第一列作为ID列: {first_col}\")\n",
    "            test_df = test_df.rename(columns={first_col: 'ID'})\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "# 2. 改进的数据预处理\n",
    "def preprocess_data(train_df, test_df):\n",
    "    # 复制数据避免修改原始数据\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    \n",
    "    # 检查特征数量是否一致\n",
    "    train_features = [col for col in train_df.columns if col != 'Price']\n",
    "    test_features = [col for col in test_df.columns if col != 'ID']\n",
    "    \n",
    "    if len(train_features) != len(test_features):\n",
    "        print(f\"警告: 训练集特征数({len(train_features)})与测试集特征数({len(test_features)})不一致\")\n",
    "        # 使用交集作为共同特征\n",
    "        common_features = list(set(train_features) & set(test_features))\n",
    "        print(f\"使用共同特征: {len(common_features)}个\")\n",
    "    else:\n",
    "        common_features = train_features\n",
    "    \n",
    "    # 计算训练集的填充值\n",
    "    fill_values = train_df[common_features].mean()\n",
    "    \n",
    "    # 填充训练集缺失值\n",
    "    train_df[common_features] = train_df[common_features].fillna(fill_values)\n",
    "    \n",
    "    # 填充测试集缺失值\n",
    "    test_df[common_features] = test_df[common_features].fillna(fill_values)\n",
    "    \n",
    "    # 分离数据\n",
    "    X_train = train_df[common_features].values\n",
    "    y_train = train_df['Price'].values\n",
    "    \n",
    "    X_test = test_df[common_features].values\n",
    "    test_ids = test_df['ID'].values\n",
    "    \n",
    "    return X_train, y_train, X_test, test_ids, common_features, fill_values\n",
    "\n",
    "# 主程序\n",
    "try:\n",
    "    # 加载并验证数据\n",
    "    train_df, test_df = load_and_validate_data(\n",
    "        '正常化数据（带反馈）_train_rent.csv', \n",
    "        '正常化数据（带反馈）_test_rent.csv'\n",
    "    )\n",
    "    \n",
    "    # 预处理数据\n",
    "    X_train, y_train, X_test, test_ids, feature_names, fill_values = preprocess_data(train_df, test_df)\n",
    "    \n",
    "    print(f\"训练集形状: {X_train.shape}, 测试集形状: {X_test.shape}\")\n",
    "    print(f\"使用特征: {feature_names}\")\n",
    "    print(f\"填充值示例: {fill_values.head() if isinstance(fill_values, pd.Series) else fill_values[:5]}\")\n",
    "    \n",
    "    # 特征标准化\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # 划分验证集\n",
    "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "        X_train_scaled, y_train, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # 构建神经网络模型\n",
    "    model = Sequential([\n",
    "        Dense(256, activation='relu', input_shape=(X_train.shape[1],), \n",
    "              kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)  # 输出层（回归任务）\n",
    "    ])\n",
    "    \n",
    "    # 编译模型\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    # 设置早停\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "    \n",
    "    # 训练模型\n",
    "    print(\"开始训练模型...\")\n",
    "    history = model.fit(\n",
    "        X_train_split, y_train_split,\n",
    "        validation_data=(X_val_split, y_val_split),\n",
    "        epochs=200,\n",
    "        batch_size=512,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 评估模型\n",
    "    val_loss, val_mae = model.evaluate(X_val_split, y_val_split, verbose=0)\n",
    "    print(f\"验证集损失: {val_loss:.4f}, MAE: {val_mae:.4f}\")\n",
    "    \n",
    "    # 进行预测\n",
    "    print(\"进行预测...\")\n",
    "    predictions = model.predict(X_test_scaled).flatten()\n",
    "    \n",
    "    # 创建结果DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        'ID': test_ids,\n",
    "        'predict_price': predictions\n",
    "    })\n",
    "    \n",
    "    # 保存结果\n",
    "    model_name = \"NeuralNetwork\"\n",
    "    output_file = f'{model_name}_predict_rent.csv'\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"预测结果已保存到: {output_file}\")\n",
    "    print(f\"文件前5行预览:\\n{result_df.head()}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"发生错误: {str(e)}\")\n",
    "    print(\"请检查: \")\n",
    "    print(\"1. 文件路径是否正确\")\n",
    "    print(\"2. 文件内容是否符合要求\")\n",
    "    print(\"3. 列名是否包含'Price'(训练集)和'ID'(测试集)\")\n",
    "    print(\"4. 数据格式是否正确\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b79396d-200b-4066-9e3b-e309f866fdf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
