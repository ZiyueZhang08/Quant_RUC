{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c3d5ec7-c059-439d-8579-51750d16c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deepseek模型的api_key\n",
    "dp_api_key = \"sk-5c17979d4ce24427880fbd1dd107ecd5\"\n",
    "data_batch = \"sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2091561f-4c77-43dd-bf9c-510c6868d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "import pandas\n",
    "import math\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad22efd-591c-4e27-b5af-bba17a197dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全局初始化客户端与菜单信息\n",
    "aclient = AsyncOpenAI(\n",
    "    api_key=dp_api_key,\n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad9b6427-00f3-4361-a16c-9dc0b78e7dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大模型调用函数\n",
    "def get_intro(comment):\n",
    "    client = OpenAI(api_key=dp_api_key, base_url=\"https://api.deepseek.com\")\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"你是一名精明的房产从业者，熟知评判一处房屋好坏的各种条件\"},\n",
    "            {\"role\": \"user\", \"content\": f\"假设将房屋硬件条件良好、配套设施齐全、周边条件便利定义为“好”，将配套设施不全、条件恶劣定义为“不好”，【{comment}】这句评价中的房屋更贴近“很好、比较好、适中、比较不好、很不好”这五种选项中的哪一种？请告诉我五个选项中最合适的一个。我需要依据你的回答进行分类，因此不要修改选项，不要解释理由。\"}\n",
    "        ],\n",
    "        stream=False\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68d38901-a2b7-4821-ba88-ae4b73123f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# com = \"电费按表计量，治安堪忧，拎包入住\"\n",
    "# print(get_intro(com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97981b33-3a69-4564-91f4-93557e647f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1))\n",
    "async def async_get_intro(comment, semaphore):\n",
    "    async with semaphore:  # 控制并发量\n",
    "        response = await aclient.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"你是一名精明的房产从业者，熟知评判一处房屋好坏的各种条件\"},\n",
    "                {\"role\": \"user\", \"content\": f\"假设将房屋硬件条件良好、配套设施齐全、周边条件便利定义为“好”，将配套设施不全、条件恶劣定义为“不好”，【{comment}】这句评价中的房屋更贴近“很好、比较好、适中、比较不好、很不好”这五种选项中的哪一种？请告诉我五个选项中最合适的一个。我需要依据你的回答进行分类，因此不要修改选项，不要解释理由。\"}\n",
    "            ],\n",
    "            stream=False\n",
    "        )\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb07c1b0-4ed5-4d87-9ec5-ea140f0d70ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "async def batch_get_intros(items, max_concurrency=50):\n",
    "    semaphore = asyncio.Semaphore(max_concurrency)\n",
    "    \n",
    "    async def bounded_get_intro(item):\n",
    "        async with semaphore:\n",
    "            # 添加缺失的 semaphore 参数\n",
    "            return await async_get_intro(item, semaphore)\n",
    "    \n",
    "    tasks = [bounded_get_intro(item) for item in items]\n",
    "    \n",
    "    results = await tqdm_asyncio.gather(\n",
    "        *tasks,\n",
    "        desc=f\"Processing: (max_concurrency={max_concurrency})\",\n",
    "        total=len(items),\n",
    "        ascii=True,\n",
    "        mininterval=0.1\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d24ee9a4-9449-4777-b255-5bdf04bd9d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch = \"train\"\n",
    "data_target = \"price\"\n",
    "path = f\"结构化数据_{data_batch}_{data_target}.csv\"  # 存有菜品名的csv文件地址\n",
    "df = pandas.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "462301eb-02b1-4242-a6ce-4d3d923003ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000  # 单次处理量\n",
    "comment_column = \"客户反馈\"  # 存有菜品名的列名\n",
    "id_column = \"Price\"\n",
    "n_dim = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6b95f76-d76b-43f5-a66f-1caa8a6d4106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 23.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 1/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 2/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 23.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 3/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 4/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 5/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 6/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 7/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 8/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 9/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 10/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 11/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 12/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:43<00:00, 23.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 13/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 14/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 15/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 23.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 16/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 17/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 18/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 19/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 20/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 21/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 23.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 22/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 23.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 23/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 24/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 25/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 26/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 27/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 28/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 29/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 30/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 31/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 32/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 33/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:43<00:00, 23.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 34/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:44<00:00, 22.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 35/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 36/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 23.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 37/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 38/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 39/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 40/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 41/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 42/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 43/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 44/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 45/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 46/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 47/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 48/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 49/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:43<00:00, 23.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 50/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:47<00:00, 21.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 51/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:44<00:00, 22.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 52/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 53/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 54/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 55/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 56/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 57/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 58/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 59/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 60/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 61/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 62/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 63/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 64/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 65/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 66/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 67/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 68/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 69/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 70/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 71/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 72/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 23.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 73/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 74/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 75/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 76/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 77/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 78/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 23.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 79/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:39<00:00, 25.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 80/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 81/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:39<00:00, 25.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 82/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:39<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 83/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:39<00:00, 25.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 84/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 85/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:39<00:00, 25.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 86/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 87/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 23.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 88/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 89/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 90/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 23.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 91/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 92/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 23.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 93/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 94/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 95/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 23.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 96/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 97/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:40<00:00, 24.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 98/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 99/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:41<00:00, 24.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 100/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 101/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:42<00:00, 23.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 102/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 1000/1000 [00:43<00:00, 23.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 103/104 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: (max_concurrency=50): 100%|##########| 871/871 [00:37<00:00, 23.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 104/104 batches\n"
     ]
    }
   ],
   "source": [
    "# 分批次获取结果\n",
    "for epoch in range(math.ceil(n_dim / batch_size)):\n",
    "    start_idx = epoch * batch_size\n",
    "    end_idx = min(start_idx + batch_size, n_dim)\n",
    "    \n",
    "    # 获取当前批次菜品名\n",
    "    batch_comments = df.iloc[start_idx:end_idx][comment_column].tolist()\n",
    "    batch_ids = df.iloc[start_idx:end_idx][id_column].tolist()\n",
    "#     for item in batch_items:\n",
    "#         item = str(item)\n",
    "    \n",
    "    # 异步获取菜品标签\n",
    "    feel_results = await batch_get_intros(batch_comments) # 确保返回顺序与 batch_items 一致\n",
    "    \n",
    "    # 构建DataFrame并进行二次检查\n",
    "    batch_intro_df = pandas.DataFrame({\n",
    "        \"ID\": batch_ids,\n",
    "        \"客户反馈\": batch_comments,\n",
    "        \"客户反馈评级\": feel_results\n",
    "    })\n",
    "    \n",
    "    # 保存文件\n",
    "    output_path = f\"batch_result//客户反馈评级//{data_batch}_{data_target}//epoch{epoch}.csv\"\n",
    "    batch_intro_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    # 更新进度\n",
    "    print(f\"Processed: {epoch+1}/{math.ceil(n_dim / batch_size)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e66f58-ba7e-4fc7-9121-e387276b8eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
