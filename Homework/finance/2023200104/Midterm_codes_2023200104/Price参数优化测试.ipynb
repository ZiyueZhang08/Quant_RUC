{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd15013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出文件夹 'LeafEncoding_Ridge_Prediction_new_price' 已创建或已存在。\n",
      "\n",
      "--- 从 'Price_Capped_Aggregated_Data' 加载 Price 数据 ---\n",
      "Price 数据加载成功。\n",
      "  训练集形状: (103871, 196)\n",
      "  测试集形状: (34017, 196)\n",
      "\n",
      "--- 准备训练和测试数据 ---\n",
      "  警告: 训练集发现非数值列，将移除: ['楼层_中楼层', '楼层_低楼层', '楼层_地下室', '楼层_底层', '楼层_顶层', '楼层_高楼层', '环线_三至四环', '环线_中环至外环', '环线_二环内', '环线_二至三环', '环线_五至六环', '环线_六环外', '环线_内环内', '环线_内环至中环', '环线_内环至外环', '环线_四至五环', '环线_外环外', '环线_无环线', '电梯_无', '电梯_有', '电梯_未知', '建筑结构_未知结构', '建筑结构_框架结构', '建筑结构_混合结构', '建筑结构_砖木结构', '建筑结构_砖混结构', '建筑结构_钢混结构', '建筑结构_钢结构', '装修_精装', '装修_简装', '装修_毛坯', '装修_其他', '装修_未知', '装修_精装.1', '装修_简装.1', '装修_毛坯.1', '装修_其他.1', '装修_未知.1', '别墅_双拼', '别墅_叠拼', '别墅_独栋', '别墅_联排', '别墅_非别墅', '产权所属_共有', '产权所属_非共有']\n",
      "  对齐后特征形状: Train=(103871, 150), Test=(34017, 150)\n",
      "  使用中位数填充缺失值...\n",
      "  缺失值填充完成。\n",
      "\n",
      "--- 训练 Gradient Boosting 模型以生成叶节点特征 ---\n",
      "  使用以下参数训练 GBRT: {'n_estimators': 100, 'max_depth': 5, 'min_samples_leaf': 30, 'learning_rate': 0.1, 'subsample': 0.7, 'random_state': 42}\n",
      "  GBRT 模型训练完成。\n",
      "\n",
      "--- 获取叶节点索引 ---\n",
      "  训练集叶节点索引形状: (103871, 100)\n",
      "  测试集叶节点索引形状: (34017, 100)\n",
      "\n",
      "--- 对叶节点索引进行 One-Hot 编码 ---\n",
      "  编码后训练集特征形状 (稀疏): (103871, 2622)\n",
      "  编码后测试集特征形状 (稀疏): (34017, 2622)\n",
      "  生成了 2622 个叶节点二元特征。\n",
      "\n",
      "  本次只使用编码后的叶节点特征作为最终输入。\n",
      "\n",
      "--- 定义评价标准 (MAE) ---\n",
      "MAE 评价标准已创建 (得分越低越好)。\n",
      "\n",
      "--- 定义并训练最终的 RidgeCV 模型 ---\n",
      "  开始训练最终的 RidgeCV Pipeline...\n",
      "  RidgeCV Pipeline 训练完成。\n",
      "  RidgeCV 找到的最佳 alpha: 10000.000000\n",
      "\n",
      "--- 在完整训练集上评估最终 Ridge 模型 ---\n",
      "  训练集 RMSE:  373386.2510\n",
      "  训练集 MAE:    228372.9479\n",
      "  训练集 MedAE: 135461.3022\n",
      "\n",
      "--- 在测试集上进行预测 ---\n",
      "  预测完成。\n",
      "\n",
      "--- 创建并保存提交文件到 'LeafEncoding_Ridge_Prediction_new_price' ---\n",
      "✓ 提交文件已成功保存: LeafEncoding_Ridge_Prediction_new_price/submission_leaf_ridge_mae.csv\n",
      "  总预测条数: 34017\n",
      "\n",
      "提交文件预览 (前5行):\n",
      "        ID  PredictedPrice\n",
      "0  1000000    1.298763e+07\n",
      "1  1000001    3.082388e+06\n",
      "2  1000002    4.285253e+06\n",
      "3  1000003    2.913804e+06\n",
      "4  1000004    9.891043e+06\n",
      "\n",
      "--- 叶节点编码 + RidgeCV 预测流程完成 ---\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 完整脚本：叶节点编码 + RidgeCV 房价预测 (Price Prediction)\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib # 用于将来可能保存对象\n",
    "from sklearn.model_selection import KFold # 只导入 KFold，因为 RidgeCV 内置 CV\n",
    "from sklearn.ensemble import GradientBoostingRegressor # 用于叶节点编码\n",
    "from sklearn.linear_model import RidgeCV # 最终的正则化线性模型\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error, median_absolute_error # 导入所有需要的指标函数\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.sparse import hstack, csr_matrix # 用于组合稀疏和稠密矩阵 (如果需要)\n",
    "\n",
    "# --- 1. 配置 ---\n",
    "# 输入文件夹 (包含 _selected.csv 文件)\n",
    "INPUT_FOLDER = 'Price_Capped_Aggregated_Data'\n",
    "# 输出文件夹 (存放本次预测结果)\n",
    "OUTPUT_FOLDER = 'LeafEncoding_Ridge_Prediction_new_price'\n",
    "# 输入文件名\n",
    "TRAIN_PRICE_FILE = 'train_price_capped_agg.csv'\n",
    "TEST_PRICE_FILE = 'test_price_capped_agg.csv'\n",
    "# 输出文件名\n",
    "OUTPUT_FILE = 'submission_leaf_ridge_mae.csv'\n",
    "\n",
    "TARGET_COLUMN = 'Price'\n",
    "ID_COLUMN = 'ID'\n",
    "\n",
    "RANDOM_STATE = 42 # 保证结果可复现\n",
    "\n",
    "# GBRT 参数 (用于生成叶节点)\n",
    "GBRT_PARAMS = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 30,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.7,\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "# RidgeCV 参数\n",
    "RIDGE_ALPHAS = np.logspace(-3, 5, 9) # alpha 搜索范围\n",
    "RIDGE_CV_FOLDS = 5 # RidgeCV 内部交叉验证折数\n",
    "\n",
    "# --- 2. 创建输出文件夹 ---\n",
    "try:\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "    print(f\"输出文件夹 '{OUTPUT_FOLDER}' 已创建或已存在。\")\n",
    "except OSError as e:\n",
    "    print(f\"创建文件夹 '{OUTPUT_FOLDER}' 时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. 加载经过特征筛选的数据 ---\n",
    "print(f\"\\n--- 从 '{INPUT_FOLDER}' 加载 Price 数据 ---\")\n",
    "try:\n",
    "    train_df = pd.read_csv(os.path.join(INPUT_FOLDER, TRAIN_PRICE_FILE), encoding='utf-8-sig')\n",
    "    test_df = pd.read_csv(os.path.join(INPUT_FOLDER, TEST_PRICE_FILE), encoding='utf-8-sig')\n",
    "    print(\"Price 数据加载成功。\")\n",
    "    print(f\"  训练集形状: {train_df.shape}\")\n",
    "    print(f\"  测试集形状: {test_df.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"加载数据时出错: {e}. 请确保文件路径正确。\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"加载数据时发生其他错误: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 存储测试集的 ID\n",
    "test_ids = test_df[ID_COLUMN].copy()\n",
    "\n",
    "# --- 4. 准备数据 (分离 X/y, 对齐, 填充 NaN) ---\n",
    "print(\"\\n--- 准备训练和测试数据 ---\")\n",
    "try:\n",
    "    y_train = train_df[TARGET_COLUMN]\n",
    "    X_train = train_df.drop(columns=[TARGET_COLUMN])\n",
    "    X_test = test_df.drop(columns=[ID_COLUMN])\n",
    "\n",
    "    # 移除可能残余的非数值列\n",
    "    non_numeric_train = X_train.select_dtypes(exclude=np.number).columns\n",
    "    if not non_numeric_train.empty:\n",
    "        print(f\"  警告: 训练集发现非数值列，将移除: {non_numeric_train.tolist()}\")\n",
    "        X_train = X_train.drop(columns=non_numeric_train)\n",
    "    non_numeric_test = X_test.select_dtypes(exclude=np.number).columns\n",
    "    if not non_numeric_test.empty:\n",
    "         X_test = X_test.drop(columns=non_numeric_test)\n",
    "\n",
    "    # 对齐列\n",
    "    train_cols = X_train.columns\n",
    "    test_cols = X_test.columns\n",
    "    missing_in_test = set(train_cols) - set(test_cols)\n",
    "    for c in missing_in_test: X_test[c] = 0\n",
    "    extra_in_test = set(test_cols) - set(train_cols)\n",
    "    if extra_in_test: X_test = X_test.drop(columns=list(extra_in_test))\n",
    "    X_test = X_test[train_cols] # 确保顺序一致\n",
    "\n",
    "    print(f\"  对齐后特征形状: Train={X_train.shape}, Test={X_test.shape}\")\n",
    "\n",
    "    # **填充缺失值**\n",
    "    print(\"  使用中位数填充缺失值...\")\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    # 使用 NumPy 数组进行后续处理效率更高\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    print(\"  缺失值填充完成。\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"数据准备时发生错误: {e}\")\n",
    "     exit()\n",
    "\n",
    "# --- 5. 训练 GBRT 模型以生成叶节点 ---\n",
    "print(\"\\n--- 训练 Gradient Boosting 模型以生成叶节点特征 ---\")\n",
    "gbrt = GradientBoostingRegressor(**GBRT_PARAMS)\n",
    "try:\n",
    "    print(f\"  使用以下参数训练 GBRT: {GBRT_PARAMS}\")\n",
    "    # GBRT 可以直接接受 NumPy 数组\n",
    "    gbrt.fit(X_train_imputed, y_train)\n",
    "    print(\"  GBRT 模型训练完成。\")\n",
    "except Exception as e:\n",
    "    print(f\"  训练 GBRT 时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 6. 获取叶节点索引 ---\n",
    "print(\"\\n--- 获取叶节点索引 ---\")\n",
    "try:\n",
    "    train_leaf_indices = gbrt.apply(X_train_imputed)\n",
    "    test_leaf_indices = gbrt.apply(X_test_imputed)\n",
    "    print(f\"  训练集叶节点索引形状: {train_leaf_indices.shape}\")\n",
    "    print(f\"  测试集叶节点索引形状: {test_leaf_indices.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"  获取叶节点索引时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 7. 对叶节点索引进行 One-Hot 编码 ---\n",
    "print(\"\\n--- 对叶节点索引进行 One-Hot 编码 ---\")\n",
    "leaf_encoder = OneHotEncoder(handle_unknown='ignore', )\n",
    "try:\n",
    "    X_train_leaves_encoded = leaf_encoder.fit_transform(train_leaf_indices)\n",
    "    X_test_leaves_encoded = leaf_encoder.transform(test_leaf_indices)\n",
    "    print(f\"  编码后训练集特征形状 (稀疏): {X_train_leaves_encoded.shape}\")\n",
    "    print(f\"  编码后测试集特征形状 (稀疏): {X_test_leaves_encoded.shape}\")\n",
    "    n_leaf_features = X_train_leaves_encoded.shape[1]\n",
    "    print(f\"  生成了 {n_leaf_features} 个叶节点二元特征。\")\n",
    "except Exception as e:\n",
    "    print(f\"  One-Hot 编码时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 8. 准备最终特征集 (本次只使用叶节点) ---\n",
    "X_train_final = X_train_leaves_encoded\n",
    "X_test_final = X_test_leaves_encoded\n",
    "print(\"\\n  本次只使用编码后的叶节点特征作为最终输入。\")\n",
    "\n",
    "\n",
    "# --- 9. 定义评价标准 (MAE Scorer) - 解决 NameError 的关键 ---\n",
    "print(\"\\n--- 定义评价标准 (MAE) ---\")\n",
    "# ！！！在这里定义 mae_scorer ！！！\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "print(\"MAE 评价标准已创建 (得分越低越好)。\")\n",
    "\n",
    "# 定义辅助函数用于后续评估\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    medae = median_absolute_error(y_true, y_pred)\n",
    "    return rmse, mae, medae\n",
    "\n",
    "# --- 10. 定义并训练最终的 RidgeCV 模型 ---\n",
    "print(\"\\n--- 定义并训练最终的 RidgeCV 模型 ---\")\n",
    "\n",
    "ridge_cv_model = RidgeCV(\n",
    "    alphas=RIDGE_ALPHAS,\n",
    "    cv=RIDGE_CV_FOLDS,\n",
    "    scoring=mae_scorer, # 使用上面定义的 mae_scorer\n",
    "    store_cv_values=False\n",
    ")\n",
    "\n",
    "# 构建最终的 Pipeline\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)), # 稀疏矩阵不中心化\n",
    "    ('model', ridge_cv_model)\n",
    "])\n",
    "\n",
    "try:\n",
    "    print(\"  开始训练最终的 RidgeCV Pipeline...\")\n",
    "    final_pipeline.fit(X_train_final, y_train)\n",
    "    print(\"  RidgeCV Pipeline 训练完成。\")\n",
    "    best_alpha = final_pipeline.named_steps['model'].alpha_\n",
    "    print(f\"  RidgeCV 找到的最佳 alpha: {best_alpha:.6f}\")\n",
    "except Exception as e:\n",
    "    print(f\"  训练 RidgeCV 时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 11. 在训练集上评估最终模型 ---\n",
    "print(\"\\n--- 在完整训练集上评估最终 Ridge 模型 ---\")\n",
    "try:\n",
    "    y_train_pred = final_pipeline.predict(X_train_final)\n",
    "    rmse_train, mae_train, medae_train = calculate_metrics(y_train, y_train_pred)\n",
    "    print(f\"  训练集 RMSE:  {rmse_train:.4f}\")\n",
    "    print(f\"  训练集 MAE:    {mae_train:.4f}\")\n",
    "    print(f\"  训练集 MedAE: {medae_train:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"  评估训练集时出错: {e}\")\n",
    "\n",
    "# --- 12. 在测试集上进行预测 ---\n",
    "print(\"\\n--- 在测试集上进行预测 ---\")\n",
    "try:\n",
    "    predictions = final_pipeline.predict(X_test_final)\n",
    "    print(\"  预测完成。\")\n",
    "except Exception as e:\n",
    "    print(f\"  在测试集上预测时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 13. 创建并保存提交文件 ---\n",
    "print(f\"\\n--- 创建并保存提交文件到 '{OUTPUT_FOLDER}' ---\")\n",
    "submission_df = pd.DataFrame({\n",
    "    ID_COLUMN: test_ids,\n",
    "    'PredictedPrice': predictions\n",
    "})\n",
    "submission_df[ID_COLUMN] = submission_df[ID_COLUMN].astype(int)\n",
    "submission_df = submission_df.sort_values(by=ID_COLUMN)\n",
    "try:\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, OUTPUT_FILE)\n",
    "    submission_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"✓ 提交文件已成功保存: {output_path}\")\n",
    "    print(f\"  总预测条数: {len(submission_df)}\")\n",
    "    print(\"\\n提交文件预览 (前5行):\")\n",
    "    print(submission_df.head())\n",
    "except Exception as e:\n",
    "    print(f\"✗ 保存提交文件时出错: {e}\")\n",
    "\n",
    "print(\"\\n--- 叶节点编码 + RidgeCV 预测流程完成 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c278f775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出文件夹 'LeafEncoding_Ridge_Prediction_new_price' 已创建或已存在。\n",
      "\n",
      "--- 从 'Price_Capped_Aggregated_Data' 加载 Price 数据 ---\n",
      "Price 数据加载成功。\n",
      "\n",
      "--- 转换布尔列 (True/False) 为整数 (1/0) ---\n",
      "  转换 train_df 中的 45 个布尔列...\n",
      "  转换 test_df 中的 45 个布尔列...\n",
      "--- 布尔列转换完成 ---\n",
      "\n",
      "--- 准备训练和测试数据 ---\n",
      "  已对目标变量 'Price' 应用 log1p 转换。\n",
      "  对齐后特征形状: Train=(103871, 195), Test=(34017, 195)\n",
      "  使用中位数填充缺失值...\n",
      "  缺失值填充完成。\n",
      "\n",
      "--- 训练 Gradient Boosting 模型以生成叶节点特征 ---\n",
      "  使用以下参数训练 GBRT: {'n_estimators': 200, 'max_depth': 5, 'min_samples_leaf': 30, 'learning_rate': 0.05, 'subsample': 0.7, 'random_state': 42}\n",
      "  GBRT 模型训练完成。\n",
      "  识别出 Top 20 原始特征: ['板块_平均价格_capped', '板块_中位数价格_capped', '面积_数值', '板块_平均面积_capped', '区域_中位数价格_capped', '区域_平均价格_capped', '户型_室', '装修_未知', '区县_中位数价格_capped', '户型_卫', '区县_平均价格_capped', '户型_房间总数', '梯户比例_数值', '装修_未知.1', '楼层_总楼层', '区域_平均面积_capped', '物业费_数值', '户型_厨', '停车费用_数值', 'coord_x']\n",
      "\n",
      "--- 获取叶节点索引 ---\n",
      "\n",
      "--- 对叶节点索引进行 One-Hot 编码 ---\n",
      "  生成了 5660 个叶节点二元特征。\n",
      "\n",
      "--- 组合叶节点特征与 Top 20 原始特征 ---\n",
      "  组合后最终特征形状: Train=(103871, 5680), Test=(34017, 5680)\n",
      "\n",
      "--- 定义评价标准 (MAE) ---\n",
      "MAE 评价标准已创建 (得分越低越好)。\n",
      "\n",
      "--- 定义最终的 RidgeCV Pipeline ---\n",
      "\n",
      "--- 使用 6-折交叉验证评估最终 Pipeline (MAE in log space) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  交叉验证得分 (负 Log MAE): -0.0983 +/- 0.0005\n",
      "  交叉验证得分 (Log MAE): 0.0983\n",
      "\n",
      "--- 在全部训练数据上训练最终的 RidgeCV Pipeline ---\n",
      "  最终 Pipeline 训练完成。\n",
      "  RidgeCV 找到的最佳 alpha: 7196.856730\n",
      "\n",
      "--- 在完整训练集上评估最终 Ridge 模型 (原始价格空间) ---\n",
      "  训练集 RMSE (原): 371854.73\n",
      "  训练集 MAE  (原): 203146.54\n",
      "  训练集 MedAE(原): 104287.47\n",
      "\n",
      "--- 在测试集上进行预测 ---\n",
      "  预测完成并已转换回原始价格空间。\n",
      "\n",
      "--- 创建并保存提交文件到 'LeafEncoding_Ridge_Prediction_new_price' ---\n",
      "✓ 提交文件已成功保存: LeafEncoding_Ridge_Prediction_new_price/submission_leaf_ridge_mae_3.csv\n",
      "  总预测条数: 34017\n",
      "\n",
      "提交文件预览 (前5行):\n",
      "        ID  PredictedPrice\n",
      "0  1000000    1.251116e+07\n",
      "1  1000001    3.244987e+06\n",
      "2  1000002    3.699393e+06\n",
      "3  1000003    2.895238e+06\n",
      "4  1000004    9.349244e+06\n",
      "\n",
      "--- 叶节点编码 + Top Features + RidgeCV (Log Target) 预测流程完成 ---\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 完整脚本：叶节点编码 + Top Features + RidgeCV 房价预测 (Price Prediction) - V3 (Log Target, Combined Features, External CV)\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib # 用于将来可能保存对象\n",
    "from sklearn.model_selection import KFold, cross_val_score # 导入 cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error, median_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.sparse import hstack, csr_matrix # 用于组合稀疏和稠密矩阵\n",
    "\n",
    "# --- 1. 配置 ---\n",
    "INPUT_FOLDER = 'Price_Capped_Aggregated_Data'\n",
    "OUTPUT_FOLDER = 'LeafEncoding_Ridge_Prediction_new_price' # 更新文件夹名\n",
    "TRAIN_PRICE_FILE = 'train_price_capped_agg.csv'\n",
    "TEST_PRICE_FILE = 'test_price_capped_agg.csv'\n",
    "OUTPUT_FILE = 'submission_leaf_ridge_mae_3.csv' # 更新文件名\n",
    "\n",
    "TARGET_COLUMN = 'Price'\n",
    "ID_COLUMN = 'ID'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# GBRT 参数 (调整后)\n",
    "GBRT_PARAMS = {\n",
    "    'n_estimators': 200,      # 稍微增加树的数量\n",
    "    'max_depth': 5,          # 稍微降低树的深度\n",
    "    'min_samples_leaf': 30,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.7,\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "# 保留多少个最重要的原始特征与叶节点结合\n",
    "N_TOP_ORIGINAL_FEATURES = 20 \n",
    "\n",
    "# RidgeCV 参数\n",
    "RIDGE_ALPHAS = np.logspace(-4, 6, 15) # 保持精细的 Alpha 范围\n",
    "RIDGE_CV_FOLDS = 5 # RidgeCV 内部交叉验证折数\n",
    "\n",
    "# 外部交叉验证折数 (用于最终评估)\n",
    "EXTERNAL_CV_FOLDS = 6 # 您之前要求的 6 折\n",
    "\n",
    "# --- 2. 创建输出文件夹 ---\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "print(f\"输出文件夹 '{OUTPUT_FOLDER}' 已创建或已存在。\")\n",
    "\n",
    "# --- 3. 加载数据 ---\n",
    "print(f\"\\n--- 从 '{INPUT_FOLDER}' 加载 Price 数据 ---\")\n",
    "try:\n",
    "    train_df = pd.read_csv(os.path.join(INPUT_FOLDER, TRAIN_PRICE_FILE), encoding='utf-8-sig')\n",
    "    test_df = pd.read_csv(os.path.join(INPUT_FOLDER, TEST_PRICE_FILE), encoding='utf-8-sig')\n",
    "    print(\"Price 数据加载成功。\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"加载数据时出错: {e}. 请确保文件路径正确。\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"加载数据时发生其他错误: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 转换布尔列 ---\n",
    "print(\"\\n--- 转换布尔列 (True/False) 为整数 (1/0) ---\")\n",
    "# (省略了详细打印，假设之前的步骤已完成)\n",
    "for df_name in ['train_df', 'test_df']:\n",
    "    df_obj = globals()[df_name]\n",
    "    bool_columns = df_obj.select_dtypes(include='bool').columns\n",
    "    if not bool_columns.empty:\n",
    "        print(f\"  转换 {df_name} 中的 {len(bool_columns)} 个布尔列...\")\n",
    "        for col in bool_columns:\n",
    "            df_obj.loc[:, col] = df_obj[col].astype(int)\n",
    "print(\"--- 布尔列转换完成 ---\")\n",
    "\n",
    "# 存储测试集的 ID\n",
    "test_ids = test_df[ID_COLUMN].copy()\n",
    "\n",
    "# --- 4. 准备数据 (分离 X/y, Log Transform y, 对齐, 填充 NaN) ---\n",
    "print(\"\\n--- 准备训练和测试数据 ---\")\n",
    "try:\n",
    "    # !!! 应用 Log Transform !!!\n",
    "    y_train = np.log1p(train_df[TARGET_COLUMN])\n",
    "    print(f\"  已对目标变量 '{TARGET_COLUMN}' 应用 log1p 转换。\")\n",
    "    \n",
    "    X_train = train_df.drop(columns=[TARGET_COLUMN])\n",
    "    X_test = test_df.drop(columns=[ID_COLUMN])\n",
    "\n",
    "    # 移除可能残余的非数值列\n",
    "    non_numeric_train = X_train.select_dtypes(exclude=np.number).columns\n",
    "    if not non_numeric_train.empty:\n",
    "        print(f\"  警告: 训练集发现非数值列，将移除: {non_numeric_train.tolist()}\")\n",
    "        X_train = X_train.drop(columns=non_numeric_train)\n",
    "    non_numeric_test = X_test.select_dtypes(exclude=np.number).columns\n",
    "    if not non_numeric_test.empty:\n",
    "         X_test = X_test.drop(columns=non_numeric_test)\n",
    "\n",
    "    # 对齐列\n",
    "    train_cols = X_train.columns # 保存列名以供后续使用\n",
    "    test_cols = X_test.columns\n",
    "    missing_in_test = set(train_cols) - set(test_cols)\n",
    "    for c in missing_in_test: X_test[c] = 0\n",
    "    extra_in_test = set(test_cols) - set(train_cols)\n",
    "    if extra_in_test: X_test = X_test.drop(columns=list(extra_in_test))\n",
    "    X_test = X_test[train_cols] \n",
    "\n",
    "    print(f\"  对齐后特征形状: Train={X_train.shape}, Test={X_test.shape}\")\n",
    "\n",
    "    # **填充缺失值**\n",
    "    print(\"  使用中位数填充缺失值...\")\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    print(\"  缺失值填充完成。\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"数据准备时发生错误: {e}\")\n",
    "     exit()\n",
    "\n",
    "# --- 5. 训练 GBRT 模型以生成叶节点 & 获取特征重要性 ---\n",
    "print(\"\\n--- 训练 Gradient Boosting 模型以生成叶节点特征 ---\")\n",
    "gbrt = GradientBoostingRegressor(**GBRT_PARAMS)\n",
    "try:\n",
    "    print(f\"  使用以下参数训练 GBRT: {GBRT_PARAMS}\")\n",
    "    # GBRT 在填充后的 NumPy 数组上训练\n",
    "    gbrt.fit(X_train_imputed, y_train) # 注意 y_train 是 log 转换后的\n",
    "    print(\"  GBRT 模型训练完成。\")\n",
    "\n",
    "    # 获取特征重要性\n",
    "    importances = gbrt.feature_importances_\n",
    "    # 获取 Top N 特征的索引和名称\n",
    "    top_n_indices = np.argsort(importances)[::-1][:N_TOP_ORIGINAL_FEATURES]\n",
    "    top_n_features = train_cols[top_n_indices].tolist() # 使用之前保存的列名\n",
    "    print(f\"  识别出 Top {N_TOP_ORIGINAL_FEATURES} 原始特征: {top_n_features}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  训练 GBRT 或获取重要性时出错: {e}\")\n",
    "    # 即使出错，也继续尝试叶节点编码，但不添加原始特征\n",
    "    top_n_features = [] \n",
    "    # exit() # 如果希望严格要求特征重要性计算成功，则取消此行注释\n",
    "\n",
    "# --- 6. 获取叶节点索引 ---\n",
    "print(\"\\n--- 获取叶节点索引 ---\")\n",
    "try:\n",
    "    train_leaf_indices = gbrt.apply(X_train_imputed)\n",
    "    test_leaf_indices = gbrt.apply(X_test_imputed)\n",
    "except Exception as e:\n",
    "    print(f\"  获取叶节点索引时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 7. 对叶节点索引进行 One-Hot 编码 ---\n",
    "print(\"\\n--- 对叶节点索引进行 One-Hot 编码 ---\")\n",
    "leaf_encoder = OneHotEncoder(handle_unknown='ignore', )\n",
    "try:\n",
    "    X_train_leaves_encoded = leaf_encoder.fit_transform(train_leaf_indices)\n",
    "    X_test_leaves_encoded = leaf_encoder.transform(test_leaf_indices)\n",
    "    n_leaf_features = X_train_leaves_encoded.shape[1]\n",
    "    print(f\"  生成了 {n_leaf_features} 个叶节点二元特征。\")\n",
    "except Exception as e:\n",
    "    print(f\"  One-Hot 编码时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 8. 组合叶节点特征与 Top N 原始特征 ---\n",
    "print(f\"\\n--- 组合叶节点特征与 Top {len(top_n_features)} 原始特征 ---\")\n",
    "try:\n",
    "    if top_n_features:\n",
    "        # 从填充后的 NumPy 数组中按索引选取 Top N 特征\n",
    "        X_train_top_features = X_train_imputed[:, top_n_indices]\n",
    "        X_test_top_features = X_test_imputed[:, top_n_indices]\n",
    "\n",
    "        # 使用 hstack 组合（需要将稠密部分转为 CSR 稀疏格式）\n",
    "        X_train_final = hstack([X_train_leaves_encoded, csr_matrix(X_train_top_features)])\n",
    "        X_test_final = hstack([X_test_leaves_encoded, csr_matrix(X_test_top_features)])\n",
    "        print(f\"  组合后最终特征形状: Train={X_train_final.shape}, Test={X_test_final.shape}\")\n",
    "    else:\n",
    "        # 如果没有 top_n_features (例如 GBRT 训练失败)，只用叶节点\n",
    "        X_train_final = X_train_leaves_encoded\n",
    "        X_test_final = X_test_leaves_encoded\n",
    "        print(\"  只使用编码后的叶节点特征。\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  组合特征时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 9. 定义评价标准 (MAE Scorer) ---\n",
    "print(\"\\n--- 定义评价标准 (MAE) ---\")\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "print(\"MAE 评价标准已创建 (得分越低越好)。\")\n",
    "# 辅助函数\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    # !!! 注意: 这里的 y_true 和 y_pred 都是 log 转换后的 !!!\n",
    "    # 计算 log 空间上的指标\n",
    "    rmse_log = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae_log = mean_absolute_error(y_true, y_pred)\n",
    "    medae_log = median_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # 计算原始价格空间上的指标 (需要逆转换)\n",
    "    y_true_orig = np.expm1(y_true)\n",
    "    y_pred_orig = np.expm1(y_pred)\n",
    "    rmse_orig = np.sqrt(mean_squared_error(y_true_orig, y_pred_orig))\n",
    "    mae_orig = mean_absolute_error(y_true_orig, y_pred_orig)\n",
    "    medae_orig = median_absolute_error(y_true_orig, y_pred_orig)\n",
    "    \n",
    "    # 返回原始空间的指标以供最终评估\n",
    "    return rmse_orig, mae_orig, medae_orig\n",
    "\n",
    "\n",
    "# --- 10. 定义最终的 RidgeCV Pipeline ---\n",
    "print(\"\\n--- 定义最终的 RidgeCV Pipeline ---\")\n",
    "ridge_cv_model = RidgeCV(\n",
    "    alphas=RIDGE_ALPHAS,\n",
    "    cv=RIDGE_CV_FOLDS,\n",
    "    scoring=mae_scorer, # RidgeCV 内部仍然优化 log 空间上的 MAE\n",
    "    store_cv_values=False\n",
    ")\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)), # 稀疏矩阵不中心化\n",
    "    ('model', ridge_cv_model)\n",
    "])\n",
    "\n",
    "# --- 11. 外部交叉验证评估 Pipeline ---\n",
    "print(f\"\\n--- 使用 {EXTERNAL_CV_FOLDS}-折交叉验证评估最终 Pipeline (MAE in log space) ---\")\n",
    "try:\n",
    "    # 使用 KFold 进行外部 CV\n",
    "    external_cv = KFold(n_splits=EXTERNAL_CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    # 在 log 空间上计算 MAE\n",
    "    cv_scores_log_mae = cross_val_score(final_pipeline, X_train_final, y_train, \n",
    "                                        cv=external_cv, scoring=mae_scorer, n_jobs=-1)\n",
    "    \n",
    "    mean_cv_log_mae = np.mean(cv_scores_log_mae)\n",
    "    std_cv_log_mae = np.std(cv_scores_log_mae)\n",
    "    \n",
    "    print(f\"  交叉验证得分 (负 Log MAE): {mean_cv_log_mae:.4f} +/- {std_cv_log_mae:.4f}\")\n",
    "    print(f\"  交叉验证得分 (Log MAE): {-mean_cv_log_mae:.4f}\") # 打印正的 Log MAE\n",
    "\n",
    "    # **重要**: 这个 CV MAE 是在 log 空间上的，不直接等于原始价格空间的 MAE\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  外部交叉验证时出错: {e}\")\n",
    "    # 即使 CV 出错，也继续尝试训练最终模型\n",
    "\n",
    "# --- 12. 在全部训练数据上训练最终 Pipeline ---\n",
    "print(\"\\n--- 在全部训练数据上训练最终的 RidgeCV Pipeline ---\")\n",
    "try:\n",
    "    final_pipeline.fit(X_train_final, y_train)\n",
    "    print(\"  最终 Pipeline 训练完成。\")\n",
    "    best_alpha = final_pipeline.named_steps['model'].alpha_\n",
    "    print(f\"  RidgeCV 找到的最佳 alpha: {best_alpha:.6f}\")\n",
    "except Exception as e:\n",
    "    print(f\"  训练最终 Pipeline 时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 13. 在训练集上评估最终模型 (原始价格空间) ---\n",
    "print(\"\\n--- 在完整训练集上评估最终 Ridge 模型 (原始价格空间) ---\")\n",
    "try:\n",
    "    y_train_pred_log = final_pipeline.predict(X_train_final)\n",
    "    # 使用更新后的 calculate_metrics 函数，它会返回原始空间的指标\n",
    "    rmse_train, mae_train, medae_train = calculate_metrics(y_train, y_train_pred_log) \n",
    "    print(f\"  训练集 RMSE (原): {rmse_train:.2f}\")\n",
    "    print(f\"  训练集 MAE  (原): {mae_train:.2f}\")\n",
    "    print(f\"  训练集 MedAE(原): {medae_train:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"  评估训练集时出错: {e}\")\n",
    "\n",
    "# --- 14. 在测试集上进行预测 ---\n",
    "print(\"\\n--- 在测试集上进行预测 ---\")\n",
    "try:\n",
    "    predictions_log = final_pipeline.predict(X_test_final)\n",
    "    # !!! 逆转换回原始价格空间 !!!\n",
    "    predictions = np.expm1(predictions_log)\n",
    "    print(\"  预测完成并已转换回原始价格空间。\")\n",
    "    \n",
    "    # 检查是否有负数预测 (log转换后理论上不会，但 expm1 可能产生接近0的负数)\n",
    "    if np.any(predictions < 0):\n",
    "        print(f\"  警告: 发现 {np.sum(predictions < 0)} 个负数预测值，将修正为 0。\")\n",
    "        predictions = np.clip(predictions, a_min=0, a_max=None)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  在测试集上预测时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 15. 创建并保存提交文件 ---\n",
    "print(f\"\\n--- 创建并保存提交文件到 '{OUTPUT_FOLDER}' ---\")\n",
    "submission_df = pd.DataFrame({\n",
    "    ID_COLUMN: test_ids,\n",
    "    'PredictedPrice': predictions\n",
    "})\n",
    "submission_df[ID_COLUMN] = submission_df[ID_COLUMN].astype(int)\n",
    "submission_df = submission_df.sort_values(by=ID_COLUMN)\n",
    "try:\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, OUTPUT_FILE)\n",
    "    submission_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"✓ 提交文件已成功保存: {output_path}\")\n",
    "    print(f\"  总预测条数: {len(submission_df)}\")\n",
    "    print(\"\\n提交文件预览 (前5行):\")\n",
    "    print(submission_df.head())\n",
    "except Exception as e:\n",
    "    print(f\"✗ 保存提交文件时出错: {e}\")\n",
    "\n",
    "print(\"\\n--- 叶节点编码 + Top Features + RidgeCV (Log Target) 预测流程完成 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dffa5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b0f62d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出文件夹 'LeafEncoding_Ridge_Prediction_new_price' 已创建或已存在。\n",
      "\n",
      "--- 从 'Price_Capped_Aggregated_Data' 加载 Price 数据 ---\n",
      "Price 数据加载成功。\n",
      "\n",
      "--- 转换布尔列 (True/False) 为整数 (1/0) ---\n",
      "  转换 train_df 中的 45 个布尔列...\n",
      "  转换 test_df 中的 45 个布尔列...\n",
      "--- 布尔列转换完成 ---\n",
      "\n",
      "--- 准备训练和测试数据 ---\n",
      "  已对目标变量 'Price' 应用 log1p 转换。\n",
      "  对齐后特征形状: Train=(103871, 195), Test=(34017, 195)\n",
      "  使用中位数填充缺失值...\n",
      "  缺失值填充完成。\n",
      "\n",
      "--- 训练 Gradient Boosting 模型以生成叶节点特征 ---\n",
      "  使用以下参数训练 GBRT: {'n_estimators': 300, 'max_depth': 5, 'min_samples_leaf': 30, 'learning_rate': 0.03, 'subsample': 0.7, 'random_state': 42}\n",
      "  GBRT 模型训练完成。\n",
      "  识别出 Top 20 原始特征: ['板块_平均价格_capped', '板块_中位数价格_capped', '面积_数值', '板块_平均面积_capped', '区域_平均价格_capped', '区域_中位数价格_capped', '装修_未知.1', '梯户比例_数值', '装修_未知', '户型_室', '区县_中位数价格_capped', '户型_卫', '区县_平均价格_capped', '户型_房间总数', '楼层_总楼层', '物业费_数值', '区域_平均面积_capped', '户型_厨', '停车费用_数值', '区县_平均面积_capped']\n",
      "\n",
      "--- 获取叶节点索引 ---\n",
      "\n",
      "--- 对叶节点索引进行 One-Hot 编码 ---\n",
      "  生成了 8703 个叶节点二元特征。\n",
      "\n",
      "--- 组合叶节点特征与 Top 20 原始特征 ---\n",
      "  组合后最终特征形状: Train=(103871, 8723), Test=(34017, 8723)\n",
      "\n",
      "--- 定义评价标准 (MAE) ---\n",
      "MAE 评价标准已创建 (得分越低越好)。\n",
      "\n",
      "--- 定义最终的 RidgeCV Pipeline ---\n",
      "\n",
      "--- 使用 10-折交叉验证评估最终 Pipeline (MAE in log space) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  交叉验证得分 (负 Log MAE): -0.0972 +/- 0.0007\n",
      "  交叉验证得分 (Log MAE): 0.0972\n",
      "\n",
      "--- 在全部训练数据上训练最终的 RidgeCV Pipeline ---\n",
      "  最终 Pipeline 训练完成。\n",
      "  RidgeCV 找到的最佳 alpha: 13894.954944\n",
      "\n",
      "--- 在完整训练集上评估最终 Ridge 模型 (原始价格空间) ---\n",
      "  训练集 RMSE (原): 359404.37\n",
      "  训练集 MAE  (原): 198967.12\n",
      "  训练集 MedAE(原): 102878.10\n",
      "\n",
      "--- 在测试集上进行预测 ---\n",
      "  预测完成并已转换回原始价格空间。\n",
      "\n",
      "--- 创建并保存提交文件到 'LeafEncoding_Ridge_Prediction_new_price' ---\n",
      "✓ 提交文件已成功保存: LeafEncoding_Ridge_Prediction_new_price/submission_leaf_ridge_mae_4.csv\n",
      "  总预测条数: 34017\n",
      "\n",
      "提交文件预览 (前5行):\n",
      "        ID  PredictedPrice\n",
      "0  1000000    1.297097e+07\n",
      "1  1000001    3.156746e+06\n",
      "2  1000002    3.587562e+06\n",
      "3  1000003    2.906455e+06\n",
      "4  1000004    9.470630e+06\n",
      "\n",
      "--- 叶节点编码 + Top Features + RidgeCV (Log Target) 预测流程完成 ---\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 完整脚本：叶节点编码 + Top Features + RidgeCV 房价预测 (Price Prediction) - V3 (Log Target, Combined Features, External CV)\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib # 用于将来可能保存对象\n",
    "from sklearn.model_selection import KFold, cross_val_score # 导入 cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error, median_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.sparse import hstack, csr_matrix # 用于组合稀疏和稠密矩阵\n",
    "\n",
    "# --- 1. 配置 ---\n",
    "INPUT_FOLDER = 'Price_Capped_Aggregated_Data'\n",
    "OUTPUT_FOLDER = 'LeafEncoding_Ridge_Prediction_new_price' # 更新文件夹名\n",
    "TRAIN_PRICE_FILE = 'train_price_capped_agg.csv'\n",
    "TEST_PRICE_FILE = 'test_price_capped_agg.csv'\n",
    "OUTPUT_FILE = 'submission_leaf_ridge_mae_4.csv' # 更新文件名\n",
    "\n",
    "TARGET_COLUMN = 'Price'\n",
    "ID_COLUMN = 'ID'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# GBRT 参数 (调整后)\n",
    "GBRT_PARAMS = {\n",
    "    'n_estimators': 300,      # 稍微增加树的数量\n",
    "    'max_depth': 5,          # 稍微降低树的深度\n",
    "    'min_samples_leaf': 30,\n",
    "    'learning_rate': 0.03,\n",
    "    'subsample': 0.7,\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "# 保留多少个最重要的原始特征与叶节点结合\n",
    "N_TOP_ORIGINAL_FEATURES = 20 \n",
    "\n",
    "# RidgeCV 参数\n",
    "RIDGE_ALPHAS = np.logspace(3, 5, 15) # 保持精细的 Alpha 范围\n",
    "RIDGE_CV_FOLDS = 5 # RidgeCV 内部交叉验证折数\n",
    "\n",
    "# 外部交叉验证折数 (用于最终评估)\n",
    "EXTERNAL_CV_FOLDS = 10 # 您之前要求的 6 折\n",
    "\n",
    "# --- 2. 创建输出文件夹 ---\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "print(f\"输出文件夹 '{OUTPUT_FOLDER}' 已创建或已存在。\")\n",
    "\n",
    "# --- 3. 加载数据 ---\n",
    "print(f\"\\n--- 从 '{INPUT_FOLDER}' 加载 Price 数据 ---\")\n",
    "try:\n",
    "    train_df = pd.read_csv(os.path.join(INPUT_FOLDER, TRAIN_PRICE_FILE), encoding='utf-8-sig')\n",
    "    test_df = pd.read_csv(os.path.join(INPUT_FOLDER, TEST_PRICE_FILE), encoding='utf-8-sig')\n",
    "    print(\"Price 数据加载成功。\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"加载数据时出错: {e}. 请确保文件路径正确。\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"加载数据时发生其他错误: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 转换布尔列 ---\n",
    "print(\"\\n--- 转换布尔列 (True/False) 为整数 (1/0) ---\")\n",
    "# (省略了详细打印，假设之前的步骤已完成)\n",
    "for df_name in ['train_df', 'test_df']:\n",
    "    df_obj = globals()[df_name]\n",
    "    bool_columns = df_obj.select_dtypes(include='bool').columns\n",
    "    if not bool_columns.empty:\n",
    "        print(f\"  转换 {df_name} 中的 {len(bool_columns)} 个布尔列...\")\n",
    "        for col in bool_columns:\n",
    "            df_obj.loc[:, col] = df_obj[col].astype(int)\n",
    "print(\"--- 布尔列转换完成 ---\")\n",
    "\n",
    "# 存储测试集的 ID\n",
    "test_ids = test_df[ID_COLUMN].copy()\n",
    "\n",
    "# --- 4. 准备数据 (分离 X/y, Log Transform y, 对齐, 填充 NaN) ---\n",
    "print(\"\\n--- 准备训练和测试数据 ---\")\n",
    "try:\n",
    "    # !!! 应用 Log Transform !!!\n",
    "    y_train = np.log1p(train_df[TARGET_COLUMN])\n",
    "    print(f\"  已对目标变量 '{TARGET_COLUMN}' 应用 log1p 转换。\")\n",
    "    \n",
    "    X_train = train_df.drop(columns=[TARGET_COLUMN])\n",
    "    X_test = test_df.drop(columns=[ID_COLUMN])\n",
    "\n",
    "    # 移除可能残余的非数值列\n",
    "    non_numeric_train = X_train.select_dtypes(exclude=np.number).columns\n",
    "    if not non_numeric_train.empty:\n",
    "        print(f\"  警告: 训练集发现非数值列，将移除: {non_numeric_train.tolist()}\")\n",
    "        X_train = X_train.drop(columns=non_numeric_train)\n",
    "    non_numeric_test = X_test.select_dtypes(exclude=np.number).columns\n",
    "    if not non_numeric_test.empty:\n",
    "         X_test = X_test.drop(columns=non_numeric_test)\n",
    "\n",
    "    # 对齐列\n",
    "    train_cols = X_train.columns # 保存列名以供后续使用\n",
    "    test_cols = X_test.columns\n",
    "    missing_in_test = set(train_cols) - set(test_cols)\n",
    "    for c in missing_in_test: X_test[c] = 0\n",
    "    extra_in_test = set(test_cols) - set(train_cols)\n",
    "    if extra_in_test: X_test = X_test.drop(columns=list(extra_in_test))\n",
    "    X_test = X_test[train_cols] \n",
    "\n",
    "    print(f\"  对齐后特征形状: Train={X_train.shape}, Test={X_test.shape}\")\n",
    "\n",
    "    # **填充缺失值**\n",
    "    print(\"  使用中位数填充缺失值...\")\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    print(\"  缺失值填充完成。\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"数据准备时发生错误: {e}\")\n",
    "     exit()\n",
    "\n",
    "# --- 5. 训练 GBRT 模型以生成叶节点 & 获取特征重要性 ---\n",
    "print(\"\\n--- 训练 Gradient Boosting 模型以生成叶节点特征 ---\")\n",
    "gbrt = GradientBoostingRegressor(**GBRT_PARAMS)\n",
    "try:\n",
    "    print(f\"  使用以下参数训练 GBRT: {GBRT_PARAMS}\")\n",
    "    # GBRT 在填充后的 NumPy 数组上训练\n",
    "    gbrt.fit(X_train_imputed, y_train) # 注意 y_train 是 log 转换后的\n",
    "    print(\"  GBRT 模型训练完成。\")\n",
    "\n",
    "    # 获取特征重要性\n",
    "    importances = gbrt.feature_importances_\n",
    "    # 获取 Top N 特征的索引和名称\n",
    "    top_n_indices = np.argsort(importances)[::-1][:N_TOP_ORIGINAL_FEATURES]\n",
    "    top_n_features = train_cols[top_n_indices].tolist() # 使用之前保存的列名\n",
    "    print(f\"  识别出 Top {N_TOP_ORIGINAL_FEATURES} 原始特征: {top_n_features}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  训练 GBRT 或获取重要性时出错: {e}\")\n",
    "    # 即使出错，也继续尝试叶节点编码，但不添加原始特征\n",
    "    top_n_features = [] \n",
    "    # exit() # 如果希望严格要求特征重要性计算成功，则取消此行注释\n",
    "\n",
    "# --- 6. 获取叶节点索引 ---\n",
    "print(\"\\n--- 获取叶节点索引 ---\")\n",
    "try:\n",
    "    train_leaf_indices = gbrt.apply(X_train_imputed)\n",
    "    test_leaf_indices = gbrt.apply(X_test_imputed)\n",
    "except Exception as e:\n",
    "    print(f\"  获取叶节点索引时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 7. 对叶节点索引进行 One-Hot 编码 ---\n",
    "print(\"\\n--- 对叶节点索引进行 One-Hot 编码 ---\")\n",
    "leaf_encoder = OneHotEncoder(handle_unknown='ignore', )\n",
    "try:\n",
    "    X_train_leaves_encoded = leaf_encoder.fit_transform(train_leaf_indices)\n",
    "    X_test_leaves_encoded = leaf_encoder.transform(test_leaf_indices)\n",
    "    n_leaf_features = X_train_leaves_encoded.shape[1]\n",
    "    print(f\"  生成了 {n_leaf_features} 个叶节点二元特征。\")\n",
    "except Exception as e:\n",
    "    print(f\"  One-Hot 编码时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 8. 组合叶节点特征与 Top N 原始特征 ---\n",
    "print(f\"\\n--- 组合叶节点特征与 Top {len(top_n_features)} 原始特征 ---\")\n",
    "try:\n",
    "    if top_n_features:\n",
    "        # 从填充后的 NumPy 数组中按索引选取 Top N 特征\n",
    "        X_train_top_features = X_train_imputed[:, top_n_indices]\n",
    "        X_test_top_features = X_test_imputed[:, top_n_indices]\n",
    "\n",
    "        # 使用 hstack 组合（需要将稠密部分转为 CSR 稀疏格式）\n",
    "        X_train_final = hstack([X_train_leaves_encoded, csr_matrix(X_train_top_features)])\n",
    "        X_test_final = hstack([X_test_leaves_encoded, csr_matrix(X_test_top_features)])\n",
    "        print(f\"  组合后最终特征形状: Train={X_train_final.shape}, Test={X_test_final.shape}\")\n",
    "    else:\n",
    "        # 如果没有 top_n_features (例如 GBRT 训练失败)，只用叶节点\n",
    "        X_train_final = X_train_leaves_encoded\n",
    "        X_test_final = X_test_leaves_encoded\n",
    "        print(\"  只使用编码后的叶节点特征。\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  组合特征时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 9. 定义评价标准 (MAE Scorer) ---\n",
    "print(\"\\n--- 定义评价标准 (MAE) ---\")\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "print(\"MAE 评价标准已创建 (得分越低越好)。\")\n",
    "# 辅助函数\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    # !!! 注意: 这里的 y_true 和 y_pred 都是 log 转换后的 !!!\n",
    "    # 计算 log 空间上的指标\n",
    "    rmse_log = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae_log = mean_absolute_error(y_true, y_pred)\n",
    "    medae_log = median_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # 计算原始价格空间上的指标 (需要逆转换)\n",
    "    y_true_orig = np.expm1(y_true)\n",
    "    y_pred_orig = np.expm1(y_pred)\n",
    "    rmse_orig = np.sqrt(mean_squared_error(y_true_orig, y_pred_orig))\n",
    "    mae_orig = mean_absolute_error(y_true_orig, y_pred_orig)\n",
    "    medae_orig = median_absolute_error(y_true_orig, y_pred_orig)\n",
    "    \n",
    "    # 返回原始空间的指标以供最终评估\n",
    "    return rmse_orig, mae_orig, medae_orig\n",
    "\n",
    "\n",
    "# --- 10. 定义最终的 RidgeCV Pipeline ---\n",
    "print(\"\\n--- 定义最终的 RidgeCV Pipeline ---\")\n",
    "ridge_cv_model = RidgeCV(\n",
    "    alphas=RIDGE_ALPHAS,\n",
    "    cv=RIDGE_CV_FOLDS,\n",
    "    scoring=mae_scorer, # RidgeCV 内部仍然优化 log 空间上的 MAE\n",
    "    store_cv_values=False\n",
    ")\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)), # 稀疏矩阵不中心化\n",
    "    ('model', ridge_cv_model)\n",
    "])\n",
    "\n",
    "# --- 11. 外部交叉验证评估 Pipeline ---\n",
    "print(f\"\\n--- 使用 {EXTERNAL_CV_FOLDS}-折交叉验证评估最终 Pipeline (MAE in log space) ---\")\n",
    "try:\n",
    "    # 使用 KFold 进行外部 CV\n",
    "    external_cv = KFold(n_splits=EXTERNAL_CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    # 在 log 空间上计算 MAE\n",
    "    cv_scores_log_mae = cross_val_score(final_pipeline, X_train_final, y_train, \n",
    "                                        cv=external_cv, scoring=mae_scorer, n_jobs=-1)\n",
    "    \n",
    "    mean_cv_log_mae = np.mean(cv_scores_log_mae)\n",
    "    std_cv_log_mae = np.std(cv_scores_log_mae)\n",
    "    \n",
    "    print(f\"  交叉验证得分 (负 Log MAE): {mean_cv_log_mae:.4f} +/- {std_cv_log_mae:.4f}\")\n",
    "    print(f\"  交叉验证得分 (Log MAE): {-mean_cv_log_mae:.4f}\") # 打印正的 Log MAE\n",
    "\n",
    "    # **重要**: 这个 CV MAE 是在 log 空间上的，不直接等于原始价格空间的 MAE\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  外部交叉验证时出错: {e}\")\n",
    "    # 即使 CV 出错，也继续尝试训练最终模型\n",
    "\n",
    "# --- 12. 在全部训练数据上训练最终 Pipeline ---\n",
    "print(\"\\n--- 在全部训练数据上训练最终的 RidgeCV Pipeline ---\")\n",
    "try:\n",
    "    final_pipeline.fit(X_train_final, y_train)\n",
    "    print(\"  最终 Pipeline 训练完成。\")\n",
    "    best_alpha = final_pipeline.named_steps['model'].alpha_\n",
    "    print(f\"  RidgeCV 找到的最佳 alpha: {best_alpha:.6f}\")\n",
    "except Exception as e:\n",
    "    print(f\"  训练最终 Pipeline 时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 13. 在训练集上评估最终模型 (原始价格空间) ---\n",
    "print(\"\\n--- 在完整训练集上评估最终 Ridge 模型 (原始价格空间) ---\")\n",
    "try:\n",
    "    y_train_pred_log = final_pipeline.predict(X_train_final)\n",
    "    # 使用更新后的 calculate_metrics 函数，它会返回原始空间的指标\n",
    "    rmse_train, mae_train, medae_train = calculate_metrics(y_train, y_train_pred_log) \n",
    "    print(f\"  训练集 RMSE (原): {rmse_train:.2f}\")\n",
    "    print(f\"  训练集 MAE  (原): {mae_train:.2f}\")\n",
    "    print(f\"  训练集 MedAE(原): {medae_train:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"  评估训练集时出错: {e}\")\n",
    "\n",
    "# --- 14. 在测试集上进行预测 ---\n",
    "print(\"\\n--- 在测试集上进行预测 ---\")\n",
    "try:\n",
    "    predictions_log = final_pipeline.predict(X_test_final)\n",
    "    # !!! 逆转换回原始价格空间 !!!\n",
    "    predictions = np.expm1(predictions_log)\n",
    "    print(\"  预测完成并已转换回原始价格空间。\")\n",
    "    \n",
    "    # 检查是否有负数预测 (log转换后理论上不会，但 expm1 可能产生接近0的负数)\n",
    "    if np.any(predictions < 0):\n",
    "        print(f\"  警告: 发现 {np.sum(predictions < 0)} 个负数预测值，将修正为 0。\")\n",
    "        predictions = np.clip(predictions, a_min=0, a_max=None)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  在测试集上预测时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 15. 创建并保存提交文件 ---\n",
    "print(f\"\\n--- 创建并保存提交文件到 '{OUTPUT_FOLDER}' ---\")\n",
    "submission_df = pd.DataFrame({\n",
    "    ID_COLUMN: test_ids,\n",
    "    'PredictedPrice': predictions\n",
    "})\n",
    "submission_df[ID_COLUMN] = submission_df[ID_COLUMN].astype(int)\n",
    "submission_df = submission_df.sort_values(by=ID_COLUMN)\n",
    "try:\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, OUTPUT_FILE)\n",
    "    submission_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"✓ 提交文件已成功保存: {output_path}\")\n",
    "    print(f\"  总预测条数: {len(submission_df)}\")\n",
    "    print(\"\\n提交文件预览 (前5行):\")\n",
    "    print(submission_df.head())\n",
    "except Exception as e:\n",
    "    print(f\"✗ 保存提交文件时出错: {e}\")\n",
    "\n",
    "print(\"\\n--- 叶节点编码 + Top Features + RidgeCV (Log Target) 预测流程完成 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68cded40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始执行 Price 预测流程 (Leaf + Auto TopN + RidgeCV)...\n",
      "=========================================================\n",
      "输出文件夹 'LeafEncoding_AutoTopN_Ridge_Prediction_Log' 已创建或已存在。\n",
      "\n",
      "--- 从 'Feature_Selected_Data' 加载 Price 数据 ---\n",
      "Price 数据加载成功。\n",
      "\n",
      "--- 转换布尔列 (True/False) 为整数 (1/0) ---\n",
      "--- 布尔列转换完成 ---\n",
      "\n",
      "--- 准备训练和测试数据 ---\n",
      "  已对目标变量 'Price' 应用 log1p 转换。\n",
      "  对齐后特征形状: Train=(103871, 149), Test=(34017, 149)\n",
      "  使用中位数填充缺失值...\n",
      "  缺失值填充完成。\n",
      "\n",
      "--- 训练 Gradient Boosting 模型并获取排序后的特征重要性 ---\n",
      "  使用以下参数训练 GBRT: {'n_estimators': 250, 'max_depth': 5, 'min_samples_leaf': 40, 'learning_rate': 0.01, 'subsample': 0.7, 'random_state': 42}\n",
      "  GBRT 模型训练完成。\n",
      "  特征重要性排序完成。最重要的特征: ['面积_数值', '城市_0', 'lon', 'lat', '停车费用_数值']...\n",
      "\n",
      "--- 获取叶节点索引 ---\n",
      "\n",
      "--- 对叶节点索引进行 One-Hot 编码 ---\n",
      "  生成了 7809 个叶节点二元特征。\n",
      "\n",
      "--- 定义评价标准 (MAE) 和最终 RidgeCV Pipeline 结构 ---\n",
      "MAE 评价标准已创建 (得分越低越好)。\n",
      "\n",
      "--- 循环搜索最优 Top N 原始特征数量 (N in [15, 20, 30, 40]) ---\n",
      "\n",
      "  测试 N = 15...\n",
      "    使用 7809 叶节点 + Top 15 原始特征。总计: 7824 特征。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    N=15 的交叉验证得分 (负 Log MAE): -0.154846\n",
      "    *** 新的最佳得分！(N=15) ***\n",
      "\n",
      "  测试 N = 20...\n",
      "    使用 7809 叶节点 + Top 20 原始特征。总计: 7829 特征。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    N=20 的交叉验证得分 (负 Log MAE): -0.154683\n",
      "    *** 新的最佳得分！(N=20) ***\n",
      "\n",
      "  测试 N = 30...\n",
      "    使用 7809 叶节点 + Top 30 原始特征。总计: 7839 特征。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    N=30 的交叉验证得分 (负 Log MAE): -0.154482\n",
      "    *** 新的最佳得分！(N=30) ***\n",
      "\n",
      "  测试 N = 40...\n",
      "    使用 7809 叶节点 + Top 40 原始特征。总计: 7849 特征。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    N=40 的交叉验证得分 (负 Log MAE): -0.154329\n",
      "    *** 新的最佳得分！(N=40) ***\n",
      "\n",
      "--- Top N 搜索完成 ---\n",
      "最优 Top N 原始特征数量 (基于 6-折 CV Log MAE): N = 40\n",
      "对应的最佳交叉验证得分 (负 Log MAE): -0.154329\n",
      "对应的交叉验证得分 (Log MAE): 0.154329\n",
      "\n",
      "--- 使用最优 N = 40 构建最终特征集 ---\n",
      "  最终使用 7809 叶节点 + Top 40 原始特征。总计: 7849 特征。\n",
      "\n",
      "--- 在全部训练数据上训练最终的 RidgeCV Pipeline (使用最优 N) ---\n",
      "  最终 Pipeline 训练完成。\n",
      "  RidgeCV 找到的最佳 alpha: 39810.717055\n",
      "\n",
      "--- 在完整训练集上评估最终 Ridge 模型 (原始价格空间) ---\n",
      "  训练集 RMSE (原): 711210.75\n",
      "  训练集 MAE  (原): 342501.34\n",
      "  训练集 MedAE(原): 161698.39\n",
      "\n",
      "--- 在测试集上进行预测 ---\n",
      "  预测完成并已转换回原始价格空间。\n",
      "\n",
      "--- 创建并保存提交文件到 'LeafEncoding_AutoTopN_Ridge_Prediction_Log' ---\n",
      "✓ 提交文件已成功保存: LeafEncoding_AutoTopN_Ridge_Prediction_Log/submission_leaf_autoTopN_ridge_log_mae.csv\n",
      "  总预测条数: 34017\n",
      "\n",
      "提交文件预览 (前5行):\n",
      "        ID  PredictedPrice\n",
      "0  1000000    1.682722e+07\n",
      "1  1000001    3.227116e+06\n",
      "2  1000002    4.641136e+06\n",
      "3  1000003    2.167827e+06\n",
      "4  1000004    9.350041e+06\n",
      "\n",
      "--- 叶节点编码 + 自动搜索 Top N + RidgeCV (Log Target) 预测流程完成 ---\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 完整脚本：叶节点编码 + **自动搜索 Top N Features** + RidgeCV 房价预测 (Price Prediction) - V4\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib # 用于将来可能保存对象\n",
    "from sklearn.model_selection import KFold, cross_val_score # 导入 cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error, median_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.sparse import hstack, csr_matrix # 用于组合稀疏和稠密矩阵\n",
    "\n",
    "print(\"开始执行 Price 预测流程 (Leaf + Auto TopN + RidgeCV)...\")\n",
    "print(\"=========================================================\")\n",
    "\n",
    "# --- 1. 配置 ---\n",
    "INPUT_FOLDER = 'Feature_Selected_Data'\n",
    "OUTPUT_FOLDER = 'LeafEncoding_AutoTopN_Ridge_Prediction_Log' # 更新文件夹名\n",
    "TRAIN_PRICE_FILE = 'train_price_selected.csv'\n",
    "TEST_PRICE_FILE = 'test_price_selected.csv'\n",
    "OUTPUT_FILE = 'submission_leaf_autoTopN_ridge_log_mae.csv' # 更新文件名\n",
    "\n",
    "TARGET_COLUMN = 'Price'\n",
    "ID_COLUMN = 'ID'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# GBRT 参数 (保持不变或根据需要调整)\n",
    "GBRT_PARAMS = {\n",
    "    'n_estimators': 250,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 40,\n",
    "    'learning_rate': 0.01, # 调整回 0.1 试试\n",
    "    'subsample': 0.7,\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "# !!! 搜索 Top N 原始特征的数量范围 !!!\n",
    "N_VALUES_TO_SEARCH = [15, 20, 30,40] # 要尝试的 N 值列表\n",
    "\n",
    "# RidgeCV 参数\n",
    "RIDGE_ALPHAS = np.logspace(3, 5, 11) # 使用上次精炼的 Alpha 范围 (1000 to 100000)\n",
    "RIDGE_CV_FOLDS = 5 # RidgeCV 内部交叉验证折数\n",
    "\n",
    "# 外部交叉验证折数 (用于评估不同 N 值)\n",
    "EXTERNAL_CV_FOLDS = 6 # 保持 6 折\n",
    "\n",
    "# --- 2. 创建输出文件夹 ---\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "print(f\"输出文件夹 '{OUTPUT_FOLDER}' 已创建或已存在。\")\n",
    "\n",
    "# --- 3. 加载数据 ---\n",
    "print(f\"\\n--- 从 '{INPUT_FOLDER}' 加载 Price 数据 ---\")\n",
    "try:\n",
    "    train_df = pd.read_csv(os.path.join(INPUT_FOLDER, TRAIN_PRICE_FILE), encoding='utf-8-sig')\n",
    "    test_df = pd.read_csv(os.path.join(INPUT_FOLDER, TEST_PRICE_FILE), encoding='utf-8-sig')\n",
    "    print(\"Price 数据加载成功。\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"加载数据时出错: {e}. 请确保文件路径正确。\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"加载数据时发生其他错误: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 转换布尔列 ---\n",
    "print(\"\\n--- 转换布尔列 (True/False) 为整数 (1/0) ---\")\n",
    "# (省略了详细打印)\n",
    "for df_name in ['train_df', 'test_df']:\n",
    "    df_obj = globals()[df_name]\n",
    "    bool_columns = df_obj.select_dtypes(include='bool').columns\n",
    "    if not bool_columns.empty:\n",
    "        # print(f\"  转换 {df_name} 中的 {len(bool_columns)} 个布尔列...\")\n",
    "        for col in bool_columns:\n",
    "            df_obj.loc[:, col] = df_obj[col].astype(int)\n",
    "print(\"--- 布尔列转换完成 ---\")\n",
    "\n",
    "# 存储测试集的 ID\n",
    "test_ids = test_df[ID_COLUMN].copy()\n",
    "\n",
    "# --- 4. 准备数据 (分离 X/y, Log Transform y, 对齐, 填充 NaN) ---\n",
    "print(\"\\n--- 准备训练和测试数据 ---\")\n",
    "try:\n",
    "    y_train = np.log1p(train_df[TARGET_COLUMN])\n",
    "    print(f\"  已对目标变量 '{TARGET_COLUMN}' 应用 log1p 转换。\")\n",
    "\n",
    "    X_train = train_df.drop(columns=[TARGET_COLUMN])\n",
    "    X_test = test_df.drop(columns=[ID_COLUMN])\n",
    "\n",
    "    non_numeric_train = X_train.select_dtypes(exclude=np.number).columns\n",
    "    if not non_numeric_train.empty:\n",
    "        # print(f\"  警告: 训练集发现非数值列，将移除: {non_numeric_train.tolist()}\")\n",
    "        X_train = X_train.drop(columns=non_numeric_train)\n",
    "    non_numeric_test = X_test.select_dtypes(exclude=np.number).columns\n",
    "    if not non_numeric_test.empty:\n",
    "         X_test = X_test.drop(columns=non_numeric_test)\n",
    "\n",
    "    train_cols = X_train.columns # 保存列名\n",
    "    test_cols = X_test.columns\n",
    "    missing_in_test = set(train_cols) - set(test_cols)\n",
    "    for c in missing_in_test: X_test[c] = 0\n",
    "    extra_in_test = set(test_cols) - set(train_cols)\n",
    "    if extra_in_test: X_test = X_test.drop(columns=list(extra_in_test))\n",
    "    X_test = X_test[train_cols]\n",
    "\n",
    "    print(f\"  对齐后特征形状: Train={X_train.shape}, Test={X_test.shape}\")\n",
    "\n",
    "    print(\"  使用中位数填充缺失值...\")\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    print(\"  缺失值填充完成。\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"数据准备时发生错误: {e}\")\n",
    "     exit()\n",
    "\n",
    "# --- 5. 训练 GBRT 模型以生成叶节点 & 获取 **排序后** 的特征重要性 ---\n",
    "print(\"\\n--- 训练 Gradient Boosting 模型并获取排序后的特征重要性 ---\")\n",
    "gbrt = GradientBoostingRegressor(**GBRT_PARAMS)\n",
    "sorted_top_indices = None\n",
    "sorted_top_features = None\n",
    "try:\n",
    "    print(f\"  使用以下参数训练 GBRT: {GBRT_PARAMS}\")\n",
    "    gbrt.fit(X_train_imputed, y_train)\n",
    "    print(\"  GBRT 模型训练完成。\")\n",
    "\n",
    "    importances = gbrt.feature_importances_\n",
    "    # 获取 **所有** 特征的索引，按重要性 **降序** 排列\n",
    "    sorted_indices = np.argsort(importances)[::-1]\n",
    "    # 保存排序后的索引和名称，以备后续按需选取 Top N\n",
    "    sorted_feature_names = train_cols[sorted_indices].tolist()\n",
    "    print(f\"  特征重要性排序完成。最重要的特征: {sorted_feature_names[:5]}...\") # 打印前5个\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  训练 GBRT 或获取重要性时出错: {e}\")\n",
    "    # 如果出错，后续无法组合原始特征\n",
    "    sorted_indices = None\n",
    "    sorted_feature_names = None\n",
    "\n",
    "# --- 6. 获取叶节点索引 ---\n",
    "print(\"\\n--- 获取叶节点索引 ---\")\n",
    "try:\n",
    "    train_leaf_indices = gbrt.apply(X_train_imputed)\n",
    "    test_leaf_indices = gbrt.apply(X_test_imputed)\n",
    "except Exception as e:\n",
    "    print(f\"  获取叶节点索引时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 7. 对叶节点索引进行 One-Hot 编码 ---\n",
    "print(\"\\n--- 对叶节点索引进行 One-Hot 编码 ---\")\n",
    "leaf_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "try:\n",
    "    X_train_leaves_encoded = leaf_encoder.fit_transform(train_leaf_indices)\n",
    "    X_test_leaves_encoded = leaf_encoder.transform(test_leaf_indices)\n",
    "    n_leaf_features = X_train_leaves_encoded.shape[1]\n",
    "    print(f\"  生成了 {n_leaf_features} 个叶节点二元特征。\")\n",
    "except Exception as e:\n",
    "    print(f\"  One-Hot 编码时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 8. 定义评价标准 (MAE Scorer) 和 最终 Pipeline 结构 ---\n",
    "print(\"\\n--- 定义评价标准 (MAE) 和最终 RidgeCV Pipeline 结构 ---\")\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "print(\"MAE 评价标准已创建 (得分越低越好)。\")\n",
    "# 辅助函数\n",
    "def calculate_metrics(y_true_log, y_pred_log):\n",
    "    y_true_orig = np.expm1(y_true_log)\n",
    "    y_pred_orig = np.expm1(y_pred_log)\n",
    "    y_pred_orig = np.clip(y_pred_orig, a_min=0, a_max=None)\n",
    "    rmse_orig = np.sqrt(mean_squared_error(y_true_orig, y_pred_orig))\n",
    "    mae_orig = mean_absolute_error(y_true_orig, y_pred_orig)\n",
    "    medae_orig = median_absolute_error(y_true_orig, y_pred_orig)\n",
    "    return rmse_orig, mae_orig, medae_orig\n",
    "\n",
    "# 定义最终的 Pipeline 结构 (模型部分先用占位符，因为 alpha 会变)\n",
    "# 注意: RidgeCV 会在 fit 时自动选择 alpha，所以这里直接定义 Pipeline 即可\n",
    "final_pipeline_structure = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('model', RidgeCV(alphas=RIDGE_ALPHAS, cv=RIDGE_CV_FOLDS, scoring=mae_scorer, store_cv_values=False))\n",
    "])\n",
    "\n",
    "# --- 9. 循环搜索最优 N 值 ---\n",
    "print(f\"\\n--- 循环搜索最优 Top N 原始特征数量 (N in {N_VALUES_TO_SEARCH}) ---\")\n",
    "best_n = -1\n",
    "best_cv_score = -np.inf # 因为 scorer 返回负值，我们要找最大值（最接近0）\n",
    "cv_scores_by_n = {} # 记录每个 N 的 CV 分数\n",
    "\n",
    "# 外部交叉验证策略\n",
    "external_cv = KFold(n_splits=EXTERNAL_CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "for n in N_VALUES_TO_SEARCH:\n",
    "    print(f\"\\n  测试 N = {n}...\")\n",
    "    \n",
    "    # --- 构造当前 N 对应的特征集 ---\n",
    "    try:\n",
    "        if n == 0 or sorted_indices is None: # N=0 或 GBRT 失败，只用叶节点\n",
    "            X_train_current_n = X_train_leaves_encoded\n",
    "            X_test_current_n = X_test_leaves_encoded\n",
    "            print(f\"    使用 {X_train_current_n.shape[1]} 个叶节点特征。\")\n",
    "        else:\n",
    "            # 选取 Top N 原始特征的索引\n",
    "            current_top_indices = sorted_indices[:n]\n",
    "            # 从填充后的 NumPy 数组中选取\n",
    "            X_train_top_features_n = X_train_imputed[:, current_top_indices]\n",
    "            X_test_top_features_n = X_test_imputed[:, current_top_indices]\n",
    "            # 组合\n",
    "            X_train_current_n = hstack([X_train_leaves_encoded, csr_matrix(X_train_top_features_n)])\n",
    "            X_test_current_n = hstack([X_test_leaves_encoded, csr_matrix(X_test_top_features_n)])\n",
    "            print(f\"    使用 {X_train_leaves_encoded.shape[1]} 叶节点 + Top {n} 原始特征。总计: {X_train_current_n.shape[1]} 特征。\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"    构造 N={n} 特征集时出错: {e}\")\n",
    "        continue # 跳过这个 N 值\n",
    "\n",
    "    # --- 使用外部 CV 评估当前 N 的效果 ---\n",
    "    try:\n",
    "        # 使用定义的 Pipeline 结构进行评估\n",
    "        current_cv_scores = cross_val_score(final_pipeline_structure, X_train_current_n, y_train,\n",
    "                                            cv=external_cv, scoring=mae_scorer, n_jobs=-1)\n",
    "        current_mean_cv_score = np.mean(current_cv_scores)\n",
    "        cv_scores_by_n[n] = current_mean_cv_score\n",
    "        print(f\"    N={n} 的交叉验证得分 (负 Log MAE): {current_mean_cv_score:.6f}\")\n",
    "        \n",
    "        # 更新最佳 N\n",
    "        if current_mean_cv_score > best_cv_score:\n",
    "            best_cv_score = current_mean_cv_score\n",
    "            best_n = n\n",
    "            print(f\"    *** 新的最佳得分！(N={best_n}) ***\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    N={n} 交叉验证时出错: {e}\")\n",
    "\n",
    "print(\"\\n--- Top N 搜索完成 ---\")\n",
    "if best_n == -1:\n",
    "    print(\"错误: 未能成功完成任何 N 值的交叉验证。无法确定最优 N。\")\n",
    "    exit()\n",
    "else:\n",
    "    print(f\"最优 Top N 原始特征数量 (基于 {EXTERNAL_CV_FOLDS}-折 CV Log MAE): N = {best_n}\")\n",
    "    print(f\"对应的最佳交叉验证得分 (负 Log MAE): {best_cv_score:.6f}\")\n",
    "    print(f\"对应的交叉验证得分 (Log MAE): {-best_cv_score:.6f}\")\n",
    "\n",
    "\n",
    "# --- 10. 使用最优 N 构建最终特征集 ---\n",
    "print(f\"\\n--- 使用最优 N = {best_n} 构建最终特征集 ---\")\n",
    "try:\n",
    "    if best_n == 0 or sorted_indices is None:\n",
    "        X_train_final = X_train_leaves_encoded\n",
    "        X_test_final = X_test_leaves_encoded\n",
    "        print(f\"  最终使用 {X_train_final.shape[1]} 个叶节点特征。\")\n",
    "    else:\n",
    "        final_top_indices = sorted_indices[:best_n]\n",
    "        X_train_top_final = X_train_imputed[:, final_top_indices]\n",
    "        X_test_top_final = X_test_imputed[:, final_top_indices]\n",
    "        X_train_final = hstack([X_train_leaves_encoded, csr_matrix(X_train_top_final)])\n",
    "        X_test_final = hstack([X_test_leaves_encoded, csr_matrix(X_test_top_final)])\n",
    "        print(f\"  最终使用 {X_train_leaves_encoded.shape[1]} 叶节点 + Top {best_n} 原始特征。总计: {X_train_final.shape[1]} 特征。\")\n",
    "except Exception as e:\n",
    "    print(f\"  构建最终特征集时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 11. 在全部训练数据上训练最终 Pipeline ---\n",
    "print(\"\\n--- 在全部训练数据上训练最终的 RidgeCV Pipeline (使用最优 N) ---\")\n",
    "# 重新定义最终 Pipeline (确保是新的实例)\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('model', RidgeCV(alphas=RIDGE_ALPHAS, cv=RIDGE_CV_FOLDS, scoring=mae_scorer, store_cv_values=False))\n",
    "])\n",
    "try:\n",
    "    final_pipeline.fit(X_train_final, y_train)\n",
    "    print(\"  最终 Pipeline 训练完成。\")\n",
    "    best_alpha_final = final_pipeline.named_steps['model'].alpha_\n",
    "    print(f\"  RidgeCV 找到的最佳 alpha: {best_alpha_final:.6f}\")\n",
    "except Exception as e:\n",
    "    print(f\"  训练最终 Pipeline 时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 12. 在训练集上评估最终模型 (原始价格空间) ---\n",
    "print(\"\\n--- 在完整训练集上评估最终 Ridge 模型 (原始价格空间) ---\")\n",
    "try:\n",
    "    y_train_pred_log = final_pipeline.predict(X_train_final)\n",
    "    rmse_train, mae_train, medae_train = calculate_metrics(y_train, y_train_pred_log)\n",
    "    print(f\"  训练集 RMSE (原): {rmse_train:.2f}\")\n",
    "    print(f\"  训练集 MAE  (原): {mae_train:.2f}\")\n",
    "    print(f\"  训练集 MedAE(原): {medae_train:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"  评估训练集时出错: {e}\")\n",
    "\n",
    "# --- 13. 在测试集上进行预测 ---\n",
    "print(\"\\n--- 在测试集上进行预测 ---\")\n",
    "try:\n",
    "    predictions_log = final_pipeline.predict(X_test_final)\n",
    "    predictions = np.expm1(predictions_log)\n",
    "    print(\"  预测完成并已转换回原始价格空间。\")\n",
    "    if np.any(predictions < 0):\n",
    "        print(f\"  警告: 发现 {np.sum(predictions < 0)} 个负数预测值，将修正为 0。\")\n",
    "        predictions = np.clip(predictions, a_min=0, a_max=None)\n",
    "except Exception as e:\n",
    "    print(f\"  在测试集上预测时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 14. 创建并保存提交文件 ---\n",
    "print(f\"\\n--- 创建并保存提交文件到 '{OUTPUT_FOLDER}' ---\")\n",
    "submission_df = pd.DataFrame({\n",
    "    ID_COLUMN: test_ids,\n",
    "    'PredictedPrice': predictions\n",
    "})\n",
    "submission_df[ID_COLUMN] = submission_df[ID_COLUMN].astype(int)\n",
    "submission_df = submission_df.sort_values(by=ID_COLUMN)\n",
    "try:\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, OUTPUT_FILE)\n",
    "    submission_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"✓ 提交文件已成功保存: {output_path}\")\n",
    "    print(f\"  总预测条数: {len(submission_df)}\")\n",
    "    print(\"\\n提交文件预览 (前5行):\")\n",
    "    print(submission_df.head())\n",
    "except Exception as e:\n",
    "    print(f\"✗ 保存提交文件时出错: {e}\")\n",
    "\n",
    "print(\"\\n--- 叶节点编码 + 自动搜索 Top N + RidgeCV (Log Target) 预测流程完成 ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
