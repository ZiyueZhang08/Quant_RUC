{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d74e6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出文件夹 'LeafEncoding_Ridge_Prediction' 已创建或已存在。\n",
      "\n",
      "--- 从 'Feature_Selected_Data' 加载 Price 数据 ---\n",
      "Price 数据加载成功。\n",
      "  训练集形状: (103871, 150)\n",
      "  测试集形状: (34017, 150)\n",
      "\n",
      "--- 准备训练和测试数据 ---\n",
      "  警告: 训练集发现非数值列，将移除: ['楼层_中楼层', '楼层_低楼层', '楼层_地下室', '楼层_底层', '楼层_顶层', '楼层_高楼层', '环线_三至四环', '环线_中环至外环', '环线_二环内', '环线_二至三环', '环线_五至六环', '环线_六环外', '环线_内环内', '环线_内环至中环', '环线_内环至外环', '环线_四至五环', '环线_外环外', '环线_无环线', '电梯_无', '电梯_有', '电梯_未知', '建筑结构_未知结构', '建筑结构_框架结构', '建筑结构_混合结构', '建筑结构_砖木结构', '建筑结构_砖混结构', '建筑结构_钢混结构', '建筑结构_钢结构', '装修_精装', '装修_简装', '装修_毛坯', '装修_其他', '装修_未知', '别墅_双拼', '别墅_叠拼', '别墅_独栋', '别墅_联排', '别墅_非别墅', '产权所属_共有', '产权所属_非共有']\n",
      "  对齐后特征形状: Train=(103871, 109), Test=(34017, 109)\n",
      "  使用中位数填充缺失值...\n",
      "  缺失值填充完成。\n",
      "\n",
      "--- 训练 Gradient Boosting 模型以生成叶节点特征 ---\n",
      "  使用以下参数训练 GBRT: {'n_estimators': 100, 'max_depth': 5, 'min_samples_leaf': 30, 'learning_rate': 0.1, 'subsample': 0.7, 'random_state': 42}\n",
      "  GBRT 模型训练完成。\n",
      "\n",
      "--- 获取叶节点索引 ---\n",
      "  训练集叶节点索引形状: (103871, 100)\n",
      "  测试集叶节点索引形状: (34017, 100)\n",
      "\n",
      "--- 对叶节点索引进行 One-Hot 编码 ---\n",
      "  编码后训练集特征形状 (稀疏): (103871, 2598)\n",
      "  编码后测试集特征形状 (稀疏): (34017, 2598)\n",
      "  生成了 2598 个叶节点二元特征。\n",
      "\n",
      "  本次只使用编码后的叶节点特征作为最终输入。\n",
      "\n",
      "--- 定义评价标准 (MAE) ---\n",
      "MAE 评价标准已创建 (得分越低越好)。\n",
      "\n",
      "--- 定义并训练最终的 RidgeCV 模型 ---\n",
      "  开始训练最终的 RidgeCV Pipeline...\n",
      "  RidgeCV Pipeline 训练完成。\n",
      "  RidgeCV 找到的最佳 alpha: 10000.000000\n",
      "\n",
      "--- 在完整训练集上评估最终 Ridge 模型 ---\n",
      "  训练集 RMSE:  530872.2111\n",
      "  训练集 MAE:    295611.7286\n",
      "  训练集 MedAE: 171295.7304\n",
      "\n",
      "--- 在测试集上进行预测 ---\n",
      "  预测完成。\n",
      "\n",
      "--- 创建并保存提交文件到 'LeafEncoding_Ridge_Prediction' ---\n",
      "✓ 提交文件已成功保存: LeafEncoding_Ridge_Prediction/submission_leaf_ridge_mae.csv\n",
      "  总预测条数: 34017\n",
      "\n",
      "提交文件预览 (前5行):\n",
      "        ID  PredictedPrice\n",
      "0  1000000    1.609129e+07\n",
      "1  1000001    3.279515e+06\n",
      "2  1000002    3.618020e+06\n",
      "3  1000003    2.282559e+06\n",
      "4  1000004    1.090587e+07\n",
      "\n",
      "--- 叶节点编码 + RidgeCV 预测流程完成 ---\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 完整脚本：叶节点编码 + RidgeCV 房价预测 (Price Prediction)\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib # 用于将来可能保存对象\n",
    "from sklearn.model_selection import KFold # 只导入 KFold，因为 RidgeCV 内置 CV\n",
    "from sklearn.ensemble import GradientBoostingRegressor # 用于叶节点编码\n",
    "from sklearn.linear_model import RidgeCV # 最终的正则化线性模型\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error, median_absolute_error # 导入所有需要的指标函数\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.sparse import hstack, csr_matrix # 用于组合稀疏和稠密矩阵 (如果需要)\n",
    "\n",
    "# --- 1. 配置 ---\n",
    "# 输入文件夹 (包含 _selected.csv 文件)\n",
    "INPUT_FOLDER = 'Feature_Selected_Data'\n",
    "# 输出文件夹 (存放本次预测结果)\n",
    "OUTPUT_FOLDER = 'LeafEncoding_Ridge_Prediction'\n",
    "# 输入文件名\n",
    "TRAIN_PRICE_FILE = 'train_price_selected.csv'\n",
    "TEST_PRICE_FILE = 'test_price_selected.csv'\n",
    "# 输出文件名\n",
    "OUTPUT_FILE = 'submission_leaf_ridge_mae.csv'\n",
    "\n",
    "TARGET_COLUMN = 'Price'\n",
    "ID_COLUMN = 'ID'\n",
    "\n",
    "RANDOM_STATE = 42 # 保证结果可复现\n",
    "\n",
    "# GBRT 参数 (用于生成叶节点)\n",
    "GBRT_PARAMS = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 30,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.7,\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "# RidgeCV 参数\n",
    "RIDGE_ALPHAS = np.logspace(-3, 5, 9) # alpha 搜索范围\n",
    "RIDGE_CV_FOLDS = 5 # RidgeCV 内部交叉验证折数\n",
    "\n",
    "# --- 2. 创建输出文件夹 ---\n",
    "try:\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "    print(f\"输出文件夹 '{OUTPUT_FOLDER}' 已创建或已存在。\")\n",
    "except OSError as e:\n",
    "    print(f\"创建文件夹 '{OUTPUT_FOLDER}' 时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. 加载经过特征筛选的数据 ---\n",
    "print(f\"\\n--- 从 '{INPUT_FOLDER}' 加载 Price 数据 ---\")\n",
    "try:\n",
    "    train_df = pd.read_csv(os.path.join(INPUT_FOLDER, TRAIN_PRICE_FILE), encoding='utf-8-sig')\n",
    "    test_df = pd.read_csv(os.path.join(INPUT_FOLDER, TEST_PRICE_FILE), encoding='utf-8-sig')\n",
    "    print(\"Price 数据加载成功。\")\n",
    "    print(f\"  训练集形状: {train_df.shape}\")\n",
    "    print(f\"  测试集形状: {test_df.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"加载数据时出错: {e}. 请确保文件路径正确。\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"加载数据时发生其他错误: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 存储测试集的 ID\n",
    "test_ids = test_df[ID_COLUMN].copy()\n",
    "\n",
    "# --- 4. 准备数据 (分离 X/y, 对齐, 填充 NaN) ---\n",
    "print(\"\\n--- 准备训练和测试数据 ---\")\n",
    "try:\n",
    "    y_train = train_df[TARGET_COLUMN]\n",
    "    X_train = train_df.drop(columns=[TARGET_COLUMN])\n",
    "    X_test = test_df.drop(columns=[ID_COLUMN])\n",
    "\n",
    "    # 移除可能残余的非数值列\n",
    "    non_numeric_train = X_train.select_dtypes(exclude=np.number).columns\n",
    "    if not non_numeric_train.empty:\n",
    "        print(f\"  警告: 训练集发现非数值列，将移除: {non_numeric_train.tolist()}\")\n",
    "        X_train = X_train.drop(columns=non_numeric_train)\n",
    "    non_numeric_test = X_test.select_dtypes(exclude=np.number).columns\n",
    "    if not non_numeric_test.empty:\n",
    "         X_test = X_test.drop(columns=non_numeric_test)\n",
    "\n",
    "    # 对齐列\n",
    "    train_cols = X_train.columns\n",
    "    test_cols = X_test.columns\n",
    "    missing_in_test = set(train_cols) - set(test_cols)\n",
    "    for c in missing_in_test: X_test[c] = 0\n",
    "    extra_in_test = set(test_cols) - set(train_cols)\n",
    "    if extra_in_test: X_test = X_test.drop(columns=list(extra_in_test))\n",
    "    X_test = X_test[train_cols] # 确保顺序一致\n",
    "\n",
    "    print(f\"  对齐后特征形状: Train={X_train.shape}, Test={X_test.shape}\")\n",
    "\n",
    "    # **填充缺失值**\n",
    "    print(\"  使用中位数填充缺失值...\")\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    # 使用 NumPy 数组进行后续处理效率更高\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    print(\"  缺失值填充完成。\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"数据准备时发生错误: {e}\")\n",
    "     exit()\n",
    "\n",
    "# --- 5. 训练 GBRT 模型以生成叶节点 ---\n",
    "print(\"\\n--- 训练 Gradient Boosting 模型以生成叶节点特征 ---\")\n",
    "gbrt = GradientBoostingRegressor(**GBRT_PARAMS)\n",
    "try:\n",
    "    print(f\"  使用以下参数训练 GBRT: {GBRT_PARAMS}\")\n",
    "    # GBRT 可以直接接受 NumPy 数组\n",
    "    gbrt.fit(X_train_imputed, y_train)\n",
    "    print(\"  GBRT 模型训练完成。\")\n",
    "except Exception as e:\n",
    "    print(f\"  训练 GBRT 时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 6. 获取叶节点索引 ---\n",
    "print(\"\\n--- 获取叶节点索引 ---\")\n",
    "try:\n",
    "    train_leaf_indices = gbrt.apply(X_train_imputed)\n",
    "    test_leaf_indices = gbrt.apply(X_test_imputed)\n",
    "    print(f\"  训练集叶节点索引形状: {train_leaf_indices.shape}\")\n",
    "    print(f\"  测试集叶节点索引形状: {test_leaf_indices.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"  获取叶节点索引时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 7. 对叶节点索引进行 One-Hot 编码 ---\n",
    "print(\"\\n--- 对叶节点索引进行 One-Hot 编码 ---\")\n",
    "leaf_encoder = OneHotEncoder(handle_unknown='ignore', )\n",
    "try:\n",
    "    X_train_leaves_encoded = leaf_encoder.fit_transform(train_leaf_indices)\n",
    "    X_test_leaves_encoded = leaf_encoder.transform(test_leaf_indices)\n",
    "    print(f\"  编码后训练集特征形状 (稀疏): {X_train_leaves_encoded.shape}\")\n",
    "    print(f\"  编码后测试集特征形状 (稀疏): {X_test_leaves_encoded.shape}\")\n",
    "    n_leaf_features = X_train_leaves_encoded.shape[1]\n",
    "    print(f\"  生成了 {n_leaf_features} 个叶节点二元特征。\")\n",
    "except Exception as e:\n",
    "    print(f\"  One-Hot 编码时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 8. 准备最终特征集 (本次只使用叶节点) ---\n",
    "X_train_final = X_train_leaves_encoded\n",
    "X_test_final = X_test_leaves_encoded\n",
    "print(\"\\n  本次只使用编码后的叶节点特征作为最终输入。\")\n",
    "\n",
    "\n",
    "# --- 9. 定义评价标准 (MAE Scorer) - 解决 NameError 的关键 ---\n",
    "print(\"\\n--- 定义评价标准 (MAE) ---\")\n",
    "# ！！！在这里定义 mae_scorer ！！！\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "print(\"MAE 评价标准已创建 (得分越低越好)。\")\n",
    "\n",
    "# 定义辅助函数用于后续评估\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    medae = median_absolute_error(y_true, y_pred)\n",
    "    return rmse, mae, medae\n",
    "\n",
    "# --- 10. 定义并训练最终的 RidgeCV 模型 ---\n",
    "print(\"\\n--- 定义并训练最终的 RidgeCV 模型 ---\")\n",
    "\n",
    "ridge_cv_model = RidgeCV(\n",
    "    alphas=RIDGE_ALPHAS,\n",
    "    cv=RIDGE_CV_FOLDS,\n",
    "    scoring=mae_scorer, # 使用上面定义的 mae_scorer\n",
    "    store_cv_values=False\n",
    ")\n",
    "\n",
    "# 构建最终的 Pipeline\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)), # 稀疏矩阵不中心化\n",
    "    ('model', ridge_cv_model)\n",
    "])\n",
    "\n",
    "try:\n",
    "    print(\"  开始训练最终的 RidgeCV Pipeline...\")\n",
    "    final_pipeline.fit(X_train_final, y_train)\n",
    "    print(\"  RidgeCV Pipeline 训练完成。\")\n",
    "    best_alpha = final_pipeline.named_steps['model'].alpha_\n",
    "    print(f\"  RidgeCV 找到的最佳 alpha: {best_alpha:.6f}\")\n",
    "except Exception as e:\n",
    "    print(f\"  训练 RidgeCV 时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 11. 在训练集上评估最终模型 ---\n",
    "print(\"\\n--- 在完整训练集上评估最终 Ridge 模型 ---\")\n",
    "try:\n",
    "    y_train_pred = final_pipeline.predict(X_train_final)\n",
    "    rmse_train, mae_train, medae_train = calculate_metrics(y_train, y_train_pred)\n",
    "    print(f\"  训练集 RMSE:  {rmse_train:.4f}\")\n",
    "    print(f\"  训练集 MAE:    {mae_train:.4f}\")\n",
    "    print(f\"  训练集 MedAE: {medae_train:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"  评估训练集时出错: {e}\")\n",
    "\n",
    "# --- 12. 在测试集上进行预测 ---\n",
    "print(\"\\n--- 在测试集上进行预测 ---\")\n",
    "try:\n",
    "    predictions = final_pipeline.predict(X_test_final)\n",
    "    print(\"  预测完成。\")\n",
    "except Exception as e:\n",
    "    print(f\"  在测试集上预测时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 13. 创建并保存提交文件 ---\n",
    "print(f\"\\n--- 创建并保存提交文件到 '{OUTPUT_FOLDER}' ---\")\n",
    "submission_df = pd.DataFrame({\n",
    "    ID_COLUMN: test_ids,\n",
    "    'PredictedPrice': predictions\n",
    "})\n",
    "submission_df[ID_COLUMN] = submission_df[ID_COLUMN].astype(int)\n",
    "submission_df = submission_df.sort_values(by=ID_COLUMN)\n",
    "try:\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, OUTPUT_FILE)\n",
    "    submission_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"✓ 提交文件已成功保存: {output_path}\")\n",
    "    print(f\"  总预测条数: {len(submission_df)}\")\n",
    "    print(\"\\n提交文件预览 (前5行):\")\n",
    "    print(submission_df.head())\n",
    "except Exception as e:\n",
    "    print(f\"✗ 保存提交文件时出错: {e}\")\n",
    "\n",
    "print(\"\\n--- 叶节点编码 + RidgeCV 预测流程完成 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e39410b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出文件夹 'LeafEncoding_Combined_Ridge_Prediction_Log' 已创建或已存在。\n",
      "\n",
      "--- 从 'Feature_Selected_Data' 加载 Price 数据 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price 数据加载成功。\n",
      "\n",
      "--- 转换布尔列 (True/False) 为整数 (1/0) ---\n",
      "  转换 train_df 中的 40 个布尔列...\n",
      "  转换 test_df 中的 40 个布尔列...\n",
      "--- 布尔列转换完成 ---\n",
      "\n",
      "--- 准备训练和测试数据 ---\n",
      "  已对目标变量 'Price' 应用 log1p 转换。\n",
      "  对齐后特征形状: Train=(103871, 149), Test=(34017, 149)\n",
      "  使用中位数填充缺失值...\n",
      "  缺失值填充完成。\n",
      "\n",
      "--- 训练 Gradient Boosting 模型以生成叶节点特征 ---\n",
      "  使用以下参数训练 GBRT: {'n_estimators': 150, 'max_depth': 4, 'min_samples_leaf': 30, 'learning_rate': 0.1, 'subsample': 0.7, 'random_state': 42}\n",
      "  GBRT 模型训练完成。\n",
      "  识别出 Top 10 原始特征: ['面积_数值', '城市_0', 'lon', 'lat', '环线_无环线', '燃气费_数值', '停车费用_数值', '城市_4', '房屋优势_地铁', 'coord_x']\n",
      "\n",
      "--- 获取叶节点索引 ---\n",
      "\n",
      "--- 对叶节点索引进行 One-Hot 编码 ---\n",
      "  生成了 2332 个叶节点二元特征。\n",
      "\n",
      "--- 组合叶节点特征与 Top 10 原始特征 ---\n",
      "  组合后最终特征形状: Train=(103871, 2342), Test=(34017, 2342)\n",
      "\n",
      "--- 定义评价标准 (MAE) ---\n",
      "MAE 评价标准已创建 (得分越低越好)。\n",
      "\n",
      "--- 定义最终的 RidgeCV Pipeline ---\n",
      "\n",
      "--- 使用 6-折交叉验证评估最终 Pipeline (MAE in log space) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  交叉验证得分 (负 Log MAE): -0.1218 +/- 0.0005\n",
      "  交叉验证得分 (Log MAE): 0.1218\n",
      "\n",
      "--- 在全部训练数据上训练最终的 RidgeCV Pipeline ---\n",
      "  最终 Pipeline 训练完成。\n",
      "  RidgeCV 找到的最佳 alpha: 7196.856730\n",
      "\n",
      "--- 在完整训练集上评估最终 Ridge 模型 (原始价格空间) ---\n",
      "  训练集 RMSE (原): 620387.86\n",
      "  训练集 MAE  (原): 278930.43\n",
      "  训练集 MedAE(原): 128644.98\n",
      "\n",
      "--- 在测试集上进行预测 ---\n",
      "  预测完成并已转换回原始价格空间。\n",
      "\n",
      "--- 创建并保存提交文件到 'LeafEncoding_Combined_Ridge_Prediction_Log' ---\n",
      "✓ 提交文件已成功保存: LeafEncoding_Combined_Ridge_Prediction_Log/submission_leaf_combined_ridge_log_mae.csv\n",
      "  总预测条数: 34017\n",
      "\n",
      "提交文件预览 (前5行):\n",
      "        ID  PredictedPrice\n",
      "0  1000000    1.639172e+07\n",
      "1  1000001    3.223934e+06\n",
      "2  1000002    3.787890e+06\n",
      "3  1000003    1.988437e+06\n",
      "4  1000004    1.017167e+07\n",
      "\n",
      "--- 叶节点编码 + Top Features + RidgeCV (Log Target) 预测流程完成 ---\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 完整脚本：叶节点编码 + Top Features + RidgeCV 房价预测 (Price Prediction) - V3 (Log Target, Combined Features, External CV)\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib # 用于将来可能保存对象\n",
    "from sklearn.model_selection import KFold, cross_val_score # 导入 cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error, median_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.sparse import hstack, csr_matrix # 用于组合稀疏和稠密矩阵\n",
    "\n",
    "# --- 1. 配置 ---\n",
    "INPUT_FOLDER = 'Feature_Selected_Data'\n",
    "OUTPUT_FOLDER = 'LeafEncoding_Combined_Ridge_Prediction_Log' # 更新文件夹名\n",
    "TRAIN_PRICE_FILE = 'train_price_selected.csv'\n",
    "TEST_PRICE_FILE = 'test_price_selected.csv'\n",
    "OUTPUT_FILE = 'submission_leaf_combined_ridge_log_mae.csv' # 更新文件名\n",
    "\n",
    "TARGET_COLUMN = 'Price'\n",
    "ID_COLUMN = 'ID'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# GBRT 参数 (调整后)\n",
    "GBRT_PARAMS = {\n",
    "    'n_estimators': 150,      # 稍微增加树的数量\n",
    "    'max_depth': 4,          # 稍微降低树的深度\n",
    "    'min_samples_leaf': 30,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.7,\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "# 保留多少个最重要的原始特征与叶节点结合\n",
    "N_TOP_ORIGINAL_FEATURES = 10 \n",
    "\n",
    "# RidgeCV 参数\n",
    "RIDGE_ALPHAS = np.logspace(-4, 6, 15) # 保持精细的 Alpha 范围\n",
    "RIDGE_CV_FOLDS = 5 # RidgeCV 内部交叉验证折数\n",
    "\n",
    "# 外部交叉验证折数 (用于最终评估)\n",
    "EXTERNAL_CV_FOLDS = 6 # 您之前要求的 6 折\n",
    "\n",
    "# --- 2. 创建输出文件夹 ---\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "print(f\"输出文件夹 '{OUTPUT_FOLDER}' 已创建或已存在。\")\n",
    "\n",
    "# --- 3. 加载数据 ---\n",
    "print(f\"\\n--- 从 '{INPUT_FOLDER}' 加载 Price 数据 ---\")\n",
    "try:\n",
    "    train_df = pd.read_csv(os.path.join(INPUT_FOLDER, TRAIN_PRICE_FILE), encoding='utf-8-sig')\n",
    "    test_df = pd.read_csv(os.path.join(INPUT_FOLDER, TEST_PRICE_FILE), encoding='utf-8-sig')\n",
    "    print(\"Price 数据加载成功。\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"加载数据时出错: {e}. 请确保文件路径正确。\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"加载数据时发生其他错误: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 转换布尔列 ---\n",
    "print(\"\\n--- 转换布尔列 (True/False) 为整数 (1/0) ---\")\n",
    "# (省略了详细打印，假设之前的步骤已完成)\n",
    "for df_name in ['train_df', 'test_df']:\n",
    "    df_obj = globals()[df_name]\n",
    "    bool_columns = df_obj.select_dtypes(include='bool').columns\n",
    "    if not bool_columns.empty:\n",
    "        print(f\"  转换 {df_name} 中的 {len(bool_columns)} 个布尔列...\")\n",
    "        for col in bool_columns:\n",
    "            df_obj.loc[:, col] = df_obj[col].astype(int)\n",
    "print(\"--- 布尔列转换完成 ---\")\n",
    "\n",
    "# 存储测试集的 ID\n",
    "test_ids = test_df[ID_COLUMN].copy()\n",
    "\n",
    "# --- 4. 准备数据 (分离 X/y, Log Transform y, 对齐, 填充 NaN) ---\n",
    "print(\"\\n--- 准备训练和测试数据 ---\")\n",
    "try:\n",
    "    # !!! 应用 Log Transform !!!\n",
    "    y_train = np.log1p(train_df[TARGET_COLUMN])\n",
    "    print(f\"  已对目标变量 '{TARGET_COLUMN}' 应用 log1p 转换。\")\n",
    "    \n",
    "    X_train = train_df.drop(columns=[TARGET_COLUMN])\n",
    "    X_test = test_df.drop(columns=[ID_COLUMN])\n",
    "\n",
    "    # 移除可能残余的非数值列\n",
    "    non_numeric_train = X_train.select_dtypes(exclude=np.number).columns\n",
    "    if not non_numeric_train.empty:\n",
    "        print(f\"  警告: 训练集发现非数值列，将移除: {non_numeric_train.tolist()}\")\n",
    "        X_train = X_train.drop(columns=non_numeric_train)\n",
    "    non_numeric_test = X_test.select_dtypes(exclude=np.number).columns\n",
    "    if not non_numeric_test.empty:\n",
    "         X_test = X_test.drop(columns=non_numeric_test)\n",
    "\n",
    "    # 对齐列\n",
    "    train_cols = X_train.columns # 保存列名以供后续使用\n",
    "    test_cols = X_test.columns\n",
    "    missing_in_test = set(train_cols) - set(test_cols)\n",
    "    for c in missing_in_test: X_test[c] = 0\n",
    "    extra_in_test = set(test_cols) - set(train_cols)\n",
    "    if extra_in_test: X_test = X_test.drop(columns=list(extra_in_test))\n",
    "    X_test = X_test[train_cols] \n",
    "\n",
    "    print(f\"  对齐后特征形状: Train={X_train.shape}, Test={X_test.shape}\")\n",
    "\n",
    "    # **填充缺失值**\n",
    "    print(\"  使用中位数填充缺失值...\")\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    print(\"  缺失值填充完成。\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"数据准备时发生错误: {e}\")\n",
    "     exit()\n",
    "\n",
    "# --- 5. 训练 GBRT 模型以生成叶节点 & 获取特征重要性 ---\n",
    "print(\"\\n--- 训练 Gradient Boosting 模型以生成叶节点特征 ---\")\n",
    "gbrt = GradientBoostingRegressor(**GBRT_PARAMS)\n",
    "try:\n",
    "    print(f\"  使用以下参数训练 GBRT: {GBRT_PARAMS}\")\n",
    "    # GBRT 在填充后的 NumPy 数组上训练\n",
    "    gbrt.fit(X_train_imputed, y_train) # 注意 y_train 是 log 转换后的\n",
    "    print(\"  GBRT 模型训练完成。\")\n",
    "\n",
    "    # 获取特征重要性\n",
    "    importances = gbrt.feature_importances_\n",
    "    # 获取 Top N 特征的索引和名称\n",
    "    top_n_indices = np.argsort(importances)[::-1][:N_TOP_ORIGINAL_FEATURES]\n",
    "    top_n_features = train_cols[top_n_indices].tolist() # 使用之前保存的列名\n",
    "    print(f\"  识别出 Top {N_TOP_ORIGINAL_FEATURES} 原始特征: {top_n_features}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  训练 GBRT 或获取重要性时出错: {e}\")\n",
    "    # 即使出错，也继续尝试叶节点编码，但不添加原始特征\n",
    "    top_n_features = [] \n",
    "    # exit() # 如果希望严格要求特征重要性计算成功，则取消此行注释\n",
    "\n",
    "# --- 6. 获取叶节点索引 ---\n",
    "print(\"\\n--- 获取叶节点索引 ---\")\n",
    "try:\n",
    "    train_leaf_indices = gbrt.apply(X_train_imputed)\n",
    "    test_leaf_indices = gbrt.apply(X_test_imputed)\n",
    "except Exception as e:\n",
    "    print(f\"  获取叶节点索引时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 7. 对叶节点索引进行 One-Hot 编码 ---\n",
    "print(\"\\n--- 对叶节点索引进行 One-Hot 编码 ---\")\n",
    "leaf_encoder = OneHotEncoder(handle_unknown='ignore', )\n",
    "try:\n",
    "    X_train_leaves_encoded = leaf_encoder.fit_transform(train_leaf_indices)\n",
    "    X_test_leaves_encoded = leaf_encoder.transform(test_leaf_indices)\n",
    "    n_leaf_features = X_train_leaves_encoded.shape[1]\n",
    "    print(f\"  生成了 {n_leaf_features} 个叶节点二元特征。\")\n",
    "except Exception as e:\n",
    "    print(f\"  One-Hot 编码时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 8. 组合叶节点特征与 Top N 原始特征 ---\n",
    "print(f\"\\n--- 组合叶节点特征与 Top {len(top_n_features)} 原始特征 ---\")\n",
    "try:\n",
    "    if top_n_features:\n",
    "        # 从填充后的 NumPy 数组中按索引选取 Top N 特征\n",
    "        X_train_top_features = X_train_imputed[:, top_n_indices]\n",
    "        X_test_top_features = X_test_imputed[:, top_n_indices]\n",
    "\n",
    "        # 使用 hstack 组合（需要将稠密部分转为 CSR 稀疏格式）\n",
    "        X_train_final = hstack([X_train_leaves_encoded, csr_matrix(X_train_top_features)])\n",
    "        X_test_final = hstack([X_test_leaves_encoded, csr_matrix(X_test_top_features)])\n",
    "        print(f\"  组合后最终特征形状: Train={X_train_final.shape}, Test={X_test_final.shape}\")\n",
    "    else:\n",
    "        # 如果没有 top_n_features (例如 GBRT 训练失败)，只用叶节点\n",
    "        X_train_final = X_train_leaves_encoded\n",
    "        X_test_final = X_test_leaves_encoded\n",
    "        print(\"  只使用编码后的叶节点特征。\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  组合特征时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 9. 定义评价标准 (MAE Scorer) ---\n",
    "print(\"\\n--- 定义评价标准 (MAE) ---\")\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "print(\"MAE 评价标准已创建 (得分越低越好)。\")\n",
    "# 辅助函数\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    # !!! 注意: 这里的 y_true 和 y_pred 都是 log 转换后的 !!!\n",
    "    # 计算 log 空间上的指标\n",
    "    rmse_log = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae_log = mean_absolute_error(y_true, y_pred)\n",
    "    medae_log = median_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # 计算原始价格空间上的指标 (需要逆转换)\n",
    "    y_true_orig = np.expm1(y_true)\n",
    "    y_pred_orig = np.expm1(y_pred)\n",
    "    rmse_orig = np.sqrt(mean_squared_error(y_true_orig, y_pred_orig))\n",
    "    mae_orig = mean_absolute_error(y_true_orig, y_pred_orig)\n",
    "    medae_orig = median_absolute_error(y_true_orig, y_pred_orig)\n",
    "    \n",
    "    # 返回原始空间的指标以供最终评估\n",
    "    return rmse_orig, mae_orig, medae_orig\n",
    "\n",
    "\n",
    "# --- 10. 定义最终的 RidgeCV Pipeline ---\n",
    "print(\"\\n--- 定义最终的 RidgeCV Pipeline ---\")\n",
    "ridge_cv_model = RidgeCV(\n",
    "    alphas=RIDGE_ALPHAS,\n",
    "    cv=RIDGE_CV_FOLDS,\n",
    "    scoring=mae_scorer, # RidgeCV 内部仍然优化 log 空间上的 MAE\n",
    "    store_cv_values=False\n",
    ")\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)), # 稀疏矩阵不中心化\n",
    "    ('model', ridge_cv_model)\n",
    "])\n",
    "\n",
    "# --- 11. 外部交叉验证评估 Pipeline ---\n",
    "print(f\"\\n--- 使用 {EXTERNAL_CV_FOLDS}-折交叉验证评估最终 Pipeline (MAE in log space) ---\")\n",
    "try:\n",
    "    # 使用 KFold 进行外部 CV\n",
    "    external_cv = KFold(n_splits=EXTERNAL_CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    # 在 log 空间上计算 MAE\n",
    "    cv_scores_log_mae = cross_val_score(final_pipeline, X_train_final, y_train, \n",
    "                                        cv=external_cv, scoring=mae_scorer, n_jobs=-1)\n",
    "    \n",
    "    mean_cv_log_mae = np.mean(cv_scores_log_mae)\n",
    "    std_cv_log_mae = np.std(cv_scores_log_mae)\n",
    "    \n",
    "    print(f\"  交叉验证得分 (负 Log MAE): {mean_cv_log_mae:.4f} +/- {std_cv_log_mae:.4f}\")\n",
    "    print(f\"  交叉验证得分 (Log MAE): {-mean_cv_log_mae:.4f}\") # 打印正的 Log MAE\n",
    "\n",
    "    # **重要**: 这个 CV MAE 是在 log 空间上的，不直接等于原始价格空间的 MAE\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  外部交叉验证时出错: {e}\")\n",
    "    # 即使 CV 出错，也继续尝试训练最终模型\n",
    "\n",
    "# --- 12. 在全部训练数据上训练最终 Pipeline ---\n",
    "print(\"\\n--- 在全部训练数据上训练最终的 RidgeCV Pipeline ---\")\n",
    "try:\n",
    "    final_pipeline.fit(X_train_final, y_train)\n",
    "    print(\"  最终 Pipeline 训练完成。\")\n",
    "    best_alpha = final_pipeline.named_steps['model'].alpha_\n",
    "    print(f\"  RidgeCV 找到的最佳 alpha: {best_alpha:.6f}\")\n",
    "except Exception as e:\n",
    "    print(f\"  训练最终 Pipeline 时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 13. 在训练集上评估最终模型 (原始价格空间) ---\n",
    "print(\"\\n--- 在完整训练集上评估最终 Ridge 模型 (原始价格空间) ---\")\n",
    "try:\n",
    "    y_train_pred_log = final_pipeline.predict(X_train_final)\n",
    "    # 使用更新后的 calculate_metrics 函数，它会返回原始空间的指标\n",
    "    rmse_train, mae_train, medae_train = calculate_metrics(y_train, y_train_pred_log) \n",
    "    print(f\"  训练集 RMSE (原): {rmse_train:.2f}\")\n",
    "    print(f\"  训练集 MAE  (原): {mae_train:.2f}\")\n",
    "    print(f\"  训练集 MedAE(原): {medae_train:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"  评估训练集时出错: {e}\")\n",
    "\n",
    "# --- 14. 在测试集上进行预测 ---\n",
    "print(\"\\n--- 在测试集上进行预测 ---\")\n",
    "try:\n",
    "    predictions_log = final_pipeline.predict(X_test_final)\n",
    "    # !!! 逆转换回原始价格空间 !!!\n",
    "    predictions = np.expm1(predictions_log)\n",
    "    print(\"  预测完成并已转换回原始价格空间。\")\n",
    "    \n",
    "    # 检查是否有负数预测 (log转换后理论上不会，但 expm1 可能产生接近0的负数)\n",
    "    if np.any(predictions < 0):\n",
    "        print(f\"  警告: 发现 {np.sum(predictions < 0)} 个负数预测值，将修正为 0。\")\n",
    "        predictions = np.clip(predictions, a_min=0, a_max=None)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  在测试集上预测时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 15. 创建并保存提交文件 ---\n",
    "print(f\"\\n--- 创建并保存提交文件到 '{OUTPUT_FOLDER}' ---\")\n",
    "submission_df = pd.DataFrame({\n",
    "    ID_COLUMN: test_ids,\n",
    "    'PredictedPrice': predictions\n",
    "})\n",
    "submission_df[ID_COLUMN] = submission_df[ID_COLUMN].astype(int)\n",
    "submission_df = submission_df.sort_values(by=ID_COLUMN)\n",
    "try:\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, OUTPUT_FILE)\n",
    "    submission_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"✓ 提交文件已成功保存: {output_path}\")\n",
    "    print(f\"  总预测条数: {len(submission_df)}\")\n",
    "    print(\"\\n提交文件预览 (前5行):\")\n",
    "    print(submission_df.head())\n",
    "except Exception as e:\n",
    "    print(f\"✗ 保存提交文件时出错: {e}\")\n",
    "\n",
    "print(\"\\n--- 叶节点编码 + Top Features + RidgeCV (Log Target) 预测流程完成 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32934eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出文件夹 'LeafEncoding_Combined_Lasso_Prediction_Log' 已创建或已存在。\n",
      "\n",
      "--- 从 'Feature_Selected_Data' 加载 Price 数据 ---\n",
      "Price 数据加载成功。\n",
      "\n",
      "--- 转换布尔列 (True/False) 为整数 (1/0) ---\n",
      "  转换 train_df 中的 40 个布尔列...\n",
      "  转换 test_df 中的 40 个布尔列...\n",
      "--- 布尔列转换完成 ---\n",
      "\n",
      "--- 准备训练和测试数据 ---\n",
      "  已对目标变量 'Price' 应用 log1p 转换。\n",
      "  对齐后特征形状: Train=(103871, 149), Test=(34017, 149)\n",
      "  使用中位数填充缺失值...\n",
      "  缺失值填充完成。\n",
      "\n",
      "--- 训练 Gradient Boosting 模型以生成叶节点特征 ---\n",
      "  使用以下参数训练 GBRT: {'n_estimators': 150, 'max_depth': 4, 'min_samples_leaf': 30, 'learning_rate': 0.1, 'subsample': 0.7, 'random_state': 42}\n",
      "  GBRT 模型训练完成。\n",
      "  识别出 Top 10 原始特征: ['面积_数值', '城市_0', 'lon', 'lat', '环线_无环线', '燃气费_数值', '停车费用_数值', '城市_4', '房屋优势_地铁', 'coord_x']\n",
      "\n",
      "--- 获取叶节点索引 ---\n",
      "\n",
      "--- 对叶节点索引进行 One-Hot 编码 ---\n",
      "  生成了 2332 个叶节点二元特征。\n",
      "\n",
      "--- 组合叶节点特征与 Top 10 原始特征 ---\n",
      "  组合后最终特征形状: Train=(103871, 2342), Test=(34017, 2342)\n",
      "\n",
      "--- 定义评价标准 (MAE) ---\n",
      "MAE 评价标准已创建 (得分越低越好)。\n",
      "\n",
      "--- 定义最终的 LassoCV Pipeline ---\n",
      "\n",
      "--- 使用 6-折交叉验证评估最终 Pipeline (MAE in log space) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:21: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 94.49892647950014, tolerance: 40.28371391274024\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 100.17139810897606, tolerance: 40.31978724187301\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 239.37740783089134, tolerance: 46.252179551542305\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 276.73466850171485, tolerance: 46.31973322421646\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 82.72131889200409, tolerance: 40.200807627821284\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 102.58487280896838, tolerance: 40.36810759204628\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 187.9708605484526, tolerance: 46.46133160534997\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 171.88657646402544, tolerance: 46.315035468257996\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 159.8141097174729, tolerance: 40.25589624882354\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 237.02222597880075, tolerance: 46.2429385235705\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 180.22550515621901, tolerance: 46.27031609238314\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 83.61866252498453, tolerance: 40.05139343804681\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 86.41985932467583, tolerance: 51.4013455407719\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 236.1158603115091, tolerance: 48.96942764514933\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 79.13686831842824, tolerance: 51.36548442524951\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 322.8294752539175, tolerance: 48.81179065072951\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 88.23738990559332, tolerance: 51.512700907642476\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 137.58349881158324, tolerance: 49.2736166205836\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154.4671572534471, tolerance: 49.07391876994727\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 82.13625042684976, tolerance: 51.390443879727435\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 166.70839398947044, tolerance: 49.14346998744768\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 160.33898362881996, tolerance: 49.03823028812637\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75.87187981269358, tolerance: 49.19952221459677\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 334.9165724334973, tolerance: 49.057689611857434\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 274.7938349096278, tolerance: 49.18486813769762\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 86.70765949869201, tolerance: 51.175460192348424\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 285.550509835512, tolerance: 49.006674076030976\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 305.2147548106101, tolerance: 48.785723381594\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.05114279050849, tolerance: 51.06327049109594\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 143.31054610677097, tolerance: 49.32030389619662\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  交叉验证得分 (负 Log MAE): -0.1202 +/- 0.0005\n",
      "  交叉验证得分 (Log MAE): 0.1202\n",
      "\n",
      "--- 在全部训练数据上训练最终的 LassoCV Pipeline ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 113.53534521364782, tolerance: 48.299134133143575\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 237.6739045619221, tolerance: 55.573202627624916\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 119.31632995766199, tolerance: 61.5740118687122\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 144.0948372446071, tolerance: 59.01302018927303\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "/home/lwyxyz/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 355.9581233891388, tolerance: 58.764313838668244\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  最终 Pipeline (LassoCV) 训练完成。\n",
      "  LassoCV 找到的最佳 alpha (优化 MSE): 0.000215\n",
      "  Lasso 模型使用了 1565 / 2342 个特征。\n",
      "\n",
      "--- 在完整训练集上评估最终 Lasso 模型 (原始价格空间) ---\n",
      "  训练集 RMSE (原): 616101.24\n",
      "  训练集 MAE  (原): 275292.36\n",
      "  训练集 MedAE(原): 126659.40\n",
      "\n",
      "--- 在测试集上进行预测 ---\n",
      "  预测完成并已转换回原始价格空间。\n",
      "\n",
      "--- 创建并保存提交文件到 'LeafEncoding_Combined_Lasso_Prediction_Log' ---\n",
      "✓ 提交文件已成功保存: LeafEncoding_Combined_Lasso_Prediction_Log/submission_leaf_combined_lasso_log_mae.csv\n",
      "  总预测条数: 34017\n",
      "\n",
      "提交文件预览 (前5行):\n",
      "        ID  PredictedPrice\n",
      "0  1000000    1.730230e+07\n",
      "1  1000001    3.245654e+06\n",
      "2  1000002    3.906523e+06\n",
      "3  1000003    2.002325e+06\n",
      "4  1000004    1.027640e+07\n",
      "\n",
      "--- 叶节点编码 + Top Features + LassoCV (Log Target) 预测流程完成 ---\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 完整脚本：叶节点编码 + Top Features + **LassoCV** 房价预测 (Price Prediction) - V3 (Log Target, Combined Features, External CV)\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib # 用于将来可能保存对象\n",
    "from sklearn.model_selection import KFold, cross_val_score # 导入 cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.linear_model import RidgeCV # 移除 RidgeCV\n",
    "from sklearn.linear_model import LassoCV # 导入 LassoCV\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error, median_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.sparse import hstack, csr_matrix # 用于组合稀疏和稠密矩阵\n",
    "\n",
    "# --- 1. 配置 ---\n",
    "INPUT_FOLDER = 'Feature_Selected_Data'\n",
    "OUTPUT_FOLDER = 'LeafEncoding_Combined_Lasso_Prediction_Log' # 更新文件夹名\n",
    "TRAIN_PRICE_FILE = 'train_price_selected.csv'\n",
    "TEST_PRICE_FILE = 'test_price_selected.csv'\n",
    "OUTPUT_FILE = 'submission_leaf_combined_lasso_log_mae.csv' # 更新文件名\n",
    "\n",
    "TARGET_COLUMN = 'Price'\n",
    "ID_COLUMN = 'ID'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# GBRT 参数 (保持不变)\n",
    "GBRT_PARAMS = {\n",
    "    'n_estimators': 150,\n",
    "    'max_depth': 4,\n",
    "    'min_samples_leaf': 30,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.7,\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "# 保留多少个最重要的原始特征与叶节点结合\n",
    "N_TOP_ORIGINAL_FEATURES = 10\n",
    "\n",
    "# LassoCV 参数\n",
    "LASSO_ALPHAS = np.logspace(-5, 1, 10) # Alpha 搜索范围 (Lasso 通常需要较小 alpha)\n",
    "LASSO_CV_FOLDS = 5 # LassoCV 内部交叉验证折数 (优化 MSE)\n",
    "LASSO_MAX_ITER = 3000 # 增加迭代次数\n",
    "LASSO_TOL = 1e-3 # 放宽收敛容忍度\n",
    "\n",
    "# 外部交叉验证折数 (用于最终评估 MAE)\n",
    "EXTERNAL_CV_FOLDS = 6\n",
    "\n",
    "# --- 2. 创建输出文件夹 ---\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "print(f\"输出文件夹 '{OUTPUT_FOLDER}' 已创建或已存在。\")\n",
    "\n",
    "# --- 3. 加载数据 ---\n",
    "print(f\"\\n--- 从 '{INPUT_FOLDER}' 加载 Price 数据 ---\")\n",
    "try:\n",
    "    train_df = pd.read_csv(os.path.join(INPUT_FOLDER, TRAIN_PRICE_FILE), encoding='utf-8-sig')\n",
    "    test_df = pd.read_csv(os.path.join(INPUT_FOLDER, TEST_PRICE_FILE), encoding='utf-8-sig')\n",
    "    print(\"Price 数据加载成功。\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"加载数据时出错: {e}. 请确保文件路径正确。\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"加载数据时发生其他错误: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 转换布尔列 ---\n",
    "print(\"\\n--- 转换布尔列 (True/False) 为整数 (1/0) ---\")\n",
    "# (省略了详细打印)\n",
    "for df_name in ['train_df', 'test_df']:\n",
    "    df_obj = globals()[df_name]\n",
    "    bool_columns = df_obj.select_dtypes(include='bool').columns\n",
    "    if not bool_columns.empty:\n",
    "        print(f\"  转换 {df_name} 中的 {len(bool_columns)} 个布尔列...\")\n",
    "        for col in bool_columns:\n",
    "            df_obj.loc[:, col] = df_obj[col].astype(int)\n",
    "print(\"--- 布尔列转换完成 ---\")\n",
    "\n",
    "# 存储测试集的 ID\n",
    "test_ids = test_df[ID_COLUMN].copy()\n",
    "\n",
    "# --- 4. 准备数据 (分离 X/y, Log Transform y, 对齐, 填充 NaN) ---\n",
    "print(\"\\n--- 准备训练和测试数据 ---\")\n",
    "try:\n",
    "    # !!! 应用 Log Transform !!!\n",
    "    y_train = np.log1p(train_df[TARGET_COLUMN])\n",
    "    print(f\"  已对目标变量 '{TARGET_COLUMN}' 应用 log1p 转换。\")\n",
    "\n",
    "    X_train = train_df.drop(columns=[TARGET_COLUMN])\n",
    "    X_test = test_df.drop(columns=[ID_COLUMN])\n",
    "\n",
    "    # 移除可能残余的非数值列\n",
    "    non_numeric_train = X_train.select_dtypes(exclude=np.number).columns\n",
    "    if not non_numeric_train.empty:\n",
    "        print(f\"  警告: 训练集发现非数值列，将移除: {non_numeric_train.tolist()}\")\n",
    "        X_train = X_train.drop(columns=non_numeric_train)\n",
    "    non_numeric_test = X_test.select_dtypes(exclude=np.number).columns\n",
    "    if not non_numeric_test.empty:\n",
    "         X_test = X_test.drop(columns=non_numeric_test)\n",
    "\n",
    "    # 对齐列\n",
    "    train_cols = X_train.columns # 保存列名\n",
    "    test_cols = X_test.columns\n",
    "    missing_in_test = set(train_cols) - set(test_cols)\n",
    "    for c in missing_in_test: X_test[c] = 0\n",
    "    extra_in_test = set(test_cols) - set(train_cols)\n",
    "    if extra_in_test: X_test = X_test.drop(columns=list(extra_in_test))\n",
    "    X_test = X_test[train_cols]\n",
    "\n",
    "    print(f\"  对齐后特征形状: Train={X_train.shape}, Test={X_test.shape}\")\n",
    "\n",
    "    # **填充缺失值**\n",
    "    print(\"  使用中位数填充缺失值...\")\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    print(\"  缺失值填充完成。\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"数据准备时发生错误: {e}\")\n",
    "     exit()\n",
    "\n",
    "# --- 5. 训练 GBRT 模型以生成叶节点 & 获取特征重要性 ---\n",
    "print(\"\\n--- 训练 Gradient Boosting 模型以生成叶节点特征 ---\")\n",
    "gbrt = GradientBoostingRegressor(**GBRT_PARAMS)\n",
    "try:\n",
    "    print(f\"  使用以下参数训练 GBRT: {GBRT_PARAMS}\")\n",
    "    gbrt.fit(X_train_imputed, y_train)\n",
    "    print(\"  GBRT 模型训练完成。\")\n",
    "    importances = gbrt.feature_importances_\n",
    "    top_n_indices = np.argsort(importances)[::-1][:N_TOP_ORIGINAL_FEATURES]\n",
    "    top_n_features = train_cols[top_n_indices].tolist()\n",
    "    print(f\"  识别出 Top {N_TOP_ORIGINAL_FEATURES} 原始特征: {top_n_features}\")\n",
    "except Exception as e:\n",
    "    print(f\"  训练 GBRT 或获取重要性时出错: {e}\")\n",
    "    top_n_features = []\n",
    "\n",
    "# --- 6. 获取叶节点索引 ---\n",
    "print(\"\\n--- 获取叶节点索引 ---\")\n",
    "try:\n",
    "    train_leaf_indices = gbrt.apply(X_train_imputed)\n",
    "    test_leaf_indices = gbrt.apply(X_test_imputed)\n",
    "except Exception as e:\n",
    "    print(f\"  获取叶节点索引时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 7. 对叶节点索引进行 One-Hot 编码 ---\n",
    "print(\"\\n--- 对叶节点索引进行 One-Hot 编码 ---\")\n",
    "leaf_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "try:\n",
    "    X_train_leaves_encoded = leaf_encoder.fit_transform(train_leaf_indices)\n",
    "    X_test_leaves_encoded = leaf_encoder.transform(test_leaf_indices)\n",
    "    n_leaf_features = X_train_leaves_encoded.shape[1]\n",
    "    print(f\"  生成了 {n_leaf_features} 个叶节点二元特征。\")\n",
    "except Exception as e:\n",
    "    print(f\"  One-Hot 编码时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 8. 组合叶节点特征与 Top N 原始特征 ---\n",
    "print(f\"\\n--- 组合叶节点特征与 Top {len(top_n_features)} 原始特征 ---\")\n",
    "try:\n",
    "    if top_n_features:\n",
    "        X_train_top_features = X_train_imputed[:, top_n_indices]\n",
    "        X_test_top_features = X_test_imputed[:, top_n_indices]\n",
    "        X_train_final = hstack([X_train_leaves_encoded, csr_matrix(X_train_top_features)])\n",
    "        X_test_final = hstack([X_test_leaves_encoded, csr_matrix(X_test_top_features)])\n",
    "        print(f\"  组合后最终特征形状: Train={X_train_final.shape}, Test={X_test_final.shape}\")\n",
    "    else:\n",
    "        X_train_final = X_train_leaves_encoded\n",
    "        X_test_final = X_test_leaves_encoded\n",
    "        print(\"  只使用编码后的叶节点特征。\")\n",
    "except Exception as e:\n",
    "    print(f\"  组合特征时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 9. 定义评价标准 (MAE Scorer) ---\n",
    "print(\"\\n--- 定义评价标准 (MAE) ---\")\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "print(\"MAE 评价标准已创建 (得分越低越好)。\")\n",
    "# 辅助函数\n",
    "def calculate_metrics(y_true_log, y_pred_log):\n",
    "    rmse_log = np.sqrt(mean_squared_error(y_true_log, y_pred_log))\n",
    "    mae_log = mean_absolute_error(y_true_log, y_pred_log)\n",
    "    medae_log = median_absolute_error(y_true_log, y_pred_log)\n",
    "    y_true_orig = np.expm1(y_true_log)\n",
    "    y_pred_orig = np.expm1(y_pred_log)\n",
    "    y_pred_orig = np.clip(y_pred_orig, a_min=0, a_max=None)\n",
    "    rmse_orig = np.sqrt(mean_squared_error(y_true_orig, y_pred_orig))\n",
    "    mae_orig = mean_absolute_error(y_true_orig, y_pred_orig)\n",
    "    medae_orig = median_absolute_error(y_true_orig, y_pred_orig)\n",
    "    return rmse_orig, mae_orig, medae_orig\n",
    "\n",
    "# --- 10. 定义最终的 LassoCV Pipeline ---\n",
    "print(\"\\n--- 定义最终的 LassoCV Pipeline ---\")\n",
    "lasso_cv_model = LassoCV( # 使用 LassoCV\n",
    "    alphas=LASSO_ALPHAS,       # 提供 alpha 搜索范围\n",
    "    cv=LASSO_CV_FOLDS,         # LassoCV 内部交叉验证折数 (优化 MSE)\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    max_iter=LASSO_MAX_ITER,\n",
    "    tol=LASSO_TOL\n",
    "    # LassoCV 不接受 scoring 参数\n",
    ")\n",
    "\n",
    "# 构建最终的 Pipeline\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)), # 稀疏矩阵不中心化\n",
    "    ('model', lasso_cv_model)                 # 使用 LassoCV 模型\n",
    "])\n",
    "\n",
    "# --- 11. 外部交叉验证评估 Pipeline (评估 MAE) ---\n",
    "print(f\"\\n--- 使用 {EXTERNAL_CV_FOLDS}-折交叉验证评估最终 Pipeline (MAE in log space) ---\")\n",
    "try:\n",
    "    external_cv = KFold(n_splits=EXTERNAL_CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    # 仍然使用 mae_scorer 进行外部评估\n",
    "    cv_scores_log_mae = cross_val_score(final_pipeline, X_train_final, y_train,\n",
    "                                        cv=external_cv, scoring=mae_scorer, n_jobs=-1)\n",
    "    mean_cv_log_mae = np.mean(cv_scores_log_mae)\n",
    "    std_cv_log_mae = np.std(cv_scores_log_mae)\n",
    "    print(f\"  交叉验证得分 (负 Log MAE): {mean_cv_log_mae:.4f} +/- {std_cv_log_mae:.4f}\")\n",
    "    print(f\"  交叉验证得分 (Log MAE): {-mean_cv_log_mae:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"  外部交叉验证时出错: {e}\")\n",
    "\n",
    "# --- 12. 在全部训练数据上训练最终 Pipeline ---\n",
    "print(\"\\n--- 在全部训练数据上训练最终的 LassoCV Pipeline ---\")\n",
    "try:\n",
    "    final_pipeline.fit(X_train_final, y_train)\n",
    "    print(\"  最终 Pipeline (LassoCV) 训练完成。\")\n",
    "    best_alpha = final_pipeline.named_steps['model'].alpha_\n",
    "    print(f\"  LassoCV 找到的最佳 alpha (优化 MSE): {best_alpha:.6f}\")\n",
    "    # 查看系数稀疏性\n",
    "    coefs = final_pipeline.named_steps['model'].coef_\n",
    "    print(f\"  Lasso 模型使用了 {np.sum(coefs != 0)} / {len(coefs)} 个特征。\")\n",
    "except Exception as e:\n",
    "    print(f\"  训练最终 Pipeline (LassoCV) 时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 13. 在训练集上评估最终模型 (原始价格空间) ---\n",
    "print(\"\\n--- 在完整训练集上评估最终 Lasso 模型 (原始价格空间) ---\")\n",
    "try:\n",
    "    y_train_pred_log = final_pipeline.predict(X_train_final)\n",
    "    rmse_train, mae_train, medae_train = calculate_metrics(y_train, y_train_pred_log)\n",
    "    print(f\"  训练集 RMSE (原): {rmse_train:.2f}\")\n",
    "    print(f\"  训练集 MAE  (原): {mae_train:.2f}\")\n",
    "    print(f\"  训练集 MedAE(原): {medae_train:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"  评估训练集时出错: {e}\")\n",
    "\n",
    "# --- 14. 在测试集上进行预测 ---\n",
    "print(\"\\n--- 在测试集上进行预测 ---\")\n",
    "try:\n",
    "    predictions_log = final_pipeline.predict(X_test_final)\n",
    "    predictions = np.expm1(predictions_log)\n",
    "    print(\"  预测完成并已转换回原始价格空间。\")\n",
    "    if np.any(predictions < 0):\n",
    "        print(f\"  警告: 发现 {np.sum(predictions < 0)} 个负数预测值，将修正为 0。\")\n",
    "        predictions = np.clip(predictions, a_min=0, a_max=None)\n",
    "except Exception as e:\n",
    "    print(f\"  在测试集上预测时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 15. 创建并保存提交文件 ---\n",
    "print(f\"\\n--- 创建并保存提交文件到 '{OUTPUT_FOLDER}' ---\")\n",
    "submission_df = pd.DataFrame({\n",
    "    ID_COLUMN: test_ids,\n",
    "    'PredictedPrice': predictions\n",
    "})\n",
    "submission_df[ID_COLUMN] = submission_df[ID_COLUMN].astype(int)\n",
    "submission_df = submission_df.sort_values(by=ID_COLUMN)\n",
    "try:\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, OUTPUT_FILE)\n",
    "    submission_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"✓ 提交文件已成功保存: {output_path}\")\n",
    "    print(f\"  总预测条数: {len(submission_df)}\")\n",
    "    print(\"\\n提交文件预览 (前5行):\")\n",
    "    print(submission_df.head())\n",
    "except Exception as e:\n",
    "    print(f\"✗ 保存提交文件时出错: {e}\")\n",
    "\n",
    "print(\"\\n--- 叶节点编码 + Top Features + LassoCV (Log Target) 预测流程完成 ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
