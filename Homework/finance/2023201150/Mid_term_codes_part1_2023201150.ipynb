{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13513308,"sourceType":"datasetVersion","datasetId":8579729},{"sourceId":13545037,"sourceType":"datasetVersion","datasetId":8602195}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Mid-Term Final Version","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport re\nimport jieba\nfrom sklearn.compose import ColumnTransformer, TransformedTargetRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedShuffleSplit, cross_validate\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\nfrom sklearn.impute import SimpleImputer, KNNImputer\nfrom sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\nfrom sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV, Lasso, Ridge, ElasticNet\nfrom sklearn.metrics import mean_absolute_error, r2_score, make_scorer\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom itertools import combinations\nfrom sklearn.base import clone\nimport itertools\nfrom itertools import chain\nfrom joblib import Memory\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom category_encoders import TargetEncoder\nfrom tqdm import tqdm\nfrom scipy.sparse import save_npz, load_npz\n\nplt.rcParams['font.sans-serif'] = ['Arial Unicode MS']  # 设置中文字体","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 导入训练集与测试集，使用深度拷贝保留原数据\nrent_train_pd = pd.read_csv(\"/kaggle/input/python-ai-midterm/ruc_Class25Q2_train_rent.csv\")\nrent_train_raw = rent_train_pd.copy()\n\nprice_train_pd = pd.read_csv(\"/kaggle/input/python-ai-midterm/ruc_Class25Q2_train_price.csv\")\nprice_train_raw = price_train_pd.copy()\n\nrent_test_pd = pd.read_csv(\"/kaggle/input/python-ai-midterm/ruc_Class25Q2_test_rent.csv\")\nrent_test = rent_test_pd.copy()\n\nprice_test_pd = pd.read_csv(\"/kaggle/input/python-ai-midterm/ruc_Class25Q2_test_price.csv\")\nprice_test = price_test_pd.copy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1 Data Processing","metadata":{}},{"cell_type":"code","source":"clean_col_price = []\nclean_col_rent = []","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 统计price缺失值\nprice_train_raw.isnull().sum().sort_values(ascending=False)\n# 其中抵押信息、别墅类型的缺失值过多，物业办公电话、区县、板块_comm、环线位置数据信息与其他数据重复，直接删掉\nclean_col_price = [\"抵押信息\", \"别墅类型\", \"物业办公电话\", \"板块_comm\", \"coord_x\", \"coord_y\",\"环线位置\", \"区县\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 统计缺失值\nrent_train_raw.isnull().sum().sort_values(ascending=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clean_col_rent = [\"物业办公电话\", \"coord_x\", \"coord_y\"]   # 用于记录后面需要drop掉的数据，在数据处理结束、模型开始时统一删,避免每次都要重跑","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 合并已经生成的sentiment, 这样可以防止IQR筛选导致的行不匹配\ncol_emo_price = [\"客户反馈\"]\ncol_emo_rent = [\"客户反馈\"]\n\"\"\"\"\"\nsenti_price = pd.read_csv(\"/kaggle/input/sentiment/price_sentiment.csv\")\nsenti_rent = pd.read_csv(\"/kaggle/input/sentiment/rent_sentiment.csv\")\n\nprice_train = pd.concat([price_train, senti_price], axis=1)\nrent_train = pd.concat([rent_train, senti_rent], axis=1)\n\"\"\"\"\"\nclean_col_price.extend(col_emo_price)\nclean_col_rent.extend(col_emo_rent)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1.1 初步清洗","metadata":{}},{"cell_type":"markdown","source":"#### 1.1.1 IQR去掉Price的离群值","metadata":{}},{"cell_type":"code","source":"# 使用IQR去掉极端值\n# 如果直接使用IQR会删掉一万个样本，此处先取log再进行IQR处理\ndef IQR(df_raw):\n    Q1 = np.log1p(df_raw[\"Price\"]).quantile(0.25)    # 25%分位数\n    Q3 = np.log1p(df_raw[\"Price\"]).quantile(0.75)\n    IQR = Q3-Q1\n\n    # 计算上下界\n    lower = Q1 - 1.5 * IQR\n    upper = Q3 + 1.5 * IQR\n\n    mask = (np.log1p(df_raw[\"Price\"]) >= lower) & (np.log1p(df_raw[\"Price\"]) <= upper)\n    df = df_raw[mask].copy()    # 返回列名，不会影响原有值\n    return df\n\nprice_train = IQR(price_train_raw)\nrent_train = IQR(rent_train_raw)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"price_train = IQR(price_train_raw)\nrent_train = IQR(rent_train_raw)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.1.2 环线数据","metadata":{}},{"cell_type":"code","source":"# 转换环线数据，其中二至三环这种取平均数，内环是一环内，中环是三环左右，外环是六环以外\nloop_map = {\n    \"内环内\": 1,\n    \"二环内\": 1.5,\n    \"内环至中环\": 2,\n    \"二至三环\": 2.5,\n    \"三至四环\": 3.5,\n    \"四至五环\": 4.5,\n    \"五至六环\": 5.5,\n    \"六环外\": 6.5,\n    \"内环至外环\": 3,  #存疑\n    \"中环至外环\": 4,  #存疑\n    \"外环外\": 7\n}\n\nprice_train[\"环线_num\"] = price_train[\"环线\"].map(loop_map)\nprice_test[\"环线_num\"] = price_test[\"环线\"].map(loop_map)\n\nclean_col_price.append(\"环线\")\n\nrent_train[\"环线_num\"] = rent_train[\"环线位置\"].map(loop_map)\nrent_test[\"环线_num\"] = rent_test[\"环线位置\"].map(loop_map)\n\nclean_col_rent.append(\"环线位置\")\n\nprice_train[\"环线_num\"].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.1.3 房屋户型","metadata":{}},{"cell_type":"code","source":"# 采用正则表达式拆分房屋户型数据为四个变量\ndef separate_room(s):\n    # 如果缺失就全部赋为缺失值\n    if pd.isna(s):\n        return np.nan, np.nan, np.nan, np.nan\n    s = str(s)  # 统一格式\n    def extract(pattern):\n        re_match = re.search(pattern, s)\n        return int(re_match.group(1)) if re_match else np.nan   # match上了就返回匹配的值，没有就返回缺失值\n    room = extract(r\"(\\d+)\\s*(?:室|房间?)\")   # 有x室和x房间两种表达形式，此处统一提取室或者房/房间\n    hall = extract(r\"(\\d+)\\s*厅\")\n    kitchen = extract(r\"(\\d+)\\s*厨\")\n    bathroom = extract(r\"(\\d+)\\s*卫\")\n\n    return room, hall, kitchen, bathroom\n\n#第一个apply调用函数处理每一个单元格，返回一个tuple，再用series展开\nprice_train[[\"室\",\"厅\",\"厨\",\"卫\"]] = price_train[\"房屋户型\"].apply(separate_room).apply(pd.Series)\nprice_test[[\"室\",\"厅\",\"厨\",\"卫\"]] = price_test[\"房屋户型\"].apply(separate_room).apply(pd.Series)\n\nrent_train[[\"室\",\"厅\",\"厨\",\"卫\"]] = rent_train[\"户型\"].apply(separate_room).apply(pd.Series)\nrent_test[[\"室\",\"厅\",\"厨\",\"卫\"]] = rent_test[\"户型\"].apply(separate_room).apply(pd.Series)\n\nclean_col_price.append(\"房屋户型\")\nclean_col_rent.append(\"户型\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"price_train[[\"室\",\"厅\",\"厨\",\"卫\"]].head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.1.4 所在楼层","metadata":{}},{"cell_type":"markdown","source":"##### Price","metadata":{}},{"cell_type":"code","source":"# 同样以正则表达式分开所在楼层类型以及楼层类型和总共楼层，后期可以加交叉项看看共同影响\ndef separate_floor(s):\n    if pd.isna(s):\n        return np.nan, np.nan\n    def extract(pattern):\n        re_match = re.search(pattern, s)\n        return re_match.group(1) if re_match else np.nan\n    type = extract(r\"^(.*?)\\s*\\(\") # ^为匹配字符串的开头，(.*?)提取任意数量的字符，英文括号前有空格\n    total_floor = int(extract(r\"共(\\d+)层\"))\n    return type, total_floor\n\nprice_train[[\"楼层类型\", \"总共楼层\"]] = price_train[\"所在楼层\"].apply(separate_floor).apply(pd.Series)\nprice_test[[\"楼层类型\", \"总共楼层\"]] = price_test[\"所在楼层\"].apply(separate_floor).apply(pd.Series)\n\nclean_col_price.append(\"所在楼层\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"price_train[[\"楼层类型\", \"总共楼层\"]].head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### Rent","metadata":{}},{"cell_type":"code","source":"# 同样以正则表达式分开所在楼层类型以及楼层类型和总共楼层\n# 把以下两种正则表达字符串编成一个匹配对象\npat_frac = re.compile(r'\\s*(\\d+)\\s*/\\s*(\\d+)\\s*层?')          # 12/18层 或 12/18\npat_text = re.compile(r'\\s*((?:地下室)|[低中高])楼层?\\s*/\\s*(\\d+)\\s*层?')  # 中楼层/25层 等\n\nlevel_ratio = {\"地下室\": 0, \"低\": 0.25, \"中\": 0.50, \"高\": 0.75}  # 折算比率\n\ndef separate_floor(s):\n    if pd.isna(s):\n        return np.nan\n    s = str(s)\n\n    # 情况1：纯数字\n    m = pat_frac.match(s)\n    if m:\n        cur = int(m.group(1))   # 所在楼层\n        tot = int(m.group(2))   # 总共楼层\n        if tot == 0: return np.nan\n        r = cur / tot\n        return r if 0 <= r <= 1 else np.nan # 如果所在楼层大于总共楼层，返回缺失值\n\n    # 情况2：文字+总层 “低楼层/22层”\n    m = pat_text.match(s)\n    if m:\n        lvl = m.group(1)\n        tot = int(m.group(2))\n        if tot == 0: return np.nan\n        r = level_ratio.get(lvl, np.nan)    # 不存在就返回缺失值\n        return r if 0 <= r <= 1 else np.nan\n\n\nrent_train[\"楼层比例\"] = rent_train[\"楼层\"].apply(separate_floor)\nrent_test[\"楼层比例\"] = rent_test[\"楼层\"].apply(separate_floor)\n\nclean_col_rent.append(\"楼层\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rent_train[\"楼层比例\"].head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.1.5 建筑面积、套内面积、房屋总数、楼栋总数","metadata":{}},{"cell_type":"code","source":"# 建筑面积与套内面积统一使用正则表达式去掉单位\ndef separate_area(s):\n    if pd.isna(s):\n        return np.nan\n    re_match = re.search(r\"(\\d+(?:\\.\\d+)?)\", s) # 可能是小数\n    if re_match:\n        return float(re_match.group(1))\n    else:\n        print(\"nan\")    #检查是否存在无法match的值\n        return np.nan\n\nprice_train[\"建筑面积(㎡)\"] = price_train[\"建筑面积\"].apply(separate_area)\nprice_train[\"套内面积(㎡)\"] = price_train[\"套内面积\"].apply(separate_area)\n\nprice_test[\"建筑面积(㎡)\"] = price_test[\"建筑面积\"].apply(separate_area)\nprice_test[\"套内面积(㎡)\"] = price_test[\"套内面积\"].apply(separate_area)\n\nprice_train[\"房屋总数_num\"] = price_train[\"房屋总数\"].apply(separate_area)\nprice_train[\"楼栋总数_num\"] = price_train[\"楼栋总数\"].apply(separate_area)\n\nprice_test[\"房屋总数_num\"] = price_test[\"房屋总数\"].apply(separate_area)\nprice_test[\"楼栋总数_num\"] = price_test[\"楼栋总数\"].apply(separate_area)\n\nrent_train[\"面积_num\"] = rent_train[\"面积\"].apply(separate_area)\nrent_test[\"面积_num\"] = rent_test[\"面积\"].apply(separate_area)\n\nrent_train[\"房屋总数_num\"] = rent_train[\"房屋总数\"].apply(separate_area)\nrent_test[\"房屋总数_num\"] = rent_test[\"房屋总数\"].apply(separate_area)\n\nrent_train[\"楼栋总数_num\"] = rent_train[\"楼栋总数\"].apply(separate_area)\nrent_test[\"楼栋总数_num\"] = rent_test[\"楼栋总数\"].apply(separate_area)\n\nclean_col_rent.extend([\"面积\", \"房屋总数\", \"楼栋总数\"])\n\nclean_col_price.extend([\"建筑面积\", \"套内面积\", \"房屋总数\", \"楼栋总数\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rent_train[\"房屋总数_num\"].head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.1.6 房屋朝向","metadata":{}},{"cell_type":"code","source":"# 房屋朝向直接拆成八个不同变量，由于中国人较为偏好坐北朝南方向的房屋，后期拟加入交叉项\noriginal_flags = {\"北\",\"东北\",\"东\",\"东南\",\"南\",\"西南\",\"西\",\"西北\"}\n\ndef separate_flags(s):\n    if pd.isna(s):\n        return [np.nan]*8   # 返回八个缺失值\n    t = re.sub(r\"\\s+\", \" \", s).strip()   # 替换空格为半角，并去除首尾空格\n    parts = [p for p in t.split(\" \") if p]  #有缺失值的时候parts就是空的\n\n    # 把flag的初始值都设为0\n    flags = {k:0 for k in original_flags}\n    for flag in parts:\n        flags[flag] = 1\n    return [\n        flags[\"北\"], flags[\"东北\"], flags[\"东\"], flags[\"东南\"],\n        flags[\"南\"], flags[\"西南\"], flags[\"西\"], flags[\"西北\"]\n    ]\n\ncols = [\"朝向_北\",\"朝向_东北\",\"朝向_东\",\"朝向_东南\",\"朝向_南\",\"朝向_西南\",\"朝向_西\",\"朝向_西北\"]\nprice_train[cols] = price_train[\"房屋朝向\"].apply(separate_flags).apply(pd.Series)\nprice_test[cols] = price_test[\"房屋朝向\"].apply(separate_flags).apply(pd.Series)\n\nclean_col_price.append(\"房屋朝向\")\n\nrent_train[cols] = rent_train[\"朝向\"].apply(separate_flags).apply(pd.Series)\nrent_test[cols] = rent_test[\"朝向\"].apply(separate_flags).apply(pd.Series)\n\nclean_col_rent.append(\"朝向\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.1.7 梯户比例","metadata":{}},{"cell_type":"code","source":"# 梯户比例分开梯与户后，再生成梯/户比率\nCN = {\"零\":0,\"一\":1,\"二\":2,\"两\":2,\"三\":3,\"四\":4,\"五\":5,\"六\":6,\"七\":7,\"八\":8,\"九\":9}\n# 中文转整数\ndef cn_to_int(s):\n    s = str(s).strip()\n    if s == \"十\":\n        return 10\n    if \"十\" in s:\n        parts = s.split(\"十\")   # 用十分开，前为十位数后为个位数\n        tens = CN.get(parts[0], 1) if parts[0] else 1   # 十二就为1*10\n        units = CN.get(parts[1], 0) if len(parts) > 1 and parts[1] else 0\n        return tens*10 + units\n    else:\n        return CN.get(s, np.nan)\n\ndef separate_tihu(text):\n    if pd.isna(text):\n        return np.nan, np.nan\n    t = re.search(r\"([一二三四五六七八九十两\\d]+)梯([一二三四五六七八九十两\\d]+)户\", text)\n    if not t:\n        return np.nan, np.nan\n    elevator_raw, units_raw = t.group(1), t.group(2)\n    L = cn_to_int(elevator_raw)\n    U = cn_to_int(units_raw)\n    return int(L), int(U)\n\nprice_train[[\"梯数\", \"户数\"]] = price_train[\"梯户比例\"].apply(separate_tihu).apply(pd.Series)\nprice_train[\"梯户比\"] = price_train[\"梯数\"] / price_train[\"户数\"]\n\nprice_test[[\"梯数\", \"户数\"]] = price_test[\"梯户比例\"].apply(separate_tihu).apply(pd.Series)\nprice_test[\"梯户比\"] = price_test[\"梯数\"] / price_test[\"户数\"]\n\nclean_col_price.append(\"梯户比例\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.1.8 交易时间&上次交易（创新点1: 以三角函数处理交易数据）","metadata":{}},{"cell_type":"code","source":"# 交易时间和上次交易时间分别提取，生成本次交易的时间来捕捉年份趋势，以及持有时间来捕捉炒房与否\ndef separate_time(df, group):\n    # 转为pandas时间戳\n    df[\"交易时间\"] = pd.to_datetime(df[\"交易时间\"], errors = \"coerce\")  # 非法日期变为NaT\n\n    # 提取交易时间\n    df[\"交易_年\"] = df[\"交易时间\"].dt.year.astype(\"float64\")    # 使其可以被模型读入\n    df[\"交易_月\"] = df[\"交易时间\"].dt.month.astype(\"float64\")\n\n    if group == \"rent\":\n        return df\n    else:\n        df[\"上次交易\"] = pd.to_datetime(df[\"上次交易\"], errors = \"coerce\")\n        # 把交易月份转为正交坐标，一是使其首尾相连（1月和12月更为相似），二是使其连续可微\n        df[\"交易_月_sin\"] = np.sin(2*np.pi*(df[\"交易_月\"]-1)/12)    # 把一月设为初始点0，1\n        df[\"交易_月_cos\"] = np.cos(2*np.pi*(df[\"交易_月\"]-1)/12)\n\n        # 持有周期\n        hold = (df[\"交易时间\"] - df[\"上次交易\"])\n        df[\"持有天数\"] = hold.dt.days.astype(\"float64\")\n\n        return df\n\nprice_train = separate_time(price_train, \"price\")\nprice_test = separate_time(price_test, \"price\")\nclean_col_price.extend([\"交易时间\", \"上次交易\"])\n\n\nrent_train = separate_time(rent_train, \"rent\")\nrent_test = separate_time(rent_test, \"rent\")\nclean_col_rent.extend([\"交易时间\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.1.9 房屋优势","metadata":{}},{"cell_type":"code","source":"# 房屋优势分词分存为不同01变量\nadvantage_cat = [\"地铁\", \"装修\", \"房本满五年\", \"房本满两年\"]\ncols = [f\"优势_{k}\" for k in advantage_cat] # 对列命名\ndef separate_advantage(s):\n    if pd.isna(s):\n        return [np.nan]*4   # 返回四个缺失值\n    \n    t = re.sub(r\"\\s+\", \" \", s).strip(\"、\")   # 替换空格为半角，并去除首尾顿号\n    advantages = [p for p in t.split(\"、\") if p]\n\n    advantage_table = {k:0 for k in advantage_cat}\n    for ad in advantages:\n        advantage_table[ad] = 1\n    return [\n        advantage_table[\"地铁\"], advantage_table[\"装修\"], advantage_table[\"房本满五年\"], advantage_table[\"房本满两年\"]\n    ]\n\nprice_train[cols] = price_train[\"房屋优势\"].apply(separate_advantage).apply(pd.Series)\nprice_test[cols] = price_test[\"房屋优势\"].apply(separate_advantage).apply(pd.Series)\n\nclean_col_price.append(\"房屋优势\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"price_train[cols].head(5)   # 检查","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.1.10 建筑年代","metadata":{}},{"cell_type":"code","source":"def separate_build_year(x):\n    if pd.isna(x):\n        return np.nan\n    s = str(x).strip()\n    years = re.findall(r'\\d{4}', s) # 可能有两种，一是xxxx年，二是xxxx-xxxx年，进行区分\n    if len(years) == 2:\n        a, b = int(years[0]), int(years[1])\n        return (a+b)/2.0\n    else:\n        return int(years[0])\n\nprice_train[\"建筑年代_num\"] = price_train[\"建筑年代\"].apply(separate_build_year)\nprice_test[\"建筑年代_num\"] = price_test[\"建筑年代\"].apply(separate_build_year)\n\nclean_col_price.append(\"建筑年代\")\n\nrent_train[\"建筑年代_num\"] = rent_train[\"建筑年代\"].apply(separate_build_year)\nrent_test[\"建筑年代_num\"] = rent_test[\"建筑年代\"].apply(separate_build_year)\n\nclean_col_rent.append(\"建筑年代\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.1.11 物业费、燃气费、供热费、绿化率","metadata":{}},{"cell_type":"code","source":"cols_12 = [\"物 业 费\", \"燃气费\", \"供热费\", \"绿 化 率\"]\ndef separate_fees(x):\n    if pd.isna(x):\n        return np.nan\n\n    # 先匹配含\"-\"的，取平均数处理\n    m = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*-\\s*(\\d+(?:\\.\\d+)?)\", x)    # 可能有小数点也可能没有\n    if m:\n        m1, m2 = float(m.group(1)), float(m.group(2))\n        return (m2 + m1) / 2.0\n    else:\n        m = re.search(r\"(\\d+(?:\\.\\d+)?)\", x)    # 此处就只需要匹配单独的数字\n        return float(m.group(1))\n\nprice_train[\"物业费(元/月/㎡)\"] = price_train[\"物 业 费\"].apply(separate_fees)\nprice_train[\"燃气费(元/m³)\"] = price_train[\"燃气费\"].apply(separate_fees)\nprice_train[\"供热费(元/㎡)\"] = price_train[\"供热费\"].apply(separate_fees)\nprice_train[\"绿化率_num\"] = price_train[\"绿 化 率\"].apply(separate_fees) / 100\n\nprice_test[\"物业费(元/月/㎡)\"] = price_test[\"物 业 费\"].apply(separate_fees)\nprice_test[\"燃气费(元/m³)\"] = price_test[\"燃气费\"].apply(separate_fees)\nprice_test[\"供热费(元/㎡)\"] = price_test[\"供热费\"].apply(separate_fees)\nprice_test[\"绿化率_num\"] = price_test[\"绿 化 率\"].apply(separate_fees) / 100\n\nclean_col_price.extend(cols_12)\n\nrent_train[\"物业费(元/月/㎡)\"] = rent_train[\"物 业 费\"].apply(separate_fees)\nrent_train[\"燃气费(元/m³)\"] = rent_train[\"燃气费\"].apply(separate_fees)\nrent_train[\"供热费(元/㎡)\"] = rent_train[\"供热费\"].apply(separate_fees)\nrent_train[\"绿化率_num\"] = rent_train[\"绿 化 率\"].apply(separate_fees) / 100\n\nrent_test[\"物业费(元/月/㎡)\"] = rent_test[\"物 业 费\"].apply(separate_fees)\nrent_test[\"燃气费(元/m³)\"] = rent_test[\"燃气费\"].apply(separate_fees)\nrent_test[\"供热费(元/㎡)\"] = rent_test[\"供热费\"].apply(separate_fees)\nrent_test[\"绿化率_num\"] = rent_test[\"绿 化 率\"].apply(separate_fees) / 100\n\nclean_col_rent.extend(cols_12)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"price_train[\"绿化率_num\"].head(6)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.1.12 停车费用(这个再看看)","metadata":{}},{"cell_type":"code","source":"# —— 规则（把“暂无”等归为未知；免费单独识别）——\nfree_re = re.compile(r'(免费|不收费|无固定车位不收费|没有停车费|无停车费|地上免费停车|目前免费|无\\b)')\nnan_re  = re.compile(r'(暂无|未知|无法核实|无法获知|不详|待定)')\n\n# 统一各种横杠/波浪线为 '-'\nDASHES = str.maketrans({'–':'-','—':'-','－':'-','~':'-','～':'-'})\n\n# 把一段文本里的数值提出来：区间取均值，单值直接取\ndef _values_from_span(text: str):\n    t = re.sub(r'\\s+', '', str(text)).translate(DASHES)\n    vals = []\n    # 区间 a-b\n    for a, b in re.findall(r'(\\d+(?:\\.\\d+)?)\\s*-\\s*(\\d+(?:\\.\\d+)?)', t):\n        vals.append((float(a) + float(b)) / 2.0)\n    # 去掉已处理的区间，再抓单值\n    t = re.sub(r'\\d+(?:\\.\\d+)?\\s*-\\s*\\d+(?:\\.\\d+)?', ' ', t)\n    for v in re.findall(r'(\\d+(?:\\.\\d+)?)', t):\n        vals.append(float(v))\n    return vals\n\ndef _mean_or_nan(vals):\n    return float(np.mean(vals)) if len(vals) else np.nan\n\n# —— 主函数：返回 (月租, 时租, 是否免费) —— \ndef separate_parking_fees(x):\n    if pd.isna(x):\n        return (np.nan, np.nan, 0)\n    s = re.sub(r'\\s+', '', str(x)).translate(DASHES)\n\n    # 忽略与租金无关的售价描述\n    s = re.sub(r'售价[^，,；;]*', '', s)\n    s = re.sub(r'\\d+(?:\\.\\d+)?万[^，,；;]*', '', s)\n\n    # 免费 / 未知\n    if free_re.search(s):\n        return (0.0, 0.0, 1)\n    if nan_re.search(s):\n        return (np.nan, np.nan, 0)\n\n    # 取“月”前面的价格片段（可能多个），求均值（地上、地下的月租直接以平均值算，否则会有大量缺失值）\n    month_vals = []\n    for span in re.findall(r'([\\d\\.\\-–—－~～]+)\\D{0,6}月', s):\n        month_vals.extend(_values_from_span(span))\n\n    # “年”价格换算为月（/12），也并入月租\n    for span in re.findall(r'([\\d\\.\\-–—－~～]+)\\D{0,6}年', s):\n        vals = _values_from_span(span)\n        month_vals.extend([v / 12.0 for v in vals])\n\n    # 时租（小时/时/h）\n    hour_vals = []\n    for span in re.findall(r'([\\d\\.\\-–—－~～]+)\\D{0,6}(?:小时|时|h|H)', s):\n        hour_vals.extend(_values_from_span(span))\n\n    # 若既无“月”也无“时”单位，但有数字 → 默认按月租\n    if not month_vals and not hour_vals:\n        vals = _values_from_span(s)\n        if vals:\n            month_vals.extend(vals)\n\n    month_fee = _mean_or_nan(month_vals)\n    hour_fee  = _mean_or_nan(hour_vals)\n    return (month_fee, hour_fee, 0)\n\n# 应用\ncol_parking = [\"月租费用(元/月/位)\", \"时租费用(元/时/位)\", \"车位是否免费\"]\n\nprice_train[col_parking] = price_train[\"停车费用\"].apply(\n    lambda x: pd.Series(separate_parking_fees(x), index=col_parking)\n)\nprice_test[col_parking] = price_test[\"停车费用\"].apply(\n    lambda x: pd.Series(separate_parking_fees(x), index=col_parking)\n)\n\nrent_train[col_parking] = rent_train[\"停车费用\"].apply(\n    lambda x: pd.Series(separate_parking_fees(x), index=col_parking)\n)\nrent_test[col_parking] = rent_test[\"停车费用\"].apply(\n    lambda x: pd.Series(separate_parking_fees(x), index=col_parking)\n)\n\nclean_col_price.append(\"停车费用\")\nclean_col_rent.append(\"停车费用\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rent_train[col_parking].head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.1.13 类别变量统一学习清理","metadata":{}},{"cell_type":"markdown","source":"##### 少类别：Onehot encoder","metadata":{}},{"cell_type":"code","source":"onehot_cols_price = [\"建筑结构\", \"装修情况\", \"交易权属\", \"房屋用途\", \"房屋年限\", \"产权所属\", \"楼层类型\", \"配备电梯\",\"城市\"]\nonehot_cols_rent = [\"付款方式\", \"租赁方式\", \"电梯\", \"用水\", \"用电\", \"燃气\", \"采暖\",\"装修\", \"车位\", \"城市\"]\n\ndef onehot_transfer(onehot_cols, df_train, df_test):\n    # 拟合训练集\n    ohe = OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False) # 采用密集矩阵，方便直接拼回df\n    ohe.fit(df_train[onehot_cols])\n    # 转换\n    train_encoded = ohe.transform(df_train[onehot_cols])\n    test_encoded  = ohe.transform(df_test[onehot_cols])\n    # 转成 DataFrame\n    train_ohe = pd.DataFrame(train_encoded, columns=ohe.get_feature_names_out(onehot_cols), index=df_train.index)\n    test_ohe  = pd.DataFrame(test_encoded,  columns=ohe.get_feature_names_out(onehot_cols), index=df_test.index)\n    # 拼回原数据，此处直接drop，不需要再加入clean_col\n    df_train = pd.concat([df_train, train_ohe], axis=1)\n    df_test  = pd.concat([df_test, test_ohe],  axis=1)\n\n    return df_train, df_test\n\n# 保留城市\nclean_col_price.extend([\"建筑结构\", \"装修情况\", \"交易权属\", \"房屋用途\", \"房屋年限\", \"产权所属\", \"楼层类型\", \"配备电梯\"])\nclean_col_rent.extend([\"付款方式\", \"租赁方式\", \"电梯\", \"用水\", \"用电\", \"燃气\", \"采暖\",\"装修\", \"车位\"])\n\nprice_train, price_test = onehot_transfer(onehot_cols_price, price_train, price_test)\nrent_train, rent_test = onehot_transfer(onehot_cols_rent, rent_train, rent_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 多类别：Target encoding：将其转化为在目标变量上的平均值","metadata":{}},{"cell_type":"code","source":"multihot_cols = [\"开发商\", \"物业公司\", \"板块\", \"区域\"]\n\nencoder = TargetEncoder(cols=multihot_cols)\n\nprice_train[multihot_cols] = encoder.fit_transform(price_train[multihot_cols], price_train['Price'])\nprice_test[multihot_cols] = encoder.transform(price_test[multihot_cols])\n\nclean_col_price.extend(multihot_cols)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"multihot_cols = [\"开发商\", \"物业公司\", \"区县\", \"板块\"]\n\nencoder = TargetEncoder(cols=multihot_cols)\n\nrent_train[multihot_cols] = encoder.fit_transform(rent_train[multihot_cols], rent_train['Price'])\nrent_test[multihot_cols] = encoder.transform(rent_test[multihot_cols])\n\nclean_col_rent.extend(multihot_cols)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.1.14 租期","metadata":{}},{"cell_type":"code","source":"# 预编译两类最常见的正则\n_pat_range  = re.compile(r'(\\d+(?:\\.\\d+)?)\\s*[~～\\-到至]\\s*(\\d+(?:\\.\\d+)?)(?:\\s*(年|个?月|月))?')\n_pat_single = re.compile(r'(\\d+(?:\\.\\d+)?)\\s*(年|个?月|月)')\n\ndef to_months(x):\n    if pd.isna(x): \n        return np.nan\n    s = str(x).strip()\n    # 1) 区间取平均值\n    m = _pat_range.search(s)\n    if m:\n        num   = (float(m.group(1)) + float(m.group(2))) / 2\n        unit = m.group(3) or ('年' if '年' in s else '月')\n        return num*12 if '年' in unit else num\n    # 2) 单值\n    m = _pat_single.search(s)\n    if m:\n        val, unit = float(m.group(1)), m.group(2)\n        return val*12 if '年' in unit else val\n    # 3) 常见词：半年\n    if '半年' in s:\n        return 6.0\n    return np.nan\n\n# 使用\nrent_train['租期_num'] = rent_train['租期'].apply(to_months).astype('float64')\nrent_test['租期_num'] = rent_test['租期'].apply(to_months).astype('float64')\n\nclean_col_rent.append(\"租期\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1.2 依赖数据分布的清洗","metadata":{}},{"cell_type":"markdown","source":"#### 1.2.1 数据分组","metadata":{}},{"cell_type":"code","source":"# 设置自变量和因变量\nX_price = price_train.drop(\"Price\", axis = 1)\ny_price = price_train[\"Price\"]\n\nX_rent = rent_train.drop(\"Price\", axis = 1)\ny_rent = rent_train[\"Price\"]\n# 分出测试组与验证组\nX_train_price, X_val_price, y_train_price, y_val_price = train_test_split(X_price, y_price, test_size=0.2, random_state=111)\nX_test_price = price_test\n\nX_train_rent, X_val_rent, y_train_rent, y_val_rent = train_test_split(X_rent, y_rent, test_size=0.2, random_state=111)\nX_test_rent = rent_test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.2.2 使用TF-IDF对非结构化特征进行处理","metadata":{}},{"cell_type":"code","source":"# 由于数据过多，此处准备采取合并多列使用一个向量器\ncol_tf_price = [\"核心卖点\", \"户型介绍\", \"周边配套\", \"交通出行\"]\n\"\"\"\"\"\ntexts_train = X_train_price[col_tf_price].fillna(\"\").agg(\"。\".join, axis=1)    # 把四列合为一列\ntexts_val = X_val_price[col_tf_price].fillna(\"\").agg(\"。\".join, axis=1)    # 把四列合为一列\ntexts_test= X_test_price[col_tf_price].fillna(\"\").agg(\"。\".join, axis=1)    # 把四列合为一列\n\ndef jieba_tokenizer(text):\n    return jieba.lcut(text)\n\ntfidf = TfidfVectorizer(\n    tokenizer=jieba_tokenizer,   #使用jieba分词\n    max_features=300,        # 选取前300个高频词（防止维度太高）\n    stop_words=[\"的\", \"了\", \"是\", \"有\", \"和\"],  # 中文停用词，可自定义\n    ngram_range=(1, 2)       # 一元词和二元词（单词+短语）\n)\n\n# 保存向量器，\nX_tfidf_train = tfidf.fit_transform(texts_train)\nX_tfidf_val = tfidf.transform(texts_val)\nX_tfidf_test = tfidf.transform(texts_test)\n# 存储（TF-IDF为稀疏矩阵）\nsave_npz(\"X_tfidf_train.npz\", X_tfidf_train)\nsave_npz(\"X_tfidf_val.npz\", X_tfidf_val)\nsave_npz(\"X_tfidf_test.npz\", X_tfidf_test)\n\"\"\"\"\"\nclean_col_price.extend(col_tf_price)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\"\"\n# 读取\nX_tfidf_train = load_npz(\"X_tfidf_train.npz\")\nX_tfidf_val = load_npz(\"X_tfidf_val.npz\")\nX_tfidf_test = load_npz(\"X_tfidf_test.npz\")\n\n# TF-IDF → DataFrame\nX_tfidf_train_df = pd.DataFrame(X_tfidf_train.toarray(),columns=tfidf.get_feature_names_out(),index=X_train_price.index)\nX_tfidf_val_df = pd.DataFrame(X_tfidf_val.toarray(),columns=tfidf.get_feature_names_out(),index=X_val_price.index)\nX_tfidf_test_df  = pd.DataFrame(X_tfidf_test.toarray(),columns=tfidf.get_feature_names_out(),index=X_test_price.index)\n\n# 拼接\nX_train_price = pd.concat([X_train_price, X_tfidf_train_df], axis=1)\nX_val_price   = pd.concat([X_val_price,   X_tfidf_val_df],   axis=1)\nX_test_price  = pd.concat([X_test_price,  X_tfidf_test_df],  axis=1)\n\"\"\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1.2.3 多类别变量：采用MultiLabelBinarizer转换","metadata":{}},{"cell_type":"code","source":"# 对训练集进行fit和transform，就每一个传进去的col_name进行训练\ndef MLB_fit_transform(col_name, X_tr, X_va, X_te):\n    # 先统计所有可能的物业类别\n    def tokenize(series):\n        s = series.fillna('').astype(str)   # 用空填补缺失\n        tokens = s.apply(lambda x: re.split(r'[\\\\/、]', x) if x else []) # 每行作为一个列表\n        return tokens\n\n    missing_train = X_tr[col_name].isna().astype(int)  # 保留是否为缺失值\n    tokens = tokenize(X_tr[col_name])\n\n    # 使用mlb进行转换\n    mlb = MultiLabelBinarizer()\n    Z = mlb.fit_transform(tokens)   # 学习每一行样本是不是包含每个标签，转为多热编码\n\n    multi_cols = [f\"{col_name}_{c}\" for c in mlb.classes_] # 生成不同类别的标签\n    dummies = pd.DataFrame(Z, columns = multi_cols, index = X_tr.index)   # 转成带有列名并与X_train对齐的df\n    dummies[f\"{col_name}_missing\"] = missing_train\n\n    X_tr = pd.concat([X_tr, dummies], axis = 1)\n\n    # 对验证集和测试集进行transform\n    def MLB_transform(df):\n        missing_train = df[col_name].isna().astype(int)  # 保留是否为缺失值\n        tokens = tokenize(df[col_name])\n\n        # 使用mlb进行转换\n        Z = mlb.transform(tokens)   # 学习每一行样本是不是包含每个标签，转为多热编码\n\n        multi_cols = [f\"{col_name}_{c}\" for c in mlb.classes_] # 生成不同物业类别的标签\n        dummies = pd.DataFrame(Z, columns = multi_cols, index = df.index)   # 转成带有列名并与X_train对齐的df\n        dummies[f\"{col_name}_missing\"] = missing_train\n        df = pd.concat([df, dummies], axis = 1)\n        return df\n    \n    return X_tr, MLB_transform(X_va), MLB_transform(X_te)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 对需要的cols进行调用\nmulti_cols_price = [\"物业类别\", \"建筑结构_comm\", \"产权描述\", \"供水\", \"供暖\", \"供电\"]\nfor col in multi_cols_price:\n    X_train_price, X_val_price, X_test_price = MLB_fit_transform(col, X_train_price, X_val_price, X_test_price)\nclean_col_price.extend(multi_cols_price)\n\nmulti_cols_rent = [\"配套设施\", \"物业类别\", \"建筑结构\", \"产权描述\", \"供水\", \"供暖\", \"供电\"]\nfor col in multi_cols_rent:\n    X_train_rent, X_val_rent, X_test_rent = MLB_fit_transform(col, X_train_rent, X_val_rent, X_test_rent)\nclean_col_rent.extend(multi_cols_rent)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 清理掉所有clean_col中包含的列\nX_train_price = X_train_price.drop(columns = clean_col_price)\nX_val_price = X_val_price.drop(columns = clean_col_price)\nX_test_price = X_test_price.drop(columns = clean_col_price)\n\n# 清理掉所有clean_col中包含的列\nX_train_rent = X_train_rent.drop(columns = clean_col_rent)\nX_val_rent = X_val_rent.drop(columns = clean_col_rent)\nX_test_rent = X_test_rent.drop(columns = clean_col_rent)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"non_num = X_train_price.select_dtypes(exclude=[np.number]).columns.tolist()\nprint(\"仍为非数值的列：\", non_num[:50])\n# 看看这些列的前几个取值\nfor c in non_num[:10]:\n    print(c, X_train_price[c].dropna().unique()[:5])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2 Price Modeling","metadata":{}},{"cell_type":"markdown","source":"### 2.1 填充缺失值","metadata":{}},{"cell_type":"code","source":"X_train = X_train_price\nX_val = X_val_price\nX_test = X_test_price\ny_train = y_train_price\ny_val = y_val_price","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"id_series = X_test[\"ID\"].copy()\nX_test_pred = X_test.copy()\nX_test_pred = X_test_pred.drop(columns = \"ID\")  # 把ID一列Drop掉防止干扰回归","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 区分数值列和0-1变量列\ndef classify_columns(df):\n    bin_cols = []\n    num_cols = []\n    for col in df.columns:\n        unique_vals = set(df[col].dropna().unique())\n        if unique_vals.issubset({0,1}):\n            bin_cols.append(col)\n        else:\n            num_cols.append(col)\n    return bin_cols, num_cols\nbin_cols, num_cols = classify_columns(X_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 分层依据\ngroup_cols = [\"城市\"]\n\n# 计算缺失率\nna_ratio = X_train[num_cols].isna().mean()\n\nlow_na  = na_ratio[na_ratio <= 0.30].index.tolist()               # ≤20% 用全局均值\nmid_na  = na_ratio[(na_ratio > 0.30) & (na_ratio <= 0.70)].index.tolist()  # 20–50% 分层均值\nhigh_na = na_ratio[na_ratio > 0.70].index.tolist()                # >50% 直接删除\n\n# 记录最终保留的列\nnum_cols_kept = [c for c in num_cols if c not in high_na]\n\n# 删除缺失值>50%的列\nX_train_imp0 = X_train.copy()\nX_val_imp0   = X_val.copy()\nX_test_imp0  = X_test_pred.copy()   # 复制原表格\n\nX_train_imp0.drop(columns=high_na, inplace=True, errors=\"ignore\")\nX_val_imp0.drop(columns=high_na,   inplace=True, errors=\"ignore\")\nX_test_imp0.drop(columns=high_na,  inplace=True, errors=\"ignore\")\n\n# 用均值填补缺失值<=10%的列\nif low_na:\n    mean_map = X_train[low_na].mean()  # 只用训练集计算\n    X_train_imp0[low_na] = X_train_imp0[low_na].fillna(mean_map)\n    X_val_imp0[low_na]   = X_val_imp0[low_na].fillna(mean_map)\n    X_test_imp0[low_na]  = X_test_imp0[low_na].fillna(mean_map)\n\n# 用分层均值填补缺失值为10%-70%的列\ndef fill_by_group_mean(df_to_fill, df_ref, cols, group_cols):   # df_ref为训练集\n    if not cols:    #没有缺失值在此范围内的\n        return df_to_fill\n    out = df_to_fill.copy()\n\n    if group_cols:\n        grp_mean = df_ref[group_cols + cols].groupby(group_cols, dropna=False).mean()\n        for c in cols:\n            mapped = out[group_cols].merge(\n                grp_mean[[c]].reset_index(),    # 把城市和训练组的均值按照城市左链接\n                on=group_cols, \n                how=\"left\"\n            )[c].values if group_cols else None # 取出生成的那一列\n            if mapped is not None:\n                out[c] = out[c].where(~out[c].isna(), mapped)\n            out[c] = out[c].fillna(df_ref[c].mean())    # 仍然缺失的还是用全局均值\n    else: # 方便反悔\n        for c in cols:\n            out[c] = out[c].fillna(df_ref[c].mean())\n    return out\nX_train_imp0 = fill_by_group_mean(X_train_imp0, X_train, mid_na, group_cols)\nX_val_imp0   = fill_by_group_mean(X_val_imp0,   X_train, mid_na, group_cols)\nX_test_imp0  = fill_by_group_mean(X_test_imp0,  X_train, mid_na, group_cols)\n\n# 二值变量采用众数填补\nif bin_cols:\n    # 计算缺失比例\n    bin_na_ratio = X_train[bin_cols].isna().mean()\n    # 按照缺失比例分组\n    bin_high_na = bin_na_ratio[bin_na_ratio > 0.70].index.tolist()\n    bin_keep    = [c for c in bin_cols if c not in bin_high_na]\n    print(f\"删除缺失>70%的二值列: {bin_high_na}\")\n\n    # 同步删除这类列\n    X_train_imp0.drop(columns=bin_high_na, inplace=True, errors=\"ignore\")\n    X_val_imp0.drop(columns=bin_high_na,   inplace=True, errors=\"ignore\")\n    X_test_imp0.drop(columns=bin_high_na,  inplace=True, errors=\"ignore\")\n\n    # 对剩余二值列用众数填补\n    if bin_keep:\n        mode_imputer = SimpleImputer(strategy=\"most_frequent\")\n        X_train_imp0[bin_keep] = mode_imputer.fit_transform(X_train_imp0[bin_keep])\n        X_val_imp0[bin_keep]   = mode_imputer.transform(X_val_imp0[bin_keep])\n        X_test_imp0[bin_keep]  = mode_imputer.transform(X_test_imp0[bin_keep])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 将price取log\n\ny_train_log = np.log1p(y_train) # 取log(1+y_train)，防止价格=0的时候报错\ny_val_log = np.log1p(y_val)\n\n# 数值型的填补pipeline\nnum_pipeline = Pipeline([\n    (\"scaler\", StandardScaler())\n])\n\nbin_passthrough = \"passthrough\"\n\npreprocessor = ColumnTransformer([\n    (\"num\", num_pipeline, num_cols_kept),\n    (\"bin\", bin_passthrough, bin_keep)\n], remainder=\"drop\")\n\n\n# 拟合/变换\nX_train_imp = preprocessor.fit_transform(X_train_imp0)\nX_val_imp   = preprocessor.transform(X_val_imp0)\nX_test_imp  = preprocessor.transform(X_test_imp0)\n\nout_cols = preprocessor.get_feature_names_out()\n\nX_train_prep = pd.DataFrame(X_train_imp, columns=out_cols, index=X_train.index)\nX_val_prep   = pd.DataFrame(X_val_imp,   columns=out_cols, index=X_val.index)\nX_test_prep  = pd.DataFrame(X_test_imp,  columns=out_cols, index=X_test_pred.index)\n\nnum_out_cols = [c for c in out_cols if c.startswith(\"num__\")]\nbin_out_cols = [c for c in out_cols if c.startswith(\"bin__\")]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(X_train_prep.columns))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.2 选择需要使用的变量","metadata":{}},{"cell_type":"code","source":"# 生成数值型变量的二次项和交叉项\ndef square_interaction(df, num_out_cols = num_out_cols, bin_out_cols = bin_out_cols):\n    # 对数值型变量生成平方项并命名\n    df_square = df[num_out_cols] ** 2\n    df_square.columns = [f\"{c}_square\" for c in num_out_cols]\n    # 对数值型变量生成交叉项并命名\n    inter_df = pd.DataFrame(\n        {f\"{a}*{b}\": df[a].values * df[b].values for a, b in combinations(num_out_cols, 2)},\n        index = df.index\n    )\n    # 生成指定交叉项\n    df[\"南北通透\"] = df[\"bin__朝向_南\"] * df[\"bin__朝向_北\"]\n\n    out = pd.concat([df, df_square, inter_df], axis=1)    # 合成大表\n    return out\n\nX_train_si = square_interaction(X_train_prep)\nX_val_si = square_interaction(X_val_prep)\nX_test_si = square_interaction(X_test_prep)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(X_train_si.columns))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pearson_cols = X_train_si.columns\n\n# 合并并排序\ncorr_df = (\n    X_train_si[pearson_cols].corrwith(y_train_log, method = \"pearson\").to_frame(\"pearson\")\n    .reset_index().rename(columns={\"index\": \"feature\"}).assign(abs_pearson=lambda d: d[\"pearson\"].abs())\n    .sort_values(\"abs_pearson\", ascending=False)\n)\nprint(corr_df.head(5))\n\n# 设置筛选阈值\ncorr_threhold = 0.1\npreselected_cols = corr_df.loc[corr_df[\"abs_pearson\"] >= corr_threhold, \"feature\"]\nprint(f\"保留样本{len(preselected_cols)}个\")\n\n# 只保留preselected中的列\nX_train_final = X_train_si.loc[:, preselected_cols]\nX_val_final = X_val_si.loc[:, preselected_cols]\nX_test_final = X_test_si.loc[:, preselected_cols]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.3 Modeling (记得还原对数！！！)","metadata":{}},{"cell_type":"code","source":"# 对y取对数（提升稳定性）\ny_train_log = np.log1p(y_train)\ny_val_log   = np.log1p(y_val)\n\n\n# 定义模型\nols   = LinearRegression()\nridge = Ridge(alpha=0.015, random_state=111)\nlasso = Lasso(alpha=0.00005, max_iter=500000, random_state=111)\nenet  = ElasticNet(alpha=0.00005, l1_ratio=0.0005, max_iter=500000, random_state=111)\n\nmodels = {'OLS': ols, 'Ridge': ridge, 'Lasso': lasso, 'ElasticNet': enet}\n\ndef safe_transfer(log_pred: np.ndarray) -> np.ndarray:\n    log_pred = log_pred.astype(np.float64)\n    y_pred = np.expm1(log_pred)\n    return y_pred\n\nrows = []\npred_dict = {}\n\n# 交叉验证mae的打分器\ndef mae_on_original_scale(y_true_log, y_pred_log):\n    # 还原\n    y_true = np.expm1(y_true_log)\n    y_pred = np.expm1(y_pred_log)\n    return mean_absolute_error(y_true, y_pred)\n\n# 交叉验证rmae的打分器\ndef rmae_on_original_scale(y_true_log, y_pred_log):\n    y_true = np.expm1(y_true_log)\n    y_pred = np.expm1(y_pred_log)\n    mae = mean_absolute_error(y_true, y_pred)\n    return mae / np.mean(y_true)\n\nmae_scorer = make_scorer(mae_on_original_scale, greater_is_better= False)  # 自定义一个评分器，规则是分数越小越好\nrmae_scorer = make_scorer(rmae_on_original_scale, greater_is_better= False)\n\ncv = KFold(n_splits=6, shuffle=True, random_state=111)  # 六折交叉验证，shuffle = True指交叉验证切块前随机打乱数据\n\nfor name, model in tqdm(models.items(), desc=\"Training models\", ncols=100):\n\n    model.fit(X_train_final, y_train_log)    # 训练模型\n    y_train_pred = safe_transfer(model.predict(X_train_final))    # in-sample\n    y_val_pred = safe_transfer(model.predict(X_val_final))    # out-of-sample\n    y_test_pred = safe_transfer(model.predict(X_test_final))  # 测试集结果\n    # mae结果\n    mae_train = mean_absolute_error(y_train, y_train_pred)\n    mae_val = mean_absolute_error(y_val, y_val_pred)\n    # rmae = mae/y真实值的平均值\n    rmae_train = mae_train / np.mean(y_train)\n    rmae_val = mae_val / np.mean(y_val)\n    # R方\n    r2_train = r2_score(y_train, y_train_pred)\n    r2_val = r2_score(y_val, y_val_pred)\n\n    # 在确定最优参数范围之后再来用交叉检验，避免算很多次\n    # 此处注意，交叉验证的mae也需要从log还原\n    cv_mae_scores = cross_val_score(\n        clone(model),   # 复制一个没训练的模型\n        X_train_final,\n        y_train_log,    # 目标变量\n        scoring = mae_scorer,\n        cv = cv,\n        n_jobs = -1 # 使用多个CPU并行运算\n    )\n\n    cv_rmae_scores = cross_val_score(\n        clone(model),   # 复制一个没训练的模型\n        X_train_final,\n        y_train_log,    # 目标变量\n        scoring = rmae_scorer,\n        cv = cv,\n        n_jobs = -1 # 使用多个CPU并行运算\n    )\n\n    cv_mae = -cv_mae_scores.mean()  # cross_val_score返回计算分数组成的数组，以负值形式\n    cv_rmae = -cv_rmae_scores.mean()\n\n    rows.append({\n        \"Metrics\": name,\n        \"In sample (mae)\": mae_train,\n        \"In sample (rmae)\": rmae_train,\n        \"In sample (R2)\": r2_train,\n        \"Out of sample (mae)\": mae_val,\n        \"Out of sample (rmae)\": rmae_val,\n        \"Out of sample (R2)\": r2_val,\n        \"Cross-Validation (mae)\": cv_mae,\n        \"Cross-Validation (rmae)\": cv_rmae\n    })\n    pred_dict[f\"{name}_pred\"] = y_test_pred\n\n\n# 汇总成表\nreport_df = pd.DataFrame(rows)\nprint(report_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.set_option('display.float_format', '{:.6f}'.format)   # 保留6位小数\npred_df = pd.DataFrame(pred_dict, index = X_test.index)\npred_df = pd.concat([pd.DataFrame(pred_dict, index=X_test.index), X_test[[\"ID\"]]], axis=1)\npred_df.head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 为每一个模型都生成一个submit结果\nmodel_pred = [\"OLS_pred\", \"Ridge_pred\", \"Lasso_pred\", \"ElasticNet_pred\"]\nfor pre in model_pred:\n    pred_df_renamed = pred_df.rename(columns={pre: \"Price\"})\n    pred_df_renamed = pred_df_renamed[[\"ID\", \"Price\"]]\n    pred_df_renamed.to_excel(f\"output_price_{pre}.xlsx\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3 Rent Modeling","metadata":{}},{"cell_type":"markdown","source":"### 3.1 填充缺失值并标准化","metadata":{}},{"cell_type":"code","source":"X_train = X_train_rent\nX_val = X_val_rent\nX_test = X_test_rent\ny_train = y_train_rent\ny_val = y_val_rent","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"id_series = X_test[\"ID\"].copy()\nX_test_pred = X_test.copy()\nX_test_pred = X_test_pred.drop(columns = \"ID\")  # 把ID一列Drop掉防止干扰回归","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 区分数值列和0-1变量列\ndef classify_columns(df):\n    bin_cols = []\n    num_cols = []\n    for col in df.columns:\n        unique_vals = set(df[col].dropna().unique())\n        if unique_vals.issubset({0,1}):\n            bin_cols.append(col)\n        else:\n            num_cols.append(col)\n    return bin_cols, num_cols\nbin_cols, num_cols = classify_columns(X_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bad_cols = [c for c in low_na if not pd.api.types.is_numeric_dtype(X_train[c])]\nprint(\"非数值列：\", bad_cols)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 分层依据\ngroup_cols = [\"城市\"]\n\n# 计算缺失率\nna_ratio = X_train[num_cols].isna().mean()\n\nlow_na  = na_ratio[na_ratio <= 0.30].index.tolist()               # ≤20% 用全局均值\nmid_na  = na_ratio[(na_ratio > 0.30) & (na_ratio <= 0.70)].index.tolist()  # 20–50% 分层均值\nhigh_na = na_ratio[na_ratio > 0.70].index.tolist()                # >50% 直接删除\n\n# 记录最终保留的列\nnum_cols_kept = [c for c in num_cols if c not in high_na]\n\n# 删除缺失值>50%的列\nX_train_imp0 = X_train.copy()\nX_val_imp0   = X_val.copy()\nX_test_imp0  = X_test_pred.copy()   # 复制原表格\n\nX_train_imp0.drop(columns=high_na, inplace=True, errors=\"ignore\")\nX_val_imp0.drop(columns=high_na,   inplace=True, errors=\"ignore\")\nX_test_imp0.drop(columns=high_na,  inplace=True, errors=\"ignore\")\n\n# 用均值填补缺失值<=10%的列\nif low_na:\n    mean_map = X_train[low_na].mean()  # 只用训练集计算\n    X_train_imp0[low_na] = X_train_imp0[low_na].fillna(mean_map)\n    X_val_imp0[low_na]   = X_val_imp0[low_na].fillna(mean_map)\n    X_test_imp0[low_na]  = X_test_imp0[low_na].fillna(mean_map)\n\n# 用分层均值填补缺失值为10%-70%的列\ndef fill_by_group_mean(df_to_fill, df_ref, cols, group_cols):   # df_ref为训练集\n    if not cols:    #没有缺失值在此范围内的\n        return df_to_fill\n    out = df_to_fill.copy()\n\n    if group_cols:\n        grp_mean = df_ref[group_cols + cols].groupby(group_cols, dropna=False).mean()\n        for c in cols:\n            mapped = out[group_cols].merge(\n                grp_mean[[c]].reset_index(),    # 把城市和训练组的均值按照城市左链接\n                on=group_cols, \n                how=\"left\"\n            )[c].values if group_cols else None # 取出生成的那一列\n            if mapped is not None:\n                out[c] = out[c].where(~out[c].isna(), mapped)\n            out[c] = out[c].fillna(df_ref[c].mean())    # 仍然缺失的还是用全局均值\n    else: # 方便反悔\n        for c in cols:\n            out[c] = out[c].fillna(df_ref[c].mean())\n    return out\nX_train_imp0 = fill_by_group_mean(X_train_imp0, X_train, mid_na, group_cols)\nX_val_imp0   = fill_by_group_mean(X_val_imp0,   X_train, mid_na, group_cols)\nX_test_imp0  = fill_by_group_mean(X_test_imp0,  X_train, mid_na, group_cols)\n\n# 二值变量采用众数填补\nif bin_cols:\n    # 计算缺失比例\n    bin_na_ratio = X_train[bin_cols].isna().mean()\n    # 按照缺失比例分组\n    bin_high_na = bin_na_ratio[bin_na_ratio > 0.70].index.tolist()\n    bin_keep    = [c for c in bin_cols if c not in bin_high_na]\n    print(f\"删除缺失>70%的二值列: {bin_high_na}\")\n\n    # 同步删除这类列\n    X_train_imp0.drop(columns=bin_high_na, inplace=True, errors=\"ignore\")\n    X_val_imp0.drop(columns=bin_high_na,   inplace=True, errors=\"ignore\")\n    X_test_imp0.drop(columns=bin_high_na,  inplace=True, errors=\"ignore\")\n\n    # 对剩余二值列用众数填补\n    if bin_keep:\n        mode_imputer = SimpleImputer(strategy=\"most_frequent\")\n        X_train_imp0[bin_keep] = mode_imputer.fit_transform(X_train_imp0[bin_keep])\n        X_val_imp0[bin_keep]   = mode_imputer.transform(X_val_imp0[bin_keep])\n        X_test_imp0[bin_keep]  = mode_imputer.transform(X_test_imp0[bin_keep])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 将price取log\n\ny_train_log = np.log1p(y_train) # 取log(1+y_train)，防止价格=0的时候报错\ny_val_log = np.log1p(y_val)\n\n# 数值型的填补pipeline\nnum_pipeline = Pipeline([\n    (\"scaler\", StandardScaler())\n])\n\nbin_passthrough = \"passthrough\"\n\npreprocessor = ColumnTransformer([\n    (\"num\", num_pipeline, num_cols_kept),\n    (\"bin\", bin_passthrough, bin_keep)\n], remainder=\"drop\")\n\n\n# 拟合/变换\nX_train_imp = preprocessor.fit_transform(X_train_imp0)\nX_val_imp   = preprocessor.transform(X_val_imp0)\nX_test_imp  = preprocessor.transform(X_test_imp0)\n\nout_cols = preprocessor.get_feature_names_out()\n\nX_train_prep = pd.DataFrame(X_train_imp, columns=out_cols, index=X_train.index)\nX_val_prep   = pd.DataFrame(X_val_imp,   columns=out_cols, index=X_val.index)\nX_test_prep  = pd.DataFrame(X_test_imp,  columns=out_cols, index=X_test_pred.index)\n\nnum_out_cols = [c for c in out_cols if c.startswith(\"num__\")]\nbin_out_cols = [c for c in out_cols if c.startswith(\"bin__\")]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.2 选择需要使用的变量","metadata":{}},{"cell_type":"code","source":"# 生成数值型变量的二次项和交叉项\ndef square_interaction(df, num_out_cols = num_out_cols, bin_out_cols = bin_out_cols):\n    # 对数值型变量生成平方项并命名\n    df_square = df[num_out_cols] ** 2\n    df_square.columns = [f\"{c}_square\" for c in num_out_cols]\n    # 对数值型变量生成交叉项并命名\n    inter_df = pd.DataFrame(\n        {f\"{a}*{b}\": df[a].values * df[b].values for a, b in combinations(num_out_cols, 2)},\n        index = df.index\n    )\n    # 生成指定交叉项\n    df[\"南北通透\"] = df[\"bin__朝向_南\"] * df[\"bin__朝向_北\"]\n\n    out = pd.concat([df, df_square, inter_df], axis=1)    # 合成大表\n    return out\n\nX_train_si = square_interaction(X_train_prep)\nX_val_si = square_interaction(X_val_prep)\nX_test_si = square_interaction(X_test_prep)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(X_train_si.columns))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pearson_cols = X_train_si.columns\n\n# 合并并排序\ncorr_df = (\n    X_train_si[pearson_cols].corrwith(y_train_log, method = \"pearson\").to_frame(\"pearson\")\n    .reset_index().rename(columns={\"index\": \"feature\"}).assign(abs_pearson=lambda d: d[\"pearson\"].abs())\n    .sort_values(\"abs_pearson\", ascending=False)\n)\nprint(corr_df.head(5))\n\n# 设置筛选阈值\ncorr_threhold = 0.08\npreselected_cols = corr_df.loc[corr_df[\"abs_pearson\"] >= corr_threhold, \"feature\"]\nprint(f\"保留样本{len(preselected_cols)}个\")\n\nX_train_final = X_train_si.loc[:, preselected_cols]\nX_val_final = X_val_si.loc[:, preselected_cols]\nX_test_final = X_test_si.loc[:, preselected_cols]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.3 Modeling (记得还原对数！！！)","metadata":{}},{"cell_type":"code","source":"# 对y取对数（提升稳定性）\ny_train_log = np.log1p(y_train)\ny_val_log   = np.log1p(y_val)\n\n\n# 定义模型\nols   = LinearRegression()\nridge = Ridge(alpha=0.015, random_state=111)\nlasso = Lasso(alpha=0.00005, max_iter=500000, random_state=111)\nenet  = ElasticNet(alpha=0.00005, l1_ratio=0.0001, max_iter=700000, random_state=111)\n\nmodels = {'OLS': ols, 'Ridge': ridge, 'Lasso': lasso, 'ElasticNet': enet}\n\ndef safe_transfer(log_pred: np.ndarray) -> np.ndarray:\n    log_pred = log_pred.astype(np.float64)\n    y_pred = np.expm1(log_pred)\n    return y_pred\n\nrows = []\npred_dict = {}\n\n# 交叉验证mae的打分器\ndef mae_on_original_scale(y_true_log, y_pred_log):\n    # 还原\n    y_true = np.expm1(y_true_log)\n    y_pred = np.expm1(y_pred_log)\n    return mean_absolute_error(y_true, y_pred)\n\n# 交叉验证rmae的打分器\ndef rmae_on_original_scale(y_true_log, y_pred_log):\n    y_true = np.expm1(y_true_log)\n    y_pred = np.expm1(y_pred_log)\n    mae = mean_absolute_error(y_true, y_pred)\n    return mae / np.mean(y_true)\n\nmae_scorer = make_scorer(mae_on_original_scale, greater_is_better= False)  # 自定义一个评分器，规则是分数越小越好\nrmae_scorer = make_scorer(rmae_on_original_scale, greater_is_better= False)\n\ncv = KFold(n_splits=6, shuffle=True, random_state=111)  # 六折交叉验证，shuffle = True指交叉验证切块前随机打乱数据\n\nfor name, model in tqdm(models.items(), desc=\"Training models\", ncols=100):\n\n    model.fit(X_train_final, y_train_log)    # 训练模型\n    y_train_pred = safe_transfer(model.predict(X_train_final))    # in-sample\n    y_val_pred = safe_transfer(model.predict(X_val_final))    # out-of-sample\n    y_test_pred = safe_transfer(model.predict(X_test_final))  # 测试集结果\n    # mae结果\n    mae_train = mean_absolute_error(y_train, y_train_pred)\n    mae_val = mean_absolute_error(y_val, y_val_pred)\n    # rmae = mae/y真实值的平均值\n    rmae_train = mae_train / np.mean(y_train)\n    rmae_val = mae_val / np.mean(y_val)\n    # R方\n    r2_train = r2_score(y_train, y_train_pred)\n    r2_val = r2_score(y_val, y_val_pred)\n\n    # 在确定最优参数范围之后再来用交叉检验，避免算很多次\n    # 此处注意，交叉验证的mae也需要从log还原\n    cv_mae_scores = cross_val_score(\n        clone(model),   # 复制一个没训练的模型\n        X_train_final,\n        y_train_log,    # 目标变量\n        scoring = mae_scorer,\n        cv = cv,\n        n_jobs = -1 # 使用多个CPU并行运算\n    )\n\n    cv_rmae_scores = cross_val_score(\n        clone(model),   # 复制一个没训练的模型\n        X_train_final,\n        y_train_log,    # 目标变量\n        scoring = rmae_scorer,\n        cv = cv,\n        n_jobs = -1 # 使用多个CPU并行运算\n    )\n\n    cv_mae = -cv_mae_scores.mean()  # cross_val_score返回计算分数组成的数组，以负值形式\n    cv_rmae = -cv_rmae_scores.mean()\n\n    rows.append({\n        \"Metrics\": name,\n        \"In sample (mae)\": mae_train,\n        \"In sample (rmae)\": rmae_train,\n        \"In sample (R2)\": r2_train,\n        \"Out of sample (mae)\": mae_val,\n        \"Out of sample (rmae)\": rmae_val,\n        \"Out of sample (R2)\": r2_val,\n        \"Cross-Validation (mae)\": cv_mae,\n        \"Cross-Validation (rmae)\": cv_rmae\n    })\n    pred_dict[f\"{name}_pred\"] = y_test_pred\n\n\n# 汇总成表\nreport_df = pd.DataFrame(rows)\nprint(report_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 检查最优参数，方便调参\nprint(\"Best alpha for Ridge:\", ridge.alpha_)\nprint(\"Best alpha for Lasso:\", lasso.alpha_)\nprint(\"Best alpha for ElasticNet:\", enet.alpha_)\nprint(\"Best l1_ratio for ElasticNet:\", enet.l1_ratio_)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.set_option('display.float_format', '{:.6f}'.format)   # 保留6位小数\npred_df = pd.DataFrame(pred_dict, index = X_test.index)\npred_df = pd.concat([pd.DataFrame(pred_dict, index=X_test.index), X_test[[\"ID\"]]], axis=1)\npred_df.head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 为每一个模型都生成一个submit结果\nmodel_pred = [\"OLS_pred\", \"Ridge_pred\", \"Lasso_pred\", \"ElasticNet_pred\"]\nfor pre in model_pred:\n    pred_df_renamed = pred_df.rename(columns={pre: \"Price\"})\n    pred_df_renamed = pred_df_renamed[[\"ID\", \"Price\"]]\n    pred_df_renamed.to_excel(f\"output_rent_{pre}.xlsx\", index=False)\n\n    df1 = pd.read_excel(f\"output_price_{pre}.xlsx\", engine=\"openpyxl\")\n    df2 = pd.read_excel(f\"output_rent_{pre}.xlsx\", engine=\"openpyxl\")\n\n    df_combined = pd.concat([df1, df2], ignore_index=True)\n    df_combined.to_csv(f\"submit_{pre}.csv\", index = False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}