{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f5c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作路径: c:\\Users\\lenovo\\Desktop\\2025\\KE\\Quent\\Quant_RUC-main\\Exam\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_path = os.getcwd()\n",
    "print(\"当前工作路径:\", current_path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import cn2an\n",
    "\n",
    "frame_patterns = {\n",
    "    'room': r'(\\d+)室',     \n",
    "    'hall': r'(\\d+)厅',      \n",
    "    'kitchen': r'(\\d+)厨',   \n",
    "    'bathroom': r'(\\d+)卫',\n",
    "    'apartment': r'(\\d+)房间' \n",
    "}\n",
    "\n",
    "def get_lift_ratio(s):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    match = re.search(r'([^梯]+)梯([^户]+)户', s)\n",
    "    if match:\n",
    "        try:\n",
    "            lift_num = cn2an.cn2an(match.group(1), 'normal')\n",
    "            household_num = cn2an.cn2an(match.group(2), 'normal')\n",
    "            return lift_num / household_num\n",
    "        except Exception as e:\n",
    "            print(f\"转换错误：{e}\")\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_relative_height(s):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    match = re.search(r'([^()]+)', s)\n",
    "    if match:\n",
    "        return match.group(1).strip() \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_total_floor(s):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    match = re.search(r'\\s*\\((共(\\d+)层)\\)', s)\n",
    "    if match:\n",
    "        return int(match.group(2))\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "direction_mapping = {\n",
    "    '东': 'east',\n",
    "    '西': 'west',\n",
    "    '南': 'south',\n",
    "    '北': 'north',\n",
    "    '东南': 'south_east',\n",
    "    '东北': 'north_east',\n",
    "    '西南': 'south_west',\n",
    "    '西北': 'north_west'\n",
    "}\n",
    "\n",
    "def process_directions(direction_str):\n",
    "    directions = direction_str.split()\n",
    "    processed_directions = []\n",
    "    for direction in directions:\n",
    "        if direction in direction_mapping:\n",
    "            processed_directions.append(direction_mapping[direction])\n",
    "    return processed_directions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8c02887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: (103871, 33)\n",
      "测试集大小: (34017, 33)\n",
      "\n",
      "预处理后的列名:\n",
      "['location1', 'location2', 'location3', 'ring', 'price', 'area_gross', 'area_net', 'structure', 'decoration', 'lift_ornot', 'transaction_ownership', 'purpose', 'age', 'property_ownership', 'lon', 'lat', 'green_rate', 'floor_area_ratio', 'structure_comm', 'water_supply']\n",
      "area_gross: 存在\n",
      "lift_ratio: 存在\n",
      "parking_per_unit: 存在\n",
      "house_age: 存在\n",
      "lon: 存在\n",
      "lat: 存在\n",
      "\n",
      "数据处理完成！\n",
      "训练集处理后大小: (103871, 55)\n",
      "测试集处理后大小: (34017, 55)\n",
      "\n",
      "================================================================================\n",
      "处理后训练集的所有列名及含义\n",
      "================================================================================\n",
      "\n",
      "共 55 列\n",
      "\n",
      "   1. location1                      - 城市\n",
      "   2. location2                      - 区域\n",
      "   3. location3                      - 板块\n",
      "   4. ring                           - 环线\n",
      "   5. price                          - 价格\n",
      "   6. area_gross                     - 建筑面积\n",
      "   7. area_net                       - 套内面积\n",
      "   8. structure                      - 建筑结构\n",
      "   9. decoration                     - 装修情况\n",
      "  10. lift_ornot                     - 是否配备电梯\n",
      "  11. transaction_ownership          - 交易权属\n",
      "  12. purpose                        - 房屋用途\n",
      "  13. age                            - 房屋年限\n",
      "  14. property_ownership             - 产权所属\n",
      "  15. lon                            - 经度\n",
      "  16. lat                            - 纬度\n",
      "  17. green_rate                     - 绿化率\n",
      "  18. floor_area_ratio               - 容积率\n",
      "  19. structure_comm                 - 建筑结构_comm\n",
      "  20. water_supply                   - 供水\n",
      "  21. heating                        - 供暖\n",
      "  22. power_supply                   - 供电\n",
      "  23. room                           - 房间数（室）\n",
      "  24. hall                           - 客厅数（厅）\n",
      "  25. kitchen                        - 厨房数（厨）\n",
      "  26. bathroom                       - 卫生间数（卫）\n",
      "  27. lift_ratio                     - 梯户比例（数值）\n",
      "  28. house_age                      - 房龄（2025-建筑年代）\n",
      "  29. parking_per_unit               - 每户停车位\n",
      "  30. relative_height                - 相对楼层高度\n",
      "  31. ring_encoded                   - 未知\n",
      "  32. structure_encoded              - 未知\n",
      "  33. decoration_encoded             - 未知\n",
      "  34. transaction_ownership_encoded  - 未知\n",
      "  35. purpose_encoded                - 未知\n",
      "  36. property_ownership_encoded     - 未知\n",
      "  37. structure_comm_encoded         - 未知\n",
      "  38. water_supply_encoded           - 未知\n",
      "  39. heating_encoded                - 未知\n",
      "  40. power_supply_encoded           - 未知\n",
      "  41. lift_ornot_encoded             - 未知\n",
      "  42. relative_height_encoded        - 未知\n",
      "  43. east                           - 朝向-东\n",
      "  44. west                           - 朝向-西\n",
      "  45. south                          - 朝向-南\n",
      "  46. north                          - 朝向-北\n",
      "  47. south_east                     - 朝向-东南\n",
      "  48. north_east                     - 朝向-东北\n",
      "  49. south_west                     - 朝向-西南\n",
      "  50. north_west                     - 朝向-西北\n",
      "  51. advantage_score                - 房屋优势得分\n",
      "  52. near_exists                    - 周边配套是否存在\n",
      "  53. transport_exists               - 交通出行是否存在\n",
      "  54. customer_feedback_exists       - 客户反馈是否存在\n",
      "  55. is_city3_or_city9              - 是否为城市3或9\n",
      "\n",
      "================================================================================\n",
      "保存处理后的数据...\n",
      "================================================================================\n",
      "\n",
      "已保存以下文件:\n",
      "  - train_processed.csv (处理后的训练集)\n",
      "  - test_processed.csv (处理后的测试集)\n"
     ]
    }
   ],
   "source": [
    "# 读取新数据集\n",
    "train_df = pd.read_csv('ruc_Class25Q2_train_price.csv')\n",
    "test_df = pd.read_csv('ruc_Class25Q2_test_price.csv')\n",
    "\n",
    "print(f\"训练集大小: {train_df.shape}\")\n",
    "print(f\"测试集大小: {test_df.shape}\")\n",
    "\n",
    "# 保存原始location1用于可视化\n",
    "train_location1 = train_df['城市'].copy()\n",
    "test_location1 = test_df['城市'].copy()\n",
    "\n",
    "def preprocess(df):\n",
    "    '''\n",
    "    数据预处理函数\n",
    "    '''\n",
    "    # ============ 第一部分：重命名列 ============\n",
    "    rename_mapping = {\n",
    "        '城市': 'location1',\n",
    "        '区域': 'location2',\n",
    "        '板块': 'location3',  # 板块作为主要位置变量\n",
    "        '环线': 'ring',\n",
    "        'Price': 'price',\n",
    "        '建筑面积': 'area_gross',\n",
    "        '套内面积': 'area_net',\n",
    "        '房屋户型': 'frame',\n",
    "        '所在楼层': 'floor',\n",
    "        '房屋朝向': 'directions',\n",
    "        '建筑结构': 'structure',\n",
    "        '装修情况': 'decoration',\n",
    "        '配备电梯': 'lift_ornot',\n",
    "        '交易权属': 'transaction_ownership',\n",
    "        '房屋用途': 'purpose',\n",
    "        '房屋年限': 'age',\n",
    "        '产权所属': 'property_ownership',\n",
    "        '房屋优势': 'advantage',\n",
    "        '周边配套': 'near',\n",
    "        '交通出行': 'transport',\n",
    "        '建筑年代': 'build_year',\n",
    "        '房屋总数': 'total_units',\n",
    "        '停车位': 'parking_spaces',\n",
    "        '绿化率': 'green_rate',\n",
    "        '容积率': 'floor_area_ratio',\n",
    "        '建筑结构_comm': 'structure_comm',\n",
    "        '供水': 'water_supply',\n",
    "        '供暖': 'heating',\n",
    "        '供电': 'power_supply',\n",
    "        '客户反馈': 'customer_feedback',\n",
    "        'lon': 'lon',\n",
    "        'lat': 'lat',\n",
    "    }\n",
    "    \n",
    "    df.rename(columns=rename_mapping, inplace=True)\n",
    "    \n",
    "    # ============ 第二部分：处理数值型变量 ============\n",
    "    \n",
    "    # 1. 建筑年代处理（支持\"xxxx年\"和\"xxxx-xxxx年\"）\n",
    "    def extract_build_year(s):\n",
    "        if pd.isna(s):\n",
    "            return None\n",
    "        s = str(s)\n",
    "        # 提取年份范围，如\"2000-2005年\"返回均值\n",
    "        match = re.search(r'(\\d{4})\\s*-\\s*(\\d{4})', s)\n",
    "        if match:\n",
    "            year1 = int(match.group(1))\n",
    "            year2 = int(match.group(2))\n",
    "            return (year1 + year2) / 2\n",
    "        # 单个年份\n",
    "        match = re.search(r'(\\d{4})', s)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        return None\n",
    "    \n",
    "    if 'build_year' in df.columns:\n",
    "        df['build_year_num'] = df['build_year'].apply(extract_build_year)\n",
    "    \n",
    "    # 2. 建筑面积和套内面积\n",
    "    if 'area_gross' in df.columns:\n",
    "        df['area_gross'] = df['area_gross'].astype(str).str.replace('㎡', '').str.strip()\n",
    "        df['area_gross'] = pd.to_numeric(df['area_gross'], errors='coerce')\n",
    "    \n",
    "    if 'area_net' in df.columns:\n",
    "        df['area_net'] = df['area_net'].astype(str).str.replace('㎡', '').str.strip()\n",
    "        df['area_net'] = pd.to_numeric(df['area_net'], errors='coerce')\n",
    "    \n",
    "    # 3. 提取房屋户型（从frame中提取房间数）\n",
    "    if 'frame' in df.columns:\n",
    "        for key, pattern in frame_patterns.items():\n",
    "            df[key] = df['frame'].astype(str).str.extract(pattern, expand=False).fillna(0).astype(int)\n",
    "    \n",
    "    # 4. 梯户比例提取和计算\n",
    "    # 梯户比例列重命名为lift_ratio_str（保存原始字符串）\n",
    "    # 然后从其中提取数字计算lift_ratio\n",
    "    if '梯户比例' in df.columns:\n",
    "        df['lift_ratio_str'] = df['梯户比例'].fillna('')\n",
    "        df['lift_ratio'] = df['lift_ratio_str'].apply(get_lift_ratio)\n",
    "    elif 'lift_ratio' in df.columns:\n",
    "        df['lift_ratio_str'] = df['lift_ratio'].fillna('')\n",
    "        df['lift_ratio'] = df['lift_ratio_str'].apply(get_lift_ratio)\n",
    "    \n",
    "    # 5. 计算房龄（使用2025作为当前年份）\n",
    "    # 注意：城市3、5、9没有建筑年代数据\n",
    "    if 'location1' in df.columns and 'build_year_num' in df.columns:\n",
    "        # 只对非3、5、9城市计算房龄\n",
    "        df['house_age'] = np.nan\n",
    "        mask = (~df['location1'].isin(['3', '5', '9'])) & (~df['build_year_num'].isna())\n",
    "        df.loc[mask, 'house_age'] = 2025 - df.loc[mask, 'build_year_num']\n",
    "    \n",
    "    # 6. 处理停车位和房屋总数（提取数字）\n",
    "    def extract_number(s):\n",
    "        if pd.isna(s):\n",
    "            return np.nan\n",
    "        s = str(s)\n",
    "        match = re.search(r'(\\d+)', s)\n",
    "        return float(match.group(1)) if match else np.nan\n",
    "    \n",
    "    if 'parking_spaces' in df.columns and 'total_units' in df.columns:\n",
    "        df['parking_spaces_num'] = df['parking_spaces'].apply(extract_number)\n",
    "        df['total_units_num'] = df['total_units'].apply(extract_number)\n",
    "        # 计算每户停车位\n",
    "        df['parking_per_unit'] = df['parking_spaces_num'] / df['total_units_num']\n",
    "        df['parking_per_unit'] = df['parking_per_unit'].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # 7. 绿化率和容积率（纯数值，只需转换为数值型）\n",
    "    # 注意：已经通过rename_mapping重命名为green_rate和floor_area_ratio\n",
    "    if 'green_rate' in df.columns:\n",
    "        df['green_rate'] = pd.to_numeric(df['green_rate'], errors='coerce')\n",
    "    if 'floor_area_ratio' in df.columns:\n",
    "        df['floor_area_ratio'] = pd.to_numeric(df['floor_area_ratio'], errors='coerce')\n",
    "    \n",
    "    # 8. 经纬度\n",
    "    if 'lon' in df.columns:\n",
    "        df['lon'] = pd.to_numeric(df['lon'], errors='coerce')\n",
    "    if 'lat' in df.columns:\n",
    "        df['lat'] = pd.to_numeric(df['lat'], errors='coerce')\n",
    "    \n",
    "    # 9. 楼层信息提取\n",
    "    if 'floor' in df.columns:\n",
    "        df['relative_height'] = df['floor'].apply(get_relative_height)\n",
    "        df['total_floor'] = df['floor'].apply(get_total_floor)\n",
    "    \n",
    "    # ============ 第三部分：基于地理层级的缺失值填充 ============\n",
    "    \n",
    "    def fill_missing_by_hierarchy(df, col_name, ratio_base_col=None):\n",
    "        \"\"\"\n",
    "        基于地理层级填充缺失值（板块->区域->城市）\n",
    "        \n",
    "        Args:\n",
    "            df: 数据框\n",
    "            col_name: 需要填充的列名\n",
    "            ratio_base_col: 如果指定，则计算比率填充（如area_net基于area_gross的比率）\n",
    "        \"\"\"\n",
    "        if col_name not in df.columns:\n",
    "            return df\n",
    "        \n",
    "        # 检查是否包含地理信息\n",
    "        if 'location3' not in df.columns:\n",
    "            return df\n",
    "        \n",
    "        # 确定缺失值的判断条件（NaN或编码为0）\n",
    "        if ratio_base_col and ratio_base_col in df.columns:\n",
    "            # 对于比率填充的情况（如area_net）\n",
    "            missing_mask = df[col_name].isna()\n",
    "        else:\n",
    "            # 对于其他情况，包括编码为0的情况\n",
    "            missing_mask = (df[col_name].isna()) | (df[col_name] == 0)\n",
    "        \n",
    "        missing_indices = df[missing_mask].index\n",
    "        \n",
    "        if len(missing_indices) == 0:\n",
    "            return df\n",
    "        \n",
    "        # 如果是指定比率填充的情况\n",
    "        if ratio_base_col and ratio_base_col in df.columns:\n",
    "            # 计算比率：先板块，再区域，再城市\n",
    "            # 1. 计算板块级别的比率\n",
    "            df_temp = df[~df[col_name].isna() & ~df[ratio_base_col].isna()].copy()\n",
    "            if len(df_temp) > 0:\n",
    "                df_temp['ratio'] = df_temp[col_name] / df_temp[ratio_base_col]\n",
    "                \n",
    "                # 板块级别\n",
    "                location3_ratios = df_temp.groupby('location3')['ratio'].mean().to_dict()\n",
    "                for idx in missing_indices:\n",
    "                    if idx in df.index:\n",
    "                        location3 = df.loc[idx, 'location3']\n",
    "                        if pd.notna(location3) and location3 in location3_ratios:\n",
    "                            if pd.notna(df.loc[idx, ratio_base_col]):\n",
    "                                df.loc[idx, col_name] = df.loc[idx, ratio_base_col] * location3_ratios[location3]\n",
    "                                continue\n",
    "                \n",
    "                # 区域级别（对于板块级别无法填充的）\n",
    "                location2_ratios = df_temp.groupby('location2')['ratio'].mean().to_dict()\n",
    "                for idx in missing_indices:\n",
    "                    if idx in df.index and (pd.isna(df.loc[idx, col_name]) or df.loc[idx, col_name] is pd.NA):\n",
    "                        location2 = df.loc[idx, 'location2']\n",
    "                        if pd.notna(location2) and location2 in location2_ratios:\n",
    "                            if pd.notna(df.loc[idx, ratio_base_col]):\n",
    "                                df.loc[idx, col_name] = df.loc[idx, ratio_base_col] * location2_ratios[location2]\n",
    "                                continue\n",
    "                \n",
    "                # 城市级别\n",
    "                location1_ratios = df_temp.groupby('location1')['ratio'].mean().to_dict()\n",
    "                for idx in missing_indices:\n",
    "                    if idx in df.index and (pd.isna(df.loc[idx, col_name]) or df.loc[idx, col_name] is pd.NA):\n",
    "                        location1 = df.loc[idx, 'location1']\n",
    "                        if pd.notna(location1) and location1 in location1_ratios:\n",
    "                            if pd.notna(df.loc[idx, ratio_base_col]):\n",
    "                                df.loc[idx, col_name] = df.loc[idx, ratio_base_col] * location1_ratios[location1]\n",
    "        else:\n",
    "            # 普通数值填充（计算平均值）\n",
    "            # 先计算板块级别的平均值\n",
    "            df_valid = df[~missing_mask].copy()\n",
    "            if len(df_valid) > 0:\n",
    "                # 板块级别\n",
    "                location3_means = df_valid.groupby('location3')[col_name].mean().to_dict()\n",
    "                for idx in missing_indices:\n",
    "                    if idx in df.index:\n",
    "                        location3 = df.loc[idx, 'location3']\n",
    "                        if pd.notna(location3) and location3 in location3_means:\n",
    "                            if pd.notna(location3_means[location3]) and location3_means[location3] != 0:\n",
    "                                df.loc[idx, col_name] = location3_means[location3]\n",
    "                                continue\n",
    "                \n",
    "                # 区域级别\n",
    "                location2_means = df_valid.groupby('location2')[col_name].mean().to_dict()\n",
    "                for idx in missing_indices:\n",
    "                    if idx in df.index and (df.loc[idx, col_name] == 0 or pd.isna(df.loc[idx, col_name])):\n",
    "                        location2 = df.loc[idx, 'location2']\n",
    "                        if pd.notna(location2) and location2 in location2_means:\n",
    "                            if pd.notna(location2_means[location2]) and location2_means[location2] != 0:\n",
    "                                df.loc[idx, col_name] = location2_means[location2]\n",
    "                                continue\n",
    "                \n",
    "                # 城市级别\n",
    "                location1_means = df_valid.groupby('location1')[col_name].mean().to_dict()\n",
    "                for idx in missing_indices:\n",
    "                    if idx in df.index and (df.loc[idx, col_name] == 0 or pd.isna(df.loc[idx, col_name])):\n",
    "                        location1 = df.loc[idx, 'location1']\n",
    "                        if pd.notna(location1) and location1 in location1_means:\n",
    "                            if pd.notna(location1_means[location1]) and location1_means[location1] != 0:\n",
    "                                df.loc[idx, col_name] = location1_means[location1]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # 对数值列进行分层级填充\n",
    "    # 1. 特殊处理：套内面积基于建筑面积的比率填充\n",
    "    if 'area_net' in df.columns and 'area_gross' in df.columns:\n",
    "        df = fill_missing_by_hierarchy(df, 'area_net', ratio_base_col='area_gross')\n",
    "    \n",
    "    # 2. 其他数值列的普通填充\n",
    "    numeric_cols_for_imputation = ['parking_spaces_num', 'total_units_num', 'green_rate', \n",
    "                                     'floor_area_ratio', 'build_year_num', 'house_age', 'parking_per_unit']\n",
    "    for col in numeric_cols_for_imputation:\n",
    "        if col in df.columns:\n",
    "            df = fill_missing_by_hierarchy(df, col)\n",
    "    \n",
    "    # ============ 第四部分：处理类别型变量 ============\n",
    "    \n",
    "    # 1. 环线（ring）编码：提取第一个数字汉字或内中外\n",
    "    if 'ring' in df.columns:\n",
    "        def encode_ring(s):\n",
    "            if pd.isna(s) or s == '':\n",
    "                return 0\n",
    "            s = str(s)\n",
    "            # 提取数字汉字：一二三四五六七八九十\n",
    "            num_chinese = ['一', '二', '三', '四', '五', '六', '七', '八', '九', '十']\n",
    "            for i, char in enumerate(num_chinese, 1):\n",
    "                if char in s:\n",
    "                    return i\n",
    "            # 提取内中外\n",
    "            if '内' in s:\n",
    "                return 1\n",
    "            elif '中' in s:\n",
    "                return 2\n",
    "            elif '外' in s:\n",
    "                return 3\n",
    "            return 0\n",
    "        df['ring_encoded'] = df['ring'].apply(encode_ring)\n",
    "        df['ring'] = df['ring'].fillna('环线_未知')\n",
    "    \n",
    "    # 2. 建筑结构（structure）编码：框架=3，钢混=2，其他=1\n",
    "    if 'structure' in df.columns:\n",
    "        def encode_structure(s):\n",
    "            if pd.isna(s) or s == '':\n",
    "                return 0\n",
    "            s = str(s)\n",
    "            if '框架' in s:\n",
    "                return 3\n",
    "            elif '钢混' in s:\n",
    "                return 2\n",
    "            else:\n",
    "                return 1\n",
    "        df['structure_encoded'] = df['structure'].apply(encode_structure)\n",
    "        df['structure'] = df['structure'].fillna('建筑结构_未知')\n",
    "    \n",
    "    # 3. 装修情况（decoration）编码：精装=4，简装=3，毛坯=2，其他=1\n",
    "    if 'decoration' in df.columns:\n",
    "        def encode_decoration(s):\n",
    "            if pd.isna(s) or s == '':\n",
    "                return 0\n",
    "            s = str(s)\n",
    "            if '精装' in s:\n",
    "                return 4\n",
    "            elif '简装' in s:\n",
    "                return 3\n",
    "            elif '毛坯' in s:\n",
    "                return 2\n",
    "            else:\n",
    "                return 1\n",
    "        df['decoration_encoded'] = df['decoration'].apply(encode_decoration)\n",
    "        df['decoration'] = df['decoration'].fillna('装修情况_未知')\n",
    "    \n",
    "    # 4. 交易权属（transaction_ownership）编码：私产=5，商品房=4，二类经济适用房=3，动迁安置房=已购公房=2，其他=1\n",
    "    if 'transaction_ownership' in df.columns:\n",
    "        def encode_transaction(s):\n",
    "            if pd.isna(s) or s == '':\n",
    "                return 0\n",
    "            s = str(s)\n",
    "            if '私产' in s:\n",
    "                return 5\n",
    "            elif '商品房' in s and '二类' not in s:\n",
    "                return 4\n",
    "            elif '二类经济适用房' in s:\n",
    "                return 3\n",
    "            elif '已购公房' in s or '动迁安置房' in s or '定向安置房' in s:\n",
    "                return 2\n",
    "            else:\n",
    "                return 1\n",
    "        df['transaction_ownership_encoded'] = df['transaction_ownership'].apply(encode_transaction)\n",
    "        df['transaction_ownership'] = df['transaction_ownership'].fillna('交易权属_未知')\n",
    "    \n",
    "    # 5. 房屋用途（purpose）编码：普通住宅/别墅=3，公寓/商住两用=2，车库/商业办公=1\n",
    "    if 'purpose' in df.columns:\n",
    "        def encode_purpose(s):\n",
    "            if pd.isna(s) or s == '':\n",
    "                return 0\n",
    "            s = str(s)\n",
    "            if '别墅' in s or '普通住宅' in s:\n",
    "                return 3\n",
    "            elif '公寓' in s or '商住两用' in s:\n",
    "                return 2\n",
    "            elif '车库' in s or '商业办公' in s or '酒店式' in s:\n",
    "                return 1\n",
    "            else:\n",
    "                return 1\n",
    "        df['purpose_encoded'] = df['purpose'].apply(encode_purpose)\n",
    "        df['purpose'] = df['purpose'].fillna('房屋用途_未知')\n",
    "    \n",
    "    # 6. 产权所属（property_ownership）编码：非共有=2，共有=1\n",
    "    if 'property_ownership' in df.columns:\n",
    "        def encode_property(s):\n",
    "            if pd.isna(s) or s == '':\n",
    "                return 0\n",
    "            s = str(s)\n",
    "            if '非共有' in s:\n",
    "                return 2\n",
    "            elif '共有' in s:\n",
    "                return 1\n",
    "            else:\n",
    "                return 1\n",
    "        df['property_ownership_encoded'] = df['property_ownership'].apply(encode_property)\n",
    "        df['property_ownership'] = df['property_ownership'].fillna('产权所属_未知')\n",
    "    \n",
    "    # 8. 建筑结构_comm（structure_comm）编码：板楼=4，塔板结合=3，平房=2，塔楼=1\n",
    "    if 'structure_comm' in df.columns:\n",
    "        def encode_structure_comm(s):\n",
    "            if pd.isna(s) or s == '':\n",
    "                return 0\n",
    "            s = str(s)\n",
    "            if '板楼' in s and '塔板' not in s:\n",
    "                return 4\n",
    "            elif '塔板结合' in s or ('塔板' in s and '结合' in s):\n",
    "                return 3\n",
    "            elif '平房' in s:\n",
    "                return 2\n",
    "            elif '塔楼' in s:\n",
    "                return 1\n",
    "            else:\n",
    "                return 2\n",
    "        df['structure_comm_encoded'] = df['structure_comm'].apply(encode_structure_comm)\n",
    "        df['structure_comm'] = df['structure_comm'].fillna('建筑结构_comm_未知')\n",
    "    \n",
    "    # 9. 供水（water_supply）编码：民水=2，商水=1\n",
    "    if 'water_supply' in df.columns:\n",
    "        def encode_water(s):\n",
    "            if pd.isna(s) or s == '':\n",
    "                return 0\n",
    "            s = str(s)\n",
    "            if '民水' in s:\n",
    "                return 2\n",
    "            elif '商水' in s:\n",
    "                return 1\n",
    "            else:\n",
    "                return 2\n",
    "        df['water_supply_encoded'] = df['water_supply'].apply(encode_water)\n",
    "        df['water_supply'] = df['water_supply'].fillna('供水_未知')\n",
    "    \n",
    "    # 10. 供暖（heating）编码：集中供暖=2，自采暖=1\n",
    "    if 'heating' in df.columns:\n",
    "        def encode_heating(s):\n",
    "            if pd.isna(s) or s == '':\n",
    "                return 0\n",
    "            s = str(s)\n",
    "            if '集中供暖' in s:\n",
    "                return 2\n",
    "            elif '自采暖' in s:\n",
    "                return 1\n",
    "            else:\n",
    "                return 2\n",
    "        df['heating_encoded'] = df['heating'].apply(encode_heating)\n",
    "        df['heating'] = df['heating'].fillna('供暖_未知')\n",
    "    \n",
    "    # 11. 供电（power_supply）编码：民电=2，商电=1\n",
    "    if 'power_supply' in df.columns:\n",
    "        def encode_power(s):\n",
    "            if pd.isna(s) or s == '':\n",
    "                return 0\n",
    "            s = str(s)\n",
    "            if '民电' in s:\n",
    "                return 2\n",
    "            elif '商电' in s:\n",
    "                return 1\n",
    "            else:\n",
    "                return 2\n",
    "        df['power_supply_encoded'] = df['power_supply'].apply(encode_power)\n",
    "        df['power_supply'] = df['power_supply'].fillna('供电_未知')\n",
    "    \n",
    "    # 12. 配备电梯（lift_ornot）编码：有=2，无=1\n",
    "    if 'lift_ornot' in df.columns:\n",
    "        def encode_lift(s):\n",
    "            if pd.isna(s) or s == '':\n",
    "                return 0\n",
    "            s = str(s)\n",
    "            if '有' in s and '无' not in s:\n",
    "                return 2\n",
    "            elif '无' in s:\n",
    "                return 1\n",
    "            else:\n",
    "                return 1\n",
    "        df['lift_ornot_encoded'] = df['lift_ornot'].apply(encode_lift)\n",
    "        df['lift_ornot'] = df['lift_ornot'].fillna('配备电梯_未知')\n",
    "    \n",
    "    # 13. 相对楼层高度（relative_height）编码：中楼层=4，高楼层=3，低楼层=2，其他=1\n",
    "    if 'relative_height' in df.columns:\n",
    "        def encode_relative_height(s):\n",
    "            if pd.isna(s) or s == '' or str(s) == '未知楼层':\n",
    "                return 0\n",
    "            s = str(s)\n",
    "            if '中楼层' in s:\n",
    "                return 4\n",
    "            elif '高楼层' in s:\n",
    "                return 3\n",
    "            elif '低楼层' in s:\n",
    "                return 2\n",
    "            elif '顶层' in s or '底层' in s or '地下室' in s:\n",
    "                return 1\n",
    "            else:\n",
    "                return 1\n",
    "        df['relative_height_encoded'] = df['relative_height'].apply(encode_relative_height)\n",
    "        df['relative_height'] = df['relative_height'].fillna('未知楼层')\n",
    "    \n",
    "    # 处理ring_encoded：对非0值取倒数，然后对0、2、3、4城市的0值用分层级填充\n",
    "    if 'ring_encoded' in df.columns:\n",
    "        # 取倒数处理（ring_encoded为0的不变）\n",
    "        df['ring_encoded'] = df['ring_encoded'].apply(lambda x: 1/x if x != 0 else 0)\n",
    "        \n",
    "        # 对城市0、2、3、4中ring_encoded=0的进行分层级填充\n",
    "        if 'location1' in df.columns:\n",
    "            # 先保存原始数据，只对指定城市进行填充\n",
    "            original_ring = df['ring_encoded'].copy()\n",
    "            # 对0、2、3、4城市的数据临时填充\n",
    "            mask_zero_cities = df['location1'].astype(str).isin(['0', '2', '3', '4'])\n",
    "            df_temp = df[mask_zero_cities].copy()\n",
    "            if len(df_temp) > 0:\n",
    "                df_temp = fill_missing_by_hierarchy(df_temp, 'ring_encoded')\n",
    "                df.loc[df_temp.index, 'ring_encoded'] = df_temp['ring_encoded']\n",
    "    \n",
    "    # 填充编码变量的缺失值（使用分层级填充）\n",
    "    encoded_cols_for_imputation = ['ring_encoded', 'structure_encoded', 'decoration_encoded',\n",
    "                                     'transaction_ownership_encoded', 'purpose_encoded',\n",
    "                                     'property_ownership_encoded', 'structure_comm_encoded', \n",
    "                                     'water_supply_encoded', 'heating_encoded', 'power_supply_encoded',\n",
    "                                     'lift_ornot_encoded', 'relative_height_encoded']\n",
    "    \n",
    "    # 对3、9城市的特定变量跳过填充\n",
    "    skip_fill_for_city_3_9 = ['structure_comm_encoded', 'water_supply_encoded', \n",
    "                               'heating_encoded', 'power_supply_encoded']\n",
    "    \n",
    "    for col in encoded_cols_for_imputation:\n",
    "        if col in df.columns:\n",
    "            if col in skip_fill_for_city_3_9:\n",
    "                # 对3、9城市的数据不填充这些变量\n",
    "                if 'location1' in df.columns:\n",
    "                    mask_not_city_3_9 = ~df['location1'].astype(str).isin(['3', '9'])\n",
    "                    df_temp = df[mask_not_city_3_9].copy()\n",
    "                    if len(df_temp) > 0:\n",
    "                        df_temp = fill_missing_by_hierarchy(df_temp, col)\n",
    "                        df.loc[df_temp.index, col] = df_temp[col]\n",
    "                else:\n",
    "                    # 如果没有location1，所有数据都填充\n",
    "                    df = fill_missing_by_hierarchy(df, col)\n",
    "            else:\n",
    "                # 其他变量对所有缺失值（编码为0）进行填充\n",
    "                df = fill_missing_by_hierarchy(df, col)\n",
    "    \n",
    "    # 2. 朝向处理（转换为8个方向标志）\n",
    "    if 'directions' in df.columns:\n",
    "        df['directions'] = df['directions'].fillna('未知朝向')\n",
    "        df['directions'] = df['directions'].apply(process_directions)\n",
    "        dummies = df['directions'].apply(lambda x: pd.Series([1 if d in x else 0 for d in direction_mapping.values()]))\n",
    "        dummies.columns = direction_mapping.values()\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    \n",
    "    # ============ 第五部分：处理半结构化文本 ============\n",
    "    \n",
    "    # 1. 房屋优势打分规则\n",
    "    if 'advantage' in df.columns:\n",
    "        def calculate_advantage_score(s):\n",
    "            if pd.isna(s):\n",
    "                return 0\n",
    "            s = str(s)\n",
    "            score = 0\n",
    "            if '地铁' in s:\n",
    "                score += 1\n",
    "            if '房本满两年' in s:\n",
    "                score += 0.4\n",
    "            if '房本满五年' in s:\n",
    "                score += 1\n",
    "            return score\n",
    "        df['advantage_score'] = df['advantage'].apply(calculate_advantage_score)\n",
    "    \n",
    "    # 2. 周边配套和交通出行转为存在性标记\n",
    "    for var in ['near', 'transport']:\n",
    "        if var in df.columns:\n",
    "            df[f'{var}_exists'] = np.where(df[var].isna(), 0, 1)\n",
    "    \n",
    "    # ============ 第六部分：处理纯自然语言 ============\n",
    "    \n",
    "    # 只有客户反馈是真正的自然语言\n",
    "    if 'customer_feedback' in df.columns:\n",
    "        df['customer_feedback_exists'] = np.where(df['customer_feedback'].isna(), 0, 1)\n",
    "    \n",
    "    # ============ 第七部分：城市3和9的特殊标记 ============\n",
    "    \n",
    "    if 'location1' in df.columns:\n",
    "        df['is_city3_or_city9'] = (df['location1'].astype(str) == '3') | (df['location1'].astype(str) == '9')\n",
    "    \n",
    "    # ============ 第八部分：清理不需要的列 ============\n",
    "    \n",
    "    # 处理绿化和容积率列名（可能有空格的问题）\n",
    "    if '绿 化 率' in df.columns:\n",
    "        df.rename(columns={'绿 化 率': 'green_rate'}, inplace=True)\n",
    "    if '容 积 率' in df.columns:\n",
    "        df.rename(columns={'容 积 率': 'floor_area_ratio'}, inplace=True)\n",
    "    if '绿化率' in df.columns and 'green_rate' not in df.columns:\n",
    "        df.rename(columns={'绿化率': 'green_rate'}, inplace=True)\n",
    "    if '容积率' in df.columns and 'floor_area_ratio' not in df.columns:\n",
    "        df.rename(columns={'容积率': 'floor_area_ratio'}, inplace=True)\n",
    "    \n",
    "    drop_columns = ['frame', 'floor', 'directions', 'lift_ratio_str', \n",
    "                    'build_year', 'build_year_num', 'advantage', \n",
    "                    'near', 'transport', 'customer_feedback',\n",
    "                    'district',  # district不再使用\n",
    "                    'parking_spaces_num', 'total_units_num',  # 只保留parking_per_unit\n",
    "                    'total_floor',  # 有了relative_height就不需要total_floor\n",
    "                    'parking_spaces',  # 有了parking_per_unit就不需要parking_spaces\n",
    "                    'total_units',  # 有了parking_per_unit就不需要total_units\n",
    "                    'apartment',  # 不需要apartment\n",
    "                    '梯户比例']  # 有了lift_ratio就不需要梯户比例\n",
    "    \n",
    "    drop_columns = [col for col in drop_columns if col in df.columns]\n",
    "    df = df.drop(drop_columns, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 处理数据\n",
    "train_df = preprocess(train_df)\n",
    "test_df = preprocess(test_df)\n",
    "\n",
    "# 检查预处理后的列名\n",
    "print(\"\\n预处理后的列名:\")\n",
    "print(train_df.columns.tolist()[:20])\n",
    "\n",
    "# 检查关键列是否存在\n",
    "key_cols = ['area_gross', 'lift_ratio', 'parking_per_unit', 'house_age', 'lon', 'lat']\n",
    "for col in key_cols:\n",
    "    exists = col in train_df.columns\n",
    "    print(f\"{col}: {'存在' if exists else '不存在'}\")\n",
    "\n",
    "print(\"\\n数据处理完成！\")\n",
    "print(f\"训练集处理后大小: {train_df.shape}\")\n",
    "print(f\"测试集处理后大小: {test_df.shape}\")\n",
    "\n",
    "# 定义列名中文说明\n",
    "column_descriptions = {\n",
    "    'location1': '城市',\n",
    "    'location2': '区域',\n",
    "    'location3': '板块',\n",
    "    'ring': '环线',\n",
    "    'price': '价格',\n",
    "    'area_gross': '建筑面积',\n",
    "    'area_net': '套内面积',\n",
    "    'room': '房间数（室）',\n",
    "    'hall': '客厅数（厅）',\n",
    "    'kitchen': '厨房数（厨）',\n",
    "    'bathroom': '卫生间数（卫）',\n",
    "    'total_floor': '总楼层数',\n",
    "    'relative_height': '相对楼层高度',\n",
    "    'lift_ratio': '梯户比例（数值）',\n",
    "    'structure': '建筑结构',\n",
    "    'structure_comm': '建筑结构_comm',\n",
    "    'decoration': '装修情况',\n",
    "    'lift_ornot': '是否配备电梯',\n",
    "    'transaction_ownership': '交易权属',\n",
    "    'purpose': '房屋用途',\n",
    "    'age': '房屋年限',\n",
    "    'property_ownership': '产权所属',\n",
    "    'green_rate': '绿化率',\n",
    "    'floor_area_ratio': '容积率',\n",
    "    'parking_per_unit': '每户停车位',\n",
    "    'build_year_num': '建筑年代（数值）',\n",
    "    'house_age': '房龄（2025-建筑年代）',\n",
    "    'lon': '经度',\n",
    "    'lat': '纬度',\n",
    "    'is_city3_or_city9': '是否为城市3或9',\n",
    "    'east': '朝向-东',\n",
    "    'west': '朝向-西',\n",
    "    'south': '朝向-南',\n",
    "    'north': '朝向-北',\n",
    "    'south_east': '朝向-东南',\n",
    "    'north_east': '朝向-东北',\n",
    "    'south_west': '朝向-西南',\n",
    "    'north_west': '朝向-西北',\n",
    "    'water_supply': '供水',\n",
    "    'heating': '供暖',\n",
    "    'power_supply': '供电',\n",
    "    'advantage_score': '房屋优势得分',\n",
    "    'near_exists': '周边配套是否存在',\n",
    "    'transport_exists': '交通出行是否存在',\n",
    "    'customer_feedback_exists': '客户反馈是否存在'\n",
    "}\n",
    "\n",
    "# 输出处理后的所有列名\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"处理后训练集的所有列名及含义\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n共 {len(train_df.columns)} 列\\n\")\n",
    "\n",
    "columns_after = train_df.columns.tolist()\n",
    "for i, col in enumerate(columns_after, 1):\n",
    "    desc = column_descriptions.get(col, '未知')\n",
    "    print(f\"  {i:2d}. {col:30s} - {desc}\")\n",
    "\n",
    "# 保存处理后的数据为CSV文件\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"保存处理后的数据...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "train_df.to_csv('train_processed.csv', index=False, encoding='utf-8-sig')\n",
    "test_df.to_csv('test_processed.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"\\n已保存以下文件:\")\n",
    "print(\"  - train_processed.csv (处理后的训练集)\")\n",
    "print(\"  - test_processed.csv (处理后的测试集)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4844a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df_na is: \n",
      " age                 44510\n",
      "green_rate          32883\n",
      "floor_area_ratio    33154\n",
      "lift_ratio           2619\n",
      "house_age           26361\n",
      "parking_per_unit     1323\n",
      "dtype: int64\n",
      "test_df_na is: \n",
      " age                 11296\n",
      "green_rate           9180\n",
      "floor_area_ratio     9303\n",
      "lift_ratio            635\n",
      "house_age            6193\n",
      "parking_per_unit     5136\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col_na_count=train_df.isna().sum()\n",
    "col_na_count=col_na_count[col_na_count!=0]\n",
    "print('train_df_na is: \\n',col_na_count)\n",
    "\n",
    "col_na_count=test_df.isna().sum()\n",
    "col_na_count=col_na_count[col_na_count!=0]\n",
    "print('test_df_na is: \\n',col_na_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3880fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_relation_df(location_index, train, test_df):\n",
    "    \"\"\"\n",
    "    基于分层级方法建立地理层级关系表（与fill_missing_by_hierarchy逻辑一致）\n",
    "    \"\"\"\n",
    "    if location_index == 1:\n",
    "        raise ValueError(\"城市数据齐全，不需要进行同级估计。\")\n",
    "    if location_index > 3:\n",
    "        raise ValueError(\"请选择正确的地理区分度！\")\n",
    "    \n",
    "    location_upper = 'location' + str(location_index - 1)\n",
    "    location_lower = 'location' + str(location_index)\n",
    "    \n",
    "    # 合并训练集和测试集\n",
    "    locations_df = pd.concat([train[[location_upper, location_lower]], \n",
    "                               test_df[[location_upper, location_lower]]], \n",
    "                              axis=0, ignore_index=True)\n",
    "    \n",
    "    # 去重并建立关系（使用pandas的去重，更高效）\n",
    "    location_relation_df = locations_df.drop_duplicates(subset=[location_lower])\n",
    "    location_relation_df = location_relation_df.sort_values(location_lower).reset_index(drop=True)\n",
    "    \n",
    "    # 标记是否在训练集中\n",
    "    train_location_lower_set = set(train[location_lower].unique())\n",
    "    location_relation_df[location_lower + '_isin_train'] = location_relation_df[location_lower].isin(train_location_lower_set)\n",
    "    \n",
    "    return location_relation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e6dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_class='area_gross'\n",
    "location_index=3  # 使用板块级别（location3）\n",
    "location_relation_df=get_location_relation_df(location_index,train_df,test_df)\n",
    "neighbor_num=10\n",
    "IS_UPPER=True\n",
    "\n",
    "def get_neighbor_location_list(this_location, location_index=None, location_relation_df=None, train_df=None, neighbor_num=None):\n",
    "    \"\"\"\n",
    "    基于分层级方法获取邻居位置列表\n",
    "    \"\"\"\n",
    "    if IS_UPPER:\n",
    "        location_upper = 'location' + str(location_index - 1)\n",
    "        location_lower = 'location' + str(location_index)\n",
    "        \n",
    "        \n",
    "        # 从关系表中获取上级位置\n",
    "        location_info = location_relation_df[location_relation_df[location_lower] == this_location]\n",
    "        if location_info.empty:\n",
    "            return []\n",
    "        \n",
    "        this_location_upper = location_info[location_upper].iloc[0]\n",
    "        \n",
    "        # 获取同一上级下的所有邻居（且在训练集中）\n",
    "        neighbors = location_relation_df[\n",
    "            (location_relation_df[location_upper] == this_location_upper) &\n",
    "            (location_relation_df[location_lower] != this_location) &\n",
    "            (location_relation_df[location_lower + '_isin_train'])\n",
    "        ][location_lower].tolist()\n",
    "        \n",
    "        return neighbors\n",
    "    else:\n",
    "        train_location_list = np.sort(np.unique(train_df['location' + str(location_index)]).astype(int))\n",
    "        sorted_indices = np.argsort(np.abs(train_location_list - this_location))\n",
    "        neighbor_location_list = train_location_list[sorted_indices[range(neighbor_num)]]\n",
    "        return neighbor_location_list.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "725699e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征变量列表定义完成\n",
      "线性变量: 38 个\n",
      "非线性变量: 4 个\n",
      "虚拟变量: 15 个\n"
     ]
    }
   ],
   "source": [
    "# 定义所有特征变量列表（与预处理后的变量对应）\n",
    "\n",
    "# 线性变量（纯数值型 + 已编码的类别型变量 + 0/1变量）\n",
    "linear_variable_name_list = [\n",
    "    # 数值型变量\n",
    "    'area_gross', 'area_net',  # 建筑面积\n",
    "    'room', 'hall', 'kitchen', 'bathroom',  # 房间数（从frame提取）\n",
    "    'lift_ratio',  # 梯户比例\n",
    "    'parking_per_unit',  # 每户停车位\n",
    "    'green_rate', 'floor_area_ratio',  # 绿化率、容积率\n",
    "    'house_age',  # 房龄（2025 - build_year_num）\n",
    "    'lon', 'lat',  # 经纬度\n",
    "    # 编码后的类别型变量（数值型编码）\n",
    "    'ring_encoded', 'structure_encoded', 'decoration_encoded',\n",
    "    'transaction_ownership_encoded', 'purpose_encoded',\n",
    "    'property_ownership_encoded', 'structure_comm_encoded', \n",
    "    'water_supply_encoded', 'heating_encoded', 'power_supply_encoded',\n",
    "    'lift_ornot_encoded', 'relative_height_encoded',\n",
    "    # 0/1变量（已经是数值型，不需要dummy）\n",
    "    'east', 'west', 'south', 'north',  # 朝向\n",
    "    'south_east', 'north_east', 'south_west', 'north_west',  # 朝向\n",
    "    'advantage_score',  # 房屋优势得分（数值型）\n",
    "    'near_exists', 'transport_exists', 'customer_feedback_exists',  # 存在性标记（0/1）\n",
    "    'is_city3_or_city9',  # 城市特殊标记（boolean，但可以作为0/1使用）\n",
    "]\n",
    "\n",
    "# 非线性变量（适合进行多项式和对数变换的连续数值变量）\n",
    "nonlinear_variable_name_list = [\n",
    "    'area_gross', 'area_net',  # 建筑面积 - 价格与面积通常有非线性关系\n",
    "    'house_age',  # 房龄 - 房龄对价格的影响可能是非线性的\n",
    "    'parking_per_unit',  # 每户停车位 - 可能影响价格\n",
    "    # 注意：编码后的变量不适合做非线性变换\n",
    "]\n",
    "\n",
    "# 虚拟变量（类别型变量，需要get_dummies处理）\n",
    "# 注意：这些是原始类别型变量，会通过get_dummies转换为0/1虚拟变量\n",
    "dummy_variable_name_list = [\n",
    "    'location1', 'location2', 'location3',  # 位置信息\n",
    "    'ring',  # 环线（原始类别型）\n",
    "    'structure', 'structure_comm',  # 建筑结构\n",
    "    'decoration',  # 装修情况\n",
    "    'lift_ornot',  # 是否配备电梯\n",
    "    'transaction_ownership',  # 交易权属\n",
    "    'purpose',  # 房屋用途\n",
    "    'property_ownership',  # 产权所属\n",
    "    'water_supply', 'heating', 'power_supply',  # 基础设施\n",
    "    'relative_height',  # 相对楼层高度（原始类别型）\n",
    "]\n",
    "\n",
    "print(\"特征变量列表定义完成\")\n",
    "print(f\"线性变量: {len(linear_variable_name_list)} 个\")\n",
    "print(f\"非线性变量: {len(nonlinear_variable_name_list)} 个\")\n",
    "print(f\"虚拟变量: {len(dummy_variable_name_list)} 个\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征矩阵生成函数定义\n",
    "# 注意：特征变量列表在Cell 6中已定义\n",
    "\n",
    "def get_Fmatrix_linear_part(df,linear_variable_name_list):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"输入 df 必须是 pandas DataFrame\")\n",
    "    if not isinstance(linear_variable_name_list, list) or not all(isinstance(var, str) for var in linear_variable_name_list):\n",
    "        raise ValueError(\"linear_variable_name_list 必须是一个字符串列表\")\n",
    "    if not all(var in df.columns for var in linear_variable_name_list):\n",
    "        raise ValueError(\"linear_variable_name_list 中的变量名必须存在于 df 的列中\")\n",
    "    # 复制原始 DataFrame，避免修改原始数据\n",
    "    result_df = pd.DataFrame()\n",
    "    for var in linear_variable_name_list:\n",
    "        result_df[var] = df[var]\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def get_Fmatrix_nonlinear_part(df,nonlinear_variable_name_list):\n",
    "    # 检查输入是否有效\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"输入 df 必须是 pandas DataFrame\")\n",
    "    if not isinstance(nonlinear_variable_name_list, list) or not all(isinstance(var, str) for var in nonlinear_variable_name_list):\n",
    "        raise ValueError(\"nonlinear_variable_name_list 必须是一个字符串列表\")\n",
    "    if not all(var in df.columns for var in nonlinear_variable_name_list):\n",
    "        raise ValueError(\"nonlinear_variable_name_list 中的变量名必须存在于 df 的列中\")\n",
    "\n",
    "    # 复制原始 DataFrame，避免修改原始数据\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "    # 为每个变量生成非线性项\n",
    "    for var in nonlinear_variable_name_list:\n",
    "        result_df[var] = df[var]\n",
    "        # 负一次项\n",
    "        result_df[f\"({var}+1)^-1\"] = 1/(df[var]+1) \n",
    "        # 二次项\n",
    "        result_df[f\"{var}^2\"] = df[var] ** 2\n",
    "        # 三次项\n",
    "        result_df[f\"{var}^3\"] = df[var] ** 3\n",
    "        # 对数项\n",
    "        result_df[f\"log({var}+1)\"] = np.log(df[var]+1)\n",
    "        # 对数的平方\n",
    "        result_df[f\"log({var}+1)^2\"] = (np.log(df[var]+1)) ** 2\n",
    "        # 对数的立方\n",
    "        result_df[f\"log({var}+1)^3\"] = (np.log(df[var]+1)) ** 3\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def get_Fmatrix_dummy_part(df,dummy_variable_name_list,is_test=False,train_df=None):\n",
    "    if is_test:\n",
    "        if train_df is None:\n",
    "            raise ValueError(\"为训练集生成虚拟变量时必须输入测试集，以保证测试集的虚拟变量与测试集完全重合！\")\n",
    "    \n",
    "    result_df = pd.DataFrame()\n",
    "    X_temp = pd.get_dummies(df, columns=dummy_variable_name_list, prefix=dummy_variable_name_list, drop_first=False)\n",
    "    \n",
    "    # 安全地过滤虚拟变量列\n",
    "    filtered_cols = X_temp.filter(regex='^(' + '|'.join(dummy_variable_name_list) + ')')\n",
    "    \n",
    "    # 逐个列处理，使用int8节省内存（虚拟变量只有0/1）\n",
    "    for col in filtered_cols.columns:\n",
    "        try:\n",
    "            # 尝试转换为浮点数再转int8（虚拟变量只需要0或1，int8足够）\n",
    "            result_df[col] = pd.to_numeric(filtered_cols[col], errors='coerce').fillna(0).astype(np.int8)\n",
    "        except (ValueError, TypeError):\n",
    "            # 如果转换失败，尝试其他方法\n",
    "            try:\n",
    "                result_df[col] = (filtered_cols[col] == filtered_cols[col].iloc[0]).astype(np.int8)\n",
    "            except:\n",
    "                # 最后手段：设为0\n",
    "                result_df[col] = 0\n",
    "                result_df[col] = result_df[col].astype(np.int8)\n",
    "    \n",
    "    if is_test:\n",
    "        X_train_dummy_part = get_Fmatrix_dummy_part(train_df, dummy_variable_name_list)\n",
    "        train_exclusive_location_list = np.setdiff1d(train_df['location'+str(location_index)], df['location'+str(location_index)])\n",
    "        test_exclusive_location_list = np.setdiff1d(df['location'+str(location_index)], train_df['location'+str(location_index)])\n",
    "        train_exclusive_list = np.setdiff1d(X_train_dummy_part.columns, result_df.columns)\n",
    "        test_exclusive_list = np.setdiff1d(result_df.columns, X_train_dummy_part.columns)\n",
    "        \n",
    "        for train_exclusive in train_exclusive_list:\n",
    "            result_df[train_exclusive] = 0\n",
    "        \n",
    "        # 处理年份\n",
    "        if 'year_2022' in result_df.columns and 'year_2023' in result_df.columns:\n",
    "            result_df['year_2022'] += result_df['year_2023']\n",
    "            result_df.drop('year_2023', axis=1, inplace=True)\n",
    "        \n",
    "        if IS_UPPER:\n",
    "            for test_location in test_exclusive_location_list:\n",
    "                # 确保test_location是字符串类型\n",
    "                test_location = str(test_location)\n",
    "                neighbor_location_list = get_neighbor_location_list(this_location=test_location, location_index=location_index, location_relation_df=location_relation_df)\n",
    "                neighbor_num = len(neighbor_location_list)\n",
    "                if neighbor_num != 0:\n",
    "                    for neighbor_location in neighbor_location_list:\n",
    "                        # 确保neighbor_location是字符串类型\n",
    "                        neighbor_location = str(neighbor_location)\n",
    "                        result_df['location'+str(location_index)+'_'+neighbor_location] += 1/neighbor_num * result_df['location'+str(location_index)+'_'+test_location]\n",
    "                    result_df.drop('location'+str(location_index)+'_'+test_location, axis=1, inplace=True)\n",
    "        else:\n",
    "            for test_location in test_exclusive_location_list:\n",
    "                # 确保test_location是字符串类型\n",
    "                test_location = str(test_location)\n",
    "                neighbor_location_list = get_neighbor_location_list(this_location=test_location, train_df=train_df, neighbor_num=neighbor_num)\n",
    "                for neighbor_location in neighbor_location_list:\n",
    "                    # 确保neighbor_location是字符串类型\n",
    "                    neighbor_location = str(neighbor_location)\n",
    "                    result_df['location'+str(location_index)+'_'+neighbor_location] += 1/neighbor_num * result_df['location'+str(location_index)+'_'+test_location]\n",
    "                result_df.drop('location'+str(location_index)+'_'+test_location, axis=1, inplace=True)\n",
    "        \n",
    "        train_exclusive_list = np.setdiff1d(X_train_dummy_part.columns, result_df.columns)\n",
    "        test_exclusive_list = np.setdiff1d(result_df.columns, X_train_dummy_part.columns)\n",
    "        \n",
    "        if len(train_exclusive_list) != 0:\n",
    "            raise ValueError(\"X_train_dummy_part仍然有独有变量！\")\n",
    "        \n",
    "        if len(test_exclusive_list) != 0:\n",
    "            for var in test_exclusive_list:\n",
    "                result_df.drop(var, axis=1, inplace=True)\n",
    "    \n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c197a009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始生成特征矩阵...\n",
      "线性部分完成\n",
      "非线性部分完成\n",
      "虚拟变量部分完成\n",
      "训练集部分数: 3\n",
      "测试集部分数: 3\n"
     ]
    }
   ],
   "source": [
    "# 生成训练集和测试集的特征矩阵\n",
    "X_train_part_list = []\n",
    "X_test_part_list = []\n",
    "\n",
    "print(\"开始生成特征矩阵...\")\n",
    "\n",
    "# 线性部分\n",
    "X_train_part_list.append(get_Fmatrix_linear_part(train_df, linear_variable_name_list))\n",
    "X_test_part_list.append(get_Fmatrix_linear_part(test_df, linear_variable_name_list))\n",
    "print(f\"线性部分完成\")\n",
    "\n",
    "# 非线性部分\n",
    "X_train_part_list.append(get_Fmatrix_nonlinear_part(train_df, nonlinear_variable_name_list))\n",
    "X_test_part_list.append(get_Fmatrix_nonlinear_part(test_df, nonlinear_variable_name_list))\n",
    "print(f\"非线性部分完成\")\n",
    "\n",
    "# 虚拟变量部分\n",
    "X_train_part_list.append(get_Fmatrix_dummy_part(train_df, dummy_variable_name_list))\n",
    "X_test_part_list.append(get_Fmatrix_dummy_part(test_df, dummy_variable_name_list, is_test=True, train_df=train_df))\n",
    "print(f\"虚拟变量部分完成\")\n",
    "\n",
    "print(f\"训练集部分数: {len(X_train_part_list)}\")\n",
    "print(f\"测试集部分数: {len(X_test_part_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b326f0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始合并训练集特征矩阵（使用numpy数组合并以节省内存）...\n",
      "  处理第 1/3 部分...\n",
      "    警告：第 1 部分为None，跳过\n",
      "  处理第 2/3 部分...\n",
      "    警告：第 2 部分为None，跳过\n",
      "  处理第 3/3 部分...\n",
      "  合并numpy数组...\n"
     ]
    }
   ],
   "source": [
    "# 优化内存使用：使用numpy数组直接合并，避免pandas concat的开销\n",
    "print(\"开始合并训练集特征矩阵（使用numpy数组合并以节省内存）...\")\n",
    "\n",
    "# 收集所有列名和数组，保存索引\n",
    "all_columns = []\n",
    "all_arrays = []\n",
    "saved_index = None\n",
    "\n",
    "for i, part in enumerate(X_train_part_list):\n",
    "    print(f\"  处理第 {i+1}/{len(X_train_part_list)} 部分...\")\n",
    "    # 确保part不是None\n",
    "    if part is None:\n",
    "        print(f\"    警告：第 {i+1} 部分为None，跳过\")\n",
    "        continue\n",
    "    # 保存第一个部分的索引\n",
    "    if i == 0:\n",
    "        saved_index = part.index\n",
    "    # 转换为numpy数组并收集列名\n",
    "    part_array = part.values\n",
    "    all_arrays.append(part_array)\n",
    "    all_columns.extend(part.columns.tolist())\n",
    "    # 释放原始DataFrame（但在循环中不设为None，而是等待循环结束后统一处理）\n",
    "\n",
    "print(\"  合并numpy数组...\")\n",
    "# 使用numpy的hstack直接合并数组（更高效）\n",
    "combined_array = np.hstack(all_arrays)\n",
    "del all_arrays  # 释放原始数组\n",
    "\n",
    "print(\"  创建最终DataFrame...\")\n",
    "# 一次性创建DataFrame\n",
    "X_train_without_interaction = pd.DataFrame(combined_array, \n",
    "                                           index=saved_index,\n",
    "                                           columns=all_columns)\n",
    "del combined_array, all_columns, saved_index\n",
    "print(\"训练集合并完成\")\n",
    "\n",
    "# 清理列表（循环结束后再清理）\n",
    "for i in range(len(X_train_part_list)):\n",
    "    X_train_part_list[i] = None\n",
    "del X_train_part_list\n",
    "\n",
    "# 检查测试集特征矩阵\n",
    "print(f\"\\nX_test_part_list长度: {len(X_test_part_list)}\")\n",
    "if len(X_test_part_list) == 0:\n",
    "    raise ValueError(\"X_test_part_list为空，请检查前面的特征生成步骤\")\n",
    "for idx, part in enumerate(X_test_part_list):\n",
    "    print(f\"X_test_part_list[{idx}] 形状: {part.shape}\")\n",
    "\n",
    "print(\"\\n开始合并测试集特征矩阵（使用numpy数组合并以节省内存）...\")\n",
    "\n",
    "# 收集所有列名和数组，保存索引\n",
    "all_columns_test = []\n",
    "all_arrays_test = []\n",
    "saved_index_test = None\n",
    "\n",
    "for i, part in enumerate(X_test_part_list):\n",
    "    print(f\"  处理第 {i+1}/{len(X_test_part_list)} 部分...\")\n",
    "    # 确保part不是None\n",
    "    if part is None:\n",
    "        print(f\"    警告：第 {i+1} 部分为None，跳过\")\n",
    "        continue\n",
    "    # 保存第一个部分的索引\n",
    "    if i == 0:\n",
    "        saved_index_test = part.index\n",
    "    # 转换为numpy数组并收集列名\n",
    "    part_array = part.values\n",
    "    all_arrays_test.append(part_array)\n",
    "    all_columns_test.extend(part.columns.tolist())\n",
    "    # 释放原始DataFrame（但在循环中不设为None，而是等待循环结束后统一处理）\n",
    "\n",
    "print(\"  合并numpy数组...\")\n",
    "# 使用numpy的hstack直接合并数组（更高效）\n",
    "combined_array_test = np.hstack(all_arrays_test)\n",
    "del all_arrays_test  # 释放原始数组\n",
    "\n",
    "print(\"  创建最终DataFrame...\")\n",
    "# 一次性创建DataFrame\n",
    "X_test_without_interaction = pd.DataFrame(combined_array_test,\n",
    "                                          index=saved_index_test,\n",
    "                                          columns=all_columns_test)\n",
    "del combined_array_test, all_columns_test, saved_index_test\n",
    "print(\"测试集合并完成\")\n",
    "\n",
    "# 清理列表（循环结束后再清理）\n",
    "for i in range(len(X_test_part_list)):\n",
    "    X_test_part_list[i] = None\n",
    "del X_test_part_list\n",
    "\n",
    "interaction_variable_pair_list=[['location1','ring']]\n",
    "\n",
    "def get_Fmatrix_with_interaction(df, interaction_variable_pair_list):\n",
    "    \"\"\"\n",
    "    生成交互项特征\n",
    "    注意：如果DataFrame有重复列名，会先处理重复列\n",
    "    \"\"\"\n",
    "    # 检查并处理重复的列名\n",
    "    if df.columns.duplicated().any():\n",
    "        print(f\"警告：发现重复列名，正在处理...\")\n",
    "        # 重命名重复的列，使用序号区分\n",
    "        cols = df.columns.tolist()\n",
    "        seen = {}\n",
    "        new_cols = []\n",
    "        for col in cols:\n",
    "            if cols.count(col) > 1:  # 如果是重复列\n",
    "                if col not in seen:\n",
    "                    seen[col] = 0\n",
    "                    new_cols.append(col)\n",
    "                else:\n",
    "                    seen[col] += 1\n",
    "                    new_cols.append(f\"{col}_dup{seen[col]}\")\n",
    "            else:\n",
    "                new_cols.append(col)\n",
    "        df.columns = new_cols\n",
    "        print(f\"已处理重复列名，新列数: {len(df.columns)}\")\n",
    "    \n",
    "    result_df = pd.DataFrame(index=df.index)\n",
    "    name_list_without_interaction = df.columns\n",
    "    \n",
    "    for variable_pair in interaction_variable_pair_list:\n",
    "        variable_former_list = [name for name in name_list_without_interaction if name.split('_')[0] == variable_pair[0]]\n",
    "        variable_later_list = [name for name in name_list_without_interaction if name.split('_')[0] == variable_pair[1]]\n",
    "        \n",
    "        for variable_former in variable_former_list:\n",
    "            for variable_later in variable_later_list:\n",
    "                # 使用.values避免对齐问题，或者确保使用Series\n",
    "                if variable_former in df.columns and variable_later in df.columns:\n",
    "                    # 直接使用Series进行乘法，避免DataFrame对齐问题\n",
    "                    interaction_name = f\"{variable_former}*{variable_later}\"\n",
    "                    result_df[interaction_name] = df[variable_former].values * df[variable_later].values\n",
    "    \n",
    "    # 合并原始数据和交互项\n",
    "    result_df = pd.concat([df, result_df], axis=1)\n",
    "    return result_df\n",
    "\n",
    "X_train=get_Fmatrix_with_interaction(X_train_without_interaction,interaction_variable_pair_list)\n",
    "X_test=get_Fmatrix_with_interaction(X_test_without_interaction,interaction_variable_pair_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5737fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape= (103871, 1455)\n",
      "X_test.shape= (34017, 1455)\n",
      "train_x_na: (house_age+1)^-1             26361\n",
      "(parking_per_unit+1)^-1       1323\n",
      "floor_area_ratio             33154\n",
      "green_rate                   32883\n",
      "house_age                    26361\n",
      "house_age^2                  26361\n",
      "house_age^3                  26361\n",
      "house_age_dup1               26361\n",
      "lift_ratio                    2619\n",
      "log(house_age+1)             26361\n",
      "log(house_age+1)^2           26361\n",
      "log(house_age+1)^3           26361\n",
      "log(parking_per_unit+1)       1323\n",
      "log(parking_per_unit+1)^2     1323\n",
      "log(parking_per_unit+1)^3     1323\n",
      "parking_per_unit              1323\n",
      "parking_per_unit^2            1323\n",
      "parking_per_unit^3            1323\n",
      "parking_per_unit_dup1         1323\n",
      "dtype: int64\n",
      "test_x_na: (house_age+1)^-1             6193\n",
      "(parking_per_unit+1)^-1      5136\n",
      "floor_area_ratio             9303\n",
      "green_rate                   9180\n",
      "house_age                    6193\n",
      "house_age^2                  6193\n",
      "house_age^3                  6193\n",
      "house_age_dup1               6193\n",
      "lift_ratio                    635\n",
      "log(house_age+1)             6193\n",
      "log(house_age+1)^2           6193\n",
      "log(house_age+1)^3           6193\n",
      "log(parking_per_unit+1)      5136\n",
      "log(parking_per_unit+1)^2    5136\n",
      "log(parking_per_unit+1)^3    5136\n",
      "parking_per_unit             5136\n",
      "parking_per_unit^2           5136\n",
      "parking_per_unit^3           5136\n",
      "parking_per_unit_dup1        5136\n",
      "dtype: int64\n",
      "train_x_if: Series([], dtype: int64)\n",
      "test_x_inf: Series([], dtype: int64)\n",
      "train_exclusive_list= []\n",
      "test_exclusive_list= []\n",
      "train_test_col_is_not_incident= 0\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train[sorted(X_train.columns)]\n",
    "X_test=X_test[X_train.columns]\n",
    "\n",
    "\n",
    "print('X_train.shape=',X_train.shape)\n",
    "print('X_test.shape=',X_test.shape)\n",
    "\n",
    "col_na_count=X_train.isna().sum()\n",
    "col_na_count=col_na_count[col_na_count!=0]\n",
    "print('train_x_na:',col_na_count)\n",
    "\n",
    "col_na_count=X_test.isna().sum()\n",
    "col_na_count=col_na_count[col_na_count!=0]\n",
    "print('test_x_na:',col_na_count)\n",
    "\n",
    "# 只检查数值列中的无穷值（isinf只能用于数值类型）\n",
    "numeric_cols_train = X_train.select_dtypes(include=[np.number]).columns\n",
    "col_na_count = pd.Series([np.isinf(X_train[col]).sum() for col in numeric_cols_train], index=numeric_cols_train)\n",
    "col_na_count = col_na_count[col_na_count != 0]\n",
    "print('train_x_if:', col_na_count)\n",
    "\n",
    "numeric_cols_test = X_test.select_dtypes(include=[np.number]).columns\n",
    "col_na_count = pd.Series([np.isinf(X_test[col]).sum() for col in numeric_cols_test], index=numeric_cols_test)\n",
    "col_na_count = col_na_count[col_na_count != 0]\n",
    "print('test_x_inf:', col_na_count)\n",
    "\n",
    "train_exclusive_list=np.setdiff1d(X_train.columns.tolist(),X_test.columns.tolist())\n",
    "test_exclusive_list=np.setdiff1d(X_test.columns.tolist(),X_train.columns.tolist())\n",
    "\n",
    "print('train_exclusive_list=',train_exclusive_list)\n",
    "print('test_exclusive_list=',test_exclusive_list)\n",
    "\n",
    "\n",
    "print('train_test_col_is_not_incident=',np.sum(X_train.columns!=X_test.columns))\n",
    "\n",
    "use_colname_list=np.array(range(len(X_train.columns))).astype(str)\n",
    "X_train_use=X_train.copy()\n",
    "X_train_use.columns=use_colname_list\n",
    "X_test_use=X_test.copy()\n",
    "X_test_use.columns=use_colname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8409363b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检查缺失值...\n",
      "训练集缺失值列: 19列\n",
      "2       26361\n",
      "3        1323\n",
      "23      33154\n",
      "24      32883\n",
      "35      26361\n",
      "36      26361\n",
      "37      26361\n",
      "38      26361\n",
      "47       2619\n",
      "1328    26361\n",
      "1329    26361\n",
      "1330    26361\n",
      "1331     1323\n",
      "1332     1323\n",
      "1333     1323\n",
      "1339     1323\n",
      "1340     1323\n",
      "1341     1323\n",
      "1342     1323\n",
      "dtype: int64\n",
      "测试集缺失值列: 19列\n",
      "2       6193\n",
      "3       5136\n",
      "23      9303\n",
      "24      9180\n",
      "35      6193\n",
      "36      6193\n",
      "37      6193\n",
      "38      6193\n",
      "47       635\n",
      "1328    6193\n",
      "1329    6193\n",
      "1330    6193\n",
      "1331    5136\n",
      "1332    5136\n",
      "1333    5136\n",
      "1339    5136\n",
      "1340    5136\n",
      "1341    5136\n",
      "1342    5136\n",
      "dtype: int64\n",
      "数值列数量: 1453\n",
      "非数值列数量: 2\n",
      "缺失值填充完成\n",
      "转换列 24 中的百分数为数值...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "y=np.log(train_df['price'])\n",
    "OLS_md = LinearRegression()\n",
    "# 检查并处理缺失值\n",
    "print(\"检查缺失值...\")\n",
    "nan_counts_train = X_train_use.isna().sum()\n",
    "nan_columns_train = nan_counts_train[nan_counts_train > 0]\n",
    "print(f\"训练集缺失值列: {len(nan_columns_train)}列\")\n",
    "print(nan_columns_train)\n",
    "\n",
    "nan_counts_test = X_test_use.isna().sum()\n",
    "nan_columns_test = nan_counts_test[nan_counts_test > 0]\n",
    "print(f\"测试集缺失值列: {len(nan_columns_test)}列\")\n",
    "print(nan_columns_test)\n",
    "\n",
    "# 填充缺失值\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 分离数值列和非数值列\n",
    "numeric_cols = X_train_use.select_dtypes(include=[np.number]).columns.tolist()\n",
    "non_numeric_cols = X_train_use.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"数值列数量: {len(numeric_cols)}\")\n",
    "print(f\"非数值列数量: {len(non_numeric_cols)}\")\n",
    "\n",
    "# 初始化结果DataFrame\n",
    "X_train_use_imputed = X_train_use.copy()\n",
    "X_test_use_imputed = X_test_use.copy()\n",
    "\n",
    "# 对数值列使用mean策略填充\n",
    "if len(numeric_cols) > 0:\n",
    "    imputer_numeric = SimpleImputer(strategy=\"mean\")\n",
    "    X_train_use_imputed[numeric_cols] = pd.DataFrame(\n",
    "        imputer_numeric.fit_transform(X_train_use[numeric_cols]), \n",
    "        columns=numeric_cols, \n",
    "        index=X_train_use.index\n",
    "    )\n",
    "    X_test_use_imputed[numeric_cols] = pd.DataFrame(\n",
    "        imputer_numeric.transform(X_test_use[numeric_cols]), \n",
    "        columns=numeric_cols, \n",
    "        index=X_test_use.index\n",
    "    )\n",
    "\n",
    "# 对非数值列使用most_frequent策略填充（如果有缺失值）\n",
    "if len(non_numeric_cols) > 0:\n",
    "    # 检查非数值列是否有缺失值\n",
    "    non_numeric_missing_train = X_train_use[non_numeric_cols].isna().any()\n",
    "    non_numeric_missing_test = X_test_use[non_numeric_cols].isna().any()\n",
    "    cols_with_missing = [col for col in non_numeric_cols if non_numeric_missing_train[col] or non_numeric_missing_test[col]]\n",
    "    \n",
    "    if len(cols_with_missing) > 0:\n",
    "        imputer_non_numeric = SimpleImputer(strategy=\"most_frequent\")\n",
    "        X_train_use_imputed[cols_with_missing] = pd.DataFrame(\n",
    "            imputer_non_numeric.fit_transform(X_train_use[cols_with_missing]), \n",
    "            columns=cols_with_missing, \n",
    "            index=X_train_use.index\n",
    "        )\n",
    "        X_test_use_imputed[cols_with_missing] = pd.DataFrame(\n",
    "            imputer_non_numeric.transform(X_test_use[cols_with_missing]), \n",
    "            columns=cols_with_missing, \n",
    "            index=X_test_use.index\n",
    "        )\n",
    "\n",
    "print(\"缺失值填充完成\")\n",
    "\n",
    "# 使用填充后的数据\n",
    "X_train_use = X_train_use_imputed\n",
    "X_test_use = X_test_use_imputed\n",
    "\n",
    "# 处理百分数字符串（如'30%'转为0.3或30）\n",
    "def convert_percentage_to_numeric(series):\n",
    "    \"\"\"\n",
    "    将百分数字符串转换为数值\n",
    "    例如：'30%' -> 30 或 0.3（根据实际情况决定）\n",
    "    \"\"\"\n",
    "    if series.dtype == 'object':\n",
    "        # 检查是否是百分数字符串格式\n",
    "        return series.apply(lambda x: \n",
    "            float(str(x).replace('%', '')) / 100 if isinstance(x, str) and '%' in str(x)\n",
    "            else pd.to_numeric(x, errors='coerce') if not pd.isna(x)\n",
    "            else x\n",
    "        )\n",
    "    else:\n",
    "        return series\n",
    "\n",
    "# 检查并转换所有可能包含百分数的列\n",
    "for col in X_train_use.columns:\n",
    "    # 检查列中是否有百分数字符串\n",
    "    if X_train_use[col].dtype == 'object':\n",
    "        has_percentage = X_train_use[col].apply(lambda x: isinstance(x, str) and '%' in str(x)).any()\n",
    "        if has_percentage:\n",
    "            print(f\"转换列 {col} 中的百分数为数值...\")\n",
    "            X_train_use[col] = convert_percentage_to_numeric(X_train_use[col])\n",
    "            X_test_use[col] = convert_percentage_to_numeric(X_test_use[col])\n",
    "\n",
    "# 确保所有列都是数值类型（除了已经是数值的）\n",
    "for col in X_train_use.columns:\n",
    "    if X_train_use[col].dtype == 'object':\n",
    "        # 尝试转换为数值\n",
    "        X_train_use[col] = pd.to_numeric(X_train_use[col], errors='coerce')\n",
    "        X_test_use[col] = pd.to_numeric(X_test_use[col], errors='coerce')\n",
    "\n",
    "OLS_md.fit(X_train_use,y)\n",
    "\n",
    "output_df=pd.DataFrame({\n",
    "    'ID':range(len(test_df)),\n",
    "    'Price':np.exp(OLS_md.predict(X_test_use))\n",
    "})\n",
    "\n",
    "output_df.to_csv('submission_2025_5_22_y=log(p).csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88438b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('X_test.csv',index=False)\n",
    "X_train.to_csv('X_train.csv', index=False)\n",
    "pd.DataFrame(y, columns=['target']).to_csv('y.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158dd9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "开始训练和评估多个线性模型...\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 准备数据：使用原始价格（不是log转换后的）\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m y_train_original \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# 检查测试集是否有价格列\u001b[39;00m\n\u001b[0;32m     27\u001b[0m has_test_price \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m test_df\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 最终输出：不同线性模型的性能评估表格\n",
    "# ============================================================================\n",
    "# 注意：所有评估指标都基于原始房价水平值的MAE\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 尝试导入display函数（用于Jupyter notebook）\n",
    "try:\n",
    "    from IPython.display import display, HTML\n",
    "except ImportError:\n",
    "    display = print\n",
    "    HTML = lambda x: print(x)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"开始训练和评估多个线性模型...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 准备数据：使用原始价格（不是log转换后的）\n",
    "y_train_original = train_df['price'].values\n",
    "\n",
    "# 检查测试集是否有价格列\n",
    "has_test_price = 'price' in test_df.columns\n",
    "if has_test_price:\n",
    "    y_test_original = test_df['price'].values\n",
    "    print(\"测试集包含价格列，将使用测试集计算样本外MAE\")\n",
    "else:\n",
    "    print(\"测试集不包含价格列，将使用训练集的20%作为验证集计算样本外MAE\")\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    # 使用训练集的20%作为验证集\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        np.arange(len(train_df)), \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "    X_train_split = X_train_use.iloc[train_indices]\n",
    "    X_val_split = X_train_use.iloc[val_indices]\n",
    "    y_train_split_original = y_train_original[train_indices]\n",
    "    y_test_original = y_train_original[val_indices]\n",
    "    # 更新用于训练的索引\n",
    "    train_split_mask = np.zeros(len(train_df), dtype=bool)\n",
    "    train_split_mask[train_indices] = True\n",
    "\n",
    "# 用于训练的目标变量（log转换）\n",
    "y_train_log = np.log(y_train_original)\n",
    "\n",
    "# 存储所有模型及其结果\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# 1. OLS模型\n",
    "print(\"\\n[1/2] 训练OLS模型...\")\n",
    "ols_model = LinearRegression()\n",
    "ols_model.fit(X_train_use, y_train_log)\n",
    "models['OLS'] = ols_model\n",
    "print(\"   ✓ OLS模型训练完成\")\n",
    "\n",
    "# 2. Ridge模型（使用网格搜索选择最佳alpha）\n",
    "print(\"\\n[2/2] 训练Ridge模型...\")\n",
    "# 将DataFrame转换为numpy数组，避免序列化问题\n",
    "X_train_array = X_train_use.values if isinstance(X_train_use, pd.DataFrame) else X_train_use\n",
    "y_train_array = y_train_log.values if isinstance(y_train_log, pd.Series) else y_train_log\n",
    "\n",
    "# 使用网格搜索寻找最佳alpha\n",
    "alphas_ridge = np.logspace(-4, 4, 20)\n",
    "ridge_grid = GridSearchCV(Ridge(max_iter=2000), \n",
    "                          param_grid={'alpha': alphas_ridge},\n",
    "                          cv=5, \n",
    "                          scoring='neg_mean_absolute_error',\n",
    "                          n_jobs=1,\n",
    "                          verbose=False)\n",
    "ridge_grid.fit(X_train_array, y_train_array)\n",
    "best_alpha_ridge = ridge_grid.best_params_['alpha']\n",
    "ridge_model = Ridge(alpha=best_alpha_ridge, max_iter=2000)\n",
    "ridge_model.fit(X_train_use, y_train_log)\n",
    "models['Ridge'] = ridge_model\n",
    "print(f\"   ✓ Ridge模型训练完成 (最优alpha={best_alpha_ridge:.6f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"所有模型训练完成！\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 定义评估函数\n",
    "def evaluate_model(model, X_train, X_test, y_train_original, y_test_original, y_train_log):\n",
    "    \"\"\"\n",
    "    评估模型，返回样本内、样本外和交叉验证的MAE（基于原始价格水平值）\n",
    "    \"\"\"\n",
    "    # 样本内预测\n",
    "    y_train_pred_log = model.predict(X_train)\n",
    "    y_train_pred = np.exp(y_train_pred_log)\n",
    "    mae_in_sample = mean_absolute_error(y_train_original, y_train_pred)\n",
    "    \n",
    "    # 样本外预测\n",
    "    y_test_pred_log = model.predict(X_test)\n",
    "    y_test_pred = np.exp(y_test_pred_log)\n",
    "    mae_out_sample = mean_absolute_error(y_test_original, y_test_pred)\n",
    "    \n",
    "    # 交叉验证（使用5折）\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    X_train_array = X_train.values if isinstance(X_train, pd.DataFrame) else X_train\n",
    "    for train_idx, val_idx in kfold.split(X_train_array):\n",
    "        X_train_fold = X_train_array[train_idx]\n",
    "        X_val_fold = X_train_array[val_idx]\n",
    "        y_train_fold_log = y_train_log[train_idx]\n",
    "        y_val_fold_original = y_train_original[val_idx]\n",
    "        \n",
    "        # 训练模型\n",
    "        model_class = type(model)\n",
    "        model_params = model.get_params()\n",
    "        temp_model = model_class(**model_params)\n",
    "        temp_model.fit(X_train_fold, y_train_fold_log)\n",
    "        \n",
    "        # 预测并计算MAE\n",
    "        y_val_pred_log = temp_model.predict(X_val_fold)\n",
    "        y_val_pred = np.exp(y_val_pred_log)\n",
    "        mae_cv = mean_absolute_error(y_val_fold_original, y_val_pred)\n",
    "        cv_scores.append(mae_cv)\n",
    "    \n",
    "    mae_cross_validation = np.mean(cv_scores)\n",
    "    \n",
    "    return mae_in_sample, mae_out_sample, mae_cross_validation\n",
    "\n",
    "# 评估所有模型\n",
    "print(\"\\n开始评估模型性能...\")\n",
    "for model_name, model in models.items():\n",
    "    print(f\"  评估{model_name}模型...\")\n",
    "    if has_test_price:\n",
    "        # 使用原始的训练集和测试集\n",
    "        results[model_name] = evaluate_model(model, X_train_use, X_test_use, \n",
    "                                              y_train_original, y_test_original, y_train_log)\n",
    "    else:\n",
    "        # 使用划分后的训练集和验证集\n",
    "        # 注意：对于样本内评估，我们仍然使用完整的训练集（这是模型实际训练的）\n",
    "        # 对于样本外评估，使用验证集\n",
    "        results[model_name] = evaluate_model(model, X_train_use, X_val_split, \n",
    "                                              y_train_original, y_test_original, y_train_log)\n",
    "\n",
    "# 找出最佳线性模型（基于样本外MAE最小）\n",
    "best_model_name = min(results.keys(), key=lambda x: results[x][1])\n",
    "print(f\"\\n最佳线性模型（基于样本外MAE）: {best_model_name}\")\n",
    "\n",
    "# 确定\"其他模型\"（从OLS和Ridge中选择不是最佳的那个）\n",
    "other_model_name = 'Ridge' if best_model_name == 'OLS' else 'OLS'\n",
    "\n",
    "# 构建结果表格（格式与图片中一致）\n",
    "table_data = {\n",
    "    '指标': ['OLS', 'Ridge', '最佳线性模型', '其他模型（非必需）'],\n",
    "    '样本内': [\n",
    "        round(results['OLS'][0], 2),\n",
    "        round(results['Ridge'][0], 2),\n",
    "        round(results[best_model_name][0], 2),\n",
    "        round(results[other_model_name][0], 2)\n",
    "    ],\n",
    "    '样本外': [\n",
    "        round(results['OLS'][1], 2),\n",
    "        round(results['Ridge'][1], 2),\n",
    "        round(results[best_model_name][1], 2),\n",
    "        round(results[other_model_name][1], 2)\n",
    "    ],\n",
    "    '交叉验证': [\n",
    "        round(results['OLS'][2], 2),\n",
    "        round(results['Ridge'][2], 2),\n",
    "        round(results[best_model_name][2], 2),\n",
    "        round(results[other_model_name][2], 2)\n",
    "    ]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(table_data)\n",
    "\n",
    "# 设置pandas显示选项\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# 打印表格（格式化的输出）\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"模型性能评估表（基于原始房价水平值的MAE）\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\" + results_df.to_string(index=False))\n",
    "print(\"\\n备注: 度量应基于原始的房价或租金\\\"水平值\\\"的 MAE。\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 显示表格（在Jupyter中更美观）\n",
    "print(\"\\n\")\n",
    "display(results_df)\n",
    "\n",
    "# 保存表格为CSV\n",
    "results_df.to_csv('模型性能评估表.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"\\n✓ 表格已保存为: 模型性能评估表.csv\")\n",
    "\n",
    "# 生成更美观的HTML格式表格\n",
    "results_df_html = results_df.to_html(index=False, classes='table table-striped', table_id='performance_table')\n",
    "html_content = f'''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>模型性能评估表</title>\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: \"Microsoft YaHei\", \"SimHei\", Arial, sans-serif;\n",
    "            margin: 0;\n",
    "            padding: 20px;\n",
    "            background-color: #f5f5f5;\n",
    "        }}\n",
    "        .container {{\n",
    "            max-width: 800px;\n",
    "            margin: 0 auto;\n",
    "            background-color: white;\n",
    "            padding: 30px;\n",
    "            border-radius: 8px;\n",
    "            box-shadow: 0 2px 10px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        h2 {{\n",
    "            text-align: center;\n",
    "            color: #333;\n",
    "            margin-bottom: 30px;\n",
    "        }}\n",
    "        table {{\n",
    "            border-collapse: collapse;\n",
    "            width: 100%;\n",
    "            margin: 20px auto;\n",
    "            font-size: 14px;\n",
    "        }}\n",
    "        th, td {{\n",
    "            border: 1px solid #ddd;\n",
    "            padding: 12px;\n",
    "            text-align: center;\n",
    "        }}\n",
    "        th {{\n",
    "            background-color: #4CAF50;\n",
    "            color: white;\n",
    "            font-weight: bold;\n",
    "        }}\n",
    "        tr:nth-child(even) {{\n",
    "            background-color: #f9f9f9;\n",
    "        }}\n",
    "        tr:hover {{\n",
    "            background-color: #f5f5f5;\n",
    "        }}\n",
    "        .note {{\n",
    "            margin-top: 30px;\n",
    "            font-style: italic;\n",
    "            color: #666;\n",
    "            text-align: left;\n",
    "            padding: 15px;\n",
    "            background-color: #f9f9f9;\n",
    "            border-left: 4px solid #4CAF50;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h2>模型性能评估表</h2>\n",
    "        {results_df_html}\n",
    "        <div class=\"note\">\n",
    "            <p><strong>备注:</strong> 度量应基于原始的房价或租金\"水平值\"的 MAE。</p>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "with open('模型性能评估表.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(html_content)\n",
    "print(\"✓ 表格已保存为HTML格式: 模型性能评估表.html\")\n",
    "\n",
    "# 打印详细的模型信息\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"详细模型信息:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"最佳线性模型: {best_model_name}\")\n",
    "print(f\"  样本内 MAE: {results[best_model_name][0]:.2f}\")\n",
    "print(f\"  样本外 MAE: {results[best_model_name][1]:.2f}\")\n",
    "print(f\"  交叉验证 MAE: {results[best_model_name][2]:.2f}\")\n",
    "print(\"\\n所有模型性能对比:\")\n",
    "for model_name in ['OLS', 'Ridge']:\n",
    "    if model_name in results:\n",
    "        print(f\"  {model_name:12s}: 样本内={results[model_name][0]:8.2f}, \"\n",
    "              f\"样本外={results[model_name][1]:8.2f}, CV={results[model_name][2]:8.2f}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecebc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "生成LASSO模型预测结果...\n",
      "================================================================================\n",
      "\n",
      "✓ LASSO模型预测完成\n",
      "  预测样本数: 34017\n",
      "  预测价格范围: [1177294.79, 57289476.77]\n",
      "  预测价格均值: 1576859.40\n",
      "\n",
      "✓ 预测结果已保存为: lasso_predictions.csv\n",
      "\n",
      "================================================================================\n",
      "\n",
      "预测结果预览（前10行）:\n",
      " ID        Price\n",
      "  0 5.182409e+06\n",
      "  1 1.431601e+06\n",
      "  2 1.998190e+06\n",
      "  3 1.489825e+06\n",
      "  4 1.701608e+06\n",
      "  5 1.492562e+06\n",
      "  6 2.299132e+06\n",
      "  7 1.452270e+06\n",
      "  8 1.460930e+06\n",
      "  9 1.620778e+06\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 输出Ridge模型的预测结果（输出文件名保持不变）\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"生成Ridge模型预测结果...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 确保Ridge模型已经训练\n",
    "if 'Ridge' not in models:\n",
    "    print(\"错误：Ridge模型尚未训练，请先运行Cell 13\")\n",
    "else:\n",
    "    # 使用Ridge模型进行预测（注意：目标变量是log转换后的）\n",
    "    y_test_pred_log = models['Ridge'].predict(X_test_use)\n",
    "    \n",
    "    # 将预测结果转换回原始价格（指数变换）\n",
    "    y_test_pred = np.exp(y_test_pred_log)\n",
    "    \n",
    "    # 创建预测结果DataFrame\n",
    "    lasso_output_df = pd.DataFrame({\n",
    "        'ID': range(len(test_df)),\n",
    "        'Price': y_test_pred\n",
    "    })\n",
    "    \n",
    "    # 保存为CSV文件（保持原有输出文件名不变）\n",
    "    output_filename = 'lasso_predictions.csv'\n",
    "    lasso_output_df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"\\n✓ Ridge模型预测完成\")\n",
    "    print(f\"  预测样本数: {len(lasso_output_df)}\")\n",
    "    print(f\"  预测价格范围: [{lasso_output_df['Price'].min():.2f}, {lasso_output_df['Price'].max():.2f}]\")\n",
    "    print(f\"  预测价格均值: {lasso_output_df['Price'].mean():.2f}\")\n",
    "    print(f\"\\n✓ 预测结果已保存为: {output_filename}\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # 显示前几行预览\n",
    "    print(\"\\n预测结果预览（前10行）:\")\n",
    "    print(lasso_output_df.head(10).to_string(index=False))\n",
    "    print(\"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
