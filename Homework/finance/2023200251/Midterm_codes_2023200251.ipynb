{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66d2534-7b21-46fc-b535-f2c2d9765d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc1c4460-fe13-4619-9d88-c870ad87543a",
   "metadata": {},
   "source": [
    "#-------------------------------SentimentModel(Can't run right here)-------------------------------------------------------------\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_id = r\"D:\\huggingface_models\\Erlangshen-Sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, local_files_only=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, local_files_only=True).to(device)\n",
    "\n",
    "def get_sentiment_batch(texts, batch_size=64):\n",
    "    all_probs = []\n",
    "    total_batches = len(texts) // batch_size + (1 if len(texts) % batch_size else 0) #處理批次次數\n",
    "    for i in tqdm(range(0, len(texts), batch_size), \n",
    "                  total=total_batches, \n",
    "                  desc=\"处理进度\", \n",
    "                  unit=\"批\"):\n",
    "        batch = texts[i:i+batch_size] #索引提取批次\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            return_tensors=\"pt\", #返回pytorch張量\n",
    "            truncation=True, #超長文本自動截斷\n",
    "            max_length=128,\n",
    "            padding=True).to(device) #自動填充到批次中最長序列的長度\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1).cpu().numpy() #列维度\n",
    "        all_probs.extend(probs)\n",
    "    return all_probs\n",
    "def comment2emotion(df, col_name=\"客户反馈\", batch_size=64):\n",
    "    texts = df[col_name].tolist()\n",
    "    all_probs = get_sentiment_batch(texts, batch_size=batch_size)\n",
    "    df[\"reflect_sentiment\"] = [round(p[1], 3) for p in all_probs] #正向文本取小數3位\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3007fbc-7be1-4844-86e3-ee7946128726",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_df_test = pd.read_csv(\"preprocess_df.csv\")# 已经处理好的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9617746d-d1ea-40de-85e6-e12129335276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 519626.61097841046\n",
      "MAEIN: 524076.68133207056\n",
      "MSE: 1193435671831.8533\n",
      "R²: 0.807239447208437\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------Price_Model-------------------------------------------------------------\n",
    "x = preprocess_df_test.drop('Price', axis=1)\n",
    "y = preprocess_df_test['Price'] \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=111\n",
    ")\n",
    "                     \n",
    "log_cols = ['area', 'gas_fee'] \n",
    "\n",
    "log1p_cols = ['density_ratio', 'reflect_sentiment', 'park_area', 'greening', 'plot_ratio','property_fee']\n",
    "\n",
    "knn_num_features = ['built_year','transaction_year', 'elevator_ratio']\n",
    "\n",
    "house_allo_cols = ['room', 'hall', 'kitchen', 'bathroom']\n",
    "\n",
    "binary_features = ['east', 'south', 'west', 'north', 'ownership']\n",
    "\n",
    "low_cat_features = ['city', 'build_struc', 'decoration', 'use_of_house', 'tran_right', 'floor', 'wat_sup', 'ele_sup']\n",
    "\n",
    "high_cat_district = ['district']  #target encoding\n",
    "high_cat_plate = ['plate']  #clustering\n",
    "\n",
    "class Winsorizer(BaseEstimator, TransformerMixin): #BE方便調超參 TM使類能與pipeline集成\n",
    "    def __init__(self, lower_q=0.01, upper_q=0.99):\n",
    "        self.lower_q = lower_q\n",
    "        self.upper_q = upper_q\n",
    "        self.low_ = None\n",
    "        self.high_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X)\n",
    "        self.low_ = np.nanpercentile(X, 100 * self.lower_q, axis=0)\n",
    "        self.high_ = np.nanpercentile(X, 100 * self.upper_q, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X).astype(float)\n",
    "        return np.clip(X, self.low_, self.high_)\n",
    "\n",
    "class LonLatClusterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=8):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.kmeans = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        lon_lat = X[['lon', 'lat']].values #Kmeans需要數值輸入\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)\n",
    "        self.kmeans.fit(lon_lat)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        lon_lat = X[['lon', 'lat']].values\n",
    "        clusters = self.kmeans.predict(lon_lat)\n",
    "        return clusters.reshape(-1, 1) #將一維數組轉为二維數組（label）\n",
    "        \n",
    "class PlateClusterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=10):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.kmeans = None\n",
    "        self.encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False) #輸出np陣列\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        plate_data = X.values.reshape(-1, 1)\n",
    "        plate_encoded = self.encoder.fit_transform(plate_data)\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)\n",
    "        self.kmeans.fit(plate_encoded)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        plate_data = X.values.reshape(-1, 1)\n",
    "        plate_encoded = self.encoder.transform(plate_data)\n",
    "        clusters = self.kmeans.predict(plate_encoded)\n",
    "        return clusters.reshape(-1, 1) #sklearn Transformer 需要二維數組\n",
    "\n",
    "knn_num_pipeline = Pipeline([\n",
    "    ('ref_imputer', SimpleImputer(strategy='median')),\n",
    "    ('knn_imputer', KNNImputer(n_neighbors=5)), \n",
    "    ('winsor', Winsorizer(lower_q=0.001, upper_q=0.999)), \n",
    "    ('scaler', StandardScaler()) \n",
    "])\n",
    "\n",
    "log_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('log', FunctionTransformer(np.log)), \n",
    "    ('winsor', Winsorizer(lower_q=0.001, upper_q=0.999)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "log1p_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('log1p', FunctionTransformer(np.log1p)),\n",
    "    ('winsor', Winsorizer(lower_q=0.001, upper_q=0.999)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "house_allo_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('winsor', Winsorizer(lower_q=0.001, upper_q=0.999)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "low_cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "binary_pipeline = Pipeline([\n",
    "    ('passthrough', FunctionTransformer(lambda x: x))  # 直接傳遞\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('geo_cluster', LonLatClusterTransformer(n_clusters=40), ['lon', 'lat']),\n",
    "    ('log_cols', log_pipeline, log_cols),\n",
    "    ('log1p_num', log1p_pipeline, log1p_cols),\n",
    "    ('built_year_knn_impute', knn_num_pipeline, knn_num_features),\n",
    "    ('house_allo', house_allo_pipeline, house_allo_cols),\n",
    "    ('binary', binary_pipeline, binary_features),\n",
    "    ('low_cat', low_cat_pipeline, low_cat_features),\n",
    "    ('district_target', TargetEncoder(cols=['district'], smoothing=50), ['district']),\n",
    "    ('plate_cluster', PlateClusterTransformer(n_clusters=10), ['plate'])\n",
    "], remainder='drop')\n",
    "\n",
    "base_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor',  Ridge(alpha=200)) #LinearRegression(), Lasso(), Ridge(), ElasticNet()\n",
    "])\n",
    "\n",
    "ttr = TransformedTargetRegressor(regressor=base_pipeline,\n",
    "                                     func=np.log,\n",
    "                                     inverse_func=np.exp)\n",
    "\n",
    "ttr.fit(x_train, y_train)\n",
    "\n",
    "y_pred = ttr.predict(x_test)\n",
    "y_pred_in = ttr.predict(x_train)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mae_in = mean_absolute_error(y_train, y_pred_in)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MAEIN: {mae_in}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R²: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0609a538-05f8-476c-b45a-3b5029957227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_avg: -527682.534245314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_folds = 6 \n",
    "scoring_metric = 'neg_mean_absolute_error'\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    estimator=ttr,\n",
    "    X=x_train,                \n",
    "    y=y_train,                 \n",
    "    cv=cv_folds,              \n",
    "    scoring=scoring_metric \n",
    ")\n",
    "\n",
    "print(f\"cv_avg: {cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5466bcfa-48d8-4069-a166-56b2aa8a6e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------process_rent-------------------------------------------------------------\n",
    "def floor2num(floor_str):\n",
    "    if pd.isna(floor_str):\n",
    "        return np.nan\n",
    "    floor_str = str(floor_str).strip()\n",
    "\n",
    "    if \"高\" in floor_str:\n",
    "        return 3\n",
    "    elif \"中\" in floor_str:\n",
    "        return 2\n",
    "    elif \"低\" in floor_str:\n",
    "        return 1\n",
    "\n",
    "    if floor_str[0].isdigit():\n",
    "        frac = eval(floor_str)\n",
    "        if frac < 0.3:\n",
    "            return 1\n",
    "        elif frac > 0.6:\n",
    "            return 3\n",
    "        else:\n",
    "            return 2\n",
    "\n",
    "def apply_floor_conversion(df, col_name=\"楼层\"):\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"floor\"] = df_copy[col_name].apply(floor2num)\n",
    "    return df_copy          \n",
    "\n",
    "def split_house_type(df, col_name=\"户型\"):\n",
    "    df_copy = df.copy()\n",
    "    patterns = {\n",
    "        'room': r'(\\d+)室',    \n",
    "        'hall': r'(\\d+)厅',    \n",
    "        'kitchen': r'(\\d+)厨', \n",
    "        'bathroom': r'(\\d+)卫' \n",
    "    }\n",
    "    for new_col, pattern in patterns.items():\n",
    "        df_copy[new_col] = df_copy[col_name].apply(\n",
    "            lambda x: int(re.search(pattern, str(x)).group(1)) #取出第一個括號捕獲群組的內容(\\d+)\n",
    "            if pd.notnull(x) and re.search(pattern, str(x))\n",
    "            else np.nan\n",
    "        )\n",
    "    return df_copy\n",
    "\n",
    "def remove_string(df, col_name, strings_to_remove):\n",
    "    df_copy = df.copy()\n",
    "    pattern = '|'.join(re.escape(s) for s in strings_to_remove) #escape()把特殊字符轉義\n",
    "    df_copy[col_name] = df_copy[col_name].str.replace(pattern, '', regex=True)\n",
    "    return df_copy\n",
    "\n",
    "def change_toward(df, col_name=\"朝向\"):\n",
    "    df_copy = df.copy()\n",
    "    directions = {\n",
    "        'east': '东',   \n",
    "        'south': '南',  \n",
    "        'west': '西',   \n",
    "        'north': '北'  \n",
    "    }\n",
    "    for new_col, direction_char in directions.items():\n",
    "        df_copy[new_col] = df_copy[col_name].apply(\n",
    "            lambda x: 1 if pd.notna(x) and direction_char in str(x) else 0\n",
    "        )\n",
    "    return df_copy\n",
    "\n",
    "def water2num(water_str):\n",
    "    if \"商水\" in str(water_str):\n",
    "        return 2\n",
    "    elif \"民水\" in str(water_str):\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def apply_water_conversion(df, col_name=\"用水\"):\n",
    "    df_copy = df.copy()\n",
    "    df_copy[col_name] = df_copy[col_name].apply(water2num) \n",
    "    return df_copy\n",
    "\n",
    "def ele2num(ele_str):\n",
    "    if \"商电\" in str(ele_str):\n",
    "        return 2\n",
    "    elif \"民电\" in str(ele_str):\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def apply_ele_conversion(df, col_name=\"用电\"):\n",
    "    df_copy = df.copy()\n",
    "    df_copy[col_name] = df_copy[col_name].apply(ele2num) \n",
    "    return df_copy\n",
    "\n",
    "def yesno2num(w_str):\n",
    "    if \"有\" in str(w_str):\n",
    "        return 1\n",
    "    elif \"无\" in str(w_str):\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def apply_yesno2num(df, col_name=None):\n",
    "    df_copy = df.copy()\n",
    "    df_copy[col_name] = df_copy[col_name].apply(yesno2num) \n",
    "    return df_copy\n",
    "\n",
    "def rent2num(r_str):\n",
    "    if \"整租\" in str(r_str):\n",
    "        return 2\n",
    "    elif \"合租\" in str(r_str):\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def apply_rent2num(df, col_name=\"租赁方式\"):\n",
    "    df_copy = df.copy()\n",
    "    df_copy[col_name] = df_copy[col_name].apply(rent2num) \n",
    "    return df_copy\n",
    "\n",
    "def avgdense_ratio(df, col1=\"房屋总数\", col2=\"楼栋总数\"):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    new_col_name = \"density_ratio\" \n",
    "    safe_col1 = df_copy[col1].replace(0, np.nan)\n",
    "    safe_col2 = df_copy[col2].replace(0, np.nan)\n",
    "    df_copy[new_col_name] = safe_col1 / safe_col2\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def cal_deal_time(df, col_name=\"交易时间\", base_year=2025):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    df_copy[\"transaction_year\"] = df_copy[col_name].apply( \n",
    "        lambda x: base_year - int(str(x)[:4]) if pd.notna(x) and str(x).strip() else np.nan\n",
    "    ) \n",
    "    return df_copy\n",
    "\n",
    "facility = [\"床\", \"衣柜\", \"空调\", \"洗衣机\", \"热水器\"]\n",
    "def check_facility(df, col_name):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    for f in facility:\n",
    "        df_copy[f] = np.nan \n",
    "    \n",
    "    def process_row(row_idx, s):\n",
    "        if pd.isna(s):\n",
    "            s = \"\"\n",
    "        else:\n",
    "            s = str(s).strip()\n",
    "        \n",
    "        s_facilities = [item.strip() for item in s.split(\"、\") if item.strip()]\n",
    "        \n",
    "        for f in facility:\n",
    "            if f in s_facilities:\n",
    "                df_copy.at[row_idx, f] = 1\n",
    "            else:\n",
    "                df_copy.at[row_idx, f] = 0\n",
    "    \n",
    "    for row_idx, s in df[col_name].items():\n",
    "        process_row(row_idx, s)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "build_cat = [\"普通住宅\", \"底商\", \"商业\", \"车库\", \"公寓\", \"别墅\"]\n",
    "def check_build_cat(df, col_name):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    for bc in build_cat:\n",
    "        df_copy[bc] = np.nan \n",
    "    \n",
    "    def process_row(row_idx, s):\n",
    "        if pd.isna(s):\n",
    "            s = \"\"\n",
    "        else:\n",
    "            s = str(s).strip()\n",
    "        \n",
    "        s_bc = [item.strip() for item in s.split(\"/\") if item.strip()]\n",
    "        \n",
    "        for bc in build_cat:\n",
    "            if bc in s_bc:\n",
    "                df_copy.at[row_idx, bc] = 1\n",
    "            else:\n",
    "                df_copy.at[row_idx, bc] = 0\n",
    "    \n",
    "    for row_idx, s in df[col_name].items():\n",
    "        process_row(row_idx, s)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def take_year(df, col_name=\"建筑年代\"):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    def process_single_value(s):\n",
    "        try:\n",
    "            year_pos = s.find(\"年\")\n",
    "            if year_pos >= 4:\n",
    "                year_str = s[year_pos - 4 : year_pos]\n",
    "                return int(year_str)\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    df_copy[col_name] = df_copy[col_name].apply(process_single_value)\n",
    "    return df_copy\n",
    "\n",
    "def interval_covert(df, col_name=None):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    def count_interval(s):\n",
    "        \n",
    "        s = str(s).strip()\n",
    "        \n",
    "        try:\n",
    "            if \"-\" in str(s):\n",
    "                dash_pos = s.find(\"-\")\n",
    "                a = s[:dash_pos].strip()\n",
    "                b = s[dash_pos + 1:].strip()\n",
    "                i_mean = (float(b)+float(a))/2\n",
    "                return i_mean\n",
    "                \n",
    "            else:\n",
    "                return float(s)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df_copy[col_name] = df_copy[col_name].apply(count_interval)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def preprocess_before_pipeline(df, config=None): #未提供config則使用默認值\n",
    "    if config is None:\n",
    "        config = {}\n",
    "\n",
    "    floor_col = config.get('floor_col', '楼层')\n",
    "    house_type_col = config.get('house_type_col', '户型')\n",
    "    toward_col = config.get('toward_col', '朝向')\n",
    "    house_area_col = config.get('house_area_col', '面积')\n",
    "    elev_col = config.get('elev_col', '电梯')\n",
    "    deal_time_col = config.get('deal_time_col', '交易时间')\n",
    "    way2rent_col = config.get('way2rent_col', '租赁方式')\n",
    "    house_total_col = config.get('house_total_col', '房屋总数')\n",
    "    building_total_col = config.get('building_total_col', '楼栋总数')\n",
    "    gas_fee_col = config.get('gas_fee_col', '燃气')\n",
    "    wat_sup_col = config.get('wat_sup_col', '用水')\n",
    "    ele_sup_col = config.get('ele_sup_col', '用电')\n",
    "    \n",
    "    facility_col = config.get('facility_col', '配套设施')\n",
    "    build_cat_col = config.get('build_cat_col', '物业类别')\n",
    "    built_year_col = config.get('built_year_col', '建筑年代')\n",
    "    greening_rate_col = config.get('greening_rate_col', '绿 化 率')\n",
    "    property_fee_col = config.get('property_fee_col', '物 业 费')\n",
    "    gas_feenum_col = config.get('gas_fee_col', '燃气费')\n",
    "    \n",
    "    \n",
    "    df_processed = df.copy()\n",
    "    df_processed = remove_string(df_processed, floor_col, \"层\")\n",
    "    df_processed = apply_floor_conversion(df_processed, floor_col)\n",
    "    \n",
    "    df_processed = split_house_type(df_processed, house_type_col)\n",
    "    \n",
    "    df_processed = remove_string(df_processed, house_area_col, \"㎡\")\n",
    "    df_processed[house_area_col] = pd.to_numeric(df_processed[house_area_col], errors='coerce')\n",
    "    \n",
    "    df_processed = change_toward(df_processed, toward_col)\n",
    "\n",
    "    df_processed = cal_deal_time(df_processed, deal_time_col)\n",
    "    \n",
    "    #df_processed = apply_rent2num(df_processed, way2rent_col)\n",
    "\n",
    "    df_processed = apply_yesno2num(df_processed, elev_col)\n",
    "    \n",
    "    df_processed = apply_yesno2num(df_processed, gas_fee_col)\n",
    "\n",
    "    df_processed = apply_water_conversion(df_processed, wat_sup_col)\n",
    "    df_processed = apply_ele_conversion(df_processed, ele_sup_col)\n",
    "    \n",
    "    df_processed = check_facility(df_processed, facility_col)\n",
    "    df_processed = check_build_cat(df_processed, build_cat_col)\n",
    "    df_processed = take_year(df_processed, built_year_col)\n",
    "    \n",
    "    df_processed = remove_string(df_processed, greening_rate_col, \"%\")\n",
    "    df_processed[greening_rate_col] = pd.to_numeric(df_processed[greening_rate_col], errors='coerce')\n",
    "    df_processed = remove_string(df_processed, property_fee_col, \"元/月/㎡\")\n",
    "    df_processed = interval_covert(df_processed, property_fee_col)\n",
    "    df_processed[property_fee_col] = pd.to_numeric(df_processed[property_fee_col], errors='coerce')\n",
    "    df_processed = remove_string(df_processed, gas_feenum_col, \"元/m³\")\n",
    "    df_processed =interval_covert(df_processed, gas_feenum_col)\n",
    "    df_processed[gas_feenum_col] = pd.to_numeric(df_processed[gas_feenum_col], errors='coerce')\n",
    "    \n",
    "    df_processed = remove_string(df_processed, house_total_col, \"户\")\n",
    "    df_processed = remove_string(df_processed, building_total_col, \"栋\")\n",
    "    df_processed[house_total_col] = pd.to_numeric(df_processed[house_total_col], errors='coerce')\n",
    "    df_processed[building_total_col] = pd.to_numeric(df_processed[building_total_col], errors='coerce')\n",
    "    df_processed = avgdense_ratio(df_processed, house_total_col, building_total_col)\n",
    "    \n",
    "    columns_to_drop = [floor_col, house_type_col, toward_col, deal_time_col]\n",
    "    existing_cols_to_drop = [col for col in columns_to_drop if col in df_processed.columns]\n",
    "    df_processed = df_processed.drop(columns=existing_cols_to_drop)\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "column_mapping = {\n",
    "    \"城市\": \"city\", \n",
    "    \"区县\": \"district\", \n",
    "    \"板块\": \"plate\", \n",
    "    \"面积\": \"area\",\n",
    "    \"年份\": \"year\",\n",
    "    \"租赁方式\": \"way2rent\",\n",
    "    \"电梯\": \"elevator\",\n",
    "    \"用水\": \"wat_sup\",\n",
    "    \"用电\": \"ele_sup\",\n",
    "    \"燃气\": \"gas\",\n",
    "    \"床\": \"bed\", \n",
    "    \"衣柜\": \"wardrobe\", \n",
    "    \"空调\": \"air_condi\", \n",
    "    \"洗衣机\": \"wash_mach\",\n",
    "    \"热水器\": \"water_heat\",\n",
    "    \"普通住宅\": \"dwelling\",\n",
    "    \"底商\": \"ground_comm\",\n",
    "    \"商业\": \"commerce\",\n",
    "    \"车库\": \"carport\",\n",
    "    \"公寓\": \"apart\",\n",
    "    \"别墅\": \"villa\",\n",
    "    \"租期\": \"period2rent\",\n",
    "    \"建筑年代\": \"built_year\",\n",
    "    \"绿 化 率\": \"greening_rate\",\n",
    "    \"容 积 率\": \"plot_ratio\",\n",
    "    \"物 业 费\": \"property_fee\",\n",
    "    \"建筑结构\": \"build_struc\",\n",
    "    \"燃气费\": \"gas_feenum\",\n",
    "    \"停车位\": \"park_area\"\n",
    "}\n",
    "\n",
    "def fraction_to_float(frac_str):\n",
    "    if pd.isna(frac_str):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        parts = str(frac_str).split('/')\n",
    "        if len(parts) == 2:\n",
    "            numerator = float(parts[0])\n",
    "            denominator = float(parts[1])\n",
    "            return numerator / denominator\n",
    "        else:\n",
    "            return float(frac_str)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0baa53bd-3b4f-4a28-a327-7a5aaa30d4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lldlu\\AppData\\Local\\Temp\\ipykernel_19116\\519720080.py:1: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_rent = pd.read_csv(\"ruc_Class25Q2_train_rent.csv\") #未处理的\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98899 entries, 0 to 98898\n",
      "Data columns (total 51 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   city               98899 non-null  int64  \n",
      " 1   装修                 25410 non-null  object \n",
      " 2   Price              98899 non-null  float64\n",
      " 3   area               98899 non-null  float64\n",
      " 4   way2rent           98899 non-null  object \n",
      " 5   elevator           98895 non-null  float64\n",
      " 6   车位                 24764 non-null  object \n",
      " 7   wat_sup            81159 non-null  float64\n",
      " 8   ele_sup            81575 non-null  float64\n",
      " 9   gas                94317 non-null  float64\n",
      " 10  采暖                 34412 non-null  object \n",
      " 11  period2rent        51966 non-null  object \n",
      " 12  lon                98899 non-null  float64\n",
      " 13  lat                98899 non-null  float64\n",
      " 14  year               98899 non-null  float64\n",
      " 15  district           94222 non-null  float64\n",
      " 16  plate              93755 non-null  float64\n",
      " 17  环线位置               29236 non-null  object \n",
      " 18  built_year         72750 non-null  float64\n",
      " 19  greening_rate      74497 non-null  float64\n",
      " 20  plot_ratio         74819 non-null  float64\n",
      " 21  property_fee       76740 non-null  float64\n",
      " 22  build_struc        78158 non-null  object \n",
      " 23  物业办公电话             38207 non-null  object \n",
      " 24  供暖                 37695 non-null  object \n",
      " 25  gas_feenum         73842 non-null  float64\n",
      " 26  供热费                28835 non-null  object \n",
      " 27  park_area          73420 non-null  float64\n",
      " 28  reflect_sentiment  98899 non-null  float64\n",
      " 29  floor              98635 non-null  float64\n",
      " 30  room               93849 non-null  float64\n",
      " 31  hall               93871 non-null  float64\n",
      " 32  kitchen            0 non-null      float64\n",
      " 33  bathroom           34765 non-null  float64\n",
      " 34  east               98899 non-null  int64  \n",
      " 35  south              98899 non-null  int64  \n",
      " 36  west               98899 non-null  int64  \n",
      " 37  north              98899 non-null  int64  \n",
      " 38  transaction_year   98899 non-null  int64  \n",
      " 39  bed                98899 non-null  float64\n",
      " 40  wardrobe           98899 non-null  float64\n",
      " 41  air_condi          98899 non-null  float64\n",
      " 42  wash_mach          98899 non-null  float64\n",
      " 43  water_heat         98899 non-null  float64\n",
      " 44  dwelling           98899 non-null  float64\n",
      " 45  ground_comm        98899 non-null  float64\n",
      " 46  commerce           98899 non-null  float64\n",
      " 47  carport            98899 non-null  float64\n",
      " 48  apart              98899 non-null  float64\n",
      " 49  villa              98899 non-null  float64\n",
      " 50  density_ratio      94268 non-null  float64\n",
      "dtypes: float64(35), int64(6), object(10)\n",
      "memory usage: 38.5+ MB\n"
     ]
    }
   ],
   "source": [
    "test_rent = pd.read_csv(\"ruc_Class25Q2_train_rent.csv\") #未处理的\n",
    "test_rent_senti = pd.read_csv(\"sentiment_rent.csv\")\n",
    "test_rent_sentiment = test_rent_senti.copy()\n",
    "test_rent[\"reflect_sentiment\"] = test_rent_senti[\"reflect_sentiment\"]\n",
    "test_rent_sentiment = test_rent.copy()\n",
    "preprocess_before_df = preprocess_before_pipeline(test_rent_sentiment, config=None)\n",
    "preprocess_before_df.drop(columns=[\"付款方式\", \"coord_x\", \"coord_y\", \"房屋总数\", \"楼栋总数\", \"客户反馈\",\n",
    "                                  \"配套设施\", \"物业类别\", \"物业类别\", \"开发商\", \"物业公司\", \"产权描述\",\n",
    "                                  \"供水\", \"供电\", \"停车费用\"], inplace=True)\n",
    "preprocess_before_df.columns = [column_mapping.get(col, col) for col in preprocess_before_df.columns]\n",
    "preprocess_before_df.info()\n",
    "preprocess_df_test = preprocess_before_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7648ec2-c541-4c51-a1ee-89730b75cba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 134220.47204780584\n",
      "MAEIN: 133596.7249174649\n",
      "MSE: 91420503538.85396\n",
      "R²: 0.7534768016171883\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------Rent_Model-------------------------------------------------------------\n",
    "x = preprocess_df_test.drop('Price', axis=1)\n",
    "y = preprocess_df_test['Price'] \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=111\n",
    ")\n",
    "\n",
    "log_cols = ['gas_feenum', 'park_area']\n",
    "\n",
    "log1p_cols = ['density_ratio', 'reflect_sentiment', 'plot_ratio', 'greening_rate', 'property_fee']\n",
    "\n",
    "num_cols = ['area']\n",
    "\n",
    "knn_num_features = ['built_year','transaction_year', 'year'] #knn\n",
    "\n",
    "house_allo_cols = ['room', 'hall', 'bathroom', 'dwelling', 'ground_comm', 'commerce', 'carport', 'apart', 'villa']#knn\n",
    "\n",
    "binary_features = ['east', 'south', 'west', 'north', 'bed', 'wardrobe', 'air_condi', 'wash_mach', 'water_heat']\n",
    "\n",
    "low_cat_features = ['city', 'way2rent', 'floor', 'wat_sup', 'ele_sup', 'build_struc']\n",
    "\n",
    "high_cat_district = ['district']  #target encoding\n",
    "high_cat_period2rent = ['period2rent']\n",
    "high_cat_plate = ['plate']  #clustering\n",
    "\n",
    "class Winsorizer(BaseEstimator, TransformerMixin): #BE方便調超參 TM使類能與pipeline集成\n",
    "    def __init__(self, lower_q=0.01, upper_q=0.99):\n",
    "        self.lower_q = lower_q\n",
    "        self.upper_q = upper_q\n",
    "        self.low_ = None\n",
    "        self.high_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X)\n",
    "        self.low_ = np.nanpercentile(X, 100 * self.lower_q, axis=0)\n",
    "        self.high_ = np.nanpercentile(X, 100 * self.upper_q, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X).astype(float)\n",
    "        return np.clip(X, self.low_, self.high_)\n",
    "\n",
    "class LonLatClusterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=8):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.kmeans = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        lon_lat = X[['lon', 'lat']].values #Kmeans需要數值輸入\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)\n",
    "        self.kmeans.fit(lon_lat)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        lon_lat = X[['lon', 'lat']].values\n",
    "        clusters = self.kmeans.predict(lon_lat)\n",
    "        return clusters.reshape(-1, 1) #將一維數組轉为二維數組（label）\n",
    "        \n",
    "class PlateClusterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=10):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.kmeans = None\n",
    "        self.encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False) #輸出np陣列\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        plate_data = X.values.reshape(-1, 1)\n",
    "        plate_encoded = self.encoder.fit_transform(plate_data)\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)\n",
    "        self.kmeans.fit(plate_encoded)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        plate_data = X.values.reshape(-1, 1)\n",
    "        plate_encoded = self.encoder.transform(plate_data)\n",
    "        clusters = self.kmeans.predict(plate_encoded)\n",
    "        return clusters.reshape(-1, 1) #sklearn Transformer 需要二維數組\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('winsor', Winsorizer(lower_q=0.01, upper_q=0.99)), \n",
    "    ('scaler', StandardScaler()) \n",
    "])\n",
    "\n",
    "log_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('log', FunctionTransformer(np.log)), \n",
    "    ('winsor', Winsorizer(lower_q=0.01, upper_q=0.99)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "log1p_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('log1p', FunctionTransformer(np.log1p)),\n",
    "    ('winsor', Winsorizer(lower_q=0.01, upper_q=0.99)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "knn_num_pipeline = Pipeline([\n",
    "    ('ref_imputer', SimpleImputer(strategy='median')),\n",
    "    ('knn_imputer', KNNImputer(n_neighbors=5)), \n",
    "    ('winsor', Winsorizer(lower_q=0.01, upper_q=0.99)), \n",
    "    ('scaler', StandardScaler()) \n",
    "])\n",
    "\n",
    "house_allo_pipeline = Pipeline([\n",
    "    ('ref_imputer', SimpleImputer(strategy='median')),\n",
    "    ('knn_imputer', KNNImputer(n_neighbors=5)),\n",
    "    ('winsor', Winsorizer(lower_q=0.01, upper_q=0.99)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "low_cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "binary_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('geo_cluster', LonLatClusterTransformer(n_clusters=25), ['lon', 'lat']),\n",
    "    ('log_cols', log_pipeline, log_cols),\n",
    "    ('log1p_num', log1p_pipeline, log1p_cols),\n",
    "    ('num_feature', num_pipeline, num_cols),\n",
    "    ('knn_num_impute', knn_num_pipeline, knn_num_features),\n",
    "    ('house_allo', house_allo_pipeline, house_allo_cols),\n",
    "    ('binary', binary_pipeline, binary_features),\n",
    "    ('low_cat', low_cat_pipeline, low_cat_features),\n",
    "    ('district_target', TargetEncoder(cols=['district'], smoothing=15), ['district']),\n",
    "    ('period2rent', TargetEncoder('period2rent', smoothing=15), ['period2rent']),\n",
    "    ('plate_cluster', PlateClusterTransformer(n_clusters=10), ['plate'])\n",
    "], remainder='drop')\n",
    "\n",
    "base_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression()) #LinearRegression()\n",
    "])\n",
    "\n",
    "ttr = TransformedTargetRegressor(regressor=base_pipeline,\n",
    "                                     func=np.log,\n",
    "                                     inverse_func=np.exp)\n",
    "\n",
    "ttr.fit(x_train, y_train)\n",
    "\n",
    "y_pred = ttr.predict(x_test)\n",
    "y_pred_in = ttr.predict(x_train)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mae_in = mean_absolute_error(y_train, y_pred_in)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MAEIN: {mae_in}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R²: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "602b2498-09a3-4b40-87c4-40a699561ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_avg: -132888.60818521338\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_folds = 6 \n",
    "scoring_metric = 'neg_mean_absolute_error'\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    estimator=ttr,\n",
    "    X=x_train,                \n",
    "    y=y_train,                 \n",
    "    cv=cv_folds,              \n",
    "    scoring=scoring_metric \n",
    ")\n",
    "\n",
    "print(f\"cv_avg: {cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "861083c3-74f4-41d2-83ca-71604c601c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('geo_cluster',\n",
      "                                                  LonLatClusterTransformer(n_clusters=25),\n",
      "                                                  ['lon', 'lat']),\n",
      "                                                 ('log_cols',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='median')),\n",
      "                                                                  ('log',\n",
      "                                                                   FunctionTransformer(func=<ufunc 'log'>)),\n",
      "                                                                  ('winsor',\n",
      "                                                                   Winsorizer()),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['gas_feenum', 'park_area']),\n",
      "                                                 ('log1p_num',\n",
      "                                                  P...\n",
      "                                                                                 sparse_output=False))]),\n",
      "                                                  ['city', 'way2rent', 'floor',\n",
      "                                                   'wat_sup', 'ele_sup',\n",
      "                                                   'build_struc']),\n",
      "                                                 ('district_target',\n",
      "                                                  TargetEncoder(cols=['district'],\n",
      "                                                                smoothing=15),\n",
      "                                                  ['district']),\n",
      "                                                 ('period2rent',\n",
      "                                                  TargetEncoder(smoothing=15,\n",
      "                                                                verbose='period2rent'),\n",
      "                                                  ['period2rent']),\n",
      "                                                 ('plate_cluster',\n",
      "                                                  PlateClusterTransformer(),\n",
      "                                                  ['plate'])])),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('regressor', LinearRegression())])\n"
     ]
    }
   ],
   "source": [
    "print(ttr.regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546afb93-0947-4fe3-9b02-86b8dac680e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ecoquant]",
   "language": "python",
   "name": "conda-env-ecoquant-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
