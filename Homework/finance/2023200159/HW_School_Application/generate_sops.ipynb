{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d8d2a91-16a6-4ede-bcc8-ffd168caecdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote universities.xlsx with 30 rows. Sample:\n",
      "                           university\n",
      "                   Harvard University\n",
      "Massachusetts Institute of Technology\n",
      "    University of California-Berkeley\n",
      "                University of Chicago\n",
      "            Paris School of Economics\n",
      "                 Princeton University\n",
      "                  Stanford University\n",
      "                      Yale University\n",
      "         Toulouse School of Economics\n",
      "                    Oxford University\n",
      "              University of Cambridge\n",
      "                       Boston College\n",
      "                University of Toronto\n",
      "                University of Warwick\n",
      "                   Cornell University\n",
      "Wrote research_areas.xlsx, journals.xlsx, skills.xlsx\n",
      "Saved template: /Users/rhae/HW_School_Application/sop_template.docx\n",
      "Generated 90 docx files in /Users/rhae/HW_School_Application\n",
      "Done. Check /Users/rhae/HW_School_Application\n"
     ]
    }
   ],
   "source": [
    "# generate_sops.ipynb\n",
    "\"\"\"\n",
    "Fixed SOP generator:\n",
    " - robustly scrapes RePEc/IDEAS for top econ depts (extracts university names)\n",
    " - writes universities.xlsx with 30 university NAMES (10 from top30, 10 from 31-60, 10 from 61-90)\n",
    " - writes research_areas.xlsx (3 areas), journals.xlsx (3 per area), skills.xlsx\n",
    " - creates a docx template suitable for docxtpl and generates 90 .docx files\n",
    "\"\"\"\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from docx import Document as DocxDocument\n",
    "from docxtpl import DocxTemplate\n",
    "from docx.shared import Pt\n",
    "\n",
    "HOME = Path.home()\n",
    "OUT_DIR = HOME / \"HW_School_Application\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (compatible; SOP-Generator/1.0)\"}\n",
    "REPEC_URL = \"https://ideas.repec.org/top/top.econdept.html\"\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def fetch(url, timeout=20):\n",
    "    r = requests.get(url, headers=HEADERS, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "def clean_univ_text(full_text: str) -> str:\n",
    "    \"\"\"\n",
    "    From \"Department of Economics, Harvard University\" -> \"Harvard University\"\n",
    "    If no comma, return the original (e.g., \"Paris School of Economics\")\n",
    "    Remove any trailing parentheses content.\n",
    "    \"\"\"\n",
    "    text = full_text.strip()\n",
    "    if not text:\n",
    "        return text\n",
    "    # split by comma, take last chunk\n",
    "    if ',' in text:\n",
    "        candidate = text.split(',')[-1].strip()\n",
    "    else:\n",
    "        candidate = text\n",
    "    # remove parentheses and content inside, e.g. (USA) or (MIT)\n",
    "    candidate = re.sub(r\"\\s*\\(.*?\\)\\s*\", \"\", candidate)\n",
    "    # normalize whitespace\n",
    "    candidate = \" \".join(candidate.split())\n",
    "    return candidate\n",
    "\n",
    "# ---------- Scrape RePEc / IDEAS ----------\n",
    "def scrape_repec_universities(limit=90):\n",
    "    html = fetch(REPEC_URL)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    # find all anchors pointing to edirc.repec.org (these are the institution links in ranking order)\n",
    "    anchors = soup.find_all('a', href=lambda h: h and 'edirc.repec.org' in h)\n",
    "    names = []\n",
    "    for a in anchors:\n",
    "        text = a.get_text(separator=\" \", strip=True)\n",
    "        if not text:\n",
    "            continue\n",
    "        # Filter: accept entries that contain 'Econom' or 'Department' or 'School' or 'Faculty' or 'Institute' or 'Department of' \n",
    "        # (this reduces unrelated links)\n",
    "        if re.search(r'\\b(Econom|Department|School|Faculty|Institute|Center|Centre|Dipartimento|Facult)', text, re.I):\n",
    "            names.append(text)\n",
    "    # dedupe while preserving order\n",
    "    cleaned = []\n",
    "    for n in names:\n",
    "        if n not in cleaned:\n",
    "            cleaned.append(n)\n",
    "        if len(cleaned) >= limit:\n",
    "            break\n",
    "    # If not enough entries found, fall back to plain anchor texts (less filtered)\n",
    "    if len(cleaned) < limit:\n",
    "        for a in anchors:\n",
    "            t = a.get_text(separator=\" \", strip=True)\n",
    "            if t and t not in cleaned:\n",
    "                cleaned.append(t)\n",
    "            if len(cleaned) >= limit:\n",
    "                break\n",
    "    return cleaned[:limit]\n",
    "\n",
    "# ---------- Create Excel lists ----------\n",
    "def make_university_list_from_repec():\n",
    "    raw_top90 = scrape_repec_universities(90)\n",
    "    if len(raw_top90) < 90:\n",
    "        print(\"Warning: less than 90 items scraped from IDEAS; got\", len(raw_top90))\n",
    "    # extract university names\n",
    "    cleaned_univs = [clean_univ_text(x) for x in raw_top90]\n",
    "    # Now select 10 from top 30 (indices 0..29), 10 from 31..60 (30..59), 10 from 61..90 (60..89)\n",
    "    def pick_section(lst, start, end, count):\n",
    "        section = lst[start:end]\n",
    "        if len(section) >= count:\n",
    "            return section[:count]\n",
    "        # fallback pad\n",
    "        out = list(section)\n",
    "        i = 0\n",
    "        while len(out) < count and i < len(lst):\n",
    "            out.append(lst[i % len(lst)])\n",
    "            i += 1\n",
    "        return out[:count]\n",
    "    top30_10 = pick_section(cleaned_univs, 0, 30, 10)\n",
    "    top60_10 = pick_section(cleaned_univs, 30, 60, 10)\n",
    "    top90_10 = pick_section(cleaned_univs, 60, 90, 10)\n",
    "    universities_30 = top30_10 + top60_10 + top90_10\n",
    "    # final dedupe preserve order\n",
    "    final = []\n",
    "    for u in universities_30:\n",
    "        if u not in final:\n",
    "            final.append(u)\n",
    "    # write to excel (column 'university')\n",
    "    df_uni = pd.DataFrame({\"university\": final})\n",
    "    df_uni.to_excel(OUT_DIR / \"universities.xlsx\", index=False)\n",
    "    print(\"Wrote universities.xlsx with\", len(final), \"rows. Sample:\")\n",
    "    print(df_uni.head(15).to_string(index=False))\n",
    "    return final\n",
    "\n",
    "# ---------- Research areas, journals, skills (step4-6) ----------\n",
    "# Per assignment pick 3 research areas from SCMOR categories: use these 3 by default\n",
    "RESEARCH_AREAS = [\"Economics\", \"Finance\", \"Information Management\"]\n",
    "TOP_JOURNALS = {\n",
    "    \"Economics\": [\"American Economic Review\", \"Econometrica\", \"Quarterly Journal of Economics\"],\n",
    "    \"Finance\": [\"Journal of Finance\", \"Review of Financial Studies\", \"Journal of Financial Economics\"],\n",
    "    \"Information Management\": [\"MIS Quarterly\", \"Information Systems Research\", \"Journal of Management Information Systems\"]\n",
    "}\n",
    "SKILLS = [\"C/C++\", \"Python\", \"R\", \"SQL\", \"LaTeX\", \"Machine Learning\", \"Mathematics\", \"PowerBI\", \"Tableau\"]\n",
    "\n",
    "def write_aux_excels(research_areas, journals_map, skills_list):\n",
    "    pd.DataFrame({\"research_area\": research_areas}).to_excel(OUT_DIR / \"research_areas.xlsx\", index=False)\n",
    "    rows = []\n",
    "    for ra in research_areas:\n",
    "        js = journals_map.get(ra, [])[:3]\n",
    "        rows.append({\"research_area\": ra, \"journal1\": js[0] if len(js)>0 else \"\",\n",
    "                     \"journal2\": js[1] if len(js)>1 else \"\", \"journal3\": js[2] if len(js)>2 else \"\"})\n",
    "    pd.DataFrame(rows).to_excel(OUT_DIR / \"journals.xlsx\", index=False)\n",
    "    pd.DataFrame({\"skill\": skills_list}).to_excel(OUT_DIR / \"skills.xlsx\", index=False)\n",
    "    print(\"Wrote research_areas.xlsx, journals.xlsx, skills.xlsx\")\n",
    "\n",
    "# ---------- Create docx template (docxtpl-friendly) ----------\n",
    "TEMPLATE_DOCX = OUT_DIR / \"sop_template.docx\"\n",
    "\n",
    "def create_docx_template(path=TEMPLATE_DOCX):\n",
    "    doc = DocxDocument()\n",
    "    style = doc.styles['Normal']\n",
    "    style.font.name = 'Times New Roman'\n",
    "    style.font.size = Pt(12)\n",
    "\n",
    "    # Keep each paragraph as a single string containing any placeholders\n",
    "    doc.add_paragraph(\"Dear Admission Committee,\")\n",
    "    doc.add_paragraph(\"\")\n",
    "    doc.add_paragraph(\"My name is {{ name }}, and I am pleased to apply for the {{ program }} at {{ university }}.\")\n",
    "    doc.add_paragraph(\"\")\n",
    "    doc.add_paragraph(\n",
    "        \"In my free time, I enjoy reading top-tier academic research to stay updated with the latest advancements in {{ research_area }}. \"\n",
    "        \"I occasionally study articles from leading journals such as {{ journals|join(', ') }}. \"\n",
    "        \"This habit deepens my understanding of theoretical and empirical approaches and sharpens my critical analysis skills.\"\n",
    "    )\n",
    "    doc.add_paragraph(\"\")\n",
    "    doc.add_paragraph(\n",
    "        \"My objective is to pursue research in {{ research_area }}. \"\n",
    "        \"To achieve this goal, I have developed practical skills including: {{ skills|join(', ') }}.\"\n",
    "    )\n",
    "    doc.add_paragraph(\"\")\n",
    "    doc.add_paragraph(\n",
    "        \"I am particularly drawn to {{ university }} because of its strong academic environment and research-oriented approach in {{ research_area }}. \"\n",
    "        \"I believe the program will allow me to grow as a researcher and contribute to the department.\"\n",
    "    )\n",
    "    doc.add_paragraph(\"\")\n",
    "    doc.add_paragraph(\n",
    "        \"Thank you for considering my application. \"\n",
    "        \"I am eager to contribute to and benefit from the rigorous academic culture at {{ university }}.\"\n",
    "    )\n",
    "    doc.add_paragraph(\"\")\n",
    "    doc.add_paragraph(\"Sincerely,\")\n",
    "    doc.add_paragraph(\"\")\n",
    "    doc.add_paragraph(\"{{ name }}\")\n",
    "\n",
    "    doc.save(path)\n",
    "    print(\"Saved template:\", path)\n",
    "\n",
    "# ---------- Generate documents using docxtpl ----------\n",
    "def generate_documents(universities, research_areas, journals_map, skills_list, applicant_info):\n",
    "    out = []\n",
    "    for uni in universities:\n",
    "        for ra in research_areas:\n",
    "            # load a fresh template every iteration to avoid side-effects\n",
    "            tpl = DocxTemplate(TEMPLATE_DOCX)\n",
    "            ctx = {\n",
    "                \"name\": applicant_info.get(\"name\", \"Xinyu Liu\"),\n",
    "                \"program\": applicant_info.get(\"program\", \"Master program\"),\n",
    "                \"university\": uni,\n",
    "                \"research_area\": ra,\n",
    "                \"journals\": journals_map.get(ra, [])[:3],\n",
    "                \"skills\": skills_list\n",
    "            }\n",
    "            fname_safe = \"\".join(c for c in uni if c.isalnum() or c in \" _-\").strip()[:50]\n",
    "            filename = f\"SOP_{fname_safe}_{ra.replace(' ', '_')}.docx\"\n",
    "            out_path = OUT_DIR / filename\n",
    "            tpl.render(ctx)\n",
    "            tpl.save(out_path)\n",
    "            out.append(out_path)\n",
    "    print(\"Generated\", len(out), \"docx files in\", OUT_DIR)\n",
    "    return out\n",
    "\n",
    "# ---------- Main ----------\n",
    "def main():\n",
    "    # 1) universities\n",
    "    universities_30 = make_university_list_from_repec()\n",
    "\n",
    "    # 2) research areas + journals + skills\n",
    "    write_aux_excels(RESEARCH_AREAS, TOP_JOURNALS, SKILLS)\n",
    "\n",
    "    # 3) create template (overwrite always to ensure correctness)\n",
    "    create_docx_template(TEMPLATE_DOCX)\n",
    "\n",
    "    # 4) generate 90 docs\n",
    "    applicant = {\"name\": \"Xinyu Liu\", \"program\": \"Master of Finance\"}\n",
    "    all_docs = generate_documents(universities_30, RESEARCH_AREAS, TOP_JOURNALS, SKILLS, applicant)\n",
    "\n",
    "    # 5) write a README summary\n",
    "    (OUT_DIR / \"README.txt\").write_text(\n",
    "        \"This folder was generated by generate_sops.ipynb\\n\"\n",
    "        \"Contains:\\n - universities.xlsx (30 universities)\\n - research_areas.xlsx, journals.xlsx, skills.xlsx\\n - sop_template.docx\\n - {} generated .docx files\\n\".format(len(all_docs))\n",
    "    )\n",
    "    print(\"Done. Check\", OUT_DIR)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2892a42-ab5f-4f64-9dc1-bef3810f7218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
