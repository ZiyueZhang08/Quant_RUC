{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "3E1550D5B60D4091B53016D4F3DC0634",
    "jupyter": {},
    "notebookId": "6900b12e7a0e19b0ec3765eb",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAEE51CAC7804597B5D0E06FB209A34B",
    "jupyter": {},
    "mdEditEnable": true,
    "notebookId": "6900b12e7a0e19b0ec3765eb",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "source": [
    "## æ¬¢è¿è¿›å…¥ Notebook  \n",
    "\n",
    "è¿™é‡Œä½ å¯ä»¥ç¼–å†™ä»£ç ï¼Œæ–‡æ¡£  \n",
    "\n",
    "### å…³äºæ–‡ä»¶ç›®å½•  \n",
    "\n",
    "\n",
    "**project**ï¼šproject ç›®å½•æ˜¯æœ¬é¡¹ç›®çš„å·¥ä½œç©ºé—´ï¼Œå¯ä»¥æŠŠå°†é¡¹ç›®è¿è¡Œæœ‰å…³çš„æ‰€æœ‰æ–‡ä»¶æ”¾åœ¨è¿™é‡Œï¼Œç›®å½•ä¸­æ–‡ä»¶çš„å¢ã€åˆ ã€æ”¹æ“ä½œéƒ½ä¼šè¢«ä¿ç•™  \n",
    "\n",
    "\n",
    "**input**ï¼šinput ç›®å½•æ˜¯æ•°æ®é›†çš„æŒ‚è½½ä½ç½®ï¼Œæ‰€æœ‰æŒ‚è½½è¿›é¡¹ç›®çš„æ•°æ®é›†éƒ½åœ¨è¿™é‡Œï¼ŒæœªæŒ‚è½½æ•°æ®é›†æ—¶ input ç›®å½•è¢«éšè—  \n",
    "\n",
    "\n",
    "**temp**ï¼štemp ç›®å½•æ˜¯ä¸´æ—¶ç£ç›˜ç©ºé—´ï¼Œè®­ç»ƒæˆ–åˆ†æè¿‡ç¨‹ä¸­äº§ç”Ÿçš„ä¸å¿…è¦æ–‡ä»¶å¯ä»¥å­˜æ”¾åœ¨è¿™é‡Œï¼Œç›®å½•ä¸­çš„æ–‡ä»¶ä¸ä¼šä¿å­˜  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "id": "3999AF60F2754394BA5F1A3C9AD8354B",
    "jupyter": {},
    "notebookId": "6900b12e7a0e19b0ec3765eb",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\r\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹ä¸ªäººæŒä¹…åŒ–å·¥ä½œåŒºæ–‡ä»¶\n",
    "!ls /home/mw/project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "id": "F8B70CD7BC87457F9CB6221D1CE5EDBB",
    "jupyter": {},
    "notebookId": "6900b12e7a0e19b0ec3765eb",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hackathon255769\r\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹å½“å‰æŒ‚è½½çš„æ•°æ®é›†ç›®å½•\n",
    "!ls /home/mw/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "1A6101B26E0646AA84E375F5D12E4815",
    "jupyter": {},
    "notebookId": "6900b12e7a0e19b0ec3765eb",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# æ ‡å‡†åº“å¯¼å…¥\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# ç¬¬ä¸‰æ–¹åŸºç¡€åº“\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# sklearn ç»„ä»¶\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, LinearRegression, RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "id": "5A7B3317C5AC48C38F48764C8CB50955",
    "jupyter": {},
    "notebookId": "6900b12e7a0e19b0ec3765eb",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_214/2934170934.py:10: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train_rent  = pd.read_csv(TRAIN_RENT)\n",
      "/tmp/ipykernel_214/2934170934.py:12: DtypeWarning: Columns (3,32,34,43,46,49,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train_price = pd.read_csv(TRAIN_PRICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rent shape=(98899, 46)\n",
      "test_rent shape=(9773, 46)\n",
      "train_price shape=(103871, 55)\n",
      "test_price shape=(34017, 55)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_214/2934170934.py:13: DtypeWarning: Columns (4,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test_price  = pd.read_csv(TEST_PRICE)\n"
     ]
    }
   ],
   "source": [
    "DATA = Path(\"/home/mw/input/hackathon255769\")\n",
    "TRAIN_RENT  = DATA / \"ruc_Class25Q2_train_rent.csv\"\n",
    "TEST_RENT   = DATA / \"ruc_Class25Q2_test_rent.csv\"\n",
    "TRAIN_PRICE = DATA / \"ruc_Class25Q2_train_price.csv\"\n",
    "TEST_PRICE  = DATA / \"ruc_Class25Q2_test_price.csv\"\n",
    "\n",
    "df_train_rent  = pd.read_csv(TRAIN_RENT)\n",
    "df_test_rent   = pd.read_csv(TEST_RENT)\n",
    "df_train_price = pd.read_csv(TRAIN_PRICE)\n",
    "df_test_price  = pd.read_csv(TEST_PRICE)\n",
    "\n",
    "for name, df in {\n",
    "    \"train_rent\": df_train_rent, \"test_rent\": df_test_rent,\n",
    "    \"train_price\": df_train_price, \"test_price\": df_test_price\n",
    "}.items():\n",
    "    print(f\"{name} shape={df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "id": "36FED90A28384CA989CD07EDB4885309",
    "jupyter": {},
    "notebookId": "6900b12e7a0e19b0ec3765eb",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31mâ•°â”€>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31mÃ—\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "D8391034DF1744F9AEB013088F70BA17",
    "jupyter": {},
    "notebookId": "6900b12e7a0e19b0ec3765eb",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---------- åŸºç¡€å·¥å…· ----------\n",
    "def to_number(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).strip()\n",
    "    if s.endswith(\"%\"):\n",
    "        try: return float(s.replace(\"%\", \"\")) / 100\n",
    "        except: return np.nan\n",
    "    for sym in [\"ã¡\", \"å…ƒ\", \"mÂ³\", \"æœˆ\", \"ï¼\", \"/\", \"æ¯\", \" \", \"æ ‹\", \"æˆ·\",\"å¹´\"]:\n",
    "        s = s.replace(sym, \"\")\n",
    "    s = s.strip()\n",
    "    if \"-\" in s:\n",
    "        try: return np.mean([float(i) for i in s.split(\"-\") if i.strip()])\n",
    "        except: return np.nan\n",
    "    try: return float(s)\n",
    "    except: return np.nan\n",
    "\n",
    "def parse_chinese_number(s):\n",
    "    if not isinstance(s, str) or s.strip() == '':\n",
    "        return np.nan\n",
    "    s = s.strip()\n",
    "    cn_num = {'é›¶':0,'ä¸€':1,'äºŒ':2,'ä¸¤':2,'ä¸‰':3,'å››':4,'äº”':5,'å…­':6,'ä¸ƒ':7,'å…«':8,'ä¹':9}\n",
    "    if re.match(r'^\\d+$', s): return float(s)\n",
    "    total = 0\n",
    "    hundred, ten, num = 0, 0, 0\n",
    "    if 'ç™¾' in s:\n",
    "        parts = s.split('ç™¾')\n",
    "        hundred = cn_num.get(parts[0], 1) * 100\n",
    "        s = parts[1] if len(parts) > 1 else ''\n",
    "    if 'å' in s:\n",
    "        parts = s.split('å')\n",
    "        left = parts[0]; right = parts[1] if len(parts) > 1 else ''\n",
    "        ten = cn_num.get(left, 1) * 10\n",
    "        num = cn_num.get(right, 0) if right else 0\n",
    "        return hundred + ten + num\n",
    "    for ch in s:\n",
    "        num = num * 10 + cn_num.get(ch, 0)\n",
    "    return hundred + num\n",
    "\n",
    "# ---------- å„å¤„ç†æ¨¡å— ----------\n",
    "class LeakRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, leak_cols): self.leak_cols = leak_cols\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return X.drop(columns=[c for c in self.leak_cols if c in X.columns], errors='ignore')\n",
    "class BuildYearAverager(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    å°†â€œå»ºç­‘å¹´ä»£â€åˆ—ä¸­å¦‚ '2011-2012å¹´', '2005å¹´', '1998-2000' ç­‰æ ¼å¼è½¬æ¢ä¸ºå¹³å‡å¹´ä»½ï¼ˆfloatï¼‰ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self, col='å»ºç­‘å¹´ä»£'):\n",
    "        self.col = col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if self.col not in X.columns:\n",
    "            return X\n",
    "\n",
    "        def parse_year(s):\n",
    "            if pd.isna(s): return np.nan\n",
    "            s = str(s).strip().replace(\"å¹´\", \"\")\n",
    "            # æå–æ‰€æœ‰4ä½æ•°å­—\n",
    "            years = re.findall(r'\\d{4}', s)\n",
    "            if not years:\n",
    "                return np.nan\n",
    "            years = [int(y) for y in years]\n",
    "            # è‹¥æ˜¯åŒºé—´å¦‚ 2011-2012ï¼Œåˆ™å–å¹³å‡\n",
    "            if len(years) == 2:\n",
    "                return np.mean(years)\n",
    "            # è‹¥åªæœ‰å•ä¸€å¹´ä»½\n",
    "            elif len(years) == 1:\n",
    "                return float(years[0])\n",
    "            else:\n",
    "                # å‡ºç°å¥‡æ€ªæ ¼å¼åˆ™å–ä¸­ä½æ•°\n",
    "                return np.mean(years)\n",
    "\n",
    "        X[self.col] = X[self.col].apply(parse_year)\n",
    "        return X\n",
    "class HouseLayoutExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"æå–æˆ¿å±‹æˆ·å‹ä¸ºå®¤/å…/å¨/å«\"\"\"\n",
    "    def __init__(self, col='æˆ¿å±‹æˆ·å‹'): self.col = col\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        def extract_layout(s):\n",
    "            if pd.isna(s) or str(s).strip()=='':\n",
    "                return (0,0,0,0)\n",
    "            s = str(s)\n",
    "            if 'æˆ¿é—´' in s:\n",
    "                rooms = re.findall(r'(\\d+)æˆ¿é—´', s)\n",
    "                baths = re.findall(r'(\\d+)å«', s)\n",
    "                return (int(rooms[0]) if rooms else 0, 0, 0, int(baths[0]) if baths else 0)\n",
    "            rooms = re.findall(r'(\\d+)å®¤', s)\n",
    "            halls = re.findall(r'(\\d+)å…', s)\n",
    "            kitchens = re.findall(r'(\\d+)å¨', s)\n",
    "            baths = re.findall(r'(\\d+)å«', s)\n",
    "            return (int(rooms[0]) if rooms else 0,\n",
    "                    int(halls[0]) if halls else 0,\n",
    "                    int(kitchens[0]) if kitchens else 0,\n",
    "                    int(baths[0]) if baths else 0)\n",
    "        layout_df = pd.DataFrame(X[self.col].apply(extract_layout).tolist(),\n",
    "                                 columns=['æˆ·å‹_å®¤æ•°','æˆ·å‹_å…æ•°','æˆ·å‹_å¨æ•°','æˆ·å‹_å«æ•°'], index=X.index)\n",
    "        return pd.concat([X.drop(columns=[self.col], errors='ignore'), layout_df], axis=1)\n",
    "class UnitCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols): self.cols = cols\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            if c in X.columns:\n",
    "                X[c] = X[c].apply(to_number)\n",
    "        return X\n",
    "class LadderRatioExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col='æ¢¯æˆ·æ¯”ä¾‹'): self.col = col\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        def parse_ratio(v):\n",
    "            if pd.isna(v) or str(v).strip()=='':\n",
    "                return 0\n",
    "            s = str(v)\n",
    "            ladders = re.findall(r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾é›¶ä¸¤\\d]+)æ¢¯', s)\n",
    "            units = re.findall(r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾é›¶ä¸¤\\d]+)æˆ·', s)\n",
    "            if ladders and units:\n",
    "                a = parse_chinese_number(ladders[0])\n",
    "                b = parse_chinese_number(units[0])\n",
    "                if not np.isnan(a) and not np.isnan(b) and b != 0:\n",
    "                    return round(a / b, 3)\n",
    "            return 0\n",
    "        X[self.col] = X[self.col].apply(parse_ratio)\n",
    "        return X\n",
    "class ElevatorFlagger(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col='é…å¤‡ç”µæ¢¯'): self.col=col\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X=X.copy()\n",
    "        if self.col in X.columns:\n",
    "            X[self.col]=X[self.col].astype(str).apply(lambda v:1 if ('æœ‰' in v or 'æ˜¯' in v or v.strip()=='1') else 0)\n",
    "        else: X[self.col]=0\n",
    "        return X\n",
    "class DynamicWinsorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, factor=1.5): self.factor=factor\n",
    "    def fit(self,X,y=None):\n",
    "        num=X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if 'Price' in num: num.remove('Price')\n",
    "        self.bounds_={}\n",
    "        for c in num:\n",
    "            q1,q3=X[c].quantile(0.25),X[c].quantile(0.75)\n",
    "            iqr=q3-q1\n",
    "            self.bounds_[c]=(q1-self.factor*iqr,q3+self.factor*iqr)\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        X=X.copy()\n",
    "        for c,(l,u) in self.bounds_.items():\n",
    "            X[c]=X[c].clip(l,u)\n",
    "        return X\n",
    "class DynamicMissingDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=0.6, exempt_cols=None):\n",
    "        self.threshold = threshold\n",
    "        self.exempt_cols = exempt_cols if exempt_cols is not None else []\n",
    "    def fit(self,X,y=None):\n",
    "        miss = X.isnull().mean()\n",
    "        self.to_drop_ = [c for c in miss.index if miss[c] > self.threshold and c not in self.exempt_cols]\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X.drop(columns=self.to_drop_, errors='ignore')\n",
    "class ImputerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,num_cols,cat_cols):\n",
    "        self.num_cols=num_cols; self.cat_cols=cat_cols\n",
    "        self.num_imp=SimpleImputer(strategy='median')\n",
    "        self.cat_imp=SimpleImputer(strategy='most_frequent')\n",
    "    def fit(self,X,y=None):\n",
    "        self.num_exist=[c for c in self.num_cols if c in X.columns]\n",
    "        self.cat_exist=[c for c in self.cat_cols if c in X.columns]\n",
    "        if self.num_exist:self.num_imp.fit(X[self.num_exist])\n",
    "        if self.cat_exist:self.cat_imp.fit(X[self.cat_exist])\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        X=X.copy()\n",
    "        if self.num_exist:X[self.num_exist]=self.num_imp.transform(X[self.num_exist])\n",
    "        if self.cat_exist:X[self.cat_exist]=self.cat_imp.transform(X[self.cat_exist])\n",
    "        return X\n",
    "class FloorExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,col='æ‰€åœ¨æ¥¼å±‚'):\n",
    "        self.col=col\n",
    "        self.map={'åœ°ä¸‹å®¤':0,'åº•å±‚':1,'ä½æ¥¼å±‚':2,'ä¸­æ¥¼å±‚':3,'é«˜æ¥¼å±‚':4,'é¡¶å±‚':5}\n",
    "    def fit(self,X,y=None):return self\n",
    "    def transform(self,X):\n",
    "        X=X.copy()\n",
    "        if self.col in X.columns:\n",
    "            s=X[self.col].astype(str)\n",
    "            X['æ€»æ¥¼å±‚']=s.str.extract(r'å…±(\\d+)å±‚')[0].astype(float)\n",
    "            X['æ¥¼å±‚ç±»å‹']=s.str.extract(r'(åœ°ä¸‹å®¤|åº•å±‚|ä½æ¥¼å±‚|ä¸­æ¥¼å±‚|é«˜æ¥¼å±‚|é¡¶å±‚)')[0]\n",
    "            X['æ¥¼å±‚ä½ç½®ç¼–ç ']=X['æ¥¼å±‚ç±»å‹'].map(self.map)\n",
    "            X=X.drop(columns=[self.col])\n",
    "        return X\n",
    "class RingEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=['ç¯çº¿']):\n",
    "        self.cols = cols\n",
    "        self.mapping = {\n",
    "            'å†…ç¯å†…':1,'äºŒç¯å†…':1,\n",
    "            'å†…ç¯è‡³ä¸­ç¯':2,'äºŒè‡³ä¸‰ç¯':2,\n",
    "            'å†…ç¯è‡³å¤–ç¯':3,'ä¸‰è‡³å››ç¯':3,\n",
    "            'ä¸­ç¯è‡³å¤–ç¯':4,'å››è‡³äº”ç¯':4,'äº”è‡³å…­ç¯':4,\n",
    "            'å…­ç¯å¤–':5,'å¤–ç¯å¤–':5\n",
    "        }\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        col_exist = None\n",
    "        for c in self.cols:\n",
    "            if c in X.columns:\n",
    "                col_exist = c\n",
    "                break\n",
    "        if col_exist:\n",
    "            X['ç¯çº¿_missing'] = X[col_exist].isna().astype(int)\n",
    "            X['ç¯çº¿_num'] = X[col_exist].map(self.mapping)\n",
    "            mean_val = np.nanmean(X['ç¯çº¿_num'])\n",
    "            X['ç¯çº¿_num_filled'] = X['ç¯çº¿_num'].fillna(mean_val)\n",
    "            X = X.drop(columns=[col_exist, 'ç¯çº¿_num'])\n",
    "        else:\n",
    "            X['ç¯çº¿_missing'] = 1\n",
    "            X['ç¯çº¿_num_filled'] = 0\n",
    "        return X\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "        try:\n",
    "            self.enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "        except TypeError:\n",
    "            self.enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    def fit(self,X,y=None): \n",
    "        self.exist=[c for c in self.cols if c in X.columns] \n",
    "        if self.exist: self.enc.fit(X[self.exist]) \n",
    "        return self \n",
    "    def transform(self,X): \n",
    "        X=X.copy() \n",
    "        if not getattr(self,'exist', None) or not self.exist: return X \n",
    "        arr = self.enc.transform(X[self.exist]) \n",
    "        cat_df = pd.DataFrame(arr, columns=self.enc.get_feature_names_out(self.exist), index=X.index) \n",
    "        return pd.concat([X.drop(columns=self.exist, errors='ignore'), cat_df], axis=1)      \n",
    "class SelectiveStandardizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.scaler=StandardScaler()\n",
    "        self.exclude=[]\n",
    "    def fit(self,X,y=None):\n",
    "        num=X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        self.cols_=[c for c in num if (c not in self.exclude and c!='Price' and '_' not in c)]\n",
    "        if self.cols_:self.scaler.fit(X[self.cols_])\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        X=X.copy()\n",
    "        if hasattr(self,'cols_') and self.cols_:\n",
    "            X[self.cols_]=self.scaler.transform(X[self.cols_])\n",
    "        return X\n",
    "class ColumnPruner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,drop_cols):self.drop_cols=drop_cols\n",
    "    def fit(self,X,y=None):return self\n",
    "    def transform(self,X):return X.drop(columns=[c for c in self.drop_cols if c in X.columns],errors='ignore')\n",
    "class FinalImputer(BaseEstimator, TransformerMixin):\n",
    "   \n",
    "    def fit(self, X, y=None):\n",
    "        self.num_cols_ = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        self.cat_cols_ = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "        self.num_imp = SimpleImputer(strategy='median')\n",
    "        self.cat_imp = SimpleImputer(strategy='most_frequent')\n",
    "        if self.num_cols_:\n",
    "            self.num_imp.fit(X[self.num_cols_])\n",
    "        if self.cat_cols_:\n",
    "            self.cat_imp.fit(X[self.cat_cols_])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if hasattr(self, 'num_cols_') and self.num_cols_:\n",
    "            X[self.num_cols_] = self.num_imp.transform(X[self.num_cols_])\n",
    "        if hasattr(self, 'cat_cols_') and self.cat_cols_:\n",
    "            X[self.cat_cols_] = self.cat_imp.transform(X[self.cat_cols_])\n",
    "        return X\n",
    "\n",
    "\n",
    "# ---------- âœ… æœ€ç»ˆç»„åˆ ----------\n",
    "def FinalPricePipeline():\n",
    "    leak_cols=['æˆ¿å±‹ä¼˜åŠ¿','æ ¸å¿ƒå–ç‚¹','æˆ·å‹ä»‹ç»','å‘¨è¾¹é…å¥—','äº¤é€šå‡ºè¡Œ','å®¢æˆ·åé¦ˆ',\n",
    "               'ä¸Šæ¬¡äº¤æ˜“','äº¤æ˜“æƒå±','äº§æƒæè¿°','äº¤æ˜“æ—¶é—´']\n",
    "    num_cols=['å»ºç­‘é¢ç§¯','å¥—å†…é¢ç§¯','ç»¿ åŒ– ç‡','å®¹ ç§¯ ç‡','ç‰© ä¸š è´¹','ç‡ƒæ°”è´¹','æˆ¿å±‹æ€»æ•°','æ¥¼æ ‹æ€»æ•°']\n",
    "    num_impute=['å®¹ ç§¯ ç‡','ç»¿ åŒ– ç‡','ç‡ƒæ°”è´¹','ç‰© ä¸š è´¹','æˆ¿å±‹æ€»æ•°','æ¥¼æ ‹æ€»æ•°']\n",
    "    cat_impute=['ä¾›æ°´','ä¾›ç”µ','ä¾›æš–','å»ºç­‘ç»“æ„','å»ºç­‘ç»“æ„_comm']\n",
    "    cat_cols=['å»ºç­‘ç»“æ„','å»ºç­‘ç»“æ„_comm','è£…ä¿®æƒ…å†µ','æˆ¿å±‹ç”¨é€”','äº§æƒæ‰€å±','ä¾›æ°´','ä¾›æš–','ä¾›ç”µ','åŸå¸‚']\n",
    "    drop_cols=['æˆ¿å±‹æœå‘','ç‰©ä¸šç±»åˆ«','ç‰©ä¸šåŠå…¬ç”µè¯','ç‰©ä¸šå…¬å¸','å¼€å‘å•†','æŠµæŠ¼ä¿¡æ¯',\n",
    "               'åˆ«å¢…ç±»å‹','æˆ¿å±‹å¹´é™','coord_x','coord_y','ç¯çº¿ä½ç½®','åœè½¦è´¹ç”¨','æ¥¼å±‚ç±»å‹']\n",
    "\n",
    "    return Pipeline([\n",
    "        ('leakremover', LeakRemover(leak_cols)),\n",
    "        ('ladder',LadderRatioExtractor()),\n",
    "        ('build_year', BuildYearAverager()),         \n",
    "        ('layout', HouseLayoutExtractor()),\n",
    "        ('unit_clean', UnitCleaner(num_cols)),\n",
    "        ('floor', FloorExtractor()),\n",
    "        ('elevator', ElevatorFlagger()),\n",
    "        ('ring', RingEncoder()),\n",
    "        ('winsor', DynamicWinsorizer()),\n",
    "        ('missing_drop', DynamicMissingDropper()),\n",
    "        ('impute', ImputerTransformer(num_impute, cat_impute)),\n",
    "        ('onehot', CategoricalEncoder(cat_cols)),\n",
    "        ('scale', SelectiveStandardizer()),\n",
    "        ('final_impute', FinalImputer()),            \n",
    "        ('prune', ColumnPruner(drop_cols))\n",
    "    ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "id": "320D9479839A4969965DB05F7F093350",
    "jupyter": {},
    "notebookId": "6900b12e7a0e19b0ec3765eb",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "price_pipeline = FinalPricePipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "id": "ABFA038BE4C94A979989E13A4FCC51F8",
    "jupyter": {},
    "notebookId": "6900b12e7a0e19b0ec3765eb",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŸå§‹è®­ç»ƒé›†: (103871, 55), æµ‹è¯•é›†: (34017, 54)\n",
      "âœ… è·³è¿‡å¤šé¡¹å¼ç‰¹å¾ï¼Œå½“å‰ç‰¹å¾æ•°: 94\n",
      "âœ… æ•°æ®åˆ’åˆ†å®Œæˆ: X_train=(83096, 94), X_val=(20775, 94)\n",
      "âœ… ç‰¹å¾é€‰æ‹©å®Œæˆ: 94 ä¸ªç‰¹å¾ä¿ç•™\n",
      "âœ… ç‰¹å¾å·²æ ‡å‡†åŒ–\n",
      "\n",
      "[OLS]\n",
      "In-sample:  MAE=696,085.29  RMSE=1,415,562.75  RÂ²=0.6904\n",
      "Out-sample: MAE=683,704.57  RMSE=1,407,717.67  RÂ²=0.6799\n",
      "\n",
      "[RidgeCV]\n",
      "In-sample:  MAE=696,082.94  RMSE=1,415,577.90  RÂ²=0.6904\n",
      "Out-sample: MAE=683,721.66  RMSE=1,407,744.10  RÂ²=0.6799\n",
      "\n",
      "[LassoCV]\n",
      "In-sample:  MAE=711,908.25  RMSE=1,475,670.73  RÂ²=0.6635\n",
      "Out-sample: MAE=700,014.50  RMSE=1,469,668.33  RÂ²=0.6511\n",
      "\n",
      "[ElasticNetCV]\n",
      "In-sample:  MAE=700,865.65  RMSE=1,437,972.45  RÂ²=0.6805\n",
      "Out-sample: MAE=688,489.49  RMSE=1,430,171.64  RÂ²=0.6696\n",
      "\n",
      "=== Summary (Validation Performance) ===\n",
      "          Model        MAE_val      RMSE_val    RÂ²_val\n",
      "0           OLS  683704.570439  1.407718e+06  0.679926\n",
      "1       RidgeCV  683721.660834  1.407744e+06  0.679914\n",
      "2  ElasticNetCV  688489.493239  1.430172e+06  0.669634\n",
      "3       LassoCV  700014.499790  1.469668e+06  0.651135\n",
      "ğŸ“ å·²ä¿å­˜æ¨¡å‹æ€§èƒ½è¡¨ metrics_price_summary.csv\n",
      "ğŸ“ å·²ä¿å­˜é¢„æµ‹ç»“æœ prediction_price.csv\n",
      "\n",
      "âœ… å…¨æµç¨‹å®Œæˆï¼ˆç¨³å®šç‰ˆï¼‰ï¼\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ğŸ§  Quant Modeling: Housing Price Prediction (Stable Version)\n",
    "# ==========================================================\n",
    "\n",
    "import os, warnings, numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"  # é™åˆ¶çº¿ç¨‹æ•°é˜²æ­¢çˆ†å†…å­˜\n",
    "\n",
    "# ==========================================================\n",
    "# 1ï¸âƒ£ æ•°æ®å‡†å¤‡\n",
    "# ==========================================================\n",
    "\n",
    "# åˆ é™¤æ— ç”¨åˆ—\n",
    "df_test_price = df_test_price.drop(columns=[\"ID\"], errors=\"ignore\")\n",
    "\n",
    "# æ‹†åˆ†ç›®æ ‡ä¸ç‰¹å¾\n",
    "y_price = df_train_price[\"Price\"]\n",
    "X_price_train = df_train_price.drop(columns=[\"Price\"], errors=\"ignore\")\n",
    "\n",
    "print(f\"åŸå§‹è®­ç»ƒé›†: {df_train_price.shape}, æµ‹è¯•é›†: {df_test_price.shape}\")\n",
    "\n",
    "# pipeline æ¸…æ´—\n",
    "clean_price = price_pipeline.fit_transform(X_price_train)\n",
    "clean_price_test = price_pipeline.transform(df_test_price)\n",
    "\n",
    "# æ£€æŸ¥åˆ—æ•°æ˜¯å¦ä¸€è‡´\n",
    "if clean_price_test.shape[1] != clean_price.shape[1]:\n",
    "    common_cols = [c for c in clean_price.columns if c in clean_price_test.columns]\n",
    "    clean_price = clean_price[common_cols]\n",
    "    clean_price_test = clean_price_test[common_cols]\n",
    "    print(f\"âš ï¸ å·²å¯¹é½å…¬å…±ç‰¹å¾æ•°: {len(common_cols)}\")\n",
    "\n",
    "# ==========================================================\n",
    "# 2ï¸âƒ£ ç‰¹å¾ä¸ç›®æ ‡è®¾ç½®\n",
    "# ==========================================================\n",
    "\n",
    "USE_LOG_TARGET = True  # å¯¹ä»·æ ¼å–å¯¹æ•°ä½¿åˆ†å¸ƒæ›´ç¨³å®š\n",
    "\n",
    "if USE_LOG_TARGET:\n",
    "    y_all = np.log1p(y_price)\n",
    "else:\n",
    "    y_all = y_price\n",
    "\n",
    "X_all = clean_price.copy()\n",
    "X_test_all = clean_price_test.copy()\n",
    "\n",
    "print(f\"âœ… è·³è¿‡å¤šé¡¹å¼ç‰¹å¾ï¼Œå½“å‰ç‰¹å¾æ•°: {X_all.shape[1]}\")\n",
    "\n",
    "# ==========================================================\n",
    "# 3ï¸âƒ£ æ•°æ®åˆ’åˆ† + ç‰¹å¾é€‰æ‹© + æ ‡å‡†åŒ–\n",
    "# ==========================================================\n",
    "\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X_all, y_all, test_size=0.2, random_state=111)\n",
    "print(f\"âœ… æ•°æ®åˆ’åˆ†å®Œæˆ: X_train={X_tr.shape}, X_val={X_va.shape}\")\n",
    "\n",
    "# ç‰¹å¾ç­›é€‰\n",
    "selector = SelectKBest(f_regression, k='all')  # ä¿ç•™æ‰€æœ‰æ˜¾è‘—ç‰¹å¾\n",
    "X_tr_sel = selector.fit_transform(X_tr, y_tr)\n",
    "X_va_sel = selector.transform(X_va)\n",
    "X_te_sel = selector.transform(X_test_all)\n",
    "print(f\"âœ… ç‰¹å¾é€‰æ‹©å®Œæˆ: {X_tr_sel.shape[1]} ä¸ªç‰¹å¾ä¿ç•™\")\n",
    "\n",
    "# æ ‡å‡†åŒ–\n",
    "scaler = StandardScaler()\n",
    "X_tr_sel = scaler.fit_transform(X_tr_sel)\n",
    "X_va_sel = scaler.transform(X_va_sel)\n",
    "X_te_sel = scaler.transform(X_te_sel)\n",
    "print(\"âœ… ç‰¹å¾å·²æ ‡å‡†åŒ–\")\n",
    "\n",
    "# ==========================================================\n",
    "# 4ï¸âƒ£ æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°\n",
    "# ==========================================================\n",
    "\n",
    "def evaluate_model(name, model, Xtr, ytr, Xva, yva, log_target=False):\n",
    "    mdl = model.fit(Xtr, ytr)\n",
    "    yhat_tr = mdl.predict(Xtr)\n",
    "    yhat_va = mdl.predict(Xva)\n",
    "\n",
    "    # è‹¥ç›®æ ‡ä¸ºlogï¼Œåå˜æ¢\n",
    "    if log_target:\n",
    "        ytr_true, yva_true = np.expm1(ytr), np.expm1(yva)\n",
    "        ytr_pred, yva_pred = np.expm1(yhat_tr), np.expm1(yhat_va)\n",
    "    else:\n",
    "        ytr_true, yva_true = ytr, yva\n",
    "        ytr_pred, yva_pred = yhat_tr, yhat_va\n",
    "\n",
    "    mae_tr = mean_absolute_error(ytr_true, ytr_pred)\n",
    "    rmse_tr = np.sqrt(mean_squared_error(ytr_true, ytr_pred))\n",
    "    r2_tr = r2_score(ytr_true, ytr_pred)\n",
    "    mae_va = mean_absolute_error(yva_true, yva_pred)\n",
    "    rmse_va = np.sqrt(mean_squared_error(yva_true, yva_pred))\n",
    "    r2_va = r2_score(yva_true, yva_pred)\n",
    "\n",
    "    print(f\"\\n[{name}]\")\n",
    "    print(f\"In-sample:  MAE={mae_tr:,.2f}  RMSE={rmse_tr:,.2f}  RÂ²={r2_tr:.4f}\")\n",
    "    print(f\"Out-sample: MAE={mae_va:,.2f}  RMSE={rmse_va:,.2f}  RÂ²={r2_va:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"MAE_train\": mae_tr, \"MAE_val\": mae_va,\n",
    "        \"RMSE_train\": rmse_tr, \"RMSE_val\": rmse_va,\n",
    "        \"RÂ²_train\": r2_tr, \"RÂ²_val\": r2_va,\n",
    "        \"Estimator\": mdl\n",
    "    }\n",
    "\n",
    "results = []\n",
    "results.append(evaluate_model(\"OLS\", LinearRegression(), X_tr_sel, y_tr, X_va_sel, y_va, USE_LOG_TARGET))\n",
    "results.append(evaluate_model(\"RidgeCV\", RidgeCV(alphas=np.logspace(-3,3,20), cv=5), X_tr_sel, y_tr, X_va_sel, y_va, USE_LOG_TARGET))\n",
    "results.append(evaluate_model(\"LassoCV\", LassoCV(alphas=np.logspace(-2,1,10), cv=3, n_jobs=1, max_iter=5000), X_tr_sel, y_tr, X_va_sel, y_va, USE_LOG_TARGET))\n",
    "results.append(evaluate_model(\"ElasticNetCV\", ElasticNetCV(alphas=np.logspace(-2,1,8), l1_ratio=[0.3,0.5,0.7], cv=3, n_jobs=1, max_iter=5000), X_tr_sel, y_tr, X_va_sel, y_va, USE_LOG_TARGET))\n",
    "\n",
    "# ==========================================================\n",
    "# 5ï¸âƒ£ æ±‡æ€»ç»“æœä¸é¢„æµ‹è¾“å‡º\n",
    "# ==========================================================\n",
    "\n",
    "metrics_df = pd.DataFrame([{k:v for k,v in r.items() if k!=\"Estimator\"} for r in results])\n",
    "metrics_df = metrics_df.sort_values(\"MAE_val\").reset_index(drop=True)\n",
    "print(\"\\n=== Summary (Validation Performance) ===\")\n",
    "print(metrics_df[[\"Model\",\"MAE_val\",\"RMSE_val\",\"RÂ²_val\"]])\n",
    "\n",
    "metrics_df.to_csv(\"metrics_price_summary.csv\", index=False)\n",
    "print(\"ğŸ“ å·²ä¿å­˜æ¨¡å‹æ€§èƒ½è¡¨ metrics_price_summary.csv\")\n",
    "\n",
    "# ä½¿ç”¨éªŒè¯é›† MAE æœ€å°çš„æ¨¡å‹è¿›è¡Œæœ€ç»ˆé¢„æµ‹\n",
    "best_model = results[metrics_df[\"MAE_val\"].idxmin()][\"Estimator\"]\n",
    "y_pred_test = best_model.predict(X_te_sel)\n",
    "if USE_LOG_TARGET:\n",
    "    y_pred_test = np.expm1(y_pred_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": np.arange(len(y_pred_test)),\n",
    "    \"prediction\": y_pred_test\n",
    "})\n",
    "submission.to_csv(\"prediction_price.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"ğŸ“ å·²ä¿å­˜é¢„æµ‹ç»“æœ prediction_price.csv\")\n",
    "\n",
    "print(\"\\nâœ… å…¨æµç¨‹å®Œæˆï¼ˆç¨³å®šç‰ˆï¼‰ï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "1FED9D5B3195414ABF00619C9580FF16",
    "jupyter": {},
    "notebookId": "6900b12e7a0e19b0ec3765eb",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---------- åŸºç¡€å·¥å…· ----------\n",
    "def to_number(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).strip()\n",
    "    if s.endswith(\"%\"):\n",
    "        try: return float(s.replace(\"%\",\"\"))/100\n",
    "        except: return np.nan\n",
    "    for sym in [\"ã¡\",\"å…ƒ\",\"mÂ³\",\"ï¼\",\"/\",\"æ¯\",\"æœˆ\",\"æ ‹\",\"æˆ·\",\"å…ƒ/æœˆ/ã¡\",\"å…ƒ/ã¡\",\"å±‚\",\" \"]:\n",
    "        s = s.replace(sym,\"\")\n",
    "    s = s.strip()\n",
    "    if \"-\" in s:\n",
    "        try: return np.mean([float(i) for i in s.split(\"-\") if i.strip()])\n",
    "        except: return np.nan\n",
    "    try: return float(s)\n",
    "    except: return np.nan\n",
    "\n",
    "# ---------- å„å­æ¨¡å— ----------\n",
    "class LeakRemover(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"åˆ é™¤æè¿°/å”®å/æ˜æ˜¾æ— ç”¨åˆ—ï¼Œé¿å…ä¿¡æ¯æ³„éœ²\"\"\"\n",
    "    def __init__(self, leak_cols): self.leak_cols = leak_cols\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=[c for c in self.leak_cols if c in X.columns], errors='ignore')\n",
    "\n",
    "\n",
    "class BuildYearAverager(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col='å»ºç­‘å¹´ä»£'):\n",
    "        self.col = col\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if self.col not in X.columns:\n",
    "            return X\n",
    "        def parse_year(s):\n",
    "            import re\n",
    "            import numpy as np\n",
    "            if pd.isna(s) or str(s).strip() == \"\":\n",
    "                return np.nan\n",
    "            s = str(s)\n",
    "            s = re.sub(r\"[ï¼â€“â€”~ï½]\", \"-\", s)\n",
    "            s = re.sub(r\"[^\\d\\-]\", \"\", s)\n",
    "            nums = re.findall(r\"\\d{4}\", s)\n",
    "            if len(nums) >= 2:\n",
    "                return np.mean([float(nums[0]), float(nums[1])])\n",
    "            elif len(nums) == 1:\n",
    "                return float(nums[0])\n",
    "            else:\n",
    "                return np.nan\n",
    "        X[self.col] = X[self.col].apply(parse_year)\n",
    "        return X\n",
    "\n",
    "\n",
    "class HouseLayoutExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"'æˆ·å‹' â†’ æˆ·å‹_å®¤/å…/å«ï¼ˆæ•°å€¼ï¼‰\"\"\"\n",
    "    def __init__(self, col='æˆ·å‹'): self.col = col\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        def extract_layout(s):\n",
    "            if pd.isna(s) or str(s).strip()=='':\n",
    "                return (0,0,0)\n",
    "            s = str(s)\n",
    "            rooms = re.findall(r'(\\d+)å®¤', s)\n",
    "            halls = re.findall(r'(\\d+)å…', s)\n",
    "            baths = re.findall(r'(\\d+)å«', s)\n",
    "            return (int(rooms[0]) if rooms else 0,\n",
    "                    int(halls[0]) if halls else 0,\n",
    "                    int(baths[0]) if baths else 0)\n",
    "        layout_df = pd.DataFrame(X[self.col].apply(extract_layout).tolist(),\n",
    "                                 columns=['æˆ·å‹_å®¤','æˆ·å‹_å…','æˆ·å‹_å«'], index=X.index)\n",
    "        return pd.concat([X.drop(columns=[self.col], errors='ignore'), layout_df], axis=1)\n",
    "\n",
    "class UnitCleaner(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"å¸¦å•ä½åˆ— â†’ çº¯æ•°å€¼\"\"\"\n",
    "    def __init__(self, cols): self.cols = cols\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in self.cols:\n",
    "            if c in X.columns:\n",
    "                X[c] = X[c].apply(to_number)\n",
    "        return X\n",
    "class FloorExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"å…¼å®¹ '4/6å±‚' ä¸ 'ä¸­æ¥¼å±‚ (å…±10å±‚)' ä¸¤ç±»æ ¼å¼\"\"\"\n",
    "    def __init__(self, col='æ¥¼å±‚'):\n",
    "        self.col = col\n",
    "        self.map={'åœ°ä¸‹å®¤':0,'åº•å±‚':1,'ä½æ¥¼å±‚':2,'ä¸­æ¥¼å±‚':3,'é«˜æ¥¼å±‚':4,'é¡¶å±‚':5}\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X=X.copy()\n",
    "        if self.col in X.columns:\n",
    "            s = X[self.col].astype(str)\n",
    "            X['æ€»æ¥¼å±‚'] = s.str.extract(r'å…±(\\d+)å±‚')[0].astype(float)\n",
    "            X['å½“å‰æ¥¼å±‚'] = s.str.extract(r'(\\d+)\\s*/')[0].astype(float)\n",
    "            m2 = s.str.extract(r'/\\s*(\\d+)')[0].astype(float)\n",
    "            X['æ€»æ¥¼å±‚'] = X['æ€»æ¥¼å±‚'].fillna(m2)\n",
    "            X['æ¥¼å±‚ç±»å‹'] = s.str.extract(r'(åœ°ä¸‹å®¤|åº•å±‚|ä½æ¥¼å±‚|ä¸­æ¥¼å±‚|é«˜æ¥¼å±‚|é¡¶å±‚)')[0]\n",
    "            X['æ¥¼å±‚ä½ç½®ç¼–ç '] = X['æ¥¼å±‚ç±»å‹'].map(self.map)\n",
    "            X.drop(columns=[self.col], inplace=True)\n",
    "        return X\n",
    "class ElevatorFlagger(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"ç”µæ¢¯ï¼šæœ‰/æ˜¯/1 â†’ 1ï¼›å…¶ä»–æˆ–ç©º â†’ 0\"\"\"\n",
    "    def __init__(self, col='ç”µæ¢¯'): self.col = col\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X=X.copy()\n",
    "        if self.col in X.columns:\n",
    "            X[self.col] = X[self.col].astype(str).apply(\n",
    "                lambda v: 1 if ('æœ‰' in v or 'æ˜¯' in v or v.strip()=='1') else 0\n",
    "            )\n",
    "        else:\n",
    "            X[self.col] = 0\n",
    "        return X\n",
    "class PaymentMonths(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"ä»˜æ¬¾æ–¹å¼ â†’ ä»˜æ¬¾æœˆæ•°ï¼ˆæ•°å€¼ï¼‰ï¼Œç™½åå•å¤–æ ·æœ¬åˆ é™¤\"\"\"\n",
    "    def __init__(self, pay_col='ä»˜æ¬¾æ–¹å¼'):\n",
    "        self.pay_col = pay_col\n",
    "        self.mapping = {'æœˆä»˜ä»·':1, 'åŒæœˆä»˜ä»·':2, 'å­£ä»˜ä»·':3, 'åŠå¹´ä»˜ä»·':6, 'å¹´ä»˜ä»·':12}\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if self.pay_col in X.columns:\n",
    "            mask = X[self.pay_col].isin(self.mapping.keys())\n",
    "            X = X[mask].copy()\n",
    "            X['ä»˜æ¬¾æœˆæ•°'] = X[self.pay_col].map(self.mapping).astype(float)\n",
    "        else:\n",
    "            # è‹¥ç¼ºåˆ—ï¼Œæ— æ³•æ„é€ è¯¥ç‰¹å¾ï¼›ä¿å®ˆèµ·è§è®¾ä¸º NaNï¼Œç¨åç”± imputer å¤„ç†æˆ–è¢«åˆ é™¤\n",
    "            X['ä»˜æ¬¾æœˆæ•°'] = np.nan\n",
    "        return X\n",
    "class RingEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"ç¯çº¿ä½ç½®ï¼šæ•°å€¼åŒ– + ç¼ºå¤±æ ‡è®°ï¼ˆæ›´ç¨³å¥ï¼‰\"\"\"\n",
    "    def __init__(self, col='ç¯çº¿ä½ç½®'):\n",
    "        self.col = col\n",
    "        self.mapping={'å†…ç¯å†…':1,'äºŒç¯å†…':1,'å†…ç¯è‡³ä¸­ç¯':2,'äºŒè‡³ä¸‰ç¯':2,\n",
    "                      'å†…ç¯è‡³å¤–ç¯':3,'ä¸‰è‡³å››ç¯':3,'ä¸­ç¯è‡³å¤–ç¯':4,'å››è‡³äº”ç¯':4,'äº”è‡³å…­ç¯':4,\n",
    "                      'å…­ç¯å¤–':5,'å¤–ç¯å¤–':5}\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X=X.copy()\n",
    "        if self.col in X.columns:\n",
    "            X['ç¯çº¿_missing'] = X[self.col].isna().astype(int)\n",
    "            X['ç¯çº¿_num'] = X[self.col].map(self.mapping)\n",
    "            mean_val = np.nanmean(X['ç¯çº¿_num'])\n",
    "            X['ç¯çº¿_num_filled'] = X['ç¯çº¿_num'].fillna(mean_val)\n",
    "            X.drop(columns=[self.col,'ç¯çº¿_num'], inplace=True)\n",
    "        else:\n",
    "            X['ç¯çº¿_missing'] = 1\n",
    "            X['ç¯çº¿_num_filled'] = 0\n",
    "        return X\n",
    "class DynamicWinsorizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"IQR æˆªå°¾ï¼›ç›®æ ‡åˆ—ä¸æ ‡å¿—åˆ—ä¸å‚ä¸\"\"\"\n",
    "    def __init__(self, factor=1.5): self.factor=factor\n",
    "    def fit(self,X,y=None):\n",
    "        num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        for skip in ['Price','ä»˜æ¬¾æœˆæ•°']: \n",
    "            if skip in num_cols: num_cols.remove(skip)\n",
    "        self.bounds_={}\n",
    "        for c in num_cols:\n",
    "            q1,q3 = X[c].quantile(0.25), X[c].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            self.bounds_[c] = (q1 - self.factor*iqr, q3 + self.factor*iqr)\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        X = X.copy()\n",
    "        for c,(l,u) in self.bounds_.items():\n",
    "            if c in X.columns:\n",
    "                X.loc[:, c] = X[c].clip(l, u)\n",
    "        return X\n",
    "class DynamicMissingDropper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\">60% ç¼ºå¤±çš„åˆ—åˆ é™¤ï¼Œä½†è±å…ç¯çº¿ä½ç½®\"\"\"\n",
    "    def __init__(self, threshold=0.6, exempt_cols=None):\n",
    "        self.threshold=threshold\n",
    "        self.exempt_cols = exempt_cols if exempt_cols else ['ç¯çº¿ä½ç½®']\n",
    "    def fit(self,X,y=None):\n",
    "        miss = X.isnull().mean()\n",
    "        self.to_drop_ = [c for c in miss.index if miss[c] > self.threshold and c not in self.exempt_cols]\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X.drop(columns=self.to_drop_, errors='ignore')\n",
    "class ImputerTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"æ•°å€¼/åˆ†ç±»ç¼ºå¤±å¡«è¡¥\"\"\"\n",
    "    def __init__(self, num_cols, cat_cols):\n",
    "        self.num_cols=num_cols; self.cat_cols=cat_cols\n",
    "        self.num_imp=SimpleImputer(strategy='median')\n",
    "        self.cat_imp=SimpleImputer(strategy='most_frequent')\n",
    "    def fit(self,X,y=None):\n",
    "        self.num_exist=[c for c in self.num_cols if c in X.columns]\n",
    "        self.cat_exist=[c for c in self.cat_cols if c in X.columns]\n",
    "        if self.num_exist: self.num_imp.fit(X[self.num_exist])\n",
    "        if self.cat_exist: self.cat_imp.fit(X[self.cat_exist])\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        X=X.copy()\n",
    "        if self.num_exist: X[self.num_exist]=self.num_imp.transform(X[self.num_exist])\n",
    "        if self.cat_exist: X[self.cat_exist]=self.cat_imp.transform(X[self.cat_exist])\n",
    "        return X\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"å¯¹æŒ‡å®šåˆ†ç±»å˜é‡åš OneHotï¼ˆä»˜æ¬¾æ–¹å¼ä¸å†è¿›æ¥ï¼ï¼‰\"\"\"\n",
    "    def __init__(self, cols):\n",
    "        self.cols=cols\n",
    "        self.enc=OneHotEncoder(handle_unknown='ignore')\n",
    "    def fit(self,X,y=None):\n",
    "        self.exist=[c for c in self.cols if c in X.columns]\n",
    "        if self.exist: self.enc.fit(X[self.exist])\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        X=X.copy()\n",
    "        if not getattr(self,'exist', None) or not self.exist: return X\n",
    "        arr = self.enc.transform(X[self.exist]).toarray()\n",
    "        cat_df = pd.DataFrame(arr, columns=self.enc.get_feature_names_out(self.exist), index=X.index)\n",
    "        return pd.concat([X.drop(columns=self.exist, errors='ignore'), cat_df], axis=1)\n",
    "class SelectiveStandardizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"æ ‡å‡†åŒ–ï¼ˆåŒ…å« 'ä»˜æ¬¾æœˆæ•°'ï¼Œä½†æ’é™¤åæ ‡/åœ°ç†æ ‡å¿—/äºŒå€¼ï¼‰\"\"\"\n",
    "    def __init__(self):\n",
    "        self.scaler=StandardScaler()\n",
    "        self.exclude=['åŸå¸‚','åŒºå¿','æ¿å—','lon','lat','coord_x','coord_y',\n",
    "                      'ç”µæ¢¯','ç¯çº¿_num_filled','ç¯çº¿_missing']\n",
    "    def fit(self,X,y=None):\n",
    "        num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        # ç›®æ ‡å˜é‡ä¸èƒ½æ ‡å‡†åŒ–\n",
    "        self.cols_ = [c for c in num_cols if c not in self.exclude and c != 'Price']\n",
    "        if self.cols_: self.scaler.fit(X[self.cols_])\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        X=X.copy()\n",
    "        if getattr(self,'cols_', None) and self.cols_:\n",
    "            X[self.cols_] = self.scaler.transform(X[self.cols_])\n",
    "        return X\n",
    "class ColumnPruner(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"åˆ é™¤æ— ç”¨/æ–‡æœ¬/æ½œåœ¨æ³„éœ²åˆ—ï¼ˆå«ä»˜æ¬¾æ–¹å¼åŸå§‹åˆ—ï¼‰\"\"\"\n",
    "    def __init__(self, drop_cols): self.drop_cols=drop_cols\n",
    "    def fit(self,X,y=None): return self\n",
    "    def transform(self,X):\n",
    "        return X.drop(columns=[c for c in self.drop_cols if c in X.columns], errors='ignore')\n",
    "class GlobalMedianImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"å¯¹æ‰€æœ‰æ•°å€¼åˆ—çš„ç¼ºå¤±å€¼è¿›è¡Œä¸­ä½æ•°å¡«è¡¥\"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        num_cols = X.select_dtypes(include=[np.number]).columns\n",
    "        self.medians_ = X[num_cols].median()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c in self.medians_.index:\n",
    "            if c in X.columns:\n",
    "                X[c] = X[c].fillna(self.medians_[c])\n",
    "        return X\n",
    "\n",
    "\n",
    "# ---------- æœ€ç»ˆç»„åˆ ----------\n",
    "def FinalRentPipeline():\n",
    "    # å¸¦å•ä½çš„æ•°å€¼åˆ—\n",
    "    num_cols = ['é¢ç§¯','ç»¿ åŒ– ç‡','å®¹ ç§¯ ç‡','ç‰© ä¸š è´¹','ç‡ƒæ°”è´¹','ä¾›çƒ­è´¹','æˆ¿å±‹æ€»æ•°','æ¥¼æ ‹æ€»æ•°','åœè½¦è´¹ç”¨']\n",
    "    # éœ€è¦æ•°å€¼å¡«è¡¥çš„åˆ—ï¼ˆä¸Šé¢çš„ä¸€éƒ¨åˆ†ï¼‰\n",
    "    num_impute = ['é¢ç§¯','ç»¿ åŒ– ç‡','å®¹ ç§¯ ç‡','ç‰© ä¸š è´¹','ç‡ƒæ°”è´¹','åœè½¦è´¹ç”¨','ä»˜æ¬¾æœˆæ•°']\n",
    "    # éœ€è¦ä¼—æ•°å¡«è¡¥çš„åˆ†ç±»åˆ—ï¼ˆä¸å«â€œä»˜æ¬¾æ–¹å¼â€ï¼‰\n",
    "    cat_impute = ['è£…ä¿®','é‡‡æš–','ä¾›æ°´','ä¾›ç”µ','ä¾›æš–','å»ºç­‘ç»“æ„','ç‰©ä¸šç±»åˆ«','ç§Ÿèµæ–¹å¼']\n",
    "    # è¿›å…¥ OneHot çš„åˆ†ç±»åˆ—\n",
    "    cat_cols   = ['è£…ä¿®','ç‡ƒæ°”','é‡‡æš–','ä¾›æ°´','ä¾›ç”µ','ä¾›æš–','å»ºç­‘ç»“æ„','ç§Ÿèµæ–¹å¼','äº§æƒæè¿°','ç‰©ä¸šç±»åˆ«']\n",
    "    # ç›´æ¥ä¸¢å¼ƒçš„åˆ—\n",
    "    drop_cols  = ['äº¤æ˜“æ—¶é—´','è½¦ä½','å¼€å‘å•†','ç‰©ä¸šå…¬å¸','ç‰©ä¸šåŠå…¬ç”µè¯',\n",
    "                  'å®¢æˆ·åé¦ˆ','æœå‘','ç§ŸæœŸ','é…å¥—è®¾æ–½','ä»˜æ¬¾æ–¹å¼','ç”¨æ°´','ç”¨ç”µ','æ¥¼å±‚ç±»å‹']  # æ³¨æ„æŠŠåŸå§‹â€œä»˜æ¬¾æ–¹å¼â€åˆ é™¤\n",
    "\n",
    "    return Pipeline([\n",
    "        ('leak_remove', LeakRemover(drop_cols + ['é…å¥—è®¾æ–½','å®¢æˆ·åé¦ˆ','äº§æƒæè¿°'])),\n",
    "        ('layout', HouseLayoutExtractor()),\n",
    "        ('unit_clean', UnitCleaner(num_cols)),\n",
    "        ('floor', FloorExtractor()),\n",
    "        ('elevator', ElevatorFlagger()),\n",
    "        ('ring', RingEncoder()),\n",
    "        ('paymonths', PaymentMonths()),\n",
    "        ('winsor', DynamicWinsorizer()),\n",
    "        ('missing_drop', DynamicMissingDropper(exempt_cols=['ç¯çº¿ä½ç½®'])),\n",
    "        ('impute', ImputerTransformer(num_impute, cat_impute)),   # åŸæœ‰åˆ—çº§å¡«è¡¥\n",
    "        ('global_median', GlobalMedianImputer()),                 # âœ… æ–°å¢å…¨å±€ä¸­ä½æ•°å¡«è¡¥\n",
    "        ('onehot', CategoricalEncoder(cat_cols)),\n",
    "        ('scale', SelectiveStandardizer()),\n",
    "        ('prune', ColumnPruner(drop_cols))\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "id": "B4B329FB513945BDA5E0A942D4896E3F",
    "jupyter": {},
    "notebookId": "6900b12e7a0e19b0ec3765eb",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1) æ‹Ÿåˆå¹¶æ¸…æ´—è®­ç»ƒé›†\n",
    "rent_pipeline = FinalRentPipeline()\n",
    "train_rent_clean = rent_pipeline.fit_transform(df_train_rent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "id": "F72B9ADB5B214BF1ABC95AD9B4CB76FF",
    "jupyter": {},
    "notebookId": "6900b12e7a0e19b0ec3765eb",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åŸå§‹è®­ç»ƒé›†: (98899, 45), æµ‹è¯•é›†: (9773, 44)\n",
      "âœ… æ¸…æ´—åè®­ç»ƒé›†å½¢çŠ¶: (98899, 284), æµ‹è¯•é›†å½¢çŠ¶: (9773, 284)\n",
      "âœ… ç‰¹å¾ä¸ç›®æ ‡åˆ†ç¦»å®Œæˆ: X_rent=(98899, 284), y_rent=(98899,)\n",
      "âœ… è®­ç»ƒ/éªŒè¯é›†åˆ’åˆ†å®Œæˆ: X_train=(79119, 284), X_valid=(19780, 284)\n",
      "âœ… ç‰¹å¾ç­›é€‰å®Œæˆï¼Œå…±ä¿ç•™ 284 ä¸ªç‰¹å¾\n",
      "âœ… ç‰¹å¾å·²æ ‡å‡†åŒ–\n",
      "\n",
      "[OLS]\n",
      "In-sample:  MAE=178,735.54  RMSE=359,871.56  RÂ²=0.6590\n",
      "Out-sample: MAE=181,432.78  RMSE=392,866.78  RÂ²=0.6274\n",
      "\n",
      "[RidgeCV]\n",
      "In-sample:  MAE=178,685.22  RMSE=359,810.75  RÂ²=0.6591\n",
      "Out-sample: MAE=181,392.92  RMSE=392,856.79  RÂ²=0.6274\n",
      "\n",
      "[LassoCV]\n",
      "In-sample:  MAE=179,334.76  RMSE=361,658.96  RÂ²=0.6556\n",
      "Out-sample: MAE=182,082.09  RMSE=396,108.64  RÂ²=0.6213\n",
      "\n",
      "[ElasticNetCV]\n",
      "In-sample:  MAE=178,764.99  RMSE=360,215.70  RÂ²=0.6583\n",
      "Out-sample: MAE=181,439.36  RMSE=393,556.34  RÂ²=0.6261\n",
      "\n",
      "=== ğŸ“Š Validation Summary ===\n",
      "          Model        MAE_val       RMSE_val    RÂ²_val\n",
      "0       RidgeCV  181392.920280  392856.788398  0.627449\n",
      "1           OLS  181432.777267  392866.782101  0.627430\n",
      "2  ElasticNetCV  181439.355580  393556.337383  0.626121\n",
      "3       LassoCV  182082.091757  396108.641194  0.621256\n",
      "ğŸ“ å·²ä¿å­˜æ¨¡å‹æ€§èƒ½è¡¨ metrics_rent_summary.csv\n",
      "\n",
      "ğŸ† æœ€ä¼˜æ¨¡å‹: OLS\n",
      "ğŸ“ å·²ä¿å­˜é¢„æµ‹ç»“æœ prediction_rent.csv\n",
      "\n",
      "âœ… å…¨æµç¨‹å®Œæˆï¼ˆç§Ÿé‡‘é¢„æµ‹ç¨³å®šç‰ˆï¼‰ï¼\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ğŸ  Rent Modeling: Price Prediction (Full Stable Version)\n",
    "# ==========================================================\n",
    "\n",
    "import os, warnings, numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==========================================================\n",
    "# 1ï¸âƒ£ æ•°æ®å‡†å¤‡ä¸æ¸…æ´—\n",
    "# ==========================================================\n",
    "\n",
    "# --- åˆ é™¤IDåˆ— ---\n",
    "df_train_rent = df_train_rent.drop(columns=[\"ID\"], errors=\"ignore\")\n",
    "df_test_rent  = df_test_rent.drop(columns=[\"ID\"], errors=\"ignore\")\n",
    "\n",
    "print(f\"âœ… åŸå§‹è®­ç»ƒé›†: {df_train_rent.shape}, æµ‹è¯•é›†: {df_test_rent.shape}\")\n",
    "\n",
    "# --- åˆ†ç¦»ç›®æ ‡å˜é‡ Price ---\n",
    "y_rent = df_train_rent[\"Price\"].astype(float)\n",
    "X_train_raw = df_train_rent.drop(columns=[\"Price\"], errors=\"ignore\")\n",
    "\n",
    "# --- pipeline æ¸…æ´— ---\n",
    "train_rent_clean = rent_pipeline.fit_transform(X_train_raw)\n",
    "test_rent_clean  = rent_pipeline.transform(df_test_rent)\n",
    "\n",
    "# --- ç‰¹å¾å¯¹é½ ---\n",
    "if test_rent_clean.shape[1] != train_rent_clean.shape[1]:\n",
    "    common_cols = [c for c in train_rent_clean.columns if c in test_rent_clean.columns]\n",
    "    train_rent_clean = train_rent_clean[common_cols]\n",
    "    test_rent_clean = test_rent_clean[common_cols]\n",
    "    print(f\"âš ï¸ å·²å¯¹é½å…¬å…±ç‰¹å¾åˆ—æ•°: {len(common_cols)}\")\n",
    "\n",
    "print(f\"âœ… æ¸…æ´—åè®­ç»ƒé›†å½¢çŠ¶: {train_rent_clean.shape}, æµ‹è¯•é›†å½¢çŠ¶: {test_rent_clean.shape}\")\n",
    "\n",
    "# ==========================================================\n",
    "# 2ï¸âƒ£ ç‰¹å¾ä¸ç›®æ ‡è®¾ç½®\n",
    "# ==========================================================\n",
    "\n",
    "# æ­¤æ—¶ train_rent_clean ä»…åŒ…å«ç‰¹å¾ï¼Œä¸å« Price\n",
    "X_rent = train_rent_clean.copy()\n",
    "\n",
    "USE_LOG_TARGET = True\n",
    "y_target = np.log1p(y_rent) if USE_LOG_TARGET else y_rent\n",
    "\n",
    "print(f\"âœ… ç‰¹å¾ä¸ç›®æ ‡åˆ†ç¦»å®Œæˆ: X_rent={X_rent.shape}, y_rent={y_rent.shape}\")\n",
    "\n",
    "# ==========================================================\n",
    "# 3ï¸âƒ£ æ•°æ®åˆ’åˆ†ä¸ç‰¹å¾é€‰æ‹©\n",
    "# ==========================================================\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_rent, y_target, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"âœ… è®­ç»ƒ/éªŒè¯é›†åˆ’åˆ†å®Œæˆ: X_train={X_train.shape}, X_valid={X_valid.shape}\")\n",
    "\n",
    "# --- ç‰¹å¾é€‰æ‹© ---\n",
    "selector = SelectKBest(f_regression, k='all')  # å¯è°ƒæˆå…·ä½“æ•°å€¼ï¼Œå¦‚ 200\n",
    "X_train_sel = selector.fit_transform(X_train, y_train)\n",
    "X_valid_sel = selector.transform(X_valid)\n",
    "print(f\"âœ… ç‰¹å¾ç­›é€‰å®Œæˆï¼Œå…±ä¿ç•™ {X_train_sel.shape[1]} ä¸ªç‰¹å¾\")\n",
    "\n",
    "# --- æ ‡å‡†åŒ– ---\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train_sel)\n",
    "X_valid_std = scaler.transform(X_valid_sel)\n",
    "print(\"âœ… ç‰¹å¾å·²æ ‡å‡†åŒ–\")\n",
    "\n",
    "# ==========================================================\n",
    "# 4ï¸âƒ£ æ¨¡å‹å®šä¹‰ä¸è¯„ä¼°å‡½æ•°\n",
    "# ==========================================================\n",
    "\n",
    "def evaluate_model(name, model, Xtr, ytr, Xva, yva, log_target=False):\n",
    "    \"\"\"é€šç”¨æ¨¡å‹è¯„ä¼°å‡½æ•°\"\"\"\n",
    "    model.fit(Xtr, ytr)\n",
    "    ytr_pred, yva_pred = model.predict(Xtr), model.predict(Xva)\n",
    "\n",
    "    # åå˜æ¢å›åŸä»·æ ¼ç©ºé—´\n",
    "    if log_target:\n",
    "        ytr_true, yva_true = np.expm1(ytr), np.expm1(yva)\n",
    "        ytr_pred, yva_pred = np.expm1(ytr_pred), np.expm1(yva_pred)\n",
    "    else:\n",
    "        ytr_true, yva_true = ytr, yva\n",
    "\n",
    "    mae_tr = mean_absolute_error(ytr_true, ytr_pred)\n",
    "    rmse_tr = np.sqrt(mean_squared_error(ytr_true, ytr_pred))\n",
    "    r2_tr = r2_score(ytr_true, ytr_pred)\n",
    "\n",
    "    mae_va = mean_absolute_error(yva_true, yva_pred)\n",
    "    rmse_va = np.sqrt(mean_squared_error(yva_true, yva_pred))\n",
    "    r2_va = r2_score(yva_true, yva_pred)\n",
    "\n",
    "    print(f\"\\n[{name}]\")\n",
    "    print(f\"In-sample:  MAE={mae_tr:,.2f}  RMSE={rmse_tr:,.2f}  RÂ²={r2_tr:.4f}\")\n",
    "    print(f\"Out-sample: MAE={mae_va:,.2f}  RMSE={rmse_va:,.2f}  RÂ²={r2_va:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"MAE_train\": mae_tr, \"RMSE_train\": rmse_tr, \"RÂ²_train\": r2_tr,\n",
    "        \"MAE_val\": mae_va, \"RMSE_val\": rmse_va, \"RÂ²_val\": r2_va,\n",
    "        \"Estimator\": model\n",
    "    }\n",
    "\n",
    "# ==========================================================\n",
    "# 5ï¸âƒ£ æ¨¡å‹è®­ç»ƒä¸éªŒè¯æ¯”è¾ƒ\n",
    "# ==========================================================\n",
    "\n",
    "models = [\n",
    "    (\"OLS\", LinearRegression()),\n",
    "    (\"RidgeCV\", RidgeCV(alphas=np.logspace(-3, 3, 20), cv=5)),\n",
    "    (\"LassoCV\", LassoCV(alphas=np.logspace(-3, 1, 15), cv=5, max_iter=8000)),\n",
    "    (\"ElasticNetCV\", ElasticNetCV(alphas=np.logspace(-3, 1, 10), \n",
    "                                  l1_ratio=[0.2,0.5,0.8], cv=5, max_iter=8000))\n",
    "]\n",
    "\n",
    "results = []\n",
    "for name, model in models:\n",
    "    res = evaluate_model(name, model, X_train_std, y_train, X_valid_std, y_valid, USE_LOG_TARGET)\n",
    "    results.append(res)\n",
    "\n",
    "# ==========================================================\n",
    "# 6ï¸âƒ£ ç»“æœæ±‡æ€»ä¸æœ€ä¼˜æ¨¡å‹é€‰æ‹©\n",
    "# ==========================================================\n",
    "\n",
    "metrics_df = pd.DataFrame([{k:v for k,v in r.items() if k!=\"Estimator\"} for r in results])\n",
    "metrics_df = metrics_df.sort_values(\"MAE_val\").reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== ğŸ“Š Validation Summary ===\")\n",
    "print(metrics_df[[\"Model\",\"MAE_val\",\"RMSE_val\",\"RÂ²_val\"]])\n",
    "\n",
    "metrics_df.to_csv(\"metrics_rent_summary.csv\", index=False)\n",
    "print(\"ğŸ“ å·²ä¿å­˜æ¨¡å‹æ€§èƒ½è¡¨ metrics_rent_summary.csv\")\n",
    "\n",
    "# --- é€‰æ‹©éªŒè¯é›†è¡¨ç°æœ€å¥½çš„æ¨¡å‹ ---\n",
    "best_idx = metrics_df[\"MAE_val\"].idxmin()\n",
    "best_model = results[best_idx][\"Estimator\"]\n",
    "best_name  = results[best_idx][\"Model\"]\n",
    "print(f\"\\nğŸ† æœ€ä¼˜æ¨¡å‹: {best_name}\")\n",
    "\n",
    "# ==========================================================\n",
    "# 7ï¸âƒ£ æœ€ç»ˆé¢„æµ‹ï¼ˆæµ‹è¯•é›†ï¼‰\n",
    "# ==========================================================\n",
    "\n",
    "X_test_sel = selector.transform(test_rent_clean)\n",
    "X_test_std = scaler.transform(X_test_sel)\n",
    "y_pred_test = best_model.predict(X_test_std)\n",
    "if USE_LOG_TARGET:\n",
    "    y_pred_test = np.expm1(y_pred_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": np.arange(len(y_pred_test)),\n",
    "    \"prediction\": y_pred_test\n",
    "})\n",
    "submission.to_csv(\"prediction_rent.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"ğŸ“ å·²ä¿å­˜é¢„æµ‹ç»“æœ prediction_rent.csv\")\n",
    "\n",
    "print(\"\\nâœ… å…¨æµç¨‹å®Œæˆï¼ˆç§Ÿé‡‘é¢„æµ‹ç¨³å®šç‰ˆï¼‰ï¼\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
