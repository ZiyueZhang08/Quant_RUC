{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e1da2b5-e559-454f-b53d-af5de7ee389c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸæå–å¹¶æ¸…ç† 90 æ‰€å¤§å­¦åç§°\n",
      "âœ… æ–‡ä»¶å·²ä¿å­˜ä¸º universiti.xlsx\n",
      "\n",
      "ğŸ“Œ æ¸…ç†åç»“æœç¤ºä¾‹ï¼ˆå‰5ä¸ªï¼‰ï¼š\n",
      "Top 30 Selected: ['Brown University', 'Stanford University', 'University College London (UCL)', 'Boston University', 'Paris School of Economics']\n",
      "Middle 30 Selected: ['Centro de Estudios Monetarios y Financieros (CEMFI)', 'Vrije Universiteit Amsterdam', 'University of California-Davis', 'Johns Hopkins University', 'Erasmus Universiteit Rotterdam']\n",
      "Bottom 30 Selected: ['New York University (NYU)', 'Universitat de Barcelona', 'Washington University in St. Louis', 'UNSW Sydney', 'University of California-Santa Barbara (UCSB)']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# --------------------------\n",
    "# 1. æ ¸å¿ƒå‡½æ•°ï¼šç”¨é€—å·åˆ†å‰²æå–æ ¸å¿ƒå¤§å­¦å\n",
    "# --------------------------\n",
    "def clean_by_comma(raw_name):\n",
    "    raw_name = raw_name.strip()\n",
    "    # åˆ†å‰²æ‰€æœ‰é€—å·ï¼Œå–æœ€åä¸€éƒ¨åˆ†ï¼ˆæ ¸å¿ƒå¤§å­¦åï¼‰\n",
    "    comma_parts = [part.strip() for part in raw_name.split(\",\") if part.strip()]\n",
    "    if len(comma_parts) >= 2:\n",
    "        # è‹¥æœ‰2ä¸ªåŠä»¥ä¸Šéƒ¨åˆ†ï¼Œå–æœ€åä¸€ä¸ªï¼ˆæ’é™¤å‰é¢çš„é™¢ç³»å†—ä½™ï¼‰\n",
    "        return comma_parts[-1]\n",
    "    else:\n",
    "        # è‹¥åªæœ‰1éƒ¨åˆ†ï¼ˆæ— é€—å·ï¼‰ï¼Œç›´æ¥è¿”å›åŸåç§°\n",
    "        return raw_name\n",
    "\n",
    "# --------------------------\n",
    "# 2. æŠ“å–ç½‘é¡µå¹¶æå–æ•°æ®\n",
    "# --------------------------\n",
    "url = \"https://ideas.repec.org/top/top.econdept.html\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\"\n",
    "}\n",
    "\n",
    "# è¯·æ±‚ç½‘é¡µ\n",
    "response = requests.get(url, headers=headers, timeout=10)\n",
    "response.raise_for_status()  # è¯·æ±‚å¤±è´¥ç›´æ¥æŠ¥é”™\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# å®šä½ä¸»æ’åè¡¨æ ¼ï¼ˆé€šè¿‡è¡¨å¤´å«\"rank\"ç¡®è®¤ï¼‰\n",
    "target_table = None\n",
    "for table in soup.find_all(\"table\"):\n",
    "    thead = table.find(\"thead\")\n",
    "    if thead and any(\"rank\" in th.get_text(strip=True).lower() for th in thead.find_all(\"th\")):\n",
    "        target_table = table\n",
    "        break\n",
    "if not target_table:\n",
    "    raise Exception(\"æœªæ‰¾åˆ°ä¸»æ’åè¡¨æ ¼ï¼Œå¯èƒ½ç½‘ç«™ç»“æ„å·²æ›´æ–°\")\n",
    "\n",
    "# æå–å‰90æ‰€å¤§å­¦ï¼ˆåªå–<a>æ ‡ç­¾çš„åŸå§‹åç§°ï¼Œåç»­ç”¨é€—å·æ¸…ç†ï¼‰\n",
    "universities = []\n",
    "rows = target_table.find_all(\"tr\")\n",
    "for row in rows:\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) >= 3 and cols[1].find(\"a\"):  # ç¡®ä¿æœ‰æ’åã€åç§°ã€å›½å®¶åˆ—\n",
    "        raw_name = cols[1].find(\"a\").get_text(strip=True)\n",
    "        clean_name = clean_by_comma(raw_name)  # ç”¨é€—å·æ¸…ç†åç§°\n",
    "        universities.append(clean_name)\n",
    "        if len(universities) >= 90:\n",
    "            break\n",
    "\n",
    "print(f\"âœ… æˆåŠŸæå–å¹¶æ¸…ç† {len(universities)} æ‰€å¤§å­¦åç§°\")\n",
    "\n",
    "# --------------------------\n",
    "# 3. æŒ‰è¦æ±‚æŠ½æ ·ï¼ˆå‰30æŠ½10ã€ä¸­30æŠ½10ã€å30æŠ½10ï¼‰\n",
    "# --------------------------\n",
    "def safe_sample(data, sample_size):\n",
    "    \"\"\"å®‰å…¨æŠ½æ ·ï¼šæ•°æ®è¶³å¤Ÿåˆ™æŠ½10ä¸ªï¼Œä¸è¶³åˆ™è¿”å›å…¨éƒ¨\"\"\"\n",
    "    if len(data) >= sample_size:\n",
    "        return random.sample(data, sample_size)\n",
    "    else:\n",
    "        print(f\"âš ï¸ æŸåŒºé—´ä»…{len(data)}æ‰€å¤§å­¦ï¼Œå·²è¿”å›å…¨éƒ¨\")\n",
    "        return data\n",
    "\n",
    "# åˆ†åŒºé—´\n",
    "top30 = universities[:30]\n",
    "middle30 = universities[30:60]\n",
    "bottom30 = universities[60:90]\n",
    "\n",
    "# æŠ½æ ·\n",
    "selected_top = safe_sample(top30, 10)\n",
    "selected_middle = safe_sample(middle30, 10)\n",
    "selected_bottom = safe_sample(bottom30, 10)\n",
    "\n",
    "# --------------------------\n",
    "# 4. ç”ŸæˆExcelæ–‡ä»¶ï¼ˆç¡®ä¿åˆ—é•¿åº¦ä¸€è‡´ï¼‰\n",
    "# --------------------------\n",
    "# å¡«å……ç©ºå€¼ï¼Œä¿è¯ä¸‰åˆ—é•¿åº¦ç›¸åŒ\n",
    "max_len = max(len(selected_top), len(selected_middle), len(selected_bottom))\n",
    "fill_empty = lambda lst: lst + [\"\"] * (max_len - len(lst))\n",
    "\n",
    "# æ•´ç†ç»“æœæ•°æ®\n",
    "result_data = {\n",
    "    \"Top 30 Selected\": fill_empty(selected_top),\n",
    "    \"Middle 30 Selected\": fill_empty(selected_middle),\n",
    "    \"Bottom 30 Selected\": fill_empty(selected_bottom)\n",
    "}\n",
    "\n",
    "# ä¿å­˜ä¸ºExcel\n",
    "df = pd.DataFrame(result_data)\n",
    "df.to_excel(\"universiti.xlsx\", index=False)\n",
    "print(\"âœ… æ–‡ä»¶å·²ä¿å­˜ä¸º universiti.xlsx\")\n",
    "\n",
    "# æ‰“å°éƒ¨åˆ†ç»“æœç¤ºä¾‹\n",
    "print(\"\\nğŸ“Œ æ¸…ç†åç»“æœç¤ºä¾‹ï¼ˆå‰5ä¸ªï¼‰ï¼š\")\n",
    "print(\"Top 30 Selected:\", selected_top[:5])\n",
    "print(\"Middle 30 Selected:\", selected_middle[:5])\n",
    "print(\"Bottom 30 Selected:\", selected_bottom[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff7546f8-041e-4776-92f0-f530bb868042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é‡å»ºarea_journal_dfæˆåŠŸï¼Œæ•°æ®é¢„è§ˆï¼š\n",
      "      Area                                Journal\n",
      "0  ACCOUNT                      Accounting Review\n",
      "1  ACCOUNT  Accounting, Organizations and Society\n",
      "2  ACCOUNT    Journal of Accounting and Economics\n",
      "3  ACCOUNT         Journal of Accounting Research\n",
      "4     ECON               American Economic Review\n",
      "5     ECON                   Annals of Statistics\n",
      "6     ECON                           Econometrica\n",
      "7     ECON           Journal of Political Economy\n",
      "8     ECON         Quarterly Journal of Economics\n",
      "9     ECON             Review of Economic Studies\n",
      "\n",
      "âœ… ç­›é€‰åçš„æ•°æ®ï¼ˆç›®æ ‡é¢†åŸŸ+å‰3æœ¬æœŸåˆŠï¼‰ï¼š\n",
      "  ä¸­æ–‡ç ”ç©¶é¢†åŸŸ    è‹±æ–‡é¢†åŸŸç¼©å†™                                         ABS 4*é¡¶çº§æœŸåˆŠ\n",
      "0    ç»æµå­¦      ECON                           American Economic Review\n",
      "1    ç»æµå­¦      ECON                               Annals of Statistics\n",
      "2    ç»æµå­¦      ECON                                       Econometrica\n",
      "3    é‡‘èå­¦   FINANCE                                 Journal of Finance\n",
      "4    é‡‘èå­¦   FINANCE                     Journal of Financial Economics\n",
      "5    é‡‘èå­¦   FINANCE                        Review of Financial Studies\n",
      "6  ä¿¡æ¯ç®¡ç†å­¦  INFO MAN      MIS Quarterly: Management Information Systems\n",
      "7  ä¿¡æ¯ç®¡ç†å­¦  INFO MAN  Journal of the Association for Information Sys...\n",
      "8  ä¿¡æ¯ç®¡ç†å­¦  INFO MAN                       Information Systems Research\n",
      "\n",
      "âœ… Excelæ–‡ä»¶å·²ç”Ÿæˆï¼šresearch_fields_top_journals_final.xlsx\n",
      "\n",
      "ğŸ“Š Excelæ–‡ä»¶ç»“æ„è¯´æ˜ï¼š\n",
      "- ä¸­æ–‡ç ”ç©¶é¢†åŸŸï¼šç»æµå­¦ã€é‡‘èå­¦ã€ä¿¡æ¯ç®¡ç†å­¦ï¼ˆç”¨æˆ·å…³æ³¨çš„é¢†åŸŸï¼‰\n",
      "- è‹±æ–‡é¢†åŸŸç¼©å†™ï¼šå¯¹åº”ç½‘ç«™çš„é¢†åŸŸæ ‡è¯†ï¼ˆECON/FINANCE/INFO MANï¼‰\n",
      "- ABS 4*é¡¶çº§æœŸåˆŠï¼šæ¯ä¸ªé¢†åŸŸçš„å‰3æœ¬è¶…å››æ˜Ÿçº§æœŸåˆŠ\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.scmor.com/view/10554\"\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "# è§‚å¯Ÿhtmlåå‘ç°ä¸ºåµŒå¥—æ ‡é¢˜ï¼Œå› æ­¤ç›´æ¥æœç´¢h3ä¸‹çš„å…¨æ–‡\n",
    "title = soup.find(lambda t: t.name == \"h3\" and \"ABS4*\" in t.get_text(strip = True))\n",
    "area_table = title.find_next(\"table\")\n",
    "rows = []\n",
    "for tr in area_table.select(\"tr\"):\n",
    "    tds = tr.select(\"td\")\n",
    "    if len(tds) >= 3:\n",
    "        area_text = tds[1].getText(strip = True)\n",
    "        journal_text = tds[2].getText(strip = True)\n",
    "        rows.append({\"Area\": area_text, \"Journal\": journal_text})\n",
    "\n",
    "# æ•´åˆæˆdataframe\n",
    "area_journal_df = pd.DataFrame(rows).sort_values(\"Area\")\n",
    "area_journal_df\n",
    "# ç¡®ä¿å·²å¯¼å…¥ä¾èµ–åº“ï¼ˆè‹¥æœªå®‰è£…ï¼Œå…ˆæ‰§è¡Œï¼špip install pandas openpyxlï¼‰\n",
    "import pandas as pd\n",
    "\n",
    "# --------------------------\n",
    "# 1. åŸºäºä½ æä¾›çš„è¿è¡Œç»“æœï¼Œé‡å»ºarea_journal_dfï¼ˆè‹¥å·²åœ¨ç¯å¢ƒä¸­å­˜åœ¨ï¼Œå¯è·³è¿‡æ­¤æ­¥ï¼‰\n",
    "# --------------------------\n",
    "# ä»ä½ çš„è¿è¡Œç»“æœä¸­æå–æ ¸å¿ƒæ•°æ®ï¼ˆArea=è‹±æ–‡é¢†åŸŸç¼©å†™ï¼ŒJournal=æœŸåˆŠåï¼‰\n",
    "data = [\n",
    "    {\"Area\": \"ACCOUNT\", \"Journal\": \"Accounting Review\"},\n",
    "    {\"Area\": \"ACCOUNT\", \"Journal\": \"Accounting, Organizations and Society\"},\n",
    "    {\"Area\": \"ACCOUNT\", \"Journal\": \"Journal of Accounting and Economics\"},\n",
    "    {\"Area\": \"ACCOUNT\", \"Journal\": \"Journal of Accounting Research\"},\n",
    "    {\"Area\": \"ECON\", \"Journal\": \"American Economic Review\"},\n",
    "    {\"Area\": \"ECON\", \"Journal\": \"Annals of Statistics\"},\n",
    "    {\"Area\": \"ECON\", \"Journal\": \"Econometrica\"},\n",
    "    {\"Area\": \"ECON\", \"Journal\": \"Journal of Political Economy\"},\n",
    "    {\"Area\": \"ECON\", \"Journal\": \"Quarterly Journal of Economics\"},\n",
    "    {\"Area\": \"ECON\", \"Journal\": \"Review of Economic Studies\"},\n",
    "    {\"Area\": \"ENT-SBM\", \"Journal\": \"Entrepreneurship Theory and Practice\"},\n",
    "    {\"Area\": \"ENT-SBM\", \"Journal\": \"Journal of Business Venturing\"},\n",
    "    {\"Area\": \"ETHICS-CSR-MAN\", \"Journal\": \"Academy of Management Annals\"},\n",
    "    {\"Area\": \"ETHICS-CSR-MAN\", \"Journal\": \"Academy of Management Journal\"},\n",
    "    {\"Area\": \"ETHICS-CSR-MAN\", \"Journal\": \"Academy of Management Review\"},\n",
    "    {\"Area\": \"ETHICS-CSR-MAN\", \"Journal\": \"Administrative Science Quarterly\"},\n",
    "    {\"Area\": \"ETHICS-CSR-MAN\", \"Journal\": \"Journal of Management\"},\n",
    "    {\"Area\": \"FINANCE\", \"Journal\": \"Journal of Finance\"},\n",
    "    {\"Area\": \"FINANCE\", \"Journal\": \"Journal of Financial Economics\"},\n",
    "    {\"Area\": \"FINANCE\", \"Journal\": \"Review of Financial Studies\"},\n",
    "    {\"Area\": \"HRM&EMP\", \"Journal\": \"Human Resource Management Journal (UK)\"},\n",
    "    {\"Area\": \"IB&AREA\", \"Journal\": \"Journal of International Business Studies\"},\n",
    "    {\"Area\": \"INFO MAN\", \"Journal\": \"Information Systems Research\"},\n",
    "    {\"Area\": \"INFO MAN\", \"Journal\": \"Journal of the Association for Information Systems\"},\n",
    "    {\"Area\": \"INFO MAN\", \"Journal\": \"MIS Quarterly: Management Information Systems\"},\n",
    "    {\"Area\": \"INNOV\", \"Journal\": \"Research Policy\"},\n",
    "    {\"Area\": \"MDEV&EDU\", \"Journal\": \"Academy of Management Learning and Education\"},\n",
    "    {\"Area\": \"MKT\", \"Journal\": \"Journal of Consumer Psychology\"},\n",
    "    {\"Area\": \"MKT\", \"Journal\": \"Journal of Consumer Research\"},\n",
    "    {\"Area\": \"MKT\", \"Journal\": \"Journal of Marketing\"},\n",
    "    {\"Area\": \"MKT\", \"Journal\": \"Journal of Marketing Research\"},\n",
    "    {\"Area\": \"MKT\", \"Journal\": \"Journal of the Academy of Marketing Science\"},\n",
    "    {\"Area\": \"MKT\", \"Journal\": \"Marketing Science\"},\n",
    "    {\"Area\": \"OPS&TECH\", \"Journal\": \"Journal of Operations Management\"},\n",
    "    {\"Area\": \"OR&MANSCI\", \"Journal\": \"Management Science\"},\n",
    "    {\"Area\": \"OR&MANSCI\", \"Journal\": \"Operations Research\"},\n",
    "    {\"Area\": \"ORG STUD\", \"Journal\": \"Organization Science\"},\n",
    "    {\"Area\": \"PSYCH (GENERAL)\", \"Journal\": \"Psychological Science\"},\n",
    "    {\"Area\": \"PSYCH (WOP-OB)\", \"Journal\": \"Journal of Applied Psychology\"},\n",
    "    {\"Area\": \"PSYCH (WOP-OB)\", \"Journal\": \"Personnel Psychology\"},\n",
    "    {\"Area\": \"PUB SEC\", \"Journal\": \"Public Administration Review\"},\n",
    "    {\"Area\": \"SOC SCI\", \"Journal\": \"American Journal of Political Science\"},\n",
    "    {\"Area\": \"SOC SCI\", \"Journal\": \"American Journal of Sociology\"},\n",
    "    {\"Area\": \"SOC SCI\", \"Journal\": \"American Political Science Review\"},\n",
    "    {\"Area\": \"SOC SCI\", \"Journal\": \"American Sociological Review\"},\n",
    "    {\"Area\": \"SOC SCI\", \"Journal\": \"Annual Review of Sociology\"},\n",
    "    {\"Area\": \"STRAT\", \"Journal\": \"Strategic Management Journal\"}\n",
    "]\n",
    "area_journal_df = pd.DataFrame(data).sort_values(\"Area\").reset_index(drop=True)\n",
    "print(\"âœ… é‡å»ºarea_journal_dfæˆåŠŸï¼Œæ•°æ®é¢„è§ˆï¼š\")\n",
    "print(area_journal_df.head(10))\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 2. å®šä¹‰ç›®æ ‡ç ”ç©¶é¢†åŸŸï¼ˆä¸­è‹±æ–‡æ˜ å°„ï¼ŒåŒ¹é…ç½‘ç«™è‹±æ–‡ç¼©å†™ï¼‰\n",
    "# --------------------------\n",
    "# ç›®æ ‡é¢†åŸŸï¼šç»æµå­¦ã€é‡‘èå­¦ã€ä¿¡æ¯ç®¡ç†å­¦ï¼ˆå¯¹åº”ç½‘ç«™è‹±æ–‡ç¼©å†™ï¼‰\n",
    "target_fields = {\n",
    "    \"ç»æµå­¦\": \"ECON\",\n",
    "    \"é‡‘èå­¦\": \"FINANCE\",\n",
    "    \"ä¿¡æ¯ç®¡ç†å­¦\": \"INFO MAN\"\n",
    "}\n",
    "\n",
    "# ç­›é€‰ç›®æ ‡é¢†åŸŸçš„æ•°æ®ï¼Œæ¯ä¸ªé¢†åŸŸä¿ç•™å‰3æœ¬ABS 4*æœŸåˆŠ\n",
    "final_data = []\n",
    "for chinese_field, english_area in target_fields.items():\n",
    "    # ç­›é€‰å½“å‰é¢†åŸŸçš„æ‰€æœ‰æœŸåˆŠ\n",
    "    field_journals = area_journal_df[area_journal_df[\"Area\"] == english_area][\"Journal\"].tolist()\n",
    "    # ä¿ç•™å‰3æœ¬ï¼ˆç¡®ä¿æ¯ä¸ªé¢†åŸŸæœ€å¤š3æœ¬é¡¶çº§æœŸåˆŠï¼‰\n",
    "    top3_journals = field_journals[:3]\n",
    "    \n",
    "    # æ•´ç†æˆæœ€ç»ˆæ ¼å¼ï¼ˆæ·»åŠ ä¸­è‹±æ–‡é¢†åŸŸåˆ—ï¼Œæå‡å¯è¯»æ€§ï¼‰\n",
    "    for journal in top3_journals:\n",
    "        final_data.append({\n",
    "            \"ä¸­æ–‡ç ”ç©¶é¢†åŸŸ\": chinese_field,\n",
    "            \"è‹±æ–‡é¢†åŸŸç¼©å†™\": english_area,\n",
    "            \"ABS 4*é¡¶çº§æœŸåˆŠ\": journal\n",
    "        })\n",
    "\n",
    "# è½¬æ¢ä¸ºDataFrame\n",
    "final_df = pd.DataFrame(final_data)\n",
    "print(\"\\nâœ… ç­›é€‰åçš„æ•°æ®ï¼ˆç›®æ ‡é¢†åŸŸ+å‰3æœ¬æœŸåˆŠï¼‰ï¼š\")\n",
    "print(final_df)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 3. ç”ŸæˆExcelæ–‡ä»¶\n",
    "# --------------------------\n",
    "excel_path = \"research_fields_top_journals_final.xlsx\"\n",
    "# ä¿å­˜Excelï¼ˆä¸ä¿ç•™ç´¢å¼•ï¼Œä½¿ç”¨openpyxlå¼•æ“æ”¯æŒxlsxæ ¼å¼ï¼‰\n",
    "final_df.to_excel(excel_path, index=False, engine=\"openpyxl\")\n",
    "\n",
    "print(f\"\\nâœ… Excelæ–‡ä»¶å·²ç”Ÿæˆï¼š{excel_path}\")\n",
    "print(\"\\nğŸ“Š Excelæ–‡ä»¶ç»“æ„è¯´æ˜ï¼š\")\n",
    "print(\"- ä¸­æ–‡ç ”ç©¶é¢†åŸŸï¼šç»æµå­¦ã€é‡‘èå­¦ã€ä¿¡æ¯ç®¡ç†å­¦ï¼ˆç”¨æˆ·å…³æ³¨çš„é¢†åŸŸï¼‰\")\n",
    "print(\"- è‹±æ–‡é¢†åŸŸç¼©å†™ï¼šå¯¹åº”ç½‘ç«™çš„é¢†åŸŸæ ‡è¯†ï¼ˆECON/FINANCE/INFO MANï¼‰\")\n",
    "print(\"- ABS 4*é¡¶çº§æœŸåˆŠï¼šæ¯ä¸ªé¢†åŸŸçš„å‰3æœ¬è¶…å››æ˜Ÿçº§æœŸåˆŠ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "442b65ef-ee2d-4ea7-8943-f1af11d412a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æŠ€èƒ½æ·»åŠ å®Œæˆï¼æ–‡ä»¶ä¿å­˜è‡³ï¼šresearch_fields_journals_skills_final.xlsx\n",
      "\n",
      "ğŸ“Š æ•°æ®é¢„è§ˆï¼ˆå‰6è¡Œï¼Œå…³é”®åˆ—ï¼‰ï¼š\n",
      "ä¸­æ–‡ç ”ç©¶é¢†åŸŸ                     ABS 4*é¡¶çº§æœŸåˆŠ           å²—ä½æ ¸å¿ƒæŠ€èƒ½ï¼ˆæ‰‹åŠ¨æ·»åŠ ï¼‰\n",
      "   ç»æµå­¦       American Economic Review   R, SQL, Python, Math\n",
      "   ç»æµå­¦           Annals of Statistics   R, SQL, Python, Math\n",
      "   ç»æµå­¦                   Econometrica   R, SQL, Python, Math\n",
      "   é‡‘èå­¦             Journal of Finance SQL, Python, Math, C++\n",
      "   é‡‘èå­¦ Journal of Financial Economics SQL, Python, Math, C++\n",
      "   é‡‘èå­¦    Review of Financial Studies SQL, Python, Math, C++\n"
     ]
    }
   ],
   "source": [
    "# ç¡®ä¿å®‰è£…ä¾èµ–ï¼ˆè‹¥æœªå®‰è£…ï¼špip install pandas openpyxlï¼‰\n",
    "import pandas as pd\n",
    "\n",
    "# --------------------------\n",
    "# 1. é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆéœ€æ ¹æ®ä½ çš„å®é™…æ–‡ä»¶ä¿®æ”¹ï¼‰\n",
    "# --------------------------\n",
    "# æ­¥éª¤4ç”Ÿæˆçš„Excelè·¯å¾„ï¼ˆæ›¿æ¢ä¸ºä½ çš„æ–‡ä»¶è·¯å¾„ï¼Œä¾‹ï¼š\"D:/step4_excel.xlsx\"ï¼‰\n",
    "step4_excel_path = \"research_fields_top_journals_final.xlsx\"\n",
    "# æ­¥éª¤6æœ€ç»ˆè¾“å‡ºè·¯å¾„ï¼ˆæ–°å¢æŠ€èƒ½åˆ—åçš„æ–‡ä»¶ï¼‰\n",
    "output_excel_path = \"research_fields_journals_skills_final.xlsx\"\n",
    "\n",
    "# --------------------------\n",
    "# 2. æ‰‹åŠ¨å®šä¹‰â€œé¢†åŸŸ-æŠ€èƒ½â€æ˜ å°„ï¼ˆåŸºäºä½ çš„æŒ‡å®šæŠ€èƒ½ï¼ŒæŒ‰é¢†åŸŸåŒ¹é…ï¼‰\n",
    "# --------------------------\n",
    "# ä½ æŒ‡å®šçš„æŠ€èƒ½ï¼šPythonã€C++ã€SQLã€Rã€PyTorchã€Math\n",
    "field_skills_map = {\n",
    "    \"ç»æµå­¦\": \"R, SQL, Python, Math\",          # ç»æµå­¦ï¼šç»Ÿè®¡å·¥å…·+æ•°æ®å¤„ç†+æ•°å­¦åŸºç¡€\n",
    "    \"é‡‘èå­¦\": \"SQL, Python, Math, C++\",        # é‡‘èå­¦ï¼šæ•°æ®æŸ¥è¯¢+é‡åŒ–åˆ†æ+åº•å±‚å¼€å‘\n",
    "    \"ä¿¡æ¯ç®¡ç†å­¦\": \"Python, SQL, PyTorch, R\"    # ä¿¡æ¯ç®¡ç†å­¦ï¼šç¼–ç¨‹+æœºå™¨å­¦ä¹ +æ•°æ®åº“\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "# 3. è¯»å–Excel + æ·»åŠ æŠ€èƒ½åˆ—ï¼ˆä¿®å¤è­¦å‘Šï¼‰\n",
    "# --------------------------\n",
    "try:\n",
    "    # 1. è¯»å–æ­¥éª¤4çš„Excelæ–‡ä»¶\n",
    "    df = pd.read_excel(step4_excel_path, engine=\"openpyxl\")\n",
    "    \n",
    "    # 2. æ£€æŸ¥å…³é”®åˆ—æ˜¯å¦å­˜åœ¨ï¼ˆé¿å…æ–‡ä»¶ç»“æ„é”™è¯¯ï¼‰\n",
    "    required_col = \"ä¸­æ–‡ç ”ç©¶é¢†åŸŸ\"\n",
    "    if required_col not in df.columns:\n",
    "        raise Exception(f\"æ­¥éª¤4çš„Excelç¼ºå°‘å¿…è¦åˆ—ï¼š{required_col}ï¼Œè¯·ç¡®è®¤æ–‡ä»¶åŒ…å«è¯¥åˆ—\")\n",
    "    \n",
    "    # 3. æ–°å¢æŠ€èƒ½åˆ—ï¼ˆä¿®å¤è­¦å‘Šï¼šç›´æ¥èµ‹å€¼ï¼Œä¸ä½¿ç”¨inplace=Trueï¼‰\n",
    "    # åŸé—®é¢˜ä»£ç ï¼šdf[\"å²—ä½æ ¸å¿ƒæŠ€èƒ½ï¼ˆæ‰‹åŠ¨æ·»åŠ ï¼‰\"].fillna(..., inplace=True)\n",
    "    # ä¿®å¤åï¼šå…ˆèµ‹å€¼æ˜ å°„æŠ€èƒ½ï¼Œå†ç”¨fillnaç”Ÿæˆæ–°Serieså¹¶é‡æ–°èµ‹å€¼\n",
    "    df[\"å²—ä½æ ¸å¿ƒæŠ€èƒ½ï¼ˆæ‰‹åŠ¨æ·»åŠ ï¼‰\"] = df[required_col].map(field_skills_map)\n",
    "    # å¡«å……ç¼ºå¤±å€¼ï¼ˆæ— åŒ¹é…é¢†åŸŸæ—¶ç”¨é»˜è®¤æŠ€èƒ½ï¼‰\n",
    "    df[\"å²—ä½æ ¸å¿ƒæŠ€èƒ½ï¼ˆæ‰‹åŠ¨æ·»åŠ ï¼‰\"] = df[\"å²—ä½æ ¸å¿ƒæŠ€èƒ½ï¼ˆæ‰‹åŠ¨æ·»åŠ ï¼‰\"].fillna(\"Python, SQL, Math\")\n",
    "    \n",
    "    # 4. ä¿å­˜æœ€ç»ˆæ–‡ä»¶\n",
    "    df.to_excel(output_excel_path, index=False, engine=\"openpyxl\")\n",
    "    \n",
    "    # æ‰“å°ç»“æœé¢„è§ˆ\n",
    "    print(f\"âœ… æŠ€èƒ½æ·»åŠ å®Œæˆï¼æ–‡ä»¶ä¿å­˜è‡³ï¼š{output_excel_path}\")\n",
    "    print(\"\\nğŸ“Š æ•°æ®é¢„è§ˆï¼ˆå‰6è¡Œï¼Œå…³é”®åˆ—ï¼‰ï¼š\")\n",
    "    preview_cols = [required_col, \"ABS 4*é¡¶çº§æœŸåˆŠ\", \"å²—ä½æ ¸å¿ƒæŠ€èƒ½ï¼ˆæ‰‹åŠ¨æ·»åŠ ï¼‰\"]\n",
    "    print(df[preview_cols].head(6).to_string(index=False))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ æœªæ‰¾åˆ°æ­¥éª¤4çš„Excelæ–‡ä»¶ï¼å½“å‰è·¯å¾„ï¼š{step4_excel_path}\")\n",
    "    print(\"ğŸ’¡ æç¤ºï¼šè¯·ä¿®æ”¹ä»£ç ä¸­`step4_excel_path`ä¸ºä½ çš„å®é™…æ–‡ä»¶è·¯å¾„ï¼ˆä¾‹ï¼š'D:/æˆ‘çš„æ–‡ä»¶/step4.xlsx'ï¼‰\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ‰§è¡Œå¤±è´¥ï¼š{str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91947512-99e2-4ab5-ba50-656bb142fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. å¯¼å…¥ä¾èµ–åº“\n",
    "import os\n",
    "import pandas as pd\n",
    "from docxtpl import DocxTemplate\n",
    "from docx2pdf import convert\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "# 2. é…ç½®å…³é”®å‚æ•°ï¼ˆâš ï¸ éœ€æ ¹æ®ä½ çš„æœ¬åœ°è·¯å¾„ä¿®æ”¹ï¼ï¼‰\n",
    "CONFIG = {\n",
    "    # æ–‡ä»¶è·¯å¾„\n",
    "    \"uni_excel_path\": \"universiti.xlsx\",  # 30æ‰€å¤§å­¦Excel\n",
    "    \"research_excel_path\": \"research_fields_journals_skills_final.xlsx\",  # é¢†åŸŸ-é¡¶åˆŠ-æŠ€èƒ½Excel\n",
    "    \"template_path\": \"application_template.docx\",  # ç”³è¯·ä¿¡æ¨¡æ¿\n",
    "    # ç›®æ ‡ç ”ç©¶é¢†åŸŸï¼ˆâš ï¸ é€‰æ‹©ä½ ç”³è¯·çš„é¢†åŸŸï¼Œå¦‚\"ç»æµå­¦\"/\"é‡‘èå­¦\"/\"ä¿¡æ¯ç®¡ç†å­¦\"ï¼‰\n",
    "    \"target_research_field\": \"ç»æµå­¦\",\n",
    "    # ç ”ç©¶ä¸»é¢˜ç¤ºä¾‹ï¼ˆâš ï¸ æŒ‰é¢†åŸŸè‡ªå®šä¹‰ï¼Œå¢å¼ºç”³è¯·ä¿¡çœŸå®æ€§ï¼‰\n",
    "    \"research_topic_map\": {\n",
    "        \"ç»æµå­¦\": \"æ”¶å…¥ä¸å¹³ç­‰å¯¹é•¿æœŸç»æµå¢é•¿çš„ä¼ å¯¼æœºåˆ¶\",\n",
    "        \"é‡‘èå­¦\": \"é«˜é¢‘é‡‘èæ•°æ®ä¸‹çš„é£é™©å¯¹å†²ç­–ç•¥ä¼˜åŒ–\",\n",
    "        \"ä¿¡æ¯ç®¡ç†å­¦\": \"æœºå™¨å­¦ä¹ åœ¨ä¼ä¸šä¿¡æ¯ç³»ç»Ÿæ•ˆç‡æå‡ä¸­çš„åº”ç”¨\"\n",
    "    },\n",
    "    # è¾“å‡ºç›®å½•ï¼ˆç”¨æˆ·ä¸»ç›®å½•ä¸‹çš„HW_School_Applicationï¼‰\n",
    "    \"output_dir\": os.path.join(os.path.expanduser(\"~\"), \"HW_School_Application\")\n",
    "}\n",
    "\n",
    "# 3. å·¥å…·å‡½æ•°ï¼šè¯»å–Excelæ•°æ®\n",
    "def load_excel_data():\n",
    "    \"\"\"è¯»å–å¤§å­¦åˆ—è¡¨å’Œç ”ç©¶é¢†åŸŸ-é¡¶åˆŠ-æŠ€èƒ½æ•°æ®\"\"\"\n",
    "    # 3.1 è¯»å–å¤§å­¦åˆ—è¡¨ï¼ˆéœ€åˆ—ååŒ¹é…\"Selected_Universities\"ï¼‰\n",
    "    try:\n",
    "        uni_df = pd.read_excel(CONFIG[\"uni_excel_path\"], engine=\"openpyxl\")\n",
    "        if \"Selected_Universities\" not in uni_df.columns:\n",
    "            raise Exception(f\"å¤§å­¦Excelç¼ºå°‘å¿…å¡«åˆ—ï¼šSelected_Universitiesï¼Œè¯·æ£€æŸ¥åˆ—å\")\n",
    "        universities = uni_df[\"Selected_Universities\"].dropna().tolist()\n",
    "        if len(universities) != 30:\n",
    "            print(f\"âš ï¸  å¤§å­¦æ•°é‡ä¸º{len(universities)}ï¼ˆå»ºè®®30æ‰€ï¼‰ï¼Œå°†ç»§ç»­ç”Ÿæˆ\")\n",
    "        print(f\"âœ… æˆåŠŸè¯»å–{len(universities)}æ‰€å¤§å­¦\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"å¤§å­¦Excelæ–‡ä»¶æœªæ‰¾åˆ°ï¼š{CONFIG['uni_excel_path']}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"è¯»å–å¤§å­¦Excelå¤±è´¥ï¼š{str(e)}\")\n",
    "    \n",
    "    # 3.2 è¯»å–ç ”ç©¶é¢†åŸŸæ•°æ®ï¼ˆç­›é€‰ç›®æ ‡é¢†åŸŸï¼Œå¦‚\"ç»æµå­¦\"ï¼‰\n",
    "    try:\n",
    "        research_df = pd.read_excel(CONFIG[\"research_excel_path\"], engine=\"openpyxl\")\n",
    "        required_cols = [\"ä¸­æ–‡ç ”ç©¶é¢†åŸŸ\", \"ABS 4*é¡¶çº§æœŸåˆŠ\", \"å²—ä½æ ¸å¿ƒæŠ€èƒ½ï¼ˆæ‰‹åŠ¨æ·»åŠ ï¼‰\"]\n",
    "        for col in required_cols:\n",
    "            if col not in research_df.columns:\n",
    "                raise Exception(f\"é¢†åŸŸExcelç¼ºå°‘å¿…å¡«åˆ—ï¼š{col}ï¼Œè¯·æ£€æŸ¥åˆ—å\")\n",
    "        \n",
    "        # ç­›é€‰ç›®æ ‡é¢†åŸŸçš„è¡Œï¼ˆå–ç¬¬ä¸€è¡Œå³å¯ï¼ŒåŒä¸€é¢†åŸŸé¡¶åˆŠ/æŠ€èƒ½ä¸€è‡´ï¼‰\n",
    "        target_field_data = research_df[research_df[\"ä¸­æ–‡ç ”ç©¶é¢†åŸŸ\"] == CONFIG[\"target_research_field\"]]\n",
    "        if target_field_data.empty:\n",
    "            raise Exception(f\"é¢†åŸŸExcelä¸­æœªæ‰¾åˆ°'{CONFIG['target_research_field']}'ï¼Œè¯·æ£€æŸ¥é¢†åŸŸåç§°\")\n",
    "        \n",
    "        # æå–é¡¶åˆŠï¼ˆå»é‡+ç”¨é€—å·è¿æ¥ï¼‰å’ŒæŠ€èƒ½\n",
    "        top_journals = \", \".join(target_field_data[\"ABS 4*é¡¶çº§æœŸåˆŠ\"].dropna().unique())\n",
    "        skills = \", \".join(target_field_data[\"å²—ä½æ ¸å¿ƒæŠ€èƒ½ï¼ˆæ‰‹åŠ¨æ·»åŠ ï¼‰\"].dropna().unique())\n",
    "        research_info = {\n",
    "            \"research_field\": CONFIG[\"target_research_field\"],\n",
    "            \"top_journals\": top_journals,\n",
    "            \"skills\": skills,\n",
    "            \"research_topic_example\": CONFIG[\"research_topic_map\"][CONFIG[\"target_research_field\"]]\n",
    "        }\n",
    "        print(f\"âœ… æˆåŠŸè¯»å–{CONFIG['target_research_field']}é¢†åŸŸæ•°æ®ï¼š{top_journals[:50]}...\")\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"é¢†åŸŸExcelæ–‡ä»¶æœªæ‰¾åˆ°ï¼š{CONFIG['research_excel_path']}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"è¯»å–é¢†åŸŸExcelå¤±è´¥ï¼š{str(e)}\")\n",
    "    \n",
    "    return universities, research_info\n",
    "\n",
    "# 4. æ­¥éª¤7-8ï¼šå¾ªç¯å¡«å……æ¨¡æ¿+ç”ŸæˆWordæ–‡æ¡£ï¼ˆdocxtplï¼‰\n",
    "def generate_word_documents(universities, research_info):\n",
    "    \"\"\"å¾ªç¯å¤§å­¦åˆ—è¡¨ï¼Œç”¨docxtplç”Ÿæˆä¸ªæ€§åŒ–Word\"\"\"\n",
    "    # åŠ è½½Wordæ¨¡æ¿\n",
    "    try:\n",
    "        tpl = DocxTemplate(CONFIG[\"template_path\"])\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"æ¨¡æ¿æ–‡ä»¶æœªæ‰¾åˆ°ï¼š{CONFIG['template_path']}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"åŠ è½½æ¨¡æ¿å¤±è´¥ï¼š{str(e)}ï¼ˆç¡®ä¿æ¨¡æ¿ä¸º.docxæ ¼å¼ï¼‰\")\n",
    "    \n",
    "    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤¹å­˜æ”¾æ‰€æœ‰ç”Ÿæˆçš„Wordï¼ˆé¿å…æ··ä¹±ï¼‰\n",
    "    temp_word_dir = os.path.join(CONFIG[\"output_dir\"], \"temp_word_files\")\n",
    "    os.makedirs(temp_word_dir, exist_ok=True)\n",
    "    \n",
    "    generated_word_paths = []\n",
    "    print(f\"\\nğŸ“ å¼€å§‹ç”ŸæˆWordæ–‡æ¡£ï¼ˆå…±{len(universities)}æ‰€å¤§å­¦ï¼‰ï¼š\")\n",
    "    for idx, school in enumerate(universities, 1):\n",
    "        # æ„å»ºå¡«å……ä¸Šä¸‹æ–‡ï¼ˆåŒ¹é…æ¨¡æ¿å ä½ç¬¦ï¼‰\n",
    "        context = {\n",
    "            \"school\": school,  # ç”³è¯·å­¦æ ¡ï¼ˆæ¥è‡ªå¤§å­¦åˆ—è¡¨ï¼‰\n",
    "            \"research_field\": research_info[\"research_field\"],  # ç ”ç©¶é¢†åŸŸ\n",
    "            \"top_journals\": research_info[\"top_journals\"],  # é¡¶çº§æœŸåˆŠ\n",
    "            \"research_topic_example\": research_info[\"research_topic_example\"],  # ç ”ç©¶ä¸»é¢˜ç¤ºä¾‹\n",
    "            \"skills\": research_info[\"skills\"]  # æŠ€èƒ½åˆ—è¡¨ï¼ˆæ¥è‡ªé¢†åŸŸExcelï¼‰\n",
    "        }\n",
    "        \n",
    "        # å¡«å……æ¨¡æ¿\n",
    "        tpl.render(context)\n",
    "        \n",
    "        # å¤„ç†æ–‡ä»¶åç‰¹æ®Šå­—ç¬¦ï¼ˆé¿å…ä¿å­˜å¤±è´¥ï¼‰\n",
    "        safe_school_name = school.replace(\"/\", \"_\").replace(\":\", \"_\").replace(\"*\", \"\")\n",
    "        word_filename = f\"Application_{safe_school_name}.docx\"\n",
    "        word_path = os.path.join(temp_word_dir, word_filename)\n",
    "        \n",
    "        # ä¿å­˜Word\n",
    "        tpl.save(word_path)\n",
    "        generated_word_paths.append(word_path)\n",
    "        print(f\"  {idx:2d}/30 ç”Ÿæˆï¼š{word_filename}\")\n",
    "    \n",
    "    print(f\"\\nâœ… Wordç”Ÿæˆå®Œæˆï¼Œå…±{len(generated_word_paths)}ä¸ªæ–‡ä»¶ï¼Œå­˜æ”¾äºï¼š{temp_word_dir}\")\n",
    "    return generated_word_paths, temp_word_dir\n",
    "\n",
    "# 5. æ­¥éª¤9ï¼šè½¬æ¢PDFï¼ˆdocx2pdfï¼Œä»…é™Windowsï¼‰\n",
    "def convert_word_to_pdf(generated_word_paths, temp_word_dir):\n",
    "    \"\"\"å°†Wordè½¬æ¢ä¸ºPDFï¼ˆä¾èµ–Microsoft Wordï¼‰\"\"\"\n",
    "    if not generated_word_paths:\n",
    "        print(\"âŒ æ— Wordæ–‡ä»¶å¯è½¬æ¢ï¼Œè·³è¿‡PDFç”Ÿæˆ\")\n",
    "        return None\n",
    "    \n",
    "    # åˆ›å»ºä¸´æ—¶PDFæ–‡ä»¶å¤¹\n",
    "    temp_pdf_dir = os.path.join(CONFIG[\"output_dir\"], \"temp_pdf_files\")\n",
    "    os.makedirs(temp_pdf_dir, exist_ok=True)\n",
    "    \n",
    "    generated_pdf_paths = []\n",
    "    print(f\"\\nğŸ“„ å¼€å§‹è½¬æ¢PDFï¼ˆéœ€å®‰è£…Microsoft Wordï¼Œè¯·å‹¿å…³é—­Wordè¿›ç¨‹ï¼‰ï¼š\")\n",
    "    for word_path in generated_word_paths[:5]:  # ä»…è½¬æ¢å‰5ä¸ªï¼ˆé¿å…è€—æ—¶ï¼Œå¯æ”¹ä¸ºå…¨éƒ¨ï¼‰\n",
    "        # å®šä¹‰PDFè·¯å¾„\n",
    "        word_filename = os.path.basename(word_path)\n",
    "        pdf_filename = os.path.splitext(word_filename)[0] + \".pdf\"\n",
    "        pdf_path = os.path.join(temp_pdf_dir, pdf_filename)\n",
    "        \n",
    "        try:\n",
    "            # è½¬æ¢PDFï¼ˆdocx2pdfä¾èµ–Wordï¼‰\n",
    "            convert(word_path, pdf_path)\n",
    "            generated_pdf_paths.append(pdf_path)\n",
    "            print(f\"  âœ… è½¬æ¢æˆåŠŸï¼š{pdf_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ è½¬æ¢å¤±è´¥{pdf_filename}ï¼š{str(e)}ï¼ˆå»ºè®®æ‰‹åŠ¨ç”¨Wordè½¬PDFï¼‰\")\n",
    "    \n",
    "    return generated_pdf_paths, temp_pdf_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ed3dba-820a-4ea9-b366-702481eff816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å…±ç”Ÿæˆ 90 å° Word å’Œ PDF ç”³è¯·ä¿¡\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from jinja2 import Template\n",
    "from docx import Document\n",
    "import win32com.client\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 1. è¯»å–æ•°æ®\n",
    "field_df = pd.read_excel(\"research_fields_journals_skills_final.xlsx\")\n",
    "univ_df = pd.read_excel(\"universiti.xlsx\")\n",
    "\n",
    "# 2. å¤„ç†å­¦æ ¡æ•°æ®ï¼ˆä¸‰åˆ—åˆå¹¶æˆä¸€åˆ—ï¼‰\n",
    "univ_long = pd.melt(univ_df, var_name='rank', value_name='school')\n",
    "univ_long = univ_long.dropna(subset=['school']).reset_index(drop=True)\n",
    "\n",
    "# 3. å¤„ç†ç ”ç©¶é¢†åŸŸæ•°æ®ï¼ˆæŒ‰è‹±æ–‡é¢†åŸŸç¼©å†™åˆå¹¶æœŸåˆŠå’ŒæŠ€èƒ½ï¼‰\n",
    "field_grouped = field_df.groupby('è‹±æ–‡é¢†åŸŸç¼©å†™').agg({\n",
    "    'ABS 4*é¡¶çº§æœŸåˆŠ': lambda x: ', '.join(x.unique()),\n",
    "    'å²—ä½æ ¸å¿ƒæŠ€èƒ½ï¼ˆæ‰‹åŠ¨æ·»åŠ ï¼‰': lambda x: ', '.join(x.unique())\n",
    "}).reset_index()\n",
    "\n",
    "# 4. ç¬›å¡å°”ç§¯ï¼šæ¯æ‰€å­¦æ ¡ Ã— æ¯ä¸ªç ”ç©¶é¢†åŸŸ\n",
    "univ_long['key'] = 1\n",
    "field_grouped['key'] = 1\n",
    "merged = univ_long.merge(field_grouped, on='key').drop(columns='key')\n",
    "\n",
    "# 5. ç”³è¯·ä¿¡æ¨¡æ¿ï¼ˆå…¨è‹±æ–‡ï¼‰\n",
    "template_str = \"\"\"Dear Admissions Committee of the Economics Department at {{ school }},\n",
    "\n",
    "Greetings!\n",
    "\n",
    "I am Zejiang Wang. Driven by a deep passion for {{ research_field }} and a profound admiration for {{ school }}'s academic reputation, I am submitting my application to your graduate program in Economics.\n",
    "\n",
    "Academically, I have consistently followed cutting-edge research in {{ research_field }}, particularly tracking publications in top-tier journals such as {{ top_journals }}. These publications have not only deepened my understanding of core {{ research_field }} theories but also inspired my exploration of specific issues like \"{{ research_topic_example }}.\" This has solidified my resolve to pursue advanced studies at your institution and further develop related research.\n",
    "\n",
    "Regarding my career path, I aim to specialize in {{ research_field }} during graduate studies and pursue quant research (e.g., research at academic institutions, quantitative analysis in financial institutions, or policy research in government economic departments) after graduation. {{ school }}'s faculty expertise and research resources in {{ research_field }} will provide crucial support for achieving this goal.\n",
    "\n",
    "Regarding skill sets, I am proficient in {{ skills }} and other tools, enabling me to independently complete tasks such as data cleaning, statistical modeling, and empirical analysis for academic papers. These competencies will facilitate my swift adaptation to the pace of graduate-level study and research.\n",
    "\n",
    "Thank you for taking the time to review my application. I look forward to the opportunity to discuss this further with you!\n",
    "\"\"\"\n",
    "\n",
    "template = Template(template_str)\n",
    "\n",
    "# 6. åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹\n",
    "os.makedirs(\"output_word\", exist_ok=True)\n",
    "os.makedirs(\"output_pdf\", exist_ok=True)\n",
    "\n",
    "# 7. ç”Ÿæˆ Word æ–‡æ¡£\n",
    "docx_files = []\n",
    "for idx, row in merged.iterrows():\n",
    "    content = template.render(\n",
    "        school=row[\"school\"],\n",
    "        research_field=row[\"è‹±æ–‡é¢†åŸŸç¼©å†™\"],\n",
    "        top_journals=row[\"ABS 4*é¡¶çº§æœŸåˆŠ\"],\n",
    "        research_topic_example=\"Impact of AI on Labor Markets\",\n",
    "        skills=row[\"å²—ä½æ ¸å¿ƒæŠ€èƒ½ï¼ˆæ‰‹åŠ¨æ·»åŠ ï¼‰\"]\n",
    "    )\n",
    "    \n",
    "    # æ¸…ç†æ–‡ä»¶å\n",
    "    safe_school = re.sub(r'[^\\w\\-_. ]', '', row['school'])\n",
    "    filename = f\"application_{safe_school.replace(' ', '_')}_{row['è‹±æ–‡é¢†åŸŸç¼©å†™']}.docx\"\n",
    "    docx_path = os.path.join(\"output_word\", filename)\n",
    "    docx_path = os.path.abspath(docx_path)  # ç»å¯¹è·¯å¾„\n",
    "    \n",
    "    doc = Document()\n",
    "    doc.add_paragraph(content)\n",
    "    doc.save(docx_path)\n",
    "    docx_files.append(docx_path)\n",
    "\n",
    "# 8. Word è½¬ PDFï¼ˆWindows + Microsoft Word å®‰è£…ï¼‰\n",
    "word = win32com.client.Dispatch(\"Word.Application\")\n",
    "word.Visible = False\n",
    "\n",
    "for docx_path in docx_files:\n",
    "    pdf_path = os.path.join(\"output_pdf\", os.path.basename(docx_path).replace(\".docx\", \".pdf\"))\n",
    "    pdf_path = os.path.abspath(pdf_path)\n",
    "    \n",
    "    try:\n",
    "        doc = word.Documents.Open(docx_path)\n",
    "        doc.SaveAs(pdf_path, FileFormat=17)  # 17 æ˜¯ PDF æ ¼å¼\n",
    "        doc.Close()\n",
    "    except Exception as e:\n",
    "        print(f\"è½¬æ¢å¤±è´¥: {docx_path}, é”™è¯¯: {e}\")\n",
    "\n",
    "word.Quit()\n",
    "\n",
    "print(f\"å…±ç”Ÿæˆ {len(merged)} å° Word å’Œ PDF ç”³è¯·ä¿¡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55857b0-a5bf-4df8-8d04-3e1c6fcca484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
