{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二手房"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "#  初始化 WebDriver \n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "url = 'https://tj.esf.fang.com/house-a041-b0967/'\n",
    "driver.get(url)\n",
    "\n",
    "# 存储所有房源的字典 \n",
    "all_listings_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 开始抓取第 1 页数据 \n",
      "第 1 页抓取完成，本页60 条，累计 60 条房源。\n",
      " 开始抓取第 2 页数据 \n",
      "第 2 页抓取完成，本页60 条，累计 120 条房源。\n",
      " 开始抓取第 3 页数据 \n",
      "第 3 页抓取完成，本页60 条，累计 180 条房源。\n",
      " 开始抓取第 4 页数据 \n",
      "第 4 页抓取完成，本页60 条，累计 240 条房源。\n",
      " 开始抓取第 5 页数据 \n",
      "第 5 页抓取完成，本页60 条，累计 300 条房源。\n",
      " 开始抓取第 6 页数据 \n",
      "第 6 页抓取完成，本页60 条，累计 360 条房源。\n",
      " 开始抓取第 7 页数据 \n",
      "第 7 页抓取完成，本页60 条，累计 420 条房源。\n",
      " 开始抓取第 8 页数据 \n",
      "第 8 页抓取完成，本页60 条，累计 480 条房源。\n",
      " 开始抓取第 9 页数据 \n",
      "第 9 页抓取完成，本页60 条，累计 540 条房源。\n",
      " 开始抓取第 10 页数据 \n",
      "第 10 页抓取完成，本页60 条，累计 600 条房源。\n",
      " 开始抓取第 11 页数据 \n",
      "第 11 页抓取完成，本页60 条，累计 660 条房源。\n",
      " 开始抓取第 12 页数据 \n",
      "第 12 页抓取完成，本页60 条，累计 720 条房源。\n",
      " 开始抓取第 13 页数据 \n",
      "第 13 页抓取完成，本页60 条，累计 780 条房源。\n",
      " 开始抓取第 14 页数据 \n",
      "第 14 页抓取完成，本页60 条，累计 840 条房源。\n",
      " 开始抓取第 15 页数据 \n",
      "第 15 页抓取完成，本页60 条，累计 900 条房源。\n",
      " 开始抓取第 16 页数据 \n",
      "第 16 页抓取完成，本页60 条，累计 960 条房源。\n",
      " 开始抓取第 17 页数据 \n",
      "第 17 页抓取完成，本页60 条，累计 1020 条房源。\n",
      " 开始抓取第 18 页数据 \n",
      "第 18 页抓取完成，本页60 条，累计 1080 条房源。\n",
      " 开始抓取第 19 页数据 \n",
      "第 19 页抓取完成，本页60 条，累计 1140 条房源。\n",
      " 开始抓取第 20 页数据 \n",
      "第 20 页抓取完成，本页60 条，累计 1200 条房源。\n"
     ]
    }
   ],
   "source": [
    "all_pages = 20\n",
    "# 开始循环翻页与数据抓取 \n",
    "page_num = 1\n",
    "while page_num <= all_pages:\n",
    "    try:\n",
    "        print(f\" 开始抓取第 {page_num} 页数据 \")\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, \"//div[contains(@class, 'shop_list')]/dl\")))\n",
    "        \n",
    "        # 获取当前页面所有的房源元素 <dl>\n",
    "        house_list = driver.find_elements(By.XPATH, \"//div[contains(@class, 'shop_list')]/dl\")\n",
    "\n",
    "        # 遍历\n",
    "        for house in house_list:\n",
    "            try:                              \n",
    "                # 提取总价\n",
    "                price_num = house.find_element(By.XPATH, \".//dd[@class='price_right']//span[@class='red']/b\").text\n",
    "                total_price = f\"{price_num}\"\n",
    "                # 提取面积\n",
    "                p_tel_shop = house.find_element(By.XPATH, \".//p[@class='tel_shop']\").text\n",
    "                \n",
    "                # 正则表达式\n",
    "                area_match = re.search(r'(\\d+\\.?\\d)㎡', p_tel_shop)\n",
    "                area = float(area_match.group(1)) if area_match else None\n",
    "                # 提取均价\n",
    "                unit_price_text = house.find_element(By.XPATH, \".//dd[@class='price_right']/span[2]\").text\n",
    "                unit_price = int(unit_price_text.replace('元/㎡', ''))\n",
    "\n",
    "                listing_info = {\n",
    "                    '面积(㎡)': area,\n",
    "                    '总价(万)': total_price,\n",
    "                     '均价(元/㎡)': unit_price\n",
    "                }\n",
    "                \n",
    "                # 追加到总列表\n",
    "                all_listings_data.append(listing_info)\n",
    "\n",
    "            except (NoSuchElementException, AttributeError):\n",
    "                print(\"发现一个结构不同的条目（可能是广告），已跳过。\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"第 {page_num} 页抓取完成，本页{len(house_list)} 条，累计 {len(all_listings_data)} 条房源。\")\n",
    "\n",
    "        # 下一页 \n",
    "        next_page_button = driver.find_element(By.LINK_TEXT, '下一页')\n",
    "        next_page_button.click()\n",
    "        \n",
    "        page_num += 1\n",
    "        time.sleep(2) \n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"\\n页面加载超时，爬虫任务终止。\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "数据已成功保存到文件: Tianjin_Balitai_esf_data.xlsx\n",
      "   面积(㎡) 总价(万)  均价(元/㎡)\n",
      "0   67.0   436    21727\n",
      "1   66.0   406    39166\n",
      "2   67.0   430    29518\n",
      "3   18.0   410    36225\n",
      "4   15.0   119    20822\n"
     ]
    }
   ],
   "source": [
    "\n",
    "driver.quit()\n",
    "#保存到 Excel \n",
    "if all_listings_data:\n",
    "    df = pd.DataFrame(all_listings_data)\n",
    "    output_filename = 'Tianjin_Balitai_esf_data.xlsx'\n",
    "    df.to_excel(output_filename, index=False)\n",
    "    \n",
    "    print(f\"\\n数据已成功保存到文件: {output_filename}\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"\\n未能抓取到任何数据。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 租房"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# 初始化 WebDriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "ur2 = 'https://tj.zu.fang.com/house-a041-b0967/'\n",
    "driver.get(ur2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始抓取第 1 页数据\n",
      "第 1 页抓取完成，本页 60 条，累计 60 条房源。\n",
      "开始抓取第 2 页数据\n",
      "第 2 页抓取完成，本页 60 条，累计 120 条房源。\n",
      "开始抓取第 3 页数据\n",
      "第 3 页抓取完成，本页 60 条，累计 180 条房源。\n",
      "开始抓取第 4 页数据\n",
      "第 4 页抓取完成，本页 60 条，累计 240 条房源。\n",
      "开始抓取第 5 页数据\n",
      "第 5 页抓取完成，本页 60 条，累计 300 条房源。\n",
      "开始抓取第 6 页数据\n",
      "第 6 页抓取完成，本页 60 条，累计 360 条房源。\n",
      "开始抓取第 7 页数据\n",
      "第 7 页抓取完成，本页 60 条，累计 420 条房源。\n",
      "开始抓取第 8 页数据\n",
      "第 8 页抓取完成，本页 60 条，累计 480 条房源。\n",
      "开始抓取第 9 页数据\n",
      "第 9 页抓取完成，本页 60 条，累计 540 条房源。\n",
      "开始抓取第 10 页数据\n",
      "第 10 页抓取完成，本页 60 条，累计 600 条房源。\n",
      "\n",
      "未找到“下一页”按钮，所有页面抓取完毕！\n"
     ]
    }
   ],
   "source": [
    "all_listings_data2 = []\n",
    "all_pages = 20  \n",
    "\n",
    "# 循环翻页\n",
    "page_num = 1\n",
    "while page_num <= all_pages:\n",
    "    try:\n",
    "        print(f\"开始抓取第 {page_num} 页数据\")\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, \"//div[@class='houseList']/dl\")))\n",
    "        \n",
    "        # 获取当前页面所有的房源元素 <dl>\n",
    "        house_list = driver.find_elements(By.XPATH, \"//div[@class='houseList']/dl\")\n",
    "\n",
    "        # 遍历\n",
    "        for house in house_list:\n",
    "            try:\n",
    "                rent_price_text = house.find_element(By.XPATH, \".//span[@class='price']\").text\n",
    "                rent_price = int(rent_price_text)\n",
    "\n",
    "                p_info_text = house.find_element(By.XPATH, \".//p[contains(@class, 'font15')]\").text\n",
    "                \n",
    "                # 正则表达式\n",
    "                area_match = re.search(r'(\\d+\\.?\\d)㎡', p_info_text)\n",
    "                area = float(area_match.group(1)) if area_match else None\n",
    "\n",
    "                listing_info = {\n",
    "                    '面积(㎡)': area,\n",
    "                    '租金(元/月)': rent_price\n",
    "                }\n",
    "                \n",
    "                # 追加到总列表中\n",
    "                all_listings_data2.append(listing_info)\n",
    "\n",
    "            except (NoSuchElementException, AttributeError, ValueError):\n",
    "                print(\"发现一个结构不同的条目（可能是广告或已下架），已跳过。\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"第 {page_num} 页抓取完成，本页 {len(house_list)} 条，累计 {len(all_listings_data2)} 条房源。\")\n",
    "\n",
    "        # 下一页\n",
    "        next_page_button = driver.find_element(By.LINK_TEXT, '下一页')\n",
    "        next_page_button.click()\n",
    "        \n",
    "        page_num += 1\n",
    "        time.sleep(2)  \n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"\\n页面加载超时，爬虫任务终止。\")\n",
    "        break\n",
    "    except NoSuchElementException:\n",
    "        print(\"\\n未找到“下一页”按钮，所有页面抓取完毕！\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "数据已成功保存到文件: Tianjin_Balitai_zu_data.xlsx\n",
      "   面积(㎡)  租金(元/月)\n",
      "0   38.0     2000\n",
      "1  400.0    29000\n",
      "2   49.0     1700\n",
      "3  380.0    30000\n",
      "4   71.0     2200\n"
     ]
    }
   ],
   "source": [
    "driver.quit()\n",
    "\n",
    "if all_listings_data2:\n",
    "    df = pd.DataFrame(all_listings_data2)\n",
    "    \n",
    "    output_filename = 'Tianjin_Balitai_zu_data.xlsx'\n",
    "    \n",
    "    df.to_excel(output_filename, index=False)\n",
    "    \n",
    "    print(f\"\\n数据已成功保存到文件: {output_filename}\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"\\n未能抓取到任何数据。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
