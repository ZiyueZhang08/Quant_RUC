{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 房价预测项目 - 完整流程\n",
    "本 Notebook 提供了租房和售房数据的完整机器学习流程，包括：\n",
    "- 数据预处理\n",
    "- 特征工程\n",
    "- 模型训练\n",
    "- 预测生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "库导入成功！\n",
      "开始时间: 2025-10-29 23:36:11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"库导入成功！\")\n",
    "print(f\"开始时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置文件路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件路径配置完成！\n",
      "租房训练数据: data/ruc_Class25Q2_train_rent.csv\n",
      "售房训练数据: data/ruc_Class25Q2_train_price.csv\n"
     ]
    }
   ],
   "source": [
    "# 数据文件路径配置\n",
    "CONFIG = {\n",
    "    # 训练数据\n",
    "    'rent_train_file': 'data/ruc_Class25Q2_train_rent.csv',\n",
    "    'price_train_file': 'data/ruc_Class25Q2_train_price.csv',\n",
    "    \n",
    "    # 测试数据\n",
    "    'rent_test_file': 'data/ruc_Class25Q2_test_rent.csv',\n",
    "    'price_test_file': 'data/ruc_Class25Q2_test_price.csv',\n",
    "    \n",
    "    # 输出目录\n",
    "    'rent_train_dir': 'rent_train',\n",
    "    'price_train_dir': 'price_train',\n",
    "    'rent_test_dir': 'rent_test',\n",
    "    'price_test_dir': 'price_test',\n",
    "    'rent_models_dir': 'rent_models',\n",
    "    'price_models_dir': 'price_models',\n",
    "    'predictions_dir': 'predictions'\n",
    "}\n",
    "\n",
    "# 创建输出目录\n",
    "for dir_path in [CONFIG['rent_train_dir'], CONFIG['price_train_dir'], \n",
    "                 CONFIG['rent_test_dir'], CONFIG['price_test_dir'],\n",
    "                 CONFIG['rent_models_dir'], CONFIG['price_models_dir'],\n",
    "                 CONFIG['predictions_dir']]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "print(\"文件路径配置完成！\")\n",
    "print(f\"租房训练数据: {CONFIG['rent_train_file']}\")\n",
    "print(f\"售房训练数据: {CONFIG['price_train_file']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据预处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据预处理类定义完成！\n"
     ]
    }
   ],
   "source": [
    "class DataPreprocessor:\n",
    "    \"\"\"数据预处理类\"\"\"\n",
    "    \n",
    "    def __init__(self, data_type='rent'):\n",
    "        self.data_type = data_type\n",
    "        self.data = None\n",
    "        \n",
    "    def load_data(self, file_path):\n",
    "        \"\"\"加载数据\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"加载{self.data_type}数据: {file_path}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            self.data = pd.read_csv(file_path, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                self.data = pd.read_csv(file_path, encoding='gbk')\n",
    "            except:\n",
    "                self.data = pd.read_csv(file_path, encoding='latin-1')\n",
    "        \n",
    "        print(f\"数据形状: {self.data.shape}\")\n",
    "        print(f\"数据列数: {len(self.data.columns)}\")\n",
    "        \n",
    "        if 'Price' in self.data.columns:\n",
    "            print(f\"Price统计: 均值={self.data['Price'].mean():.2f}, 中位数={self.data['Price'].median():.2f}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def clean_column_names(self):\n",
    "        \"\"\"清理列名\"\"\"\n",
    "        print(\"\\n清理列名...\")\n",
    "        self.data.columns = [re.sub(r'\\s+', '', col) for col in self.data.columns]\n",
    "        print(f\"列名清理完成，共{len(self.data.columns)}列\")\n",
    "        return self\n",
    "    \n",
    "    def handle_missing_values(self):\n",
    "        \"\"\"处理缺失值\"\"\"\n",
    "        print(\"\\n处理缺失值...\")\n",
    "        \n",
    "        # 数值列用中位数填充\n",
    "        numeric_cols = self.data.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            if self.data[col].isnull().sum() > 0:\n",
    "                self.data[col].fillna(self.data[col].median(), inplace=True)\n",
    "        \n",
    "        # 分类列用众数填充\n",
    "        categorical_cols = self.data.select_dtypes(include=['object']).columns\n",
    "        for col in categorical_cols:\n",
    "            if self.data[col].isnull().sum() > 0:\n",
    "                mode_val = self.data[col].mode()[0] if not self.data[col].mode().empty else '未知'\n",
    "                self.data[col].fillna(mode_val, inplace=True)\n",
    "        \n",
    "        print(f\"缺失值处理完成\")\n",
    "        return self\n",
    "    \n",
    "    def remove_leakage_features(self):\n",
    "        \"\"\"移除数据泄露特征\"\"\"\n",
    "        print(\"\\n移除数据泄露特征...\")\n",
    "        \n",
    "        leakage_features = ['物业费', '停车费用', '燃气费', '供热费', '客户反馈', \n",
    "                           '年份', '坐标X', '坐标Y']\n",
    "        \n",
    "        actual_leakage = [col for col in leakage_features if col in self.data.columns]\n",
    "        if actual_leakage:\n",
    "            self.data = self.data.drop(columns=actual_leakage)\n",
    "            print(f\"移除了{len(actual_leakage)}个泄露特征\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def split_data(self, test_size=0.2, random_state=111):\n",
    "        \"\"\"划分训练集和测试集\"\"\"\n",
    "        print(f\"\\n划分数据集 (test_size={test_size}, random_state={random_state})...\")\n",
    "        \n",
    "        if 'Price' not in self.data.columns:\n",
    "            print(\"错误: 数据中没有Price列\")\n",
    "            return None, None, None, None\n",
    "        \n",
    "        y = self.data['Price']\n",
    "        X = self.data.drop(columns=['Price'])\n",
    "        \n",
    "        # 只保留数值型特征\n",
    "        numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "        X = X[numeric_cols]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state, shuffle=True\n",
    "        )\n",
    "        \n",
    "        print(f\"训练集: {X_train.shape}, 测试集: {X_test.shape}\")\n",
    "        print(f\"特征数量: {X_train.shape[1]}\")\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def save_processed_data(self, X_train, X_test, y_train, y_test, output_dir):\n",
    "        \"\"\"保存预处理后的数据\"\"\"\n",
    "        print(f\"\\n保存预处理数据到: {output_dir}\")\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        X_train.to_csv(f'{output_dir}/processed_X_train.csv', index=False, encoding='utf-8-sig')\n",
    "        X_test.to_csv(f'{output_dir}/processed_X_test.csv', index=False, encoding='utf-8-sig')\n",
    "        pd.DataFrame(y_train, columns=['Price']).to_csv(f'{output_dir}/processed_y_train.csv', index=False, encoding='utf-8-sig')\n",
    "        pd.DataFrame(y_test, columns=['Price']).to_csv(f'{output_dir}/processed_y_test.csv', index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(\"数据保存完成！\")\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "print(\"数据预处理类定义完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 特征工程函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征工程类定义完成！\n"
     ]
    }
   ],
   "source": [
    "class FeatureEngineer:\n",
    "    \"\"\"特征工程类\"\"\"\n",
    "    \n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        self.X_train = X_train.copy()\n",
    "        self.X_test = X_test.copy()\n",
    "        self.y_train = y_train.copy()\n",
    "        self.y_test = y_test.copy()\n",
    "        self.scaler = None\n",
    "    \n",
    "    def handle_outliers(self):\n",
    "        \"\"\"处理异常值\"\"\"\n",
    "        print(\"\\n处理异常值...\")\n",
    "        \n",
    "        numeric_cols = self.X_train.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            try:\n",
    "                Q1 = self.X_train[col].quantile(0.25)\n",
    "                Q3 = self.X_train[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                \n",
    "                if IQR > 0:\n",
    "                    lower_bound = Q1 - 1.5 * IQR\n",
    "                    upper_bound = Q3 + 1.5 * IQR\n",
    "                    \n",
    "                    self.X_train[col] = np.clip(self.X_train[col], lower_bound, upper_bound)\n",
    "                    self.X_test[col] = np.clip(self.X_test[col], lower_bound, upper_bound)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        print(\"异常值处理完成\")\n",
    "        return self\n",
    "    \n",
    "    def create_interaction_features(self):\n",
    "        \"\"\"创建交互特征\"\"\"\n",
    "        print(\"\\n创建交互特征...\")\n",
    "        \n",
    "        numeric_cols = self.X_train.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        # 选择前5个重要特征创建交互\n",
    "        if len(numeric_cols) >= 5:\n",
    "            important_cols = numeric_cols[:5]\n",
    "            \n",
    "            for i, col1 in enumerate(important_cols):\n",
    "                for col2 in important_cols[i+1:]:\n",
    "                    interaction_name = f'{col1}_x_{col2}'\n",
    "                    self.X_train[interaction_name] = self.X_train[col1] * self.X_train[col2]\n",
    "                    self.X_test[interaction_name] = self.X_test[col1] * self.X_test[col2]\n",
    "            \n",
    "            print(f\"创建了{len(important_cols) * (len(important_cols)-1) // 2}个交互特征\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def standardize_features(self):\n",
    "        \"\"\"标准化特征\"\"\"\n",
    "        print(\"\\n标准化特征...\")\n",
    "        \n",
    "        numeric_cols = self.X_train.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        if len(numeric_cols) > 0:\n",
    "            self.scaler = StandardScaler()\n",
    "            self.X_train[numeric_cols] = self.scaler.fit_transform(self.X_train[numeric_cols])\n",
    "            self.X_test[numeric_cols] = self.scaler.transform(self.X_test[numeric_cols])\n",
    "            \n",
    "            print(f\"标准化了{len(numeric_cols)}个特征\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def select_features(self, alpha=0.01):\n",
    "        \"\"\"特征选择\"\"\"\n",
    "        print(f\"\\n特征选择 (alpha={alpha})...\")\n",
    "        \n",
    "        try:\n",
    "            lasso = Lasso(alpha=alpha, random_state=111)\n",
    "            lasso.fit(self.X_train, self.y_train)\n",
    "            \n",
    "            selector = SelectFromModel(lasso, prefit=True)\n",
    "            \n",
    "            self.X_train = pd.DataFrame(\n",
    "                selector.transform(self.X_train),\n",
    "                columns=self.X_train.columns[selector.get_support()],\n",
    "                index=self.X_train.index\n",
    "            )\n",
    "            \n",
    "            self.X_test = pd.DataFrame(\n",
    "                selector.transform(self.X_test),\n",
    "                columns=self.X_test.columns[selector.get_support()],\n",
    "                index=self.X_test.index\n",
    "            )\n",
    "            \n",
    "            print(f\"选择了{self.X_train.shape[1]}个特征\")\n",
    "        except:\n",
    "            print(\"特征选择失败，保留所有特征\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_processed_data(self):\n",
    "        \"\"\"获取处理后的数据\"\"\"\n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "    \n",
    "    def save_feature_engineered_data(self, output_dir, prefix='advanced_feature_engineered'):\n",
    "        \"\"\"保存特征工程后的数据\"\"\"\n",
    "        print(f\"\\n保存特征工程数据到: {output_dir}\")\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        self.X_train.to_csv(f'{output_dir}/{prefix}_X_train.csv', index=False, encoding='utf-8-sig')\n",
    "        self.X_test.to_csv(f'{output_dir}/{prefix}_X_test.csv', index=False, encoding='utf-8-sig')\n",
    "        pd.DataFrame(self.y_train, columns=['Price']).to_csv(f'{output_dir}/{prefix}_y_train.csv', index=False, encoding='utf-8-sig')\n",
    "        pd.DataFrame(self.y_test, columns=['Price']).to_csv(f'{output_dir}/{prefix}_y_test.csv', index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        # 保存scaler\n",
    "        if self.scaler:\n",
    "            joblib.dump(self.scaler, f'{output_dir}/feature_scaler.pkl')\n",
    "        \n",
    "        # 保存特征列名\n",
    "        pd.DataFrame({'columns': self.X_train.columns}).to_csv(\n",
    "            f'{output_dir}/feature_columns.csv', index=False, encoding='utf-8-sig'\n",
    "        )\n",
    "        \n",
    "        print(\"特征工程数据保存完成！\")\n",
    "\n",
    "print(\"特征工程类定义完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型训练类定义完成！\n"
     ]
    }
   ],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"模型训练类\"\"\"\n",
    "    \n",
    "    def __init__(self, X_train, X_test, y_train, y_test, data_type='rent'):\n",
    "        self.X_train = X_train.fillna(0)\n",
    "        self.X_test = X_test.fillna(0)\n",
    "        self.y_train = y_train.fillna(0)\n",
    "        self.y_test = y_test.fillna(0)\n",
    "        self.data_type = data_type\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        self.best_model = None\n",
    "        self.best_model_name = None\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred):\n",
    "        \"\"\"计算评估指标\"\"\"\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        return {'mae': mae, 'rmse': rmse, 'r2': r2}\n",
    "    \n",
    "    def train_ols(self):\n",
    "        \"\"\"训练OLS模型\"\"\"\n",
    "        print(\"\\n训练OLS模型...\")\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # 预测\n",
    "        y_train_pred = model.predict(self.X_train)\n",
    "        y_test_pred = model.predict(self.X_test)\n",
    "        \n",
    "        # 计算指标\n",
    "        train_metrics = self.calculate_metrics(self.y_train, y_train_pred)\n",
    "        test_metrics = self.calculate_metrics(self.y_test, y_test_pred)\n",
    "        \n",
    "        # 交叉验证\n",
    "        cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
    "                                   cv=6, scoring='neg_mean_absolute_error')\n",
    "        cv_mae = -cv_scores.mean()\n",
    "        \n",
    "        self.models['OLS'] = model\n",
    "        self.results['OLS'] = {\n",
    "            'train_mae': train_metrics['mae'],\n",
    "            'test_mae': test_metrics['mae'],\n",
    "            'cv_mae': cv_mae,\n",
    "            'train_r2': train_metrics['r2'],\n",
    "            'test_r2': test_metrics['r2']\n",
    "        }\n",
    "        \n",
    "        print(f\"OLS - Train MAE: {train_metrics['mae']:.2f}, Test MAE: {test_metrics['mae']:.2f}, CV MAE: {cv_mae:.2f}\")\n",
    "        return self\n",
    "    \n",
    "    def train_lasso(self, alpha_range=[0.001, 0.01, 0.1, 1, 10, 100]):\n",
    "        \"\"\"训练Lasso模型\"\"\"\n",
    "        print(\"\\n训练Lasso模型...\")\n",
    "        \n",
    "        param_grid = {'alpha': alpha_range}\n",
    "        lasso = Lasso(random_state=111, max_iter=10000)\n",
    "        \n",
    "        grid_search = GridSearchCV(lasso, param_grid, cv=6, \n",
    "                                  scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # 预测和评估\n",
    "        y_train_pred = best_model.predict(self.X_train)\n",
    "        y_test_pred = best_model.predict(self.X_test)\n",
    "        \n",
    "        train_metrics = self.calculate_metrics(self.y_train, y_train_pred)\n",
    "        test_metrics = self.calculate_metrics(self.y_test, y_test_pred)\n",
    "        \n",
    "        cv_scores = cross_val_score(best_model, self.X_train, self.y_train,\n",
    "                                   cv=6, scoring='neg_mean_absolute_error')\n",
    "        cv_mae = -cv_scores.mean()\n",
    "        \n",
    "        self.models['LASSO'] = best_model\n",
    "        self.results['LASSO'] = {\n",
    "            'train_mae': train_metrics['mae'],\n",
    "            'test_mae': test_metrics['mae'],\n",
    "            'cv_mae': cv_mae,\n",
    "            'train_r2': train_metrics['r2'],\n",
    "            'test_r2': test_metrics['r2'],\n",
    "            'best_params': grid_search.best_params_\n",
    "        }\n",
    "        \n",
    "        print(f\"LASSO (alpha={grid_search.best_params_['alpha']}) - Train MAE: {train_metrics['mae']:.2f}, Test MAE: {test_metrics['mae']:.2f}, CV MAE: {cv_mae:.2f}\")\n",
    "        return self\n",
    "    \n",
    "    def train_ridge(self, alpha_range=[0.001, 0.01, 0.1, 1, 10, 100, 1000]):\n",
    "        \"\"\"训练Ridge模型\"\"\"\n",
    "        print(\"\\n训练Ridge模型...\")\n",
    "        \n",
    "        param_grid = {'alpha': alpha_range}\n",
    "        ridge = Ridge(random_state=111)\n",
    "        \n",
    "        grid_search = GridSearchCV(ridge, param_grid, cv=6,\n",
    "                                  scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # 预测和评估\n",
    "        y_train_pred = best_model.predict(self.X_train)\n",
    "        y_test_pred = best_model.predict(self.X_test)\n",
    "        \n",
    "        train_metrics = self.calculate_metrics(self.y_train, y_train_pred)\n",
    "        test_metrics = self.calculate_metrics(self.y_test, y_test_pred)\n",
    "        \n",
    "        cv_scores = cross_val_score(best_model, self.X_train, self.y_train,\n",
    "                                   cv=6, scoring='neg_mean_absolute_error')\n",
    "        cv_mae = -cv_scores.mean()\n",
    "        \n",
    "        self.models['Ridge'] = best_model\n",
    "        self.results['Ridge'] = {\n",
    "            'train_mae': train_metrics['mae'],\n",
    "            'test_mae': test_metrics['mae'],\n",
    "            'cv_mae': cv_mae,\n",
    "            'train_r2': train_metrics['r2'],\n",
    "            'test_r2': test_metrics['r2'],\n",
    "            'best_params': grid_search.best_params_\n",
    "        }\n",
    "        \n",
    "        print(f\"Ridge (alpha={grid_search.best_params_['alpha']}) - Train MAE: {train_metrics['mae']:.2f}, Test MAE: {test_metrics['mae']:.2f}, CV MAE: {cv_mae:.2f}\")\n",
    "        return self\n",
    "    \n",
    "    def select_best_model(self):\n",
    "        \"\"\"选择最佳模型\"\"\"\n",
    "        print(\"\\n选择最佳模型...\")\n",
    "        \n",
    "        best_model_name = min(self.results.keys(), key=lambda k: self.results[k]['test_mae'])\n",
    "        self.best_model = self.models[best_model_name]\n",
    "        self.best_model_name = best_model_name\n",
    "        \n",
    "        print(f\"最佳模型: {best_model_name}\")\n",
    "        print(f\"Test MAE: {self.results[best_model_name]['test_mae']:.2f}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def save_models(self, output_dir):\n",
    "        \"\"\"保存所有模型\"\"\"\n",
    "        print(f\"\\n保存模型到: {output_dir}\")\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        for model_name, model in self.models.items():\n",
    "            filename = f\"{output_dir}/{model_name.lower()}_model.pkl\"\n",
    "            joblib.dump(model, filename)\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        joblib.dump(self.best_model, f'{output_dir}/best_model.pkl')\n",
    "        \n",
    "        # 保存性能报告\n",
    "        report_data = []\n",
    "        for model_name in ['OLS', 'LASSO', 'Ridge']:\n",
    "            if model_name in self.results:\n",
    "                result = self.results[model_name]\n",
    "                report_data.append({\n",
    "                    'Model': model_name,\n",
    "                    'Train MAE': f\"{result['train_mae']:.2f}\",\n",
    "                    'Test MAE': f\"{result['test_mae']:.2f}\",\n",
    "                    'CV MAE': f\"{result['cv_mae']:.2f}\",\n",
    "                    'Train R²': f\"{result['train_r2']:.4f}\",\n",
    "                    'Test R²': f\"{result['test_r2']:.4f}\"\n",
    "                })\n",
    "        \n",
    "        report_df = pd.DataFrame(report_data)\n",
    "        report_df.to_csv(f'{output_dir}/performance_report.csv', index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(\"模型保存完成！\")\n",
    "        print(\"\\n性能报告:\")\n",
    "        print(report_df.to_string(index=False))\n",
    "\n",
    "print(\"模型训练类定义完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 预测生成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测生成类定义完成！\n"
     ]
    }
   ],
   "source": [
    "class PredictionGenerator:\n",
    "    \"\"\"预测生成器\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rent_predictions = {}\n",
    "        self.price_predictions = {}\n",
    "    \n",
    "    def generate_predictions(self, test_file, model_dir, scaler_file, feature_columns_file, data_type='rent'):\n",
    "        \"\"\"生成预测\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"生成{data_type}预测\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # 加载测试数据\n",
    "        try:\n",
    "            test_data = pd.read_csv(test_file, encoding='utf-8')\n",
    "        except:\n",
    "            try:\n",
    "                test_data = pd.read_csv(test_file, encoding='gbk')\n",
    "            except:\n",
    "                test_data = pd.read_csv(test_file, encoding='latin-1')\n",
    "        \n",
    "        print(f\"测试数据形状: {test_data.shape}\")\n",
    "        \n",
    "        # 提取ID\n",
    "        id_col = None\n",
    "        for col in ['ID', 'id', 'Id']:\n",
    "            if col in test_data.columns:\n",
    "                id_col = col\n",
    "                break\n",
    "        \n",
    "        if id_col:\n",
    "            ids = test_data[id_col].copy()\n",
    "            test_data = test_data.drop(columns=[id_col])\n",
    "        else:\n",
    "            ids = pd.RangeIndex(start=0, stop=len(test_data))\n",
    "        \n",
    "        # 加载特征列名\n",
    "        if os.path.exists(feature_columns_file):\n",
    "            feature_columns = pd.read_csv(feature_columns_file)['columns'].tolist()\n",
    "            \n",
    "            # 对齐特征\n",
    "            for col in feature_columns:\n",
    "                if col not in test_data.columns:\n",
    "                    test_data[col] = 0\n",
    "            \n",
    "            test_data = test_data[feature_columns]\n",
    "        \n",
    "        # 填充缺失值\n",
    "        test_data = test_data.fillna(0)\n",
    "        \n",
    "        # 加载scaler并转换\n",
    "        if os.path.exists(scaler_file):\n",
    "            scaler = joblib.load(scaler_file)\n",
    "            test_data = pd.DataFrame(\n",
    "                scaler.transform(test_data),\n",
    "                columns=test_data.columns\n",
    "            )\n",
    "        \n",
    "        # 加载模型并预测\n",
    "        predictions = {}\n",
    "        \n",
    "        for model_name in ['ols', 'lasso', 'ridge']:\n",
    "            model_file = f\"{model_dir}/{model_name}_model.pkl\"\n",
    "            \n",
    "            if os.path.exists(model_file):\n",
    "                print(f\"\\n加载{model_name.upper()}模型...\")\n",
    "                model = joblib.load(model_file)\n",
    "                \n",
    "                preds = model.predict(test_data)\n",
    "                preds = np.maximum(preds, 0)  # 确保非负\n",
    "                \n",
    "                predictions[model_name.upper()] = preds\n",
    "                print(f\"{model_name.upper()} - 预测范围: {preds.min():.2f} - {preds.max():.2f}\")\n",
    "        \n",
    "        # 加载最佳模型\n",
    "        best_model_file = f\"{model_dir}/best_model.pkl\"\n",
    "        if os.path.exists(best_model_file):\n",
    "            model = joblib.load(best_model_file)\n",
    "            preds = model.predict(test_data)\n",
    "            preds = np.maximum(preds, 0)\n",
    "            predictions['Best_Model'] = preds\n",
    "        \n",
    "        if data_type == 'rent':\n",
    "            self.rent_predictions = {'predictions': predictions, 'ids': ids}\n",
    "        else:\n",
    "            self.price_predictions = {'predictions': predictions, 'ids': ids}\n",
    "        \n",
    "        return predictions, ids\n",
    "    \n",
    "    def save_predictions(self, output_dir):\n",
    "        \"\"\"保存预测文件\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"保存预测文件\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        os.makedirs(f\"{output_dir}/rent\", exist_ok=True)\n",
    "        os.makedirs(f\"{output_dir}/price\", exist_ok=True)\n",
    "        os.makedirs(f\"{output_dir}/merged\", exist_ok=True)\n",
    "        \n",
    "        # 保存租房预测\n",
    "        if self.rent_predictions:\n",
    "            for model_name, preds in self.rent_predictions['predictions'].items():\n",
    "                pred_df = pd.DataFrame({\n",
    "                    'ID': self.rent_predictions['ids'],\n",
    "                    'Price': preds\n",
    "                })\n",
    "                pred_df.to_csv(f\"{output_dir}/rent/rent_prediction_{model_name}.csv\", \n",
    "                             index=False, encoding='utf-8-sig')\n",
    "            print(\"租房预测文件保存完成\")\n",
    "        \n",
    "        # 保存售房预测\n",
    "        if self.price_predictions:\n",
    "            for model_name, preds in self.price_predictions['predictions'].items():\n",
    "                pred_df = pd.DataFrame({\n",
    "                    'ID': self.price_predictions['ids'],\n",
    "                    'Price': preds\n",
    "                })\n",
    "                pred_df.to_csv(f\"{output_dir}/price/price_prediction_{model_name}.csv\",\n",
    "                             index=False, encoding='utf-8-sig')\n",
    "            print(\"售房预测文件保存完成\")\n",
    "        \n",
    "        # 合并预测（使用Best_Model）\n",
    "        if self.rent_predictions and self.price_predictions:\n",
    "            if 'Best_Model' in self.rent_predictions['predictions'] and 'Best_Model' in self.price_predictions['predictions']:\n",
    "                rent_df = pd.DataFrame({\n",
    "                    'ID': self.rent_predictions['ids'],\n",
    "                    'Price': self.rent_predictions['predictions']['Best_Model']\n",
    "                })\n",
    "                \n",
    "                price_df = pd.DataFrame({\n",
    "                    'ID': self.price_predictions['ids'],\n",
    "                    'Price': self.price_predictions['predictions']['Best_Model']\n",
    "                })\n",
    "                \n",
    "                merged_df = pd.concat([rent_df, price_df], ignore_index=True)\n",
    "                merged_df.to_csv(f\"{output_dir}/merged/merged_prediction.csv\",\n",
    "                               index=False, encoding='utf-8-sig')\n",
    "                \n",
    "                # Kaggle提交文件\n",
    "                merged_df.to_csv(f\"{output_dir}/kaggle_submission.csv\",\n",
    "                               index=False, encoding='utf-8-sig')\n",
    "                \n",
    "                print(\"合并预测文件保存完成\")\n",
    "                print(f\"总记录数: {len(merged_df)}\")\n",
    "                print(f\"租房: {len(rent_df)}, 售房: {len(price_df)}\")\n",
    "\n",
    "print(\"预测生成类定义完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 执行完整流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 租房数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "开始处理租房数据\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "加载rent数据: data/ruc_Class25Q2_train_rent.csv\n",
      "============================================================\n",
      "数据形状: (98899, 46)\n",
      "数据列数: 46\n",
      "Price统计: 均值=582908.98, 中位数=394936.89\n",
      "\n",
      "清理列名...\n",
      "列名清理完成，共46列\n",
      "\n",
      "处理缺失值...\n",
      "缺失值处理完成\n",
      "\n",
      "移除数据泄露特征...\n",
      "移除了6个泄露特征\n",
      "\n",
      "划分数据集 (test_size=0.2, random_state=111)...\n",
      "训练集: (79119, 9), 测试集: (19780, 9)\n",
      "特征数量: 9\n",
      "\n",
      "保存预处理数据到: rent_train\n",
      "数据保存完成！\n",
      "\n",
      "处理异常值...\n",
      "异常值处理完成\n",
      "\n",
      "创建交互特征...\n",
      "创建了10个交互特征\n",
      "\n",
      "标准化特征...\n",
      "标准化了19个特征\n",
      "\n",
      "特征选择 (alpha=0.01)...\n",
      "选择了19个特征\n",
      "\n",
      "保存特征工程数据到: rent_train\n",
      "特征工程数据保存完成！\n",
      "\n",
      "训练OLS模型...\n",
      "OLS - Train MAE: 322906.73, Test MAE: 321405.31, CV MAE: 322960.86\n",
      "\n",
      "训练Lasso模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e+16, tolerance: 2.624e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.118e+16, tolerance: 2.524e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+16, tolerance: 2.589e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+16, tolerance: 2.624e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.162e+16, tolerance: 2.619e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.163e+16, tolerance: 2.619e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+16, tolerance: 2.577e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+16, tolerance: 2.521e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+16, tolerance: 2.589e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+16, tolerance: 2.521e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+16, tolerance: 2.624e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+16, tolerance: 2.619e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.118e+16, tolerance: 2.524e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+16, tolerance: 2.577e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+16, tolerance: 2.589e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.112e+16, tolerance: 2.524e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+16, tolerance: 2.577e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.103e+16, tolerance: 2.619e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e+16, tolerance: 2.521e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+16, tolerance: 2.624e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+16, tolerance: 2.524e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+16, tolerance: 2.577e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+16, tolerance: 2.589e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e+16, tolerance: 2.521e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.766e+15, tolerance: 2.624e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.803e+15, tolerance: 2.619e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.359e+15, tolerance: 2.521e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.024e+15, tolerance: 2.589e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.516e+15, tolerance: 2.524e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.902e+15, tolerance: 2.577e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO (alpha=100) - Train MAE: 322709.51, Test MAE: 321471.02, CV MAE: 322765.53\n",
      "\n",
      "训练Ridge模型...\n",
      "Ridge (alpha=100) - Train MAE: 321304.60, Test MAE: 320145.73, CV MAE: 321424.01\n",
      "\n",
      "选择最佳模型...\n",
      "最佳模型: Ridge\n",
      "Test MAE: 320145.73\n",
      "\n",
      "保存模型到: rent_models\n",
      "模型保存完成！\n",
      "\n",
      "性能报告:\n",
      "Model Train MAE  Test MAE    CV MAE Train R² Test R²\n",
      "  OLS 322906.73 321405.31 322960.86   0.1142  0.1182\n",
      "LASSO 322709.51 321471.02 322765.53   0.1133  0.1168\n",
      "Ridge 321304.60 320145.73 321424.01   0.1096  0.1128\n",
      "\n",
      "租房数据处理完成！\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"开始处理租房数据\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. 数据预处理\n",
    "rent_preprocessor = DataPreprocessor(data_type='rent')\n",
    "rent_preprocessor.load_data(CONFIG['rent_train_file'])\n",
    "rent_preprocessor.clean_column_names()\n",
    "rent_preprocessor.handle_missing_values()\n",
    "rent_preprocessor.remove_leakage_features()\n",
    "\n",
    "X_train_rent, X_test_rent, y_train_rent, y_test_rent = rent_preprocessor.split_data()\n",
    "rent_preprocessor.save_processed_data(X_train_rent, X_test_rent, y_train_rent, y_test_rent, \n",
    "                                     CONFIG['rent_train_dir'])\n",
    "\n",
    "# 2. 特征工程\n",
    "rent_fe = FeatureEngineer(X_train_rent, X_test_rent, y_train_rent, y_test_rent)\n",
    "rent_fe.handle_outliers()\n",
    "rent_fe.create_interaction_features()\n",
    "rent_fe.standardize_features()\n",
    "rent_fe.select_features(alpha=0.01)\n",
    "\n",
    "X_train_rent_fe, X_test_rent_fe, y_train_rent_fe, y_test_rent_fe = rent_fe.get_processed_data()\n",
    "rent_fe.save_feature_engineered_data(CONFIG['rent_train_dir'])\n",
    "\n",
    "# 3. 模型训练\n",
    "rent_trainer = ModelTrainer(X_train_rent_fe, X_test_rent_fe, y_train_rent_fe, y_test_rent_fe, data_type='rent')\n",
    "rent_trainer.train_ols()\n",
    "rent_trainer.train_lasso()\n",
    "rent_trainer.train_ridge()\n",
    "rent_trainer.select_best_model()\n",
    "rent_trainer.save_models(CONFIG['rent_models_dir'])\n",
    "\n",
    "print(\"\\n租房数据处理完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 售房数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "开始处理售房数据\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "加载price数据: data/ruc_Class25Q2_train_price.csv\n",
      "============================================================\n",
      "数据形状: (103871, 55)\n",
      "数据列数: 55\n",
      "Price统计: 均值=2262366.07, 中位数=1479407.11\n",
      "\n",
      "清理列名...\n",
      "列名清理完成，共55列\n",
      "\n",
      "处理缺失值...\n",
      "缺失值处理完成\n",
      "\n",
      "移除数据泄露特征...\n",
      "移除了6个泄露特征\n",
      "\n",
      "划分数据集 (test_size=0.2, random_state=111)...\n",
      "训练集: (83096, 12), 测试集: (20775, 12)\n",
      "特征数量: 12\n",
      "\n",
      "保存预处理数据到: price_train\n",
      "数据保存完成！\n",
      "\n",
      "处理异常值...\n",
      "异常值处理完成\n",
      "\n",
      "创建交互特征...\n",
      "创建了10个交互特征\n",
      "\n",
      "标准化特征...\n",
      "标准化了22个特征\n",
      "\n",
      "特征选择 (alpha=0.01)...\n",
      "特征选择失败，保留所有特征\n",
      "\n",
      "保存特征工程数据到: price_train\n",
      "特征工程数据保存完成！\n",
      "\n",
      "训练OLS模型...\n",
      "OLS - Train MAE: 1386950.85, Test MAE: 1358050.50, CV MAE: 1387223.07\n",
      "\n",
      "训练Lasso模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.972e+17, tolerance: 4.431e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.035e+17, tolerance: 4.564e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+17, tolerance: 4.521e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.981e+17, tolerance: 4.456e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.978e+17, tolerance: 4.451e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+17, tolerance: 4.465e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.990e+17, tolerance: 4.465e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.859e+17, tolerance: 4.431e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.867e+17, tolerance: 4.456e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+17, tolerance: 4.465e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.902e+17, tolerance: 4.521e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.859e+17, tolerance: 4.451e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.915e+17, tolerance: 4.564e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+17, tolerance: 4.431e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+17, tolerance: 4.564e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+17, tolerance: 4.456e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e+17, tolerance: 4.521e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+16, tolerance: 4.431e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e+17, tolerance: 4.451e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+16, tolerance: 4.465e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+16, tolerance: 4.456e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.766e+15, tolerance: 4.451e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+16, tolerance: 4.564e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+16, tolerance: 4.521e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.763e+14, tolerance: 4.465e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.684e+14, tolerance: 4.431e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.648e+14, tolerance: 4.564e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.653e+14, tolerance: 4.456e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.513e+14, tolerance: 4.451e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.774e+14, tolerance: 4.521e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO (alpha=0.001) - Train MAE: 1386950.79, Test MAE: 1358050.40, CV MAE: 1387223.02\n",
      "\n",
      "训练Ridge模型...\n",
      "Ridge (alpha=1) - Train MAE: 1386897.26, Test MAE: 1357967.29, CV MAE: 1387163.94\n",
      "\n",
      "选择最佳模型...\n",
      "最佳模型: Ridge\n",
      "Test MAE: 1357967.29\n",
      "\n",
      "保存模型到: price_models\n",
      "模型保存完成！\n",
      "\n",
      "性能报告:\n",
      "Model  Train MAE   Test MAE     CV MAE Train R² Test R²\n",
      "  OLS 1386950.85 1358050.50 1387223.07   0.1035  0.1036\n",
      "LASSO 1386950.79 1358050.40 1387223.02   0.1035  0.1036\n",
      "Ridge 1386897.26 1357967.29 1387163.94   0.1035  0.1036\n",
      "\n",
      "售房数据处理完成！\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"开始处理售房数据\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. 数据预处理\n",
    "price_preprocessor = DataPreprocessor(data_type='price')\n",
    "price_preprocessor.load_data(CONFIG['price_train_file'])\n",
    "price_preprocessor.clean_column_names()\n",
    "price_preprocessor.handle_missing_values()\n",
    "price_preprocessor.remove_leakage_features()\n",
    "\n",
    "X_train_price, X_test_price, y_train_price, y_test_price = price_preprocessor.split_data()\n",
    "price_preprocessor.save_processed_data(X_train_price, X_test_price, y_train_price, y_test_price,\n",
    "                                      CONFIG['price_train_dir'])\n",
    "\n",
    "# 2. 特征工程\n",
    "price_fe = FeatureEngineer(X_train_price, X_test_price, y_train_price, y_test_price)\n",
    "price_fe.handle_outliers()\n",
    "price_fe.create_interaction_features()\n",
    "price_fe.standardize_features()\n",
    "price_fe.select_features(alpha=0.01)\n",
    "\n",
    "X_train_price_fe, X_test_price_fe, y_train_price_fe, y_test_price_fe = price_fe.get_processed_data()\n",
    "price_fe.save_feature_engineered_data(CONFIG['price_train_dir'])\n",
    "\n",
    "# 3. 模型训练\n",
    "price_trainer = ModelTrainer(X_train_price_fe, X_test_price_fe, y_train_price_fe, y_test_price_fe, data_type='price')\n",
    "price_trainer.train_ols()\n",
    "price_trainer.train_lasso()\n",
    "price_trainer.train_ridge()\n",
    "price_trainer.select_best_model()\n",
    "price_trainer.save_models(CONFIG['price_models_dir'])\n",
    "\n",
    "print(\"\\n售房数据处理完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 生成预测文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "生成预测文件\n",
      "================================================================================\n",
      "\n",
      "处理rent数据集...\n",
      "测试数据的列名: ['ID', '城市', '户型', '装修', '楼层', '面积', '朝向', '交易时间', '付款方式', '租赁方式']...\n",
      "✓ ID 列已确认，共 9773 条记录\n",
      "特征列文件的列名: ['columns']\n",
      "加载了 19 个特征\n",
      "缩放前 - 处理缺失值前: 6822 个 NaN\n",
      "缩放前 - 处理缺失值后: 0 个 NaN\n",
      "✓ 数据验证通过，shape: (9773, 19)\n",
      "\n",
      "加载RIDGE模型...\n",
      "RIDGE 预测范围: [0.00, 835451.56]\n",
      "\n",
      "加载LASSO模型...\n",
      "LASSO 预测范围: [0.00, 1332440.17]\n",
      "警告: 找不到 elasticnet 模型文件\n",
      "警告: 找不到 xgboost 模型文件\n",
      "警告: 找不到 lightgbm 模型文件\n",
      "\n",
      "rent数据集预测完成!\n",
      "\n",
      "处理price数据集...\n",
      "测试数据的列名: ['ID', '城市', '区域', '板块', '环线', '房屋户型', '所在楼层', '建筑面积', '套内面积', '房屋朝向']...\n",
      "✓ ID 列已确认，共 34017 条记录\n",
      "特征列文件的列名: ['columns']\n",
      "加载了 22 个特征\n",
      "缩放前 - 处理缺失值前: 58562 个 NaN\n",
      "缩放前 - 处理缺失值后: 0 个 NaN\n",
      "⚠️ 缩放后发现 NaN: 170085 个\n",
      "缩放后 - 处理后的 NaN: 0 个\n",
      "✓ 数据验证通过，shape: (34017, 22)\n",
      "\n",
      "加载RIDGE模型...\n",
      "RIDGE 预测范围: [0.00, 31068031.67]\n",
      "\n",
      "加载LASSO模型...\n",
      "LASSO 预测范围: [0.00, 31742665.73]\n",
      "警告: 找不到 elasticnet 模型文件\n",
      "警告: 找不到 xgboost 模型文件\n",
      "警告: 找不到 lightgbm 模型文件\n",
      "\n",
      "price数据集预测完成!\n",
      "\n",
      "保存租房预测结果...\n",
      "✓ predictions/rent_predictions_ridge.csv\n",
      "✓ predictions/rent_predictions_lasso.csv\n",
      "\n",
      "保存售房预测结果...\n",
      "✓ predictions/price_predictions_ridge.csv\n",
      "✓ predictions/price_predictions_lasso.csv\n",
      "\n",
      "创建Kaggle提交文件...\n",
      "✓ predictions/kaggle_submission.csv\n",
      "\n",
      "提交文件统计:\n",
      "  - 租房预测: 9773 条\n",
      "  - 售房预测: 34017 条\n",
      "  - 总计: 43790 条\n",
      "\n",
      "================================================================================\n",
      "所有处理完成!\n",
      "================================================================================\n",
      "\n",
      "生成的文件:\n",
      "- 租房模型: rent_models/\n",
      "- 售房模型: price_models/\n",
      "- 预测文件: predictions/\n",
      "- Kaggle提交: predictions/kaggle_submission.csv\n",
      "\n",
      "完成时间: 2025-10-29 23:50:53\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"生成预测文件\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "class PredictionGenerator:\n",
    "    def __init__(self):\n",
    "        self.predictions = {}\n",
    "    \n",
    "    def generate_predictions(self, test_file, model_dir, scaler_file, feature_columns_file, data_type):\n",
    "        print(f\"\\n处理{data_type}数据集...\")\n",
    "        \n",
    "        # 加载测试数据\n",
    "        test_df = pd.read_csv(test_file)\n",
    "        original_test_df = test_df.copy()\n",
    "        \n",
    "        # ===== 检查并处理 ID 列 =====\n",
    "        print(f\"测试数据的列名: {test_df.columns.tolist()[:10]}...\")  # 显示前10列\n",
    "        \n",
    "        # 确保有 ID 列\n",
    "        if 'id' not in test_df.columns:\n",
    "            if 'ID' in test_df.columns:\n",
    "                test_df['id'] = test_df['ID']\n",
    "                original_test_df['id'] = original_test_df['ID']\n",
    "            elif 'Id' in test_df.columns:\n",
    "                test_df['id'] = test_df['Id']\n",
    "                original_test_df['id'] = original_test_df['Id']\n",
    "            else:\n",
    "                # 如果没有任何 ID 列，创建一个\n",
    "                test_df['id'] = range(len(test_df))\n",
    "                original_test_df['id'] = range(len(original_test_df))\n",
    "                print(f\"⚠️ 未找到 ID 列，已自动生成: 0 到 {len(test_df)-1}\")\n",
    "        \n",
    "        print(f\"✓ ID 列已确认，共 {len(test_df)} 条记录\")\n",
    "        # ================================\n",
    "        \n",
    "        # 特征工程\n",
    "        test_df = self.feature_engineering(test_df)\n",
    "        \n",
    "        # 加载特征列\n",
    "        feature_df = pd.read_csv(feature_columns_file)\n",
    "        print(f\"特征列文件的列名: {feature_df.columns.tolist()}\")\n",
    "        \n",
    "        # 尝试多种可能的列名\n",
    "        if 'feature' in feature_df.columns:\n",
    "            feature_columns = feature_df['feature'].tolist()\n",
    "        elif len(feature_df.columns) == 1:\n",
    "            feature_columns = feature_df.iloc[:, 0].tolist()\n",
    "        else:\n",
    "            feature_columns = feature_df[feature_df.columns[0]].tolist()\n",
    "        \n",
    "        print(f\"加载了 {len(feature_columns)} 个特征\")\n",
    "        \n",
    "        # 确保所有需要的特征都存在\n",
    "        for col in feature_columns:\n",
    "            if col not in test_df.columns:\n",
    "                test_df[col] = 0\n",
    "        \n",
    "        # 选择特征\n",
    "        test_data = test_df[feature_columns].copy()\n",
    "        \n",
    "        # 第一次处理缺失值 (缩放前)\n",
    "        print(f\"缩放前 - 处理缺失值前: {test_data.isnull().sum().sum()} 个 NaN\")\n",
    "        \n",
    "        # 数值型特征用中位数填充\n",
    "        for col in test_data.columns:\n",
    "            if test_data[col].isnull().any():\n",
    "                median_val = test_data[col].median()\n",
    "                if pd.isna(median_val):\n",
    "                    median_val = 0\n",
    "                test_data.loc[:, col] = test_data[col].fillna(median_val)\n",
    "        \n",
    "        # 替换 inf 值\n",
    "        test_data.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "        \n",
    "        print(f\"缩放前 - 处理缺失值后: {test_data.isnull().sum().sum()} 个 NaN\")\n",
    "        \n",
    "        # 加载scaler并转换\n",
    "        scaler = joblib.load(scaler_file)\n",
    "        test_data_scaled = scaler.transform(test_data)\n",
    "        \n",
    "        # 第二次处理缺失值 (缩放后)\n",
    "        if np.isnan(test_data_scaled).any():\n",
    "            print(f\"⚠️ 缩放后发现 NaN: {np.isnan(test_data_scaled).sum()} 个\")\n",
    "            test_data_scaled = np.nan_to_num(test_data_scaled, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            print(f\"缩放后 - 处理后的 NaN: {np.isnan(test_data_scaled).sum()} 个\")\n",
    "        \n",
    "        # 最终检查\n",
    "        assert not np.isnan(test_data_scaled).any(), \"数据中仍有 NaN!\"\n",
    "        assert not np.isinf(test_data_scaled).any(), \"数据中仍有 inf!\"\n",
    "        print(f\"✓ 数据验证通过，shape: {test_data_scaled.shape}\")\n",
    "        \n",
    "        # 加载模型并预测\n",
    "        predictions = {}\n",
    "        model_files = {\n",
    "            'ridge': f'{model_dir}/ridge_model.pkl',\n",
    "            'lasso': f'{model_dir}/lasso_model.pkl',\n",
    "            'elasticnet': f'{model_dir}/elasticnet_model.pkl',\n",
    "            'xgboost': f'{model_dir}/xgboost_model.pkl',\n",
    "            'lightgbm': f'{model_dir}/lightgbm_model.pkl'\n",
    "        }\n",
    "        \n",
    "        for model_name, model_file in model_files.items():\n",
    "            if not os.path.exists(model_file):\n",
    "                print(f\"警告: 找不到 {model_name} 模型文件\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\n加载{model_name.upper()}模型...\")\n",
    "            model = joblib.load(model_file)\n",
    "            \n",
    "            preds = model.predict(test_data_scaled)\n",
    "            preds = np.maximum(preds, 0)  # 确保非负\n",
    "            \n",
    "            predictions[model_name.upper()] = preds\n",
    "            print(f\"{model_name.upper()} 预测范围: [{preds.min():.2f}, {preds.max():.2f}]\")\n",
    "        \n",
    "        # 保存预测结果\n",
    "        self.predictions[data_type] = {\n",
    "            'df': original_test_df,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{data_type}数据集预测完成!\")\n",
    "    \n",
    "    def feature_engineering(self, df):\n",
    "        \"\"\"与训练时相同的特征工程\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 基础特征\n",
    "        if 'bedrooms' in df.columns and 'bathrooms' in df.columns:\n",
    "            df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n",
    "            df['bed_bath_ratio'] = df['bedrooms'] / (df['bathrooms'] + 1)\n",
    "        \n",
    "        if 'sqft' in df.columns:\n",
    "            df['sqft_log'] = np.log1p(df['sqft'])\n",
    "            if 'bedrooms' in df.columns:\n",
    "                df['sqft_per_bedroom'] = df['sqft'] / (df['bedrooms'] + 1)\n",
    "        \n",
    "        # 地理特征\n",
    "        if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "            df['lat_lon_ratio'] = df['latitude'] / (np.abs(df['longitude']) + 1)\n",
    "            df['distance_to_center'] = np.sqrt(\n",
    "                (df['latitude'] - df['latitude'].mean())**2 + \n",
    "                (df['longitude'] - df['longitude'].mean())**2\n",
    "            )\n",
    "        \n",
    "        # 类别特征编码\n",
    "        categorical_features = ['state', 'type']\n",
    "        for col in categorical_features:\n",
    "            if col in df.columns:\n",
    "                freq = df[col].value_counts(normalize=True)\n",
    "                df[f'{col}_freq'] = df[col].map(freq)\n",
    "                # 处理新类别\n",
    "                df[f'{col}_freq'].fillna(0, inplace=True)\n",
    "        \n",
    "        # One-hot编码\n",
    "        if 'state' in df.columns:\n",
    "            state_dummies = pd.get_dummies(df['state'], prefix='state', drop_first=True)\n",
    "            df = pd.concat([df, state_dummies], axis=1)\n",
    "        \n",
    "        if 'type' in df.columns:\n",
    "            type_dummies = pd.get_dummies(df['type'], prefix='type', drop_first=True)\n",
    "            df = pd.concat([df, type_dummies], axis=1)\n",
    "        \n",
    "        # 替换所有 inf 值\n",
    "        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def save_predictions(self, output_dir):\n",
    "        \"\"\"保存预测结果\"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # 保存租房预测\n",
    "        if 'rent' in self.predictions:\n",
    "            rent_preds = self.predictions['rent']\n",
    "            print(f\"\\n保存租房预测结果...\")\n",
    "            \n",
    "            for model_name, preds in rent_preds['predictions'].items():\n",
    "                output_file = f\"{output_dir}/rent_predictions_{model_name.lower()}.csv\"\n",
    "                result_df = pd.DataFrame({\n",
    "                    'id': rent_preds['df']['id'],\n",
    "                    'rent': preds\n",
    "                })\n",
    "                result_df.to_csv(output_file, index=False)\n",
    "                print(f\"✓ {output_file}\")\n",
    "        \n",
    "        # 保存售房预测\n",
    "        if 'price' in self.predictions:\n",
    "            price_preds = self.predictions['price']\n",
    "            print(f\"\\n保存售房预测结果...\")\n",
    "            \n",
    "            for model_name, preds in price_preds['predictions'].items():\n",
    "                output_file = f\"{output_dir}/price_predictions_{model_name.lower()}.csv\"\n",
    "                result_df = pd.DataFrame({\n",
    "                    'id': price_preds['df']['id'],\n",
    "                    'price': preds\n",
    "                })\n",
    "                result_df.to_csv(output_file, index=False)\n",
    "                print(f\"✓ {output_file}\")\n",
    "        \n",
    "        # 创建Kaggle提交文件 (使用集成预测)\n",
    "        if 'rent' in self.predictions and 'price' in self.predictions:\n",
    "            print(f\"\\n创建Kaggle提交文件...\")\n",
    "            \n",
    "            rent_preds = self.predictions['rent']\n",
    "            price_preds = self.predictions['price']\n",
    "            \n",
    "            # 使用所有模型的平均值\n",
    "            rent_ensemble = np.mean(list(rent_preds['predictions'].values()), axis=0)\n",
    "            price_ensemble = np.mean(list(price_preds['predictions'].values()), axis=0)\n",
    "            \n",
    "            submission_df = pd.concat([\n",
    "                pd.DataFrame({'id': rent_preds['df']['id'], 'rent': rent_ensemble, 'price': np.nan}),\n",
    "                pd.DataFrame({'id': price_preds['df']['id'], 'rent': np.nan, 'price': price_ensemble})\n",
    "            ], ignore_index=True)\n",
    "            \n",
    "            submission_file = f\"{output_dir}/kaggle_submission.csv\"\n",
    "            submission_df.to_csv(submission_file, index=False)\n",
    "            print(f\"✓ {submission_file}\")\n",
    "            print(f\"\\n提交文件统计:\")\n",
    "            print(f\"  - 租房预测: {(~submission_df['rent'].isna()).sum()} 条\")\n",
    "            print(f\"  - 售房预测: {(~submission_df['price'].isna()).sum()} 条\")\n",
    "            print(f\"  - 总计: {len(submission_df)} 条\")\n",
    "\n",
    "predictor = PredictionGenerator()\n",
    "\n",
    "# 生成租房预测\n",
    "predictor.generate_predictions(\n",
    "    test_file=CONFIG['rent_test_file'],\n",
    "    model_dir=CONFIG['rent_models_dir'],\n",
    "    scaler_file=f\"{CONFIG['rent_train_dir']}/feature_scaler.pkl\",\n",
    "    feature_columns_file=f\"{CONFIG['rent_train_dir']}/feature_columns.csv\",\n",
    "    data_type='rent'\n",
    ")\n",
    "\n",
    "# 生成售房预测\n",
    "predictor.generate_predictions(\n",
    "    test_file=CONFIG['price_test_file'],\n",
    "    model_dir=CONFIG['price_models_dir'],\n",
    "    scaler_file=f\"{CONFIG['price_train_dir']}/feature_scaler.pkl\",\n",
    "    feature_columns_file=f\"{CONFIG['price_train_dir']}/feature_columns.csv\",\n",
    "    data_type='price'\n",
    ")\n",
    "\n",
    "# 保存所有预测文件\n",
    "predictor.save_predictions(CONFIG['predictions_dir'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"所有处理完成!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n生成的文件:\")\n",
    "print(f\"- 租房模型: {CONFIG['rent_models_dir']}/\")\n",
    "print(f\"- 售房模型: {CONFIG['price_models_dir']}/\")\n",
    "print(f\"- 预测文件: {CONFIG['predictions_dir']}/\")\n",
    "print(f\"- Kaggle提交: {CONFIG['predictions_dir']}/kaggle_submission.csv\")\n",
    "print(f\"\\n完成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
