{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6abc07e5-95f0-48f8-af30-6d70e0b22d75",
   "metadata": {},
   "source": [
    "## Price测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c2f15503-b4a3-4ca4-9703-22d915fe30e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 训练集加载成功，编码: utf-8-sig，分隔符: Comma。\n",
      "✅ 测试集加载成功，编码: utf-8-sig，分隔符: Comma。\n",
      "Train shape: (103871, 55)\n",
      "Test shape: (34017, 55)\n",
      "\n",
      "--- 离群值处理结果 ---\n",
      "原始样本数: 103871\n",
      "移除离群值后样本数: 102726 (请报告此数字)\n",
      "\n",
      "--- 修正后的特征 ---\n",
      "数值特征 (20): ['建筑面积', '套内面积', 'lon', 'lat', '房屋总数', '楼栋总数', '绿 化 率', '容 积 率', '物 业 费_均值', '燃气费_均值', '供热费_均值', '停车费用_均值', '建筑年代_均值', '停车位_均值', '总楼层数', '室', '厅', '卫', '套内面积_比', '容积率_sq']\n",
      "分类特征 (19): ['环线', '供电', '供水', '年份', '梯户比例', '产权所属', '房屋朝向', '物业类别', '城市', '板块', '交易权属', '环线位置', '建筑结构', '区域', '装修情况', '楼层位置', '配备电梯', '区县', '供暖']\n",
      "\n",
      "--- 步骤 B (优化): 立即执行预处理 ---\n",
      "--- Transforming Data ---\n",
      "Data transformed. Shape: (102726, 418)\n",
      "\n",
      "--- 步骤 9 (优化): 在已转换数据上运行 GSCV 和评估 ---\n",
      "\n",
      "--- 开始处理: OLS ---\n",
      "--- 拟合 (无 GSCV): OLS ---\n",
      "--- OLS 手动 CV (无 GSCV) ---\n",
      "--- OLS CV MAE: 410888.11 ---\n",
      "  Intercept: 14.3715\n",
      "  Coefficient Stats: Mean=-0.0101, Std=0.7568\n",
      "\n",
      "--- 开始处理: LASSO ---\n",
      "--- 运行 GridSearchCV: LASSO ---\n",
      "Fitting 6 folds for each of 3 candidates, totalling 18 fits\n",
      "✅ LASSO Best Params found: {'alpha': np.float64(0.0001)}\n",
      "--- LASSO CV MAE: 418347.83 ---\n",
      "  Intercept: 13.9289\n",
      "  Coefficient Stats: Mean=0.0111, Std=0.1882\n",
      "\n",
      "--- 开始处理: Ridge ---\n",
      "--- 运行 GridSearchCV: Ridge ---\n",
      "Fitting 6 folds for each of 3 candidates, totalling 18 fits\n",
      "✅ Ridge Best Params found: {'alpha': np.float64(0.01)}\n",
      "--- Ridge CV MAE: 410824.15 ---\n",
      "  Intercept: 14.3632\n",
      "  Coefficient Stats: Mean=-0.0099, Std=0.7424\n",
      "\n",
      "--- 开始处理: ElasticNet ---\n",
      "--- 运行 GridSearchCV: ElasticNet ---\n",
      "Fitting 6 folds for each of 4 candidates, totalling 24 fits\n",
      "✅ ElasticNet Best Params found: {'alpha': np.float64(0.0001), 'l1_ratio': 0.1}\n",
      "--- ElasticNet CV MAE: 416135.28 ---\n",
      "  Intercept: 14.1840\n",
      "  Coefficient Stats: Mean=-0.0004, Std=0.1893\n",
      "\n",
      "--- Determining Best Linear Model (based on Cross-validation MAE) ---\n",
      "最佳模型（基于 CV MAE）: Ridge\n",
      "\n",
      "--- 10. Model Performance Summary (MAE and RMAE for Original Price Level) ---\n",
      "| Metrics           |   In-sample MAE |   In-sample RMAE |   Out-of-sample MAE |   Out-of-sample RMAE |   Cross-validation MAE |   Cross-validation RMAE |\n",
      "|:------------------|----------------:|-----------------:|--------------------:|---------------------:|-----------------------:|------------------------:|\n",
      "| OLS               |          410056 |             0.19 |              405741 |                 0.19 |                 410888 |                    0.19 |\n",
      "| LASSO             |          417957 |             0.2  |              414388 |                 0.19 |                 418348 |                    0.2  |\n",
      "| Best Linear Model |          410019 |             0.19 |              405729 |                 0.19 |                 410824 |                    0.19 |\n",
      "| ElasticNet        |          415565 |             0.2  |              411454 |                 0.19 |                 416135 |                    0.2  |\n",
      "\n",
      "--- Selecting Final Model for Prediction: Ridge ---\n",
      "\n",
      "--- 使用最终模型进行预测: Ridge ---\n",
      "预测的对数价格 (前 5 个): [17.03597019 14.99497064 15.60520153 14.76060152 16.40738321]\n",
      "对数价格统计 (有限值): Min=11.74, Max=17.17, Mean=14.42, Std=0.80\n",
      "最终预测价格 (前 5 个): [25039625.67546035  3252616.58613584  5987600.86705289  2573046.42849863\n",
      " 13354755.99748335]\n",
      "🎯 Prediction file saved as **prediction_price.csv** (使用逗号分隔)\n",
      "📊 Model performance saved as **performance_table_price.csv** (使用逗号分隔)\n"
     ]
    }
   ],
   "source": [
    "# 1️⃣ 环境准备\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer #FunctionTransformer: 用于将自定义函数（如 np.log1p）应用为 Pipeline 中的一个步骤。\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, make_scorer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import clone\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# 🎯自定义指标函数（计算原始价格尺度上的MAE与RMSE）\n",
    "def calculate_mae_rmse_original(y_log_true, y_log_pred):\n",
    "    mae, rmse = np.nan, np.nan\n",
    "    try:\n",
    "        y_log_true_np = np.asarray(y_log_true).flatten()\n",
    "        y_log_pred_np = np.asarray(y_log_pred).flatten()\n",
    "        #清理nan\\inf，防止后续指数计算溢出\n",
    "        log_max = np.log1p(np.finfo(np.float64).max / 10)\n",
    "        y_log_true_np = np.nan_to_num(y_log_true_np, nan=0.0, posinf=log_max, neginf=-700)\n",
    "        y_log_pred_np = np.nan_to_num(y_log_pred_np, nan=0.0, posinf=log_max, neginf=-700)\n",
    "        y_log_true_np = np.clip(y_log_true_np, -700, log_max)\n",
    "        y_log_pred_np = np.clip(y_log_pred_np, -700, log_max)\n",
    "        \n",
    "        y_price_pred = np.expm1(y_log_pred_np)\n",
    "        y_price_true = np.expm1(y_log_true_np)\n",
    "        y_price_pred[y_price_pred < 0] = 0 #价格不能为负，裁剪为0\n",
    "\n",
    "        large_finite_val = np.finfo(np.float64).max / 10\n",
    "        y_price_pred = np.nan_to_num(y_price_pred, nan=0.0, posinf=large_finite_val, neginf=0.0)\n",
    "        y_price_true = np.nan_to_num(y_price_true, nan=0.0, posinf=large_finite_val, neginf=0.0)\n",
    "        y_price_pred = np.clip(y_price_pred, 0, large_finite_val)\n",
    "        y_price_true = np.clip(y_price_true, 0, large_finite_val)\n",
    "\n",
    "        if np.isnan(y_price_pred).any() or np.isnan(y_price_true).any():\n",
    "            y_price_pred = np.nan_to_num(y_price_pred, nan=0.0)\n",
    "            y_price_true = np.nan_to_num(y_price_true, nan=0.0)\n",
    "\n",
    "        mae = mean_absolute_error(y_price_true, y_price_pred)\n",
    "        mse = mean_squared_error(y_price_true, y_price_pred)\n",
    "        if mse < 0 or not np.isfinite(mse): rmse = np.nan\n",
    "        else: rmse = np.sqrt(mse) # 计算RMSE\n",
    "        return mae, rmse\n",
    "    except (ValueError, OverflowError, TypeError) as e:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "# --- 🚀 优化点 1: 重新定义 mae_metric (用于 make_scorer) ---\n",
    "# GridSearchCV 默认认为“分数越高越好”，MAE是一个误差指标，越低越好。\n",
    "def mae_metric(y_log_true, y_log_pred):\n",
    "    \"\"\"指标：返回负 MAE (需最大化)\"\"\"\n",
    "    mae, _ = calculate_mae_rmse_original(y_log_true, y_log_pred)\n",
    "    if np.isnan(mae):\n",
    "        return -np.finfo(np.float64).max \n",
    "    return -mae\n",
    "\n",
    "# --- 🚀 优化点 2: 向量化特征清理函数 ---\n",
    "def clean_complex_features_optimized(df):\n",
    "    \"\"\"执行单位转换、正则提取和初始特征清理 (向量化版本)\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. 单位转换 (不变)\n",
    "    def clean_unit(series, unit):\n",
    "        cleaned = series.astype(str).str.replace(unit, '', regex=False).str.strip()\n",
    "        cleaned = cleaned.replace(['', '暂无', 'null', 'None'], np.nan)\n",
    "        return pd.to_numeric(cleaned, errors='coerce')\n",
    "    \n",
    "    for col, unit in [('建筑面积', '㎡'), ('套内面积', '㎡'), ('房屋总数', '户'), ('楼栋总数', '栋')]:\n",
    "        if col in df.columns:\n",
    "            df[col] = clean_unit(df[col], unit)\n",
    "    if '绿 化 率' in df.columns:\n",
    "        df['绿 化 率'] = clean_unit(df['绿 化 率'], '%')\n",
    "        if df['绿 化 率'] is not None:\n",
    "            df['绿 化 率'] = df['绿 化 率'] / 100\n",
    "\n",
    "    # 2. 提取数字范围均值 (使用 .str.extractall 向量化)\n",
    "    cols_to_extract = ['物 业 费', '燃气费', '供热费', '停车费用', '建筑年代', '停车位']\n",
    "    for col in cols_to_extract:\n",
    "        if col in df.columns:\n",
    "            cleaned_series = df[col].astype(str).replace(['暂无', 'null', 'None', ''], np.nan)\n",
    "            all_nums = cleaned_series.str.extractall(r\"(\\d+(?:\\.\\d+)?)\")[0].astype(float)\n",
    "            avg_series = all_nums.groupby(level=0).mean()\n",
    "            df[f'{col}_均值'] = avg_series\n",
    "            df = df.drop(columns=[col], errors='ignore')\n",
    "    \n",
    "    for col in df.filter(like='_均值').columns:\n",
    "        if df[col].isnull().any():\n",
    "            median_val = df[col].dropna().median()\n",
    "            if pd.isna(median_val): median_val = 0\n",
    "            df[col] = df[col].fillna(median_val)\n",
    "\n",
    "    # 3. 提取楼层\n",
    "    if '所在楼层' in df.columns:\n",
    "        df['楼层位置'] = df['所在楼层'].astype(str).str.extract(r'([A-Za-z\\u4e00-\\u9fa5]+)').fillna('未知')\n",
    "        df['总楼层数'] = pd.to_numeric(df['所在楼层'].astype(str).str.extract(r'\\(共(\\d+)层\\)')[0], errors='coerce').fillna(0).astype(int)\n",
    "        df = df.drop(columns=['所在楼层'])\n",
    "\n",
    "    # 4. 提取户型\n",
    "    if '房屋户型' in df.columns:\n",
    "        df['室'] = pd.to_numeric(df['房屋户型'].astype(str).str.extract(r'(\\d+)室')[0], errors='coerce').fillna(0).astype(int)\n",
    "        df['厅'] = pd.to_numeric(df['房屋户型'].astype(str).str.extract(r'(\\d+)厅')[0], errors='coerce').fillna(0).astype(int)\n",
    "        df['卫'] = pd.to_numeric(df['房屋户型'].astype(str).str.extract(r'(\\d+)卫')[0], errors='coerce').fillna(0).astype(int)\n",
    "        df = df.drop(columns=['房屋户型'])\n",
    "\n",
    "    # 5. 交互项/多项式特征 (不变)\n",
    "    if '建筑面积' in df.columns and '套内面积' in df.columns:\n",
    "        df['建筑面积_clean'] = df['建筑面积'].replace(0, np.nan)\n",
    "        df['套内面积_比'] = (df['套内面积'] / df['建筑面积_clean']).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        df = df.drop(columns=['建筑面积_clean'])\n",
    "    if '容 积 率' in df.columns:\n",
    "        df['容 积 率'] = pd.to_numeric(df['容 积 率'], errors='coerce').fillna(df['容 积 率'].median())\n",
    "        df['容积率_sq'] = df['容 积 率'] ** 2\n",
    "    \n",
    "    # 填充数值型缺失 (对所有数值列进行最终的中位数填充)\n",
    "    for col in df.select_dtypes(include=np.number).columns:\n",
    "        if df[col].isnull().any():\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    # 6. 删除列 (不变)\n",
    "    drop_cols = [\n",
    "        '抵押信息', '别墅类型', '交易时间', '上次交易',\n",
    "        '房屋优势', '核心卖点', '户型介绍', '周边配套', '交通出行', '客户反馈', '产权描述', '房屋用途',\n",
    "        'coord_x', 'coord_y', '物业办公电话', '开发商', '物业公司', '房屋年限',\n",
    "        '停车费用' \n",
    "    ]\n",
    "    df = df.drop(columns=[col for col in drop_cols if col in df.columns], errors='ignore')\n",
    "\n",
    "    # 填充缺失分类特征 (不变)\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = df[col].fillna('缺失')\n",
    "\n",
    "    return df\n",
    "\n",
    "# 2️⃣ 数据读取 (PRICE 文件)\n",
    "TRAIN_SNIPPET = \"ruc_Class25Q2_train_price.csv\"\n",
    "TEST_SNIPPET = \"ruc_Class25Q2_test_price.csv\"\n",
    "TARGET_NAME = \"Price\"\n",
    "TRAIN_ENCODING = 'utf-8-sig'\n",
    "TEST_ENCODING = 'utf-8-sig'\n",
    "\n",
    "# (加载逻辑不变)\n",
    "try:\n",
    "    train_price = pd.read_csv(TRAIN_SNIPPET, low_memory=False, encoding=TRAIN_ENCODING, sep=',')\n",
    "    print(f\"✅ 训练集加载成功，编码: {TRAIN_ENCODING}，分隔符: Comma。\")\n",
    "except Exception:\n",
    "    train_price = pd.read_csv(TRAIN_SNIPPET, low_memory=False, encoding=TRAIN_ENCODING, sep='\\t')\n",
    "    print(f\"✅ 训练集加载成功，编码: {TRAIN_ENCODING}，分隔符: Tab。\")\n",
    "try:\n",
    "    test_price = pd.read_csv(TEST_SNIPPET, low_memory=False, encoding=TEST_ENCODING, sep=',')\n",
    "    print(f\"✅ 测试集加载成功，编码: {TEST_ENCODING}，分隔符: Comma。\")\n",
    "except Exception:\n",
    "    test_price = pd.read_csv(TEST_SNIPPET, low_memory=False, encoding=TEST_ENCODING, sep='\\t')\n",
    "    print(f\"✅ 测试集加载成功，编码: {TEST_ENCODING}，分隔符: Tab。\")\n",
    "\n",
    "train_data = train_price\n",
    "test_data = test_price\n",
    "\n",
    "# 3️⃣ 初步检查与清洗 \n",
    "print(\"Train shape:\", train_data.shape)\n",
    "print(\"Test shape:\", test_data.shape)\n",
    "target = TARGET_NAME\n",
    "if target not in train_data.columns:\n",
    "    raise ValueError(f\"目标变量 '{target}' 不在训练集列中。\")\n",
    "KEEP_COLS = [target, \"物 业 费\", \"停车费用\"]\n",
    "#识别数据泄露特征，排除在KEEP_COLS中的重要列，删除泄露未来信息的列\n",
    "leak_cols = [c for c in train_data.columns if (\"comm\" in c.lower() or \"price\" in c.lower()) and c not in KEEP_COLS]\n",
    "train_data.drop(columns=[col for col in leak_cols if col in train_data.columns], inplace=True, errors='ignore')\n",
    "test_data.drop(columns=[col for col in leak_cols if col in test_data.columns], inplace=True, errors='ignore')\n",
    "\n",
    "all_data = pd.concat([train_data.drop(columns=[target]), test_data], keys=['train', 'test'])\n",
    "all_data_cleaned = clean_complex_features_optimized(all_data) \n",
    "for col in all_data_cleaned.select_dtypes(include='object').columns:\n",
    "    all_data_cleaned[col] = all_data_cleaned[col].astype('category') #所有文本列换为分类数据类型\n",
    "X_train_raw = all_data_cleaned.loc['train'].copy() #训练特征\n",
    "X_test_final = all_data_cleaned.loc['test'].copy() #测试特征\n",
    "y_train_log = np.log1p(train_data[target])\n",
    "y_train_price = train_data[target]\n",
    "\n",
    "# 4️⃣ 离群值处理 \n",
    "Q1 = y_train_log.quantile(0.25)\n",
    "Q3 = y_train_log.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outlier_mask = (y_train_log >= lower_bound) & (y_train_log <= upper_bound)\n",
    "X_train_no_outliers = X_train_raw.loc[outlier_mask].copy()\n",
    "y_train_log_no_outliers = y_train_log.loc[outlier_mask].copy()\n",
    "y_train_price_no_outliers = y_train_price.loc[outlier_mask].copy() #使用掩码过滤离群值对应的样本\n",
    "initial_count = len(train_data)\n",
    "final_count = len(X_train_no_outliers)\n",
    "print(f\"\\n--- 离群值处理结果 ---\")\n",
    "print(f\"原始样本数: {initial_count}\")\n",
    "print(f\"移除离群值后样本数: {final_count} (请报告此数字)\")\n",
    "\n",
    "# 5️⃣ 区分变量类型 \n",
    "auto_numeric_features = X_train_no_outliers.select_dtypes(include=[np.number]).columns.tolist()\n",
    "auto_categorical_features = X_train_no_outliers.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "known_categorical_numerics = ['城市', '区域', '板块', '区县', '年份']\n",
    "categorical_features = list(set(auto_categorical_features + [col for col in known_categorical_numerics if col in X_train_no_outliers.columns])) #set()：去重，避免重复特征/条件判断：只添加数据集中实际存在的特征\n",
    "numeric_features = [f for f in auto_numeric_features if f not in known_categorical_numerics]\n",
    "if 'ID' in numeric_features: numeric_features.remove('ID')\n",
    "if 'ID' in categorical_features: categorical_features.remove('ID')\n",
    "print(f\"\\n--- 修正后的特征 ---\")\n",
    "print(f\"数值特征 ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"分类特征 ({len(categorical_features)}): {categorical_features}\")\n",
    "\n",
    "# 6️⃣ 特征预处理 Pipeline 定义 \n",
    "log_transformer = FunctionTransformer(lambda x: np.log1p(np.maximum(x, 0)), validate=False)\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer1', SimpleImputer(strategy='median')), # 第一步：中位数填充缺失值\n",
    "    ('logtransform', log_transformer),              # 第二步：对数变换\n",
    "    ('imputer2', SimpleImputer(strategy='median')), # 第三步：再次填充，处理变换后可能产生的异常值\n",
    "    ('scaler', StandardScaler())                    # 第四步：标准化，使特征均值为0，方差为1，便于模型优化\n",
    "])\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='缺失')),    # 填充缺失\n",
    "    ('astype_str', FunctionTransformer(lambda x: x.astype(str), validate=False)), # 转字符串\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', max_categories=50)) # 未见过的类别时忽略，避免报错；限制最大类别数，防止维度爆炸\n",
    "])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features), # 数值特征流水线\n",
    "        ('cat', categorical_transformer, categorical_features) # 分类特征流水线\n",
    "    ],\n",
    "    remainder='drop',      # 处理其他列的方式\n",
    "    sparse_threshold=0.3   # 稀疏矩阵阈值\n",
    ")\n",
    "\n",
    "# 7️⃣ 模型定义与超参数（重点步骤）\n",
    "models_base = {\n",
    "    'OLS': LinearRegression(),\n",
    "    'LASSO': Lasso(max_iter=10000, random_state=111),\n",
    "    # --- ⬇️ 核心修正：已删除所有导致崩溃的参数 (tol, random_state, solver) ⬇️ ---\n",
    "    'Ridge': Ridge(max_iter=10000), \n",
    "    'ElasticNet': ElasticNet(max_iter=10000, random_state=111)\n",
    "}\n",
    "\n",
    "# 为需要调优的模型指定超参数的搜索范围\n",
    "param_grids = {\n",
    "    'LASSO': {'alpha': np.logspace(-4, 0, 3)}, #[0.0001, 0.01, 1]产生一系列对数等距的值，搜索alpha常用方法\n",
    "    'Ridge': {'alpha': np.logspace(-2, 2, 3)}, #[0.01, 1, 100]\n",
    "    'ElasticNet': {'alpha': np.logspace(-4, 0, 2), 'l1_ratio': [0.1, 0.9]},\n",
    "}\n",
    "\n",
    "# --- 🚀 优化点 4: 调换顺序，先做预处理 (原步骤 B) ---\n",
    "print(\"\\n--- 步骤 B (优化): 立即执行预处理 ---\")\n",
    "preprocessor_final = clone(preprocessor)\n",
    "preprocessor_final.fit(X_train_no_outliers)\n",
    "print(\"--- Transforming Data ---\")\n",
    "X_full_transformed = preprocessor_final.transform(X_train_no_outliers)\n",
    "X_test_transformed = preprocessor_final.transform(X_test_final)  #将训练数据、测试数据转换为模型可以使用的数值矩阵\n",
    "y_full_log_np = y_train_log_no_outliers.values\n",
    "y_full_price_np = y_train_price_no_outliers.values\n",
    "mean_price = np.mean(y_full_price_np)\n",
    "print(f\"Data transformed. Shape: {X_full_transformed.shape}\")\n",
    "\n",
    "# --- 🚀 优化点 5: 在预处理后的数据上进行 GSCV 和评估 ---\n",
    "print(\"\\n--- 步骤 9 (优化): 在已转换数据上运行 GSCV 和评估 ---\")\n",
    "X_train_transformed, X_valid_transformed, y_train_log_split, y_valid_log_split = train_test_split(\n",
    "    X_full_transformed, y_full_log_np, test_size=0.2, random_state=111\n",
    ")\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=111) #6折交叉验证：平衡偏差/方差\n",
    "custom_mae_scorer = make_scorer(mae_metric, greater_is_better=True) \n",
    "\n",
    "results = []\n",
    "fitted_models = {}\n",
    "\n",
    "for name, model_base in models_base.items():\n",
    "    print(f\"\\n--- 开始处理: {name} ---\")\n",
    "    final_model = clone(model_base)\n",
    "    \n",
    "    if name in param_grids:\n",
    "        print(f\"--- 运行 GridSearchCV: {name} ---\")\n",
    "        gscv = GridSearchCV(\n",
    "            final_model, param_grids[name], scoring=custom_mae_scorer,\n",
    "            cv=kf, n_jobs=-1, verbose=1, refit=True \n",
    "        )\n",
    "        gscv.fit(X_full_transformed, y_full_log_np) #网格搜索交叉验证\n",
    "        print(f\"✅ {name} Best Params found: {gscv.best_params_}\")\n",
    "        cv_mae = -gscv.best_score_  #将结果中提取最佳交叉验证\n",
    "        final_model = gscv.best_estimator_ \n",
    "        fitted_models[name] = final_model\n",
    "        \n",
    "    else: # (OLS 逻辑不变)\n",
    "        print(f\"--- 拟合 (无 GSCV): {name} ---\")\n",
    "        final_model.fit(X_full_transformed, y_full_log_np)\n",
    "        print(f\"--- {name} 手动 CV (无 GSCV) ---\")\n",
    "        fold_mae_scores = []\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_full_transformed, y_full_log_np)):\n",
    "            X_train_fold, X_val_fold = X_full_transformed[train_idx], X_full_transformed[val_idx]\n",
    "            y_train_fold, y_val_fold = y_full_log_np[train_idx], y_full_log_np[val_idx]\n",
    "            fold_model = clone(final_model).fit(X_train_fold, y_train_fold)\n",
    "            y_pred_fold_log = fold_model.predict(X_val_fold)\n",
    "            fold_mae_scores.append(-mae_metric(y_val_fold, y_pred_fold_log))\n",
    "        \n",
    "        cv_mae = np.nanmean(fold_mae_scores)\n",
    "        fitted_models[name] = final_model\n",
    "\n",
    "    print(f\"--- {name} CV MAE: {cv_mae:.2f} ---\")\n",
    "\n",
    "    # --- 性能计算 (In-sample / Out-of-sample) ---\n",
    "    try:\n",
    "        y_pred_train_log = final_model.predict(X_train_transformed)\n",
    "        mae_train, _ = calculate_mae_rmse_original(y_train_log_split, y_pred_train_log)\n",
    "    except Exception: mae_train = np.nan\n",
    "    try:\n",
    "        y_pred_valid_log = final_model.predict(X_valid_transformed)\n",
    "        mae_valid, _ = calculate_mae_rmse_original(y_valid_log_split, y_pred_valid_log)\n",
    "    except Exception: mae_valid = np.nan\n",
    "    \n",
    "    results.append({\n",
    "        \"Metrics\": name,\n",
    "        \"In-sample MAE\": mae_train,     # 训练集性能\n",
    "        \"In-sample RMAE\": mae_train / mean_price if mean_price != 0 else np.nan,\n",
    "        \"Out-of-sample MAE\": mae_valid, # 验证集性能\n",
    "        \"Out-of-sample RMAE\": mae_valid / mean_price if mean_price != 0 else np.nan,\n",
    "        \"Cross-validation MAE\": cv_mae, # 交叉验证性能\n",
    "        \"Cross-validation RMAE\": cv_mae / mean_price if mean_price != 0 and not np.isnan(cv_mae) else np.nan\n",
    "    })\n",
    "    \n",
    "    # 诊断 (不变)\n",
    "    print(f\"  Intercept: {final_model.intercept_:.4f}\")\n",
    "    if hasattr(final_model, 'coef_'):\n",
    "        coefs = final_model.coef_\n",
    "        if issparse(coefs): coefs = coefs.toarray().flatten()\n",
    "        print(f\"  Coefficient Stats: Mean={np.mean(coefs):.4f}, Std={np.std(coefs):.4f}\")\n",
    "        if np.allclose(coefs, 0, atol=1e-5):\n",
    "            print(f\"  ⚠️ 警告: 模型 {name} 的系数几乎全为零！\")\n",
    "\n",
    "# 🔟 输出结果表 (不变)\n",
    "result_df = pd.DataFrame(results)\n",
    "print(\"\\n--- Determining Best Linear Model (based on Cross-validation MAE) ---\")\n",
    "valid_cv_mae_indices = result_df[\"Cross-validation MAE\"].dropna().index\n",
    "best_model_name_final = 'OLS'\n",
    "if not valid_cv_mae_indices.empty:\n",
    "    best_model_idx = result_df.loc[valid_cv_mae_indices, \"Cross-validation MAE\"].idxmin() #在所有有效的交叉验证 MAE 中，找到最小值对应的索引。.idxmin() 函数返回最小值的索引。\n",
    "    best_model_name_orig = result_df.loc[best_model_idx, \"Metrics\"] #根据找到的最小MAE的索引，从\"Metrics\"列中获取该模型的原始名称（比如'Ridge'）。\n",
    "    if best_model_name_orig in fitted_models and fitted_models[best_model_name_orig] is not None: #检查这个找到的最佳模型（比如 'Ridge'）是否在前一步骤中成功训练并被保存在了fitted_models字典里。\n",
    "        #如果成功了\n",
    "        result_df.loc[result_df['Metrics'] == best_model_name_orig, 'Metrics'] = 'Best Linear Model' #在result_df中，将这个最佳模型的名字（比如 'Ridge'）重命名为'Best Linear Model'，方便在最终表格中识别。\n",
    "        best_model_name_final = best_model_name_orig \n",
    "        print(f\"最佳模型（基于 CV MAE）: {best_model_name_final}\")\n",
    "    else:\n",
    "        #如果失败了\n",
    "        print(f\"警告: 确定的最佳模型 '{best_model_name_orig}' (CV MAE) 训练失败或不存在。正在回退。\")\n",
    "        available_models = [m for m in ['OLS', 'Ridge', 'LASSO', 'ElasticNet'] if m in fitted_models and fitted_models[m] is not None]\n",
    "        #创建一个列表，包含所有成功训练的模型，按 OLS, Ridge, LASSO, ElasticNet 的优先顺序排列。\n",
    "        if available_models: #如果至少有一个模型成功训练了\n",
    "            best_model_name_final = available_models[0] #选择列表中的第一个（即优先级最高的）可用模型作为备选的最佳模型\n",
    "            print(f\"回退到第一个可用模型: {best_model_name_final}\")\n",
    "            #在result_df中将这个备选模型的名字重命名为 'Best Linear Model (Fallback)'。\n",
    "            if best_model_name_final in result_df['Metrics'].values:\n",
    "                result_df.loc[result_df['Metrics'] == best_model_name_final, 'Metrics'] = 'Best Linear Model (Fallback)'\n",
    "            else: #如果所有模型都训练失败了，打印错误信息。\n",
    "                fallback_idx = next((i for i, r in enumerate(results) if r['Metrics'] == best_model_name_final), None)\n",
    "                if fallback_idx is not None:\n",
    "                    result_df.loc[fallback_idx, 'Metrics'] = 'Best Linear Model (Fallback)'\n",
    "        else:\n",
    "            print(\"错误: 所有模型训练失败。无法确定最佳模型。\")\n",
    "else:\n",
    "    print(\"警告: 所有模型在 Cross-validation MAE 上失败。无法确定最佳模型。\")\n",
    "\n",
    "result_df_formatted = result_df.copy() #格式化结果表格：创建 result_df 的一个副本，以免修改原始数据\n",
    "for col in result_df_formatted.columns:\n",
    "    if 'MAE' in col:\n",
    "        result_df_formatted[col] = result_df_formatted[col].apply(lambda x: f\"{x:.2f}\" if pd.notna(x) else 'NaN')\n",
    "    #将该列中的数值格式化为保留两位小数的字符串。如果是缺失值 (NaN)，则显示 'NaN'\n",
    "    elif 'RMAE' in col:\n",
    "        result_df_formatted[col] = result_df_formatted[col].apply(lambda x: f\"{x:.4f}\" if pd.notna(x) else 'NaN')\n",
    "    #将该列中的数值格式化为保留四位小数的字符串。如果是缺失值 (NaN)，则显示 'NaN'。\n",
    "print(\"\\n--- 10. Model Performance Summary (MAE and RMAE for Original Price Level) ---\")\n",
    "print(result_df_formatted.to_markdown(index=False))\n",
    "\n",
    "\n",
    "# 🔟➕1️⃣ 选择最优模型 (不变)\n",
    "print(f\"\\n--- Selecting Final Model for Prediction: {best_model_name_final} ---\")\n",
    "if best_model_name_final in fitted_models and fitted_models[best_model_name_final] is not None:\n",
    "    best_model = fitted_models[best_model_name_final] #如果上述检查通过（即最佳模型确实成功训练了），就从 fitted_models 字典中取出那个训练好的模型对象（比如训练好的 Ridge 实例），并将其赋值给变量 best_model。\n",
    "    best_model_name_predict = best_model_name_final #记录下实际用于预测的模型名称\n",
    "else: #稳健性设计\n",
    "    available_models = [m for m in ['Ridge', 'OLS', 'LASSO', 'ElasticNet'] if m in fitted_models and fitted_models[m] is not None]\n",
    "    if available_models:\n",
    "        best_model_name_predict = available_models[0] #选择列表中第一个（即优先级最高的）成功训练的模型作为备选预测模型。\n",
    "        best_model = fitted_models[best_model_name_predict]\n",
    "        print(f\"警告: CV MAE 最佳模型 '{best_model_name_final}' 失败或不可用，回退到第一个可用的模型: {best_model_name_predict}。\")\n",
    "    else:\n",
    "        raise RuntimeError(\"所有模型训练失败，无法继续进行预测。\")\n",
    "\n",
    "\n",
    "# 🔟➕2️⃣ 预测测试集 (不变)\n",
    "try:\n",
    "    print(f\"\\n--- 使用最终模型进行预测: {best_model_name_predict} ---\")\n",
    "    \n",
    "    input_data_is_sparse = issparse(X_test_transformed) #检查输入的测试数据是否是稀疏矩阵格式\n",
    "    input_data_nan = (input_data_is_sparse and np.isnan(X_test_transformed.data).any()) or \\\n",
    "                     (not input_data_is_sparse and np.isnan(X_test_transformed).any())\n",
    "    input_data_inf = (input_data_is_sparse and np.isinf(X_test_transformed.data).any()) or \\\n",
    "                     (not input_data_is_sparse and np.isinf(X_test_transformed).any())\n",
    "    if input_data_nan or input_data_inf:\n",
    "        print(\"警告：最终预测前在 X_test_transformed 中检测到 NaN/Inf，尝试填充 0。\")\n",
    "        if input_data_is_sparse:\n",
    "            X_test_transformed.data = np.nan_to_num(X_test_transformed.data, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        else:\n",
    "            X_test_transformed = np.nan_to_num(X_test_transformed, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    test_pred_log = best_model.predict(X_test_transformed) #使用选定的 best_model 对处理后的测试数据 X_test_transformed 进行预测\n",
    "\n",
    "    # (诊断逻辑不变)\n",
    "    print(f\"预测的对数价格 (前 5 个): {test_pred_log[:5]}\")\n",
    "    finite_preds = test_pred_log[np.isfinite(test_pred_log)]\n",
    "    if finite_preds.size > 0:\n",
    "        print(f\"对数价格统计 (有限值): Min={np.min(finite_preds):.2f}, Max={np.max(finite_preds):.2f}, Mean={np.mean(finite_preds):.2f}, Std={np.std(finite_preds):.2f}\")\n",
    "    if np.isnan(test_pred_log).any() or np.isinf(test_pred_log).any():\n",
    "        print(\"❌ 警告: 预测的对数价格包含 NaN 或 Inf！正在尝试清理...\")\n",
    "        median_log_pred = np.nanmedian(finite_preds) if finite_preds.size > 0 else np.log1p(np.median(y_train_price_no_outliers))\n",
    "        test_pred_log = np.nan_to_num(test_pred_log, nan=median_log_pred, posinf=np.log1p(np.finfo(np.float64).max / 10), neginf=-700)\n",
    "    #逆转换回原始价格尺度与最终清理\n",
    "    test_pred_price = np.expm1(test_pred_log) #对数尺度的预测值 test_pred_log 转换回原始的价格尺度\n",
    "    test_pred_price[test_pred_price < 0] = 0\n",
    "    large_finite_val = np.finfo(np.float64).max / 10 #数值上限\n",
    "    median_fallback = np.median(y_train_price_no_outliers) if len(y_train_price_no_outliers)>0 else 0 #计算训练集原始价格的中位数，作为最终的备用值。\n",
    "    test_pred_price = np.nan_to_num(test_pred_price, nan=median_fallback,\n",
    "                                      posinf=large_finite_val, neginf=0.0) #对价格尺度的预测值进行最后一次清理，替换可能因 expm1 产生的 NaN 或 Inf，并将超出极大范围的值替换掉。\n",
    "    test_pred_price = np.clip(test_pred_price, 0, large_finite_val) #将所有预测值限制在 0 和 large_finite_val 之间，确保数值的合理性。\n",
    "    print(f\"最终预测价格 (前 5 个): {test_pred_price[:5]}\")\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"最终预测出错: {e}\")\n",
    "    traceback.print_exc()\n",
    "    median_fallback = np.median(y_train_price_no_outliers) if len(y_train_price_no_outliers)>0 else 0\n",
    "    print(f\"预测失败，回退到预测中位数: {median_fallback}\")\n",
    "    test_pred_price = np.full(X_test_transformed.shape[0], median_fallback) #创建一个数组，其长度与测试集样本数相同，并将所有预测值都设置为这个 median_fallback\n",
    "\n",
    "# 🔟➕3️⃣ 生成提交文件 (使用您已修正的路径)\n",
    "submission_df = pd.DataFrame({\n",
    "    \"ID\": test_data['ID'].values if 'ID' in test_data.columns and len(test_data['ID']) == X_test_transformed.shape[0] else np.arange(X_test_transformed.shape[0]),\n",
    "    \"prediction\": test_pred_price\n",
    "})\n",
    "submission_df.to_csv(\"prediction_price.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"🎯 Prediction file saved as **prediction_price.csv** (使用逗号分隔)\")\n",
    "\n",
    "# 🔟➕4️⃣ 保存模型性能表 (使用您已修正的路径)\n",
    "result_df.to_csv(\"performance_table_price.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"📊 Model performance saved as **performance_table_price.csv** (使用逗号分隔)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229032cc-cf66-4443-8011-dfbd063d7ad1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 关于租价预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fca45fbb-a88d-42db-9857-68d59a9e7b9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 训练集加载成功，编码: UTF-8，分隔符: Comma。\n",
      "✅ 测试集加载成功，编码: UTF-8，分隔符: Comma。\n",
      "Train shape: (98899, 46)\n",
      "Test shape: (9773, 46)\n",
      "\n",
      "--- 离群值处理结果 ---\n",
      "原始样本数: 98899\n",
      "移除离群值后样本数: 98205 (请报告此数字)\n",
      "\n",
      "--- 修正后的特征 ---\n",
      "数值特征 (19): ['面积', 'lon', 'lat', '房屋总数', '楼栋总数', '绿 化 率', '容 积 率', '物 业 费_均值', '燃气费_均值', '供热费_均值', '停车费用_均值', '建筑年代_均值', '停车位_均值', '总楼层数', '室', '厅', '卫', '面积_sq', '容积率_sq']\n",
      "分类特征 (18): ['燃气', '用水', '朝向', '用电', '环线位置', '供电', '楼层位置', '物业类别', '城市', '建筑结构', '车位', '供水', '区县', '采暖', '年份', '板块', '电梯', '供暖']\n",
      "\n",
      "--- 9. 模型训练、超参数调优 (GridSearchCV) 与评估 (手动 CV) ---\n",
      "\n",
      "--- 步骤 A: 使用 GridSearchCV 寻找最佳参数 ---\n",
      "✅ OLS 不需要 GridSearchCV。\n",
      "\n",
      "--- 开始 GridSearchCV: LASSO ---\n",
      "Fitting 6 folds for each of 3 candidates, totalling 18 fits\n",
      "✅ LASSO Best Params found: {'model__alpha': np.float64(0.0001)}\n",
      "\n",
      "--- 开始 GridSearchCV: Ridge ---\n",
      "Fitting 6 folds for each of 3 candidates, totalling 18 fits\n",
      "✅ Ridge Best Params found: {'model__alpha': np.float64(0.01)}\n",
      "\n",
      "--- 开始 GridSearchCV: ElasticNet ---\n",
      "Fitting 6 folds for each of 4 candidates, totalling 24 fits\n",
      "✅ ElasticNet Best Params found: {'model__alpha': np.float64(0.0001), 'model__l1_ratio': 0.1}\n",
      "\n",
      "--- 步骤 B: 分离预处理 ---\n",
      "--- Transforming Data ---\n",
      "Data transformed. Shape: (98205, 301)\n",
      "\n",
      "--- 步骤 C: 使用最佳参数训练模型并手动 CV 评估 ---\n",
      "--- Fitting OLS ---\n",
      "✅ OLS Trained using best/default params: {'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'positive': False}\n",
      "   Intercept: 12.8462\n",
      "   Coefficient Stats: Mean=0.0010, Std=0.3911, Min=-4.0894, Max=4.4693\n",
      "--- 开始手动 6-Fold Cross-Validation: OLS ---\n",
      "--- OLS Manual CV finished. Average MAE: 104894.02051643231 ---\n",
      "--- Fitting LASSO ---\n",
      "✅ LASSO Trained using best/default params: {'alpha': np.float64(0.0001), 'copy_X': True, 'fit_intercept': True, 'max_iter': 10000, 'positive': False, 'precompute': False, 'random_state': 111, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}\n",
      "   Intercept: 12.6577\n",
      "   Coefficient Stats: Mean=0.0134, Std=0.1994, Min=-1.2823, Max=1.6636\n",
      "--- 开始手动 6-Fold Cross-Validation: LASSO ---\n",
      "--- LASSO Manual CV finished. Average MAE: 106126.39284800114 ---\n",
      "--- Fitting Ridge ---\n",
      "✅ Ridge Trained using best/default params: {'alpha': np.float64(0.01), 'copy_X': True, 'fit_intercept': True, 'max_iter': 10000, 'positive': False, 'random_state': 111, 'solver': 'sag', 'tol': 0.001}\n",
      "   Intercept: 12.9164\n",
      "   Coefficient Stats: Mean=0.0014, Std=0.3669, Min=-3.7660, Max=4.1450\n",
      "--- 开始手动 6-Fold Cross-Validation: Ridge ---\n",
      "--- Ridge Manual CV finished. Average MAE: 105069.15781744685 ---\n",
      "--- Fitting ElasticNet ---\n",
      "✅ ElasticNet Trained using best/default params: {'alpha': np.float64(0.0001), 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 10000, 'positive': False, 'precompute': False, 'random_state': 111, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}\n",
      "   Intercept: 12.9115\n",
      "   Coefficient Stats: Mean=0.0028, Std=0.1915, Min=-1.1394, Max=1.5203\n",
      "--- 开始手动 6-Fold Cross-Validation: ElasticNet ---\n",
      "--- ElasticNet Manual CV finished. Average MAE: 105683.17946456534 ---\n",
      "\n",
      "--- Determining Best Linear Model (based on Cross-validation MAE) ---\n",
      "最佳模型（基于 CV MAE）: OLS\n",
      "\n",
      "--- 10. Model Performance Summary (MAE and RMAE for Original Rent Level) ---\n",
      "| Metrics           |   In-sample MAE |   In-sample RMAE |   Out-of-sample MAE |   Out-of-sample RMAE |   Cross-validation MAE |   Cross-validation RMAE |\n",
      "|:------------------|----------------:|-----------------:|--------------------:|---------------------:|-----------------------:|------------------------:|\n",
      "| Best Linear Model |          104515 |             0.19 |              104587 |                 0.19 |                 104894 |                    0.19 |\n",
      "| LASSO             |          105819 |             0.19 |              106099 |                 0.19 |                 106126 |                    0.19 |\n",
      "| Ridge             |          104717 |             0.19 |              104800 |                 0.19 |                 105069 |                    0.19 |\n",
      "| ElasticNet        |          105344 |             0.19 |              105516 |                 0.19 |                 105683 |                    0.19 |\n",
      "\n",
      "--- Selecting Final Model based on CV MAE: OLS ---\n",
      "\n",
      "--- 使用最终模型进行预测: OLS ---\n",
      "预测的对数价格 (前 5 个): [12.02437078 13.03284144 12.98116211 14.31975746 13.7928045 ]\n",
      "对数价格统计 (有限值): Min=10.81, Max=15.45, Mean=12.94, Std=0.70\n",
      "最终预测价格 (前 5 个): [ 166768.98017207  457183.10478763  434156.26383824 1655737.1221806\n",
      "  977548.78618685]\n",
      "🎯 Prediction file saved as **prediction_rent.csv** (使用逗号分隔)\n",
      "📊 Model performance saved as **performance_table_rent.csv** (使用逗号分隔)\n"
     ]
    }
   ],
   "source": [
    "# 1️⃣ 环境准备\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "# Add scipy sparse matrix check\n",
    "from scipy.sparse import issparse # 从 scipy.sparse 模块导入 issparse 函数，用于检查数据是否是稀疏矩阵格式\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer \n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline # Pipeline 用于定义转换器和 GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, make_scorer # 导入 make_scorer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import clone # 需要 clone\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# 🎯自定义指标函数\n",
    "# (calculate_mae_rmse_original 函数保持不变，包含健壮性处理) \n",
    "def calculate_mae_rmse_original(y_log_true, y_log_pred):\n",
    "    mae, rmse = np.nan, np.nan\n",
    "    try:\n",
    "        y_log_true_np = np.asarray(y_log_true).flatten()\n",
    "        y_log_pred_np = np.asarray(y_log_pred).flatten()\n",
    "\n",
    "        log_max = np.log1p(np.finfo(np.float64).max / 10)\n",
    "        y_log_true_np = np.nan_to_num(y_log_true_np, nan=0.0, posinf=log_max, neginf=-700)\n",
    "        y_log_pred_np = np.nan_to_num(y_log_pred_np, nan=0.0, posinf=log_max, neginf=-700) \n",
    "        y_log_true_np = np.clip(y_log_true_np, -700, log_max)\n",
    "        y_log_pred_np = np.clip(y_log_pred_np, -700, log_max)\n",
    "\n",
    "        y_price_pred = np.expm1(y_log_pred_np) #进行指数运算的逆操作：使用 np.expm1(x) 函数（计算 exp(x) - 1）将清理过的**预测对数值**转换回**原始价格尺度**。这是 np.log1p() 的精确逆运算。\n",
    "        y_price_true = np.expm1(y_log_true_np)\n",
    "        y_price_pred[y_price_pred < 0] = 0\n",
    "\n",
    "        large_finite_val = np.finfo(np.float64).max / 10\n",
    "        y_price_pred = np.nan_to_num(y_price_pred, nan=0.0, posinf=large_finite_val, neginf=0.0)\n",
    "        y_price_true = np.nan_to_num(y_price_true, nan=0.0, posinf=large_finite_val, neginf=0.0)\n",
    "        y_price_pred = np.clip(y_price_pred, 0, large_finite_val)\n",
    "        y_price_true = np.clip(y_price_true, 0, large_finite_val)\n",
    "\n",
    "        if np.isnan(y_price_pred).any() or np.isnan(y_price_true).any():\n",
    "             y_price_pred = np.nan_to_num(y_price_pred, nan=0.0)\n",
    "             y_price_true = np.nan_to_num(y_price_true, nan=0.0)\n",
    "\n",
    "        mae = mean_absolute_error(y_price_true, y_price_pred)\n",
    "        mse = mean_squared_error(y_price_true, y_price_pred)\n",
    "        if mse < 0 or not np.isfinite(mse): rmse = np.nan\n",
    "        else: rmse = np.sqrt(mse)\n",
    "        return mae, rmse\n",
    "    except (ValueError, OverflowError, TypeError) as e:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "# 自定义 MAE 评分器 (用于 GridSearchCV)\n",
    "def mae_scorer(estimator, X, y_log_true):\n",
    "    \"\"\"评分器：返回负 MAE (需最大化)\"\"\"\n",
    "    y_log_pred = estimator.predict(X)\n",
    "    mae, _ = calculate_mae_rmse_original(y_log_true, y_log_pred)\n",
    "    if np.isnan(mae):\n",
    "        return -np.finfo(np.float64).max # 返回极差分数\n",
    "    return -mae\n",
    "\n",
    "# ⚙️ 复杂特征清理函数 (核心修正：适配 RENT 并保留关键特征)\n",
    "def clean_complex_features(df):\n",
    "    \"\"\"执行单位转换、正则提取和初始特征清理。已针对 RENT 数据集列名适配。\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1. 单位转换\n",
    "    def clean_unit(series, unit):\n",
    "        cleaned = series.astype(str).str.replace(unit, '', regex=False).str.strip()\n",
    "        cleaned = cleaned.replace(['', '暂无', 'null', 'None'], np.nan)\n",
    "        return pd.to_numeric(cleaned, errors='coerce')\n",
    "\n",
    "    # *** 适配 RENT: '面积', '房屋总数', '楼栋总数' ***\n",
    "    for col, unit in [('面积', '㎡'), ('房屋总数', '户'), ('楼栋总数', '栋')]:\n",
    "        if col in df.columns:\n",
    "            df[col] = clean_unit(df[col], unit)\n",
    "    if '绿 化 率' in df.columns:\n",
    "        df['绿 化 率'] = clean_unit(df['绿 化 率'], '%')\n",
    "        if df['绿 化 率'] is not None:\n",
    "            df['绿 化 率'] = df['绿 化 率'] / 100\n",
    "\n",
    "    # 2. 提取数字范围均值\n",
    "    def extract_avg_value(text):\n",
    "        if pd.isna(text) or str(text).strip() in ['暂无', 'null', 'None','']: return np.nan\n",
    "        match = re.findall(r\"(\\d+(?:\\.\\d+)?)\", str(text)) ## 使用正则表达式查找文本中的所有数字（包括整数和小数）\n",
    "        nums = [float(n) for n in match]\n",
    "        return np.mean(nums) if nums else np.nan\n",
    "\n",
    "    # 适配 RENT: 确保 '停车位' 和 '停车费用' 都被清理\n",
    "    for col in ['物 业 费', '燃气费', '供热费', '停车费用', '建筑年代', '停车位']:\n",
    "        if col in df.columns:\n",
    "            df[f'{col}_均值'] = df[col].apply(extract_avg_value)\n",
    "            df = df.drop(columns=[col], errors='ignore')\n",
    "    \n",
    "    for col in df.filter(like='_均值').columns:\n",
    "         if df[col].isnull().any():\n",
    "             median_val = df[col].dropna().median()\n",
    "             if pd.isna(median_val): median_val = 0\n",
    "             df[col] = df[col].fillna(median_val)\n",
    "\n",
    "    # 3. 提取楼层 (适配 RENT 列名 '楼层' 和格式 \"低楼层/18层\")\n",
    "    if '楼层' in df.columns:\n",
    "        df['楼层位置'] = df['楼层'].astype(str).str.extract(r'([A-Za-z\\u4e00-\\u9fa5]+)').fillna('未知')\n",
    "        df['总楼层数'] = pd.to_numeric(df['楼层'].astype(str).str.extract(r'/(\\d+)层')[0], errors='coerce').fillna(0).astype(int)\n",
    "        df = df.drop(columns=['楼层'])\n",
    "    \n",
    "    # 4. 提取户型 (适配 RENT 列名 '户型')\n",
    "    if '户型' in df.columns:\n",
    "        df['室'] = pd.to_numeric(df['户型'].astype(str).str.extract(r'(\\d+)室')[0], errors='coerce').fillna(0).astype(int)\n",
    "        df['厅'] = pd.to_numeric(df['户型'].astype(str).str.extract(r'(\\d+)厅')[0], errors='coerce').fillna(0).astype(int)\n",
    "        df['卫'] = pd.to_numeric(df['户型'].astype(str).str.extract(r'(\\d+)卫')[0], errors='coerce').fillna(0).astype(int)\n",
    "        df = df.drop(columns=['户型'])\n",
    "\n",
    "    # 5. 交互项/多项式特征 (适配 RENT：仅使用 '面积' 和 '容 积 率')\n",
    "    if '面积' in df.columns:\n",
    "        df['面积'] = pd.to_numeric(df['面积'], errors='coerce') # 确保 '面积' 是数值\n",
    "        df['面积_sq'] = df['面积'] ** 2\n",
    "    if '容 积 率' in df.columns:\n",
    "        df['容 积 率'] = pd.to_numeric(df['容 积 率'], errors='coerce').fillna(df['容 积 率'].median())\n",
    "        df['容积率_sq'] = df['容 积 率'] ** 2\n",
    "    \n",
    "    # 修正：对所有数值列填充中位数\n",
    "    for col in df.select_dtypes(include=np.number).columns:\n",
    "        if df[col].isnull().any():\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    # 6. 删除列 (RENT 列表)\n",
    "    # 核心修正：保留 '城市', '板块', '区县', 'lon', 'lat' \n",
    "    drop_cols = [\n",
    "        # RENT 独有需删除的特征\n",
    "        '装修', '交易时间', '付款方式', '租赁方式', '租期', '配套设施', \n",
    "        # '城市', '区域', '板块', '区县', # <-- 保留\n",
    "        # 'lon', 'lat', # <-- 保留\n",
    "        # '房屋总数', '停车位_均值', # <-- 保留\n",
    "        '核心卖点', '户型介绍', '周边配套', '交通出行', '客户反馈', '产权描述', '房屋用途', \n",
    "        'coord_x', 'coord_y', '物业办公电话', '开发商', '物业公司', '房屋年限',\n",
    "        '停车费用'\n",
    "    ]\n",
    "    df = df.drop(columns=[col for col in drop_cols if col in df.columns], errors='ignore')\n",
    "\n",
    "    # 填充缺失分类特征\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "         df[col] = df[col].fillna('缺失')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# 2️⃣ 数据读取 (RENT 文件)\n",
    "TRAIN_SNIPPET = \"ruc_Class25Q2_train_rent.csv\"\n",
    "TEST_SNIPPET = \"ruc_Class25Q2_test_rent.csv\"\n",
    "TARGET_NAME = \"Price\" \n",
    "\n",
    "TRAIN_ENCODING = 'UTF-8'\n",
    "TEST_ENCODING = 'UTF-8'\n",
    "\n",
    "train_rent = None\n",
    "test_rent = None\n",
    "\n",
    "# 核心修正：RENT 训练集优先尝试 Comma (',') 分隔符\n",
    "# 1. 加载训练集\n",
    "try:\n",
    "    train_rent = pd.read_csv(TRAIN_SNIPPET, low_memory=False, encoding=TRAIN_ENCODING, sep=',')\n",
    "    print(f\"✅ 训练集加载成功，编码: {TRAIN_ENCODING}，分隔符: Comma。\")\n",
    "except Exception as e:\n",
    "    try:\n",
    "        train_rent = pd.read_csv(TRAIN_SNIPPET, low_memory=False, encoding=TRAIN_ENCODING, sep='\\t')\n",
    "        print(f\"✅ 训练集加载成功，编码: {TRAIN_ENCODING}，分隔符: Tab。\")\n",
    "    except Exception as e_inner:\n",
    "        print(f\"❌ 训练集加载失败。错误: {e_inner}\")\n",
    "        raise RuntimeError(\"无法加载 RENT 模型的训练集。\")\n",
    "\n",
    "# 2. 加载测试集 (修正：RENT 测试集也优先尝试 Comma (','))\n",
    "try:\n",
    "    test_rent = pd.read_csv(TEST_SNIPPET, low_memory=False, encoding=TEST_ENCODING, sep=',')\n",
    "    print(f\"✅ 测试集加载成功，编码: {TEST_ENCODING}，分隔符: Comma。\")\n",
    "except Exception:\n",
    "    try:\n",
    "        test_rent = pd.read_csv(TEST_SNIPPET, low_memory=False, encoding=TEST_ENCODING, sep='\\t')\n",
    "        print(f\"✅ 测试集加载成功，编码: {TEST_ENCODING}，分隔符: Tab。\")\n",
    "    except Exception as e_inner:\n",
    "         print(f\"❌ 测试集加载失败。错误: {e_inner}\")\n",
    "         raise RuntimeError(\"无法加载 RENT 模型的测试集。\")\n",
    "\n",
    "train_data = train_rent\n",
    "test_data = test_rent\n",
    "\n",
    "\n",
    "# 3️⃣ 初步检查与清洗\n",
    "# (清洗逻辑保持不变)\n",
    "print(\"Train shape:\", train_data.shape)\n",
    "print(\"Test shape:\", test_data.shape)\n",
    "\n",
    "target = TARGET_NAME\n",
    "if target not in train_data.columns:\n",
    "    raise ValueError(f\"目标变量 '{target}' 不在训练集列中。\")\n",
    "\n",
    "KEEP_COLS = [target, \"物 业 费\", \"停车费用\"] # 原始文本列\n",
    "leak_cols_potential = [\n",
    "    c for c in train_data.columns\n",
    "    if \"comm\" in c.lower() or \"price\" in c.lower() or \"rent\" in c.lower() \n",
    "]\n",
    "leak_cols = [c for c in leak_cols_potential if c not in KEEP_COLS] # 从潜在泄露列中，排除掉KEEP_COLS中指定的列，得到最终要删除的泄露列列表。\n",
    "\n",
    "train_data.drop(columns=[col for col in leak_cols if col in train_data.columns],\n",
    "                inplace=True, errors='ignore')\n",
    "#从训练数据中删除leak_cols列表里存在的列。inplace=True表示直接在原 DataFrame上修改。\n",
    "test_data.drop(columns=[col for col in leak_cols if col in test_data.columns],\n",
    "               inplace=True, errors='ignore')\n",
    "\n",
    "all_data = pd.concat([train_data.drop(columns=[target]), test_data], keys=['train', 'test'])\n",
    "all_data_cleaned = clean_complex_features(all_data)\n",
    "\n",
    "for col in all_data_cleaned.select_dtypes(include='object').columns:\n",
    "    all_data_cleaned[col] = all_data_cleaned[col].astype('category')\n",
    "    \n",
    "X_train_raw = all_data_cleaned.loc['train'].copy()\n",
    "X_test_final = all_data_cleaned.loc['test'].copy()\n",
    "\n",
    "y_train_log = np.log1p(train_data[target])\n",
    "y_train_price = train_data[target]\n",
    "\n",
    "# 4️⃣ 离群值处理\n",
    "Q1 = y_train_log.quantile(0.25)\n",
    "Q3 = y_train_log.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outlier_mask = (y_train_log >= lower_bound) & (y_train_log <= upper_bound)\n",
    "X_train_no_outliers = X_train_raw.loc[outlier_mask].copy()\n",
    "y_train_log_no_outliers = y_train_log.loc[outlier_mask].copy()\n",
    "y_train_price_no_outliers = y_train_price.loc[outlier_mask].copy()\n",
    "\n",
    "initial_count = len(train_data)\n",
    "final_count = len(X_train_no_outliers)\n",
    "print(f\"\\n--- 离群值处理结果 ---\")\n",
    "print(f\"原始样本数: {initial_count}\")\n",
    "print(f\"移除离群值后样本数: {final_count} (请报告此数字)\")\n",
    "\n",
    "# 5️⃣ 训练集与验证集划分(保持pandas类型)\n",
    "X_train, X_valid, y_train_log_split, y_valid_log_split = train_test_split(\n",
    "    X_train_no_outliers, y_train_log_no_outliers, test_size=0.2, random_state=111\n",
    ")\n",
    "_, _, y_train_price_split, y_valid_price_split = train_test_split(\n",
    "    X_train_no_outliers, y_train_price_no_outliers, test_size=0.2, random_state=111\n",
    ")\n",
    "\n",
    "# 6️⃣ 区分变量类型 (在完整无离群值数据上定义)\n",
    "# 核心修正：手动定义哪些“数字”列应该是分类的\n",
    "auto_numeric_features = X_train_no_outliers.select_dtypes(include=[np.number]).columns.tolist()\n",
    "auto_categorical_features = X_train_no_outliers.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "known_categorical_numerics = ['城市', '区域', '板块', '区县', '年份'] # '区域' 在 RENT 数据中可能不存在\n",
    "\n",
    "categorical_features = list(set(auto_categorical_features + [col for col in known_categorical_numerics if col in X_train_no_outliers.columns]))\n",
    "numeric_features = [f for f in auto_numeric_features if f not in known_categorical_numerics]\n",
    "# 确保 ID 列（如果存在）不被用作特征\n",
    "if 'ID' in numeric_features:\n",
    "    numeric_features.remove('ID')\n",
    "if 'ID' in categorical_features:\n",
    "    categorical_features.remove('ID')\n",
    "\n",
    "print(f\"\\n--- 修正后的特征 ---\")\n",
    "print(f\"数值特征 ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"分类特征 ({len(categorical_features)}): {categorical_features}\")\n",
    "\n",
    "# 7️⃣ 特征预处理 Pipeline 定义\n",
    "# 核心修正：对数值特征先 Log 变换(处理非负)，再Impute和 Scale\n",
    "log_transformer = FunctionTransformer(lambda x: np.log1p(np.maximum(x, 0)), validate=False)\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer1', SimpleImputer(strategy='median')),\n",
    "    ('logtransform', log_transformer),\n",
    "    ('imputer2', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# 保持放松的 OHE 限制 (max_categories=50)\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='缺失')),\n",
    "    ('astype_str', FunctionTransformer(lambda x: x.astype(str), validate=False)), # 确保 OHE 接收字符串\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', max_categories=50)) # 独热编码\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=0.3\n",
    ")\n",
    "\n",
    "# 8️⃣ 模型定义与超参数 (用于 GridSearchCV - 极速版)\n",
    "# 定义基础模型\n",
    "models_base = {\n",
    "    'OLS': LinearRegression(),\n",
    "    'LASSO': Lasso(max_iter=10000, random_state=111),\n",
    "    'Ridge': Ridge(max_iter=10000, random_state=111, solver='sag', tol=1e-3), # 使用 'sag' 求解器\n",
    "    'ElasticNet': ElasticNet(max_iter=10000, random_state=111)\n",
    "}\n",
    "# 定义最小化的参数网格\n",
    "param_grids = {\n",
    "    'LASSO': {'model__alpha': np.logspace(-4, 0, 3)},\n",
    "    'Ridge': {'model__alpha': np.logspace(-2, 2, 3)},\n",
    "    'ElasticNet': {'model__alpha': np.logspace(-4, 0, 2), 'model__l1_ratio': [0.1, 0.9]},\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_params_found = {} # 存储 GridSearchCV 找到的最佳参数\n",
    "fitted_models = {} # 存储最终拟合的模型 (不是 Pipeline)\n",
    "\n",
    "# 9️⃣ 模型训练与评估 (GridSearchCV 调优 + 分离预处理 + 手动 CV 评估)\n",
    "print(\"\\n--- 9. 模型训练、超参数调优 (GridSearchCV) 与评估 (手动 CV) ---\")\n",
    "full_data_X = X_train_no_outliers\n",
    "full_data_y_log = y_train_log_no_outliers\n",
    "mean_price = np.mean(y_train_price_no_outliers)\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=111)\n",
    "\n",
    "# 创建自定义评分器实例\n",
    "custom_mae_scorer = make_scorer(mae_scorer, greater_is_better=False)\n",
    "\n",
    "# 步骤 A: 使用 GridSearchCV 寻找最佳参数\n",
    "print(\"\\n--- 步骤 A: 使用 GridSearchCV 寻找最佳参数 ---\")\n",
    "for name, model_base in models_base.items():\n",
    "    pipe_for_gridsearch = Pipeline(steps=[('preprocessor', preprocessor), ('model', model_base)])\n",
    "    best_params_found[name] = {}\n",
    "\n",
    "    if name in param_grids:\n",
    "        print(f\"\\n--- 开始 GridSearchCV: {name} ---\")\n",
    "        gscv = GridSearchCV(\n",
    "            pipe_for_gridsearch, param_grids[name], scoring=custom_mae_scorer,\n",
    "            cv=kf, n_jobs=-1, verbose=1\n",
    "        )\n",
    "        try:\n",
    "            gscv.fit(full_data_X, full_data_y_log)\n",
    "            best_params_found[name] = gscv.best_params_\n",
    "            print(f\"✅ {name} Best Params found: {best_params_found[name]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {name} GridSearchCV failed: {e}. 将使用默认参数。\")\n",
    "            best_params_found[name] = {}\n",
    "    else:\n",
    "        print(f\"✅ {name} 不需要 GridSearchCV。\")\n",
    "\n",
    "# 步骤 B: 分离预处理\n",
    "print(\"\\n--- 步骤 B: 分离预处理 ---\")\n",
    "# 1. 拟合预处理器\n",
    "preprocessor_final = clone(preprocessor)\n",
    "preprocessor_final.fit(X_train_no_outliers)\n",
    "# 2. 转换数据\n",
    "print(\"--- Transforming Data ---\")\n",
    "try:\n",
    "    X_full_transformed = preprocessor_final.transform(X_train_no_outliers)\n",
    "    X_train_transformed = preprocessor_final.transform(X_train)\n",
    "    X_valid_transformed = preprocessor_final.transform(X_valid)\n",
    "    X_test_transformed = preprocessor_final.transform(X_test_final)\n",
    "    full_data_y_log_np = y_train_log_no_outliers.values # 转换为 NumPy array\n",
    "    print(f\"Data transformed. Shape: {X_full_transformed.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 错误: 数据转换失败: {e}\")\n",
    "    raise\n",
    "\n",
    "# 步骤 C: 使用最佳参数训练模型并进行手动 CV 评估\n",
    "print(\"\\n--- 步骤 C: 使用最佳参数训练模型并手动 CV 评估 ---\")\n",
    "for name, model_base in models_base.items():\n",
    "    params_for_model = {k.split('__')[1]: v for k, v in best_params_found[name].items()}\n",
    "    \n",
    "    final_model = clone(model_base)\n",
    "    # 保 Ridge 使用 'sag' 求解器\n",
    "    if name == 'Ridge' and 'solver' not in params_for_model:\n",
    "        # 如果 GridSearchCV 没搜索 solver，手动添加 'sag'\n",
    "        final_model.set_params(solver='sag', tol=1e-3, **params_for_model)\n",
    "    else:\n",
    "        final_model.set_params(**params_for_model)\n",
    "\n",
    "    # 1. 在完整的转换后数据上拟合最终模型\n",
    "    try:\n",
    "        # (训练前检查数据) \n",
    "        is_sparse_full = issparse(X_full_transformed) # 检查数据是否稀疏\n",
    "        if (is_sparse_full and (np.isnan(X_full_transformed.data).any() or np.isinf(X_full_transformed.data).any())) or \\\n",
    "           (not is_sparse_full and (np.isnan(X_full_transformed).any() or np.isinf(X_full_transformed).any())):\n",
    "             raise ValueError(f\"NaN or Inf detected in X_full_transformed before fitting {name}\")\n",
    "        if np.isnan(full_data_y_log_np).any() or np.isinf(full_data_y_log_np).any():\n",
    "             raise ValueError(f\"NaN or Inf detected in y_log before fitting {name}\")\n",
    "\n",
    "        print(f\"--- Fitting {name} ---\")\n",
    "        current_model = final_model.fit(X_full_transformed, full_data_y_log_np)\n",
    "        print(f\"✅ {name} Trained using best/default params: {current_model.get_params()}\")\n",
    "        fitted_models[name] = current_model\n",
    "\n",
    "        # 保持系数诊断\n",
    "        print(f\"   Intercept: {current_model.intercept_:.4f}\")\n",
    "        if hasattr(current_model, 'coef_'): # 检查模型是否有 coef_ 属性\n",
    "             coefs = current_model.coef_\n",
    "             if issparse(coefs): coefs = coefs.toarray().flatten() # 如果系数是稀疏的，转换为密集数组\n",
    "             print(f\"   Coefficient Stats: Mean={np.mean(coefs):.4f}, Std={np.std(coefs):.4f}, Min={np.min(coefs):.4f}, Max={np.max(coefs):.4f}\")\n",
    "             if np.allclose(coefs, 0, atol=1e-5): # 检查系数是否几乎都为零（Lasso 可能出现）\n",
    "                 print(f\"   ⚠️ 警告: 模型 {name} 的系数几乎全为零！\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {name} Failed to train on full data: {e}\")\n",
    "        fitted_models[name] = None\n",
    "        results.append({\n",
    "            \"Metrics\": name, \"In-sample MAE\": np.nan, \"In-sample RMAE\": np.nan,\n",
    "            \"Out-of-sample MAE\": np.nan, \"Out-of-sample RMAE\": np.nan,\n",
    "            \"Cross-validation MAE\": np.nan, \"Cross-validation RMAE\": np.nan\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    current_model = fitted_models[name]\n",
    "    if current_model is None: continue\n",
    "\n",
    "    # 性能计算 (原始价格水平)\n",
    "    # 1. In-sample\n",
    "    try:\n",
    "        y_pred_train_log = current_model.predict(X_train_transformed)\n",
    "        mae_train, _ = calculate_mae_rmse_original(y_train_log_split, y_pred_train_log)\n",
    "    except Exception as e: mae_train = np.nan\n",
    "\n",
    "    # 2. Out-of-sample\n",
    "    try:\n",
    "        y_pred_valid_log = current_model.predict(X_valid_transformed)\n",
    "        mae_valid, _ = calculate_mae_rmse_original(y_valid_log_split, y_pred_valid_log)\n",
    "    except Exception as e: mae_valid = np.nan\n",
    "\n",
    "    # 手动实现 6-Fold Cross-Validation (在转换后数据上) \n",
    "    print(f\"--- 开始手动 6-Fold Cross-Validation: {name} ---\")\n",
    "    fold_mae_scores = [] # 用于存储每一折的 MAE\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_full_transformed, full_data_y_log_np)): # 遍历 6 个折的索引\n",
    "        X_train_fold, X_val_fold = X_full_transformed[train_idx], X_full_transformed[val_idx]      # 获取当前折的训练和验证数据\n",
    "        y_train_fold, y_val_fold = full_data_y_log_np[train_idx], full_data_y_log_np[val_idx]      # 获取对应的目标值\n",
    "\n",
    "        fold_model = clone(model_base).set_params(**params_for_model) # 创建一个新的模型实例并设置参数\n",
    "        if name == 'Ridge' and 'solver' not in params_for_model:\n",
    "             fold_model.set_params(solver='sag', tol=1e-3)\n",
    "\n",
    "        try:\n",
    "            # (数据检查是否有 NaN/Inf)\n",
    "            is_sparse_train_fold = issparse(X_train_fold)\n",
    "            if (is_sparse_train_fold and (np.isnan(X_train_fold.data).any() or np.isinf(X_train_fold.data).any())) or \\\n",
    "               (not is_sparse_train_fold and (np.isnan(X_train_fold).any() or np.isinf(X_train_fold).any())) or \\\n",
    "               np.isnan(y_train_fold).any() or np.isinf(y_train_fold).any():\n",
    "                 raise ValueError(\"NaN or Inf in fold training data\")\n",
    "\n",
    "            fold_model.fit(X_train_fold, y_train_fold) # 在当前折的训练数据上拟合模型\n",
    "\n",
    "            is_sparse_val_fold = issparse(X_val_fold)\n",
    "            if (is_sparse_val_fold and (np.isnan(X_val_fold.data).any() or np.isinf(X_val_fold.data).any())) or \\\n",
    "               (not is_sparse_val_fold and (np.isnan(X_val_fold).any() or np.isinf(X_val_fold).any())):\n",
    "                raise ValueError(\"NaN or Inf in fold validation data for prediction\")\n",
    "\n",
    "            y_pred_fold_log = fold_model.predict(X_val_fold) # 在当前折的验证数据上预测\n",
    "            mae_fold, _ = calculate_mae_rmse_original(y_val_fold, y_pred_fold_log) # 计算当前折的 MAE\n",
    "            fold_mae_scores.append(mae_fold)\n",
    "        except Exception as e:\n",
    "            # print(f\"  Fold {fold+1} failed: {e}\") # 可选\n",
    "            fold_mae_scores.append(np.nan)\n",
    "\n",
    "    cv_mae = np.nanmean(fold_mae_scores) if np.isfinite(fold_mae_scores).any() else np.nan\n",
    "    print(f\"--- {name} Manual CV finished. Average MAE: {cv_mae if not np.isnan(cv_mae) else 'NaN'} ---\")\n",
    "\n",
    "    results.append({\n",
    "        \"Metrics\": name,\n",
    "        \"In-sample MAE\": mae_train,\n",
    "        \"In-sample RMAE\": mae_train / mean_price if mean_price != 0 else np.nan,\n",
    "        \"Out-of-sample MAE\": mae_valid,\n",
    "        \"Out-of-sample RMAE\": mae_valid / mean_price if mean_price != 0 else np.nan,\n",
    "        \"Cross-validation MAE\": cv_mae,\n",
    "        \"Cross-validation RMAE\": cv_mae / mean_price if mean_price != 0 and not np.isnan(cv_mae) else np.nan\n",
    "    })\n",
    "\n",
    "# 🔟 输出结果表\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "# 核心修正：根据 Cross-validation MAE 自动选择最佳模型\n",
    "print(\"\\n--- Determining Best Linear Model (based on Cross-validation MAE) ---\")\n",
    "valid_cv_mae_indices = result_df[\"Cross-validation MAE\"].dropna().index\n",
    "best_model_name_final = 'OLS' # Default fallback\n",
    "if not valid_cv_mae_indices.empty:\n",
    "    best_model_idx = result_df.loc[valid_cv_mae_indices, \"Cross-validation MAE\"].idxmin() # *** 使用 CV MAE 排序 ***\n",
    "    best_model_name_orig = result_df.loc[best_model_idx, \"Metrics\"]\n",
    "    \n",
    "    if best_model_name_orig in fitted_models and fitted_models[best_model_name_orig] is not None:\n",
    "        result_df.loc[result_df['Metrics'] == best_model_name_orig, 'Metrics'] = 'Best Linear Model'\n",
    "        best_model_name_final = best_model_name_orig # 使用实际的最佳模型名称\n",
    "        print(f\"最佳模型（基于 CV MAE）: {best_model_name_final}\")\n",
    "    else:\n",
    "        print(f\"警告: 确定的最佳模型 '{best_model_name_orig}' (CV MAE) 训练失败或不存在。正在回退。\")\n",
    "        # 回退逻辑：寻找 OOS MAE 最小的\n",
    "        valid_oos_mae_indices = result_df[\"Out-of-sample MAE\"].dropna().index\n",
    "        if not valid_oos_mae_indices.empty:\n",
    "            best_oos_model_idx = result_df.loc[valid_oos_mae_indices, \"Out-of-sample MAE\"].idxmin()\n",
    "            best_model_name_final = result_df.loc[best_oos_model_idx, \"Metrics\"]\n",
    "            print(f\"回退到 OOS MAE 最佳模型: {best_model_name_final}\")\n",
    "            if best_model_name_final in result_df['Metrics'].values:\n",
    "                 result_df.loc[result_df['Metrics'] == best_model_name_final, 'Metrics'] = 'Best Linear Model (Fallback OOS)'\n",
    "            else: \n",
    "                 pass \n",
    "        else:\n",
    "             print(\"错误: 所有模型在 OOS 和 CV MAE 上均失败。回退到 OLS。\")\n",
    "             best_model_name_final = 'OLS' # 最后手段\n",
    "else:\n",
    "    print(\"警告: 所有模型在 Cross-validation MAE 上失败。回退到 OOS MAE 最佳模型。\")\n",
    "    valid_oos_mae_indices = result_df[\"Out-of-sample MAE\"].dropna().index\n",
    "    if not valid_oos_mae_indices.empty:\n",
    "        best_oos_model_idx = result_df.loc[valid_oos_mae_indices, \"Out-of-sample MAE\"].idxmin()\n",
    "        best_model_name_final = result_df.loc[best_oos_model_idx, \"Metrics\"]\n",
    "        print(f\"回退到 OOS MAE 最佳模型: {best_model_name_final}\")\n",
    "        if best_model_name_final in result_df['Metrics'].values: # Check if it's not already 'Best Linear Model'\n",
    "             result_df.loc[result_df['Metrics'] == best_model_name_final, 'Metrics'] = 'Best Linear Model (Fallback OOS)'\n",
    "    else:\n",
    "        print(\"错误: 所有模型在 OOS 和 CV MAE 上均失败。回退到 OLS。\")\n",
    "        best_model_name_final = 'OLS'\n",
    "\n",
    "\n",
    "result_df_formatted = result_df.copy()\n",
    "for col in result_df_formatted.columns:\n",
    "    if 'MAE' in col:\n",
    "        result_df_formatted[col] = result_df_formatted[col].apply(lambda x: f\"{x:.2f}\" if pd.notna(x) else 'NaN')\n",
    "    elif 'RMAE' in col:\n",
    "        result_df_formatted[col] = result_df_formatted[col].apply(lambda x: f\"{x:.4f}\" if pd.notna(x) else 'NaN')\n",
    "\n",
    "print(\"\\n--- 10. Model Performance Summary (MAE and RMAE for Original Rent Level) ---\")\n",
    "print(result_df_formatted.to_markdown(index=False))\n",
    "\n",
    "\n",
    "# 🔟➕1️⃣ 选择最优模型\n",
    "# 核心修正：使用由 CV MAE 自动选择的 best_model_name_final\n",
    "print(f\"\\n--- Selecting Final Model based on CV MAE: {best_model_name_final} ---\")\n",
    "if best_model_name_final in fitted_models and fitted_models[best_model_name_final] is not None:\n",
    "    best_model = fitted_models[best_model_name_final]\n",
    "    best_model_name_predict = best_model_name_final # 记录实际使用的模型\n",
    "else:\n",
    "     # 如果 CV MAE 选择的模型失败了\n",
    "     available_models = [m for m in ['Ridge', 'OLS', 'LASSO', 'ElasticNet'] if m in fitted_models and fitted_models[m] is not None]\n",
    "     if available_models:\n",
    "         best_model_name_predict = available_models[0]\n",
    "         best_model = fitted_models[best_model_name_predict]\n",
    "         print(f\"警告: CV MAE 最佳模型 '{best_model_name_final}' 失败或不可用，回退到第一个可用的模型 (优先 Ridge/OLS): {best_model_name_predict}。\")\n",
    "     else:\n",
    "        raise RuntimeError(\"所有模型训练失败，无法继续进行预测。\")\n",
    "\n",
    "\n",
    "# 🔟➕2️⃣ 预测测试集 (使用转换后的 X_test)\n",
    "try:\n",
    "    print(f\"\\n--- 使用最终模型进行预测: {best_model_name_predict} ---\")\n",
    "    # (预测前检查)\n",
    "    input_data_is_sparse = issparse(X_test_transformed)\n",
    "    input_data_nan = (input_data_is_sparse and np.isnan(X_test_transformed.data).any()) or \\\n",
    "                     (not input_data_is_sparse and np.isnan(X_test_transformed).any())\n",
    "    input_data_inf = (input_data_is_sparse and np.isinf(X_test_transformed.data).any()) or \\\n",
    "                     (not input_data_is_sparse and np.isinf(X_test_transformed).any())\n",
    "    if input_data_nan or input_data_inf:\n",
    "        # 尝试最后一次清理\n",
    "        print(\"警告：最终预测前在 X_test_transformed 中检测到 NaN/Inf，尝试填充 0。\")\n",
    "        if input_data_is_sparse:\n",
    "            X_test_transformed.data = np.nan_to_num(X_test_transformed.data, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        else:\n",
    "            X_test_transformed = np.nan_to_num(X_test_transformed, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    test_pred_log = best_model.predict(X_test_transformed)\n",
    "\n",
    "    # 保持预测后诊断\n",
    "    print(f\"预测的对数价格 (前 5 个): {test_pred_log[:5]}\")\n",
    "    finite_preds = test_pred_log[np.isfinite(test_pred_log)]\n",
    "    if finite_preds.size > 0:\n",
    "        print(f\"对数价格统计 (有限值): Min={np.min(finite_preds):.2f}, Max={np.max(finite_preds):.2f}, Mean={np.mean(finite_preds):.2f}, Std={np.std(finite_preds):.2f}\")\n",
    "        if np.allclose(finite_preds, finite_preds[0], atol=1e-6): # 使用更小的容忍度检查\n",
    "            print(\"⚠️ 警告: 所有预测的对数价格几乎相同！\")\n",
    "    else:\n",
    "        print(\"⚠️ 警告: 预测的对数价格不包含任何有限值！\")\n",
    "    if np.isnan(test_pred_log).any() or np.isinf(test_pred_log).any():\n",
    "        print(\"❌ 警告: 预测的对数价格包含 NaN 或 Inf！正在尝试清理...\")\n",
    "        median_log_pred = np.nanmedian(finite_preds) if finite_preds.size > 0 else np.log1p(np.median(y_train_price_no_outliers))\n",
    "        test_pred_log = np.nan_to_num(test_pred_log, nan=median_log_pred, posinf=np.log1p(np.finfo(np.float64).max / 10), neginf=-700)\n",
    "\n",
    "    test_pred_price = np.expm1(test_pred_log)\n",
    "    test_pred_price[test_pred_price < 0] = 0\n",
    "    large_finite_val = np.finfo(np.float64).max / 10\n",
    "    median_fallback = np.median(y_train_price_no_outliers) if len(y_train_price_no_outliers)>0 else 0\n",
    "    test_pred_price = np.nan_to_num(test_pred_price, nan=median_fallback,\n",
    "                                   posinf=large_finite_val, neginf=0.0)\n",
    "    test_pred_price = np.clip(test_pred_price, 0, large_finite_val)\n",
    "\n",
    "    # 保持最终价格预测诊断\n",
    "    print(f\"最终预测价格 (前 5 个): {test_pred_price[:5]}\")\n",
    "    if test_pred_price.size > 0 and np.allclose(test_pred_price, test_pred_price[0], atol=1e-2): # 允许微小差异\n",
    "         print(\"❌ 警告: 所有最终预测价格几乎相同！\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    # ... (Fallback 代码保持不变) ...\n",
    "    import traceback\n",
    "    print(f\"最终预测出错: {e}\")\n",
    "    traceback.print_exc() # <--- *** 核心修正：取消注释以打印完整错误 ***\n",
    "    median_fallback = np.median(y_train_price_no_outliers) if len(y_train_price_no_outliers)>0 else 0\n",
    "    print(f\"预测失败，回退到预测中位数: {median_fallback}\")\n",
    "    test_pred_price = np.full(X_test_transformed.shape[0], median_fallback)\n",
    "\n",
    "# 🔟➕3️⃣ 生成提交文件\n",
    "# (代码不变)\n",
    "submission_df = pd.DataFrame({\n",
    "    # 修正点：使用大写 \"ID\"\n",
    "    \"ID\": test_data['ID'].values if 'ID' in test_data.columns and len(test_data['ID']) == X_test_transformed.shape[0] else np.arange(X_test_transformed.shape[0]),\n",
    "    \"prediction\": test_pred_price\n",
    "})\n",
    "\n",
    "submission_df.to_csv(\"prediction_rent.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"🎯 Prediction file saved as **prediction_rent.csv** (使用逗号分隔)\")\n",
    "\n",
    "# 🔟➕4️⃣ 保存模型性能表\n",
    "result_df.to_csv(\"performance_table_rent.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"📊 Model performance saved as **performance_table_rent.csv** (使用逗号分隔)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d7753c-518e-42fe-8f25-3862bfbce00d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1a1cdfab-5fd1-4e1d-9baf-cbb1c7f844b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 开始合并 ---\n",
      "正在读取 prediction_price.csv...\n",
      "✅ prediction_price.csv 加载成功，包含 34017 行。\n",
      "正在读取 prediction_rent.csv...\n",
      "✅ prediction_rent.csv 加载成功，包含 9773 行。\n",
      "正在合并两个文件...\n",
      "✅ 合并完成，总共 43790 行。\n",
      "正在保存合并后的文件到 prediction.csv...\n",
      "🎉 成功！合并后的提交文件已保存为 prediction.csv。\n",
      "--- 合并脚本执行完毕 ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "price_file = \"prediction_price.csv\"  \n",
    "rent_file = \"prediction_rent.csv\"    \n",
    "output_file = \"prediction.csv\"       \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(f\"--- 开始合并 ---\")\n",
    "\n",
    "try:\n",
    "    # 1. 读取房价预测文件\n",
    "    print(f\"正在读取 {price_file}...\")\n",
    "    df_price = pd.read_csv(price_file)\n",
    "    print(f\"✅ {price_file} 加载成功，包含 {len(df_price)} 行。\")\n",
    "\n",
    "    # 檢查必需的列是否存在\n",
    "    if 'ID' not in df_price.columns or 'prediction' not in df_price.columns:\n",
    "        raise ValueError(f\"错误：{price_file} 文件缺少 'ID' 或 'prediction' 列。\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ 错误：找不到文件 {price_file}。请确保文件在当前目录下。\")\n",
    "    exit() # 退出腳本\n",
    "except Exception as e:\n",
    "    print(f\"❌ 读取 {price_file} 时出错：{e}\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    # 2. 读取租金预测文件\n",
    "    print(f\"正在读取 {rent_file}...\")\n",
    "    df_rent = pd.read_csv(rent_file)\n",
    "    print(f\"✅ {rent_file} 加载成功，包含 {len(df_rent)} 行。\")\n",
    "\n",
    "    # 检查必需的列是否存在\n",
    "    if 'ID' not in df_rent.columns or 'prediction' not in df_rent.columns:\n",
    "        raise ValueError(f\"错误：{rent_file} 文件缺少 'ID' 或 'prediction' 列。\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ 错误：找不到文件 {rent_file}。请确保文件在当前目录下。\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"❌ 读取 {rent_file} 时出错：{e}\")\n",
    "    exit()\n",
    "\n",
    "# 3. 合并\n",
    "#    pd.concat 确认按行堆叠 (axis=0)\n",
    "#    ignore_index=True 会重新生成一个连续索引 (0, 1, 2, ...)\n",
    "print(f\"正在合并两个文件...\")\n",
    "df_combined = pd.concat([df_price, df_rent], ignore_index=True)\n",
    "total_rows = len(df_combined)\n",
    "print(f\"✅ 合并完成，总共 {total_rows} 行。\")\n",
    "\n",
    "# 可选：检查合并后的文件是否有重复的 ID \n",
    "if df_combined['ID'].duplicated().any():\n",
    "    print(f\"⚠️ 警告：合并后的文件中检测到重复的 ID！请检查您的原始预测文件。\")\n",
    "    duplicate_ids = df_combined[df_combined['ID'].duplicated()]['ID'].unique()\n",
    "    print(f\"   重复的 ID 示例: {list(duplicate_ids[:5])}...\") # 只顯示前5個\n",
    "\n",
    "# 4. 保存合并后的文件\n",
    "try:\n",
    "    print(f\"正在保存合并后的文件到 {output_file}...\")\n",
    "    # index=False: 不将 DataFrame 的索引写入 CSV 文件\n",
    "    df_combined[['ID', 'prediction']].to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"🎉 成功！合并后的提交文件已保存为 {output_file}。\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 保存文件 {output_file} 时出错：{e}\")\n",
    "\n",
    "print(f\"--- 合并脚本执行完毕 ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
