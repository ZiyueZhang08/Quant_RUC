{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fdc3ad7-28a3-4525-beff-2653bbb2b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import warnings\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47a4ecf9-f95a-41dc-9659-d846b8b9a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== 全局变量 ==================\n",
    "DATA_DIR        = Path.cwd() \n",
    "TRAIN_PRICE     = DATA_DIR / \"ruc_Class25Q2_train_price.csv\"\n",
    "TRAIN_RENT      = DATA_DIR / \"ruc_Class25Q2_train_rent.csv\"\n",
    "TEST_PRICE = DATA_DIR / \"ruc_Class25Q2_test_price.csv\"\n",
    "TEST_RENT  = DATA_DIR / \"ruc_Class25Q2_test_rent.csv\"\n",
    "\n",
    "OUT_PRICE  = DATA_DIR / \"pred_test_price.csv\"   \n",
    "OUT_RENT   = DATA_DIR / \"pred_test_rent.csv\"    \n",
    "\n",
    "FAST_DEMO       = True        # True: 仍6折，但CV最多抽样 MAX_CV_ROWS 且参数网格较小；False: 全量搜索\n",
    "MAX_CV_ROWS     = 30000       # FAST_DEMO 抽样上限\n",
    "CV_FOLDS        = 6           \n",
    "RANDOM_STATE    = 111         \n",
    "\n",
    "USE_POLY        = False       # 是否加入多项式/交互项（默认关闭，避免维度膨胀）\n",
    "LOW_CARD_MAX    = 12          # OHE 仅对基数<=12的分类变量\n",
    "LOW_CORR_THR    = 0.05        # 与目标Spearman绝对相关度阈值，低于此阈值的数值列剔除\n",
    "VIF_THRESH      = 15.0        # 多重共线VIF阈值\n",
    "VAR_THR         = 0.01        # 方差过滤阈值\n",
    "# ============================================\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34631413-6834-4428-9e79-c0c7a3990f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ 清洗 ------------------\n",
    "def normalize_colnames(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"列名标准化：小写、非字母数字转下划线，去首尾下划线\"\"\"\n",
    "    mapping = {c: re.sub(r\"[^0-9a-z]+\", \"_\", str(c).strip().lower()).strip(\"_\") for c in df.columns}\n",
    "    return df.rename(columns=mapping)\n",
    "\n",
    "def strip_strings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"字符串去空格；统一空值：'', '—', '无' 等替换为 NaN\"\"\"\n",
    "    empties = {\"\", \"null\", \"none\", \"nan\", \"na\", \"无\", \"不详\", \"未知\", \"—\", \"-\", \"— —\"}\n",
    "    for c in df.columns:\n",
    "        if pd.api.types.is_object_dtype(df[c]):\n",
    "            df[c] = df[c].astype(str).str.strip()\n",
    "            df[c] = df[c].replace({v: np.nan for v in empties})\n",
    "    return df\n",
    "\n",
    "def parse_chinese_number(s: str) -> float | None:\n",
    "    \"\"\"解析带中文单位的数字，如 '2.3万', '5千', '120元/㎡' -> 规范化为float（单位按数值本身）\"\"\"\n",
    "    if s is None or (not isinstance(s, str)):\n",
    "        try: return float(s)\n",
    "        except Exception: return None\n",
    "    x = s.strip()\n",
    "    if x == \"\": return None\n",
    "    sign = -1.0 if x.startswith(\"-\") else 1.0\n",
    "    x = x.lstrip(\"+-\").strip()\n",
    "    x = re.sub(r\"[,\\s]\", \"\", x)\n",
    "    scale = 1.0\n",
    "    # 规模单位转换\n",
    "    if re.search(r\"亿\", x): scale = 1e8; x = x.replace(\"亿\", \"\")\n",
    "    elif re.search(r\"万\", x): scale = 1e4; x = x.replace(\"万\", \"\")\n",
    "    elif re.search(r\"[千kK]\", x): scale = 1e3; x = re.sub(r\"[千kK]\", \"\", x)\n",
    "    # 去尾部单位/杂质\n",
    "    x = re.sub(r\"(元|块|人民币|rmb|￥|/.*|平方米|平米|㎡|m2|m²|平|套|层|间|户|年|月|天)$\", \"\", x, flags=re.I)\n",
    "    try:\n",
    "        return sign * float(x) * scale\n",
    "    except Exception:\n",
    "        # 若仍失败，兜底提取首个数字\n",
    "        m = re.search(r\"([+-]?\\d+(?:\\.\\d+)?)\", x)\n",
    "        return sign * float(m.group(1)) * scale if m else None\n",
    "\n",
    "def parse_area_m2(s: str) -> float | None:\n",
    "    \"\"\"解析面积字符串，可识别区间 '80-90㎡' 取均值\"\"\"\n",
    "    if not isinstance(s, str): return parse_chinese_number(s)\n",
    "    # 先解析区间均值（80-90㎡）\n",
    "    m = re.search(r\"([+-]?\\d+(?:\\.\\d+)?)\\s*(?:-|~|至|到)\\s*([+-]?\\d+(?:\\.\\d+)?)\", s)\n",
    "    if m:\n",
    "        a, b = parse_chinese_number(m.group(1)), parse_chinese_number(m.group(2))\n",
    "        if a is not None and b is not None: return (a + b) / 2.0\n",
    "    # 统一面积单位\n",
    "    x = (s.strip().lower()\n",
    "         .replace(\"平方米\",\"㎡\").replace(\"平米\",\"㎡\").replace(\"m2\",\"㎡\")\n",
    "         .replace(\"m^2\",\"㎡\").replace(\"m²\",\"㎡\")).replace(\"㎡\",\"\")\n",
    "    return parse_chinese_number(x)\n",
    "\n",
    "def parse_floor_info(s: str) -> tuple[float | None, float | None, str | None]:\n",
    "    \"\"\"解析楼层信息：当前层数、总层数、楼层等级（高/中/低/顶/底）\"\"\"\n",
    "    if not isinstance(s, str): return None, None, None\n",
    "    x = s.strip()\n",
    "    level = next((lvl for lvl in [\"高层\",\"中层\",\"低层\",\"顶层\",\"底层\"] if lvl in x), None)\n",
    "    total = None\n",
    "    m_total = re.search(r\"共\\s*([0-9]+)\\s*层\", x) or re.search(r\"/\\s*([0-9]+)\\s*层\", x)\n",
    "    if m_total: total = float(m_total.group(1))\n",
    "    cur = None\n",
    "    m_cur = re.search(r\"(?:第)?\\s*([0-9]+)\\s*层\", x) or re.search(r\"^\\s*([0-9]+)\\s*/\", x)\n",
    "    if m_cur:\n",
    "        try: cur = float(m_cur.group(1))\n",
    "        except Exception: cur = None\n",
    "    return cur, total, level\n",
    "\n",
    "def parse_layout_compact(s: str) -> dict:\n",
    "    \"\"\"户型解析为少量**数值**列（室/厅/厨/卫），避免OHE产生过多维度\"\"\"\n",
    "    d = {\"layout_rooms\":0.0,\"layout_halls\":0.0,\"layout_kitchens\":0.0,\"layout_baths\":0.0}\n",
    "    if not isinstance(s, str): return d\n",
    "    for k, ch in [(\"layout_rooms\",\"室\"),(\"layout_halls\",\"厅\"),(\"layout_kitchens\",\"厨\"),(\"layout_baths\",\"卫\")]:\n",
    "        m = re.search(r\"(\\d+)\\s*\"+ch, s); \n",
    "        if m: d[k] = float(m.group(1))\n",
    "    return d\n",
    "\n",
    "def parse_year_built(s: str) -> float | None:\n",
    "    \"\"\"解析建成年份（如 '1998年'）\"\"\"\n",
    "    if not isinstance(s, str): return None\n",
    "    m = re.search(r\"(19\\d{2}|20\\d{2})\\s*年\", s)\n",
    "    return float(m.group(1)) if m else None\n",
    "\n",
    "def orientation_bucket(s: str) -> str | None:\n",
    "    \"\"\"朝向合并为少数类别：E/S/W/N/NE/NW/SE/SW/NS_Through/Other\"\"\"\n",
    "    if not isinstance(s, str) or s.strip()==\"\":\n",
    "        return None\n",
    "    st = s.strip()\n",
    "    if \"南北\" in st and \"通\" in st: return \"NS_Through\"\n",
    "    for k in [(\"东南\",\"SE\"),(\"东北\",\"NE\"),(\"西南\",\"SW\"),(\"西北\",\"NW\")]:\n",
    "        if k[0] in st: return k[1]\n",
    "    if \"东\" in st: return \"E\"\n",
    "    if \"西\" in st: return \"W\"\n",
    "    if \"南\" in st: return \"S\"\n",
    "    if \"北\" in st: return \"N\"\n",
    "    return \"Other\"\n",
    "\n",
    "def detect_cols(df: pd.DataFrame, keys: list[str]) -> Optional[str]:\n",
    "    \"\"\"根据关键字模糊匹配列名，返回命中的第一列名；找不到返回 None\"\"\"\n",
    "    for key in keys:\n",
    "        for c in df.columns:\n",
    "            if key in c:\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "def clean_housing_df(df: pd.DataFrame, is_rent: bool) -> pd.DataFrame:\n",
    "    \"\"\"正则清洗：目标是输出少量数值/有限类别特征；避免生成大量二值列\"\"\"\n",
    "    df = normalize_colnames(df)\n",
    "    df = strip_strings(df)\n",
    "\n",
    "    # 可能的关键列定位\n",
    "    colmap: Dict[str, str] = {}\n",
    "    colmap[\"layout\"]    = detect_cols(df, [\"layout\",\"huxing\",\"house_type\",\"户型\"])\n",
    "    colmap[\"floor\"]     = detect_cols(df, [\"floor\",\"楼层\"])\n",
    "    colmap[\"area\"]      = detect_cols(df, [\"area\",\"mianji\",\"面积\"])\n",
    "    colmap[\"unit_price\"]= detect_cols(df, [\"unit_price\",\"danjia\",\"单价\",\"price_per_m2\",\"price_sqm\"])\n",
    "    colmap[\"total_price\"]=detect_cols(df, [\"total_price\",\"zongjia\",\"总价\",\"price\"])\n",
    "    colmap[\"orientation\"]= detect_cols(df, [\"orientation\",\"chaoxiang\",\"朝向\"])\n",
    "    colmap[\"decoration\"]= detect_cols(df, [\"decoration\",\"zhuangxiu\",\"装修\"])\n",
    "    colmap[\"year_built\"]= detect_cols(df, [\"year_built\",\"build_year\",\"建\",\"竣工\",\"年代\"])\n",
    "    colmap[\"elevator\"]  = detect_cols(df, [\"elevator\",\"dianti\",\"电梯\"])\n",
    "    colmap[\"subway\"]    = detect_cols(df, [\"subway\",\"地铁\",\"metro\",\"rail\"])\n",
    "    colmap[\"property\"]  = detect_cols(df, [\"property\",\"chanquan\",\"产权\"])\n",
    "\n",
    "    # 户型四个数值列\n",
    "    if colmap.get(\"layout\"):\n",
    "        parsed = df[colmap[\"layout\"]].fillna(\"\").apply(parse_layout_compact)\n",
    "        for k in parsed.iloc[0].keys():\n",
    "            df[k] = parsed.apply(lambda d: d.get(k, 0.0))\n",
    "\n",
    "    # 楼层文本 -> 当前层数/总层数/等级 + 楼层比\n",
    "    if colmap.get(\"floor\"):\n",
    "        parsed = df[colmap[\"floor\"]].fillna(\"\").apply(parse_floor_info)\n",
    "        df[\"floor_number\"]  = parsed.apply(lambda t: t[0])\n",
    "        df[\"total_floors\"]  = parsed.apply(lambda t: t[1])\n",
    "        df[\"floor_level\"]   = parsed.apply(lambda t: t[2])  # 少数等级类别\n",
    "        with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n",
    "            df[\"floor_ratio\"] = df[\"floor_number\"] / df[\"total_floors\"]\n",
    "\n",
    "    # 面积/单价/总价解析\n",
    "    if colmap.get(\"area\"):\n",
    "        df[\"area_m2\"] = df[colmap[\"area\"]].apply(lambda x: parse_area_m2(x) if isinstance(x, str) else parse_area_m2(str(x)))\n",
    "    if colmap.get(\"unit_price\"):\n",
    "        df[\"unit_price_per_m2\"] = df[colmap[\"unit_price\"]].apply(parse_chinese_number)\n",
    "    if colmap.get(\"total_price\"):\n",
    "        df[\"total_price_yuan\"] = df[colmap[\"total_price\"]].apply(parse_chinese_number)\n",
    "\n",
    "    # 朝向合并\n",
    "    if colmap.get(\"orientation\"):\n",
    "        df[\"orientation_bucket\"] = df[colmap[\"orientation\"]].apply(orientation_bucket)\n",
    "\n",
    "    # 装修映射到少数类别\n",
    "    if colmap.get(\"decoration\"):\n",
    "        c = colmap[\"decoration\"]\n",
    "        df[\"decoration_std\"] = None\n",
    "        mapping = {\"精装\":\"fine\", \"简装\":\"simple\", \"豪装\":\"luxury\", \"中装\":\"mid\", \"毛坯\":\"bare\"}\n",
    "        for zh, en in mapping.items():\n",
    "            df.loc[df[c].astype(str).str.contains(zh, na=False), \"decoration_std\"] = en\n",
    "\n",
    "    # 建成年份\n",
    "    if colmap.get(\"year_built\"):\n",
    "        df[\"year_built_num\"] = df[colmap[\"year_built\"]].apply(parse_year_built)\n",
    "\n",
    "    # 电梯：1/0/NaN\n",
    "    if colmap.get(\"elevator\"):\n",
    "        s = df[colmap[\"elevator\"]].astype(str)\n",
    "        df[\"has_elevator\"] = np.where(s.str.contains(\"无电梯|没电梯\"), 0,\n",
    "                               np.where(s.str.contains(\"有电梯|配电梯|电梯\"), 1, np.nan))\n",
    "\n",
    "    # 地铁距离，最终统一为米\n",
    "    if colmap.get(\"subway\"):\n",
    "        s = df[colmap[\"subway\"]].astype(str)\n",
    "        km = s.str.extract(r\"([0-9]+(?:\\.\\d+)?)\\s*(?:km|公里)\", expand=False)\n",
    "        m  = s.str.extract(r\"([0-9]+(?:\\.\\d+)?)\\s*(?:m|米)\", expand=False)\n",
    "        df[\"subway_dist_m\"] = np.where(km.notna(), km.astype(float)*1000, m.astype(float))\n",
    "\n",
    "    # 产权年限\n",
    "    if colmap.get(\"property\"):\n",
    "        s = df[colmap[\"property\"]].astype(str)\n",
    "        years = s.str.extract(r\"([1-9][0-9]?)\\s*年\\s*产\\s*权\", expand=False)\n",
    "        df[\"property_years\"] = years.astype(float)\n",
    "\n",
    "    # 基本合理性修正\n",
    "    for c in [\"area_m2\",\"unit_price_per_m2\",\"total_price_yuan\",\"subway_dist_m\"]:\n",
    "        if c in df.columns: df.loc[df[c] < 0, c] = np.nan\n",
    "    if \"floor_number\" in df.columns and \"total_floors\" in df.columns:\n",
    "        df.loc[df[\"floor_number\"] > df[\"total_floors\"], \"floor_number\"] = np.nan\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fa2f0d9-a805-422a-bb55-5f38eb72dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ 防泄漏 & 特征工程 ------------------\n",
    "LEAK_PATTERNS = [\n",
    "    r\"community.*price\",                 \n",
    "    r\"avg.*price\", r\"mean.*price\", r\"median.*price\",\n",
    "    r\"list.*price\", r\"quoted.*price\",    \n",
    "    r\"target\", r\"y_true\", r\"label\", r\"ground.*truth\",  \n",
    "]\n",
    "class LeakageDropper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"按列名正则匹配，删除疑似泄漏特征（在训练前置处理阶段）\"\"\"\n",
    "    def __init__(self, target: str):\n",
    "        self.target = target\n",
    "        self.to_drop_: List[str] = []\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        cols = normalize_colnames(X).columns\n",
    "        for c in cols:\n",
    "            if c == self.target: continue\n",
    "            for pat in LEAK_PATTERNS:\n",
    "                if re.search(pat, c, flags=re.IGNORECASE):\n",
    "                    self.to_drop_.append(c); break\n",
    "        self.to_drop_ = sorted(set(self.to_drop_)); return self\n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        return X.drop(columns=[c for c in self.to_drop_ if c in X.columns], errors=\"ignore\")\n",
    "\n",
    "class IQRClipper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"对数值特征按IQR区间截断，缓解极端值影响\"\"\"\n",
    "    def __init__(self): self.bounds_=[]; self.n_features_=0\n",
    "    @staticmethod\n",
    "    def _as_2d(X):\n",
    "        if isinstance(X, pd.DataFrame): return X.to_numpy(dtype=float)\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = X.astype(float, copy=False)\n",
    "            return X if X.ndim==2 else X.reshape(-1,1)\n",
    "        return np.asarray(X, dtype=float)\n",
    "    def fit(self, X, y=None):\n",
    "        A = self._as_2d(X); self.n_features_ = A.shape[1]; self.bounds_=[]\n",
    "        for j in range(self.n_features_):\n",
    "            col = A[:,j]; col = col[~np.isnan(col)]\n",
    "            if col.size==0: self.bounds_.append((np.nan,np.nan)); continue\n",
    "            q1,q3 = np.nanpercentile(col,[25,75]); iqr=q3-q1\n",
    "            self.bounds_.append((q1-1.5*iqr, q3+1.5*iqr))\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        A = self._as_2d(X).copy()\n",
    "        for j,(lo,hi) in enumerate(self.bounds_):\n",
    "            if not (np.isnan(lo) or np.isnan(hi)): A[:,j] = np.clip(A[:,j], lo, hi)\n",
    "        return A\n",
    "\n",
    "class AutoLogTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"对右偏严重且非负的数值特征做 log1p 变换\"\"\"\n",
    "    def __init__(self, skew_threshold: float=1.0): \n",
    "        self.skew_threshold=skew_threshold; self.log_mask_=None\n",
    "    def fit(self, X, y=None):\n",
    "        A = IQRClipper._as_2d(X); self.log_mask_ = np.zeros(A.shape[1], dtype=bool)\n",
    "        for j in range(A.shape[1]):\n",
    "            col = A[:,j]; col = col[~np.isnan(col)]\n",
    "            if col.size==0: continue\n",
    "            if np.nanmin(col) >= 0:\n",
    "                sk = pd.Series(col).skew(skipna=True)\n",
    "                if np.isfinite(sk) and sk > self.skew_threshold: self.log_mask_[j]=True\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        A = IQRClipper._as_2d(X).copy()\n",
    "        if self.log_mask_ is None: return A\n",
    "        for j,flag in enumerate(self.log_mask_):\n",
    "            if flag: A[:,j] = np.log1p(np.where(np.isnan(A[:,j]), np.nan, A[:,j]))\n",
    "        return A\n",
    "\n",
    "def identify_target(df: pd.DataFrame) -> str:\n",
    "    \"\"\"自动识别目标列：优先 'price' 其次 'rent'\"\"\"\n",
    "    cols = normalize_colnames(df).columns\n",
    "    if \"price\" in cols: return \"price\"\n",
    "    if \"rent\"  in cols: return \"rent\"\n",
    "    for c in cols:\n",
    "        if c in (\"y\",\"target\",\"label\"): return c\n",
    "    raise ValueError(\"无法识别目标列（price 或 rent）。\")\n",
    "\n",
    "def select_low_card_cats(X: pd.DataFrame, max_card=LOW_CARD_MAX) -> List[str]:\n",
    "    \"\"\"仅保留低基数分类变量用于 OHE，避免维度爆炸\"\"\"\n",
    "    cats = [c for c in X.columns if not pd.api.types.is_numeric_dtype(X[c])]\n",
    "    keep = []\n",
    "    for c in cats:\n",
    "        try:\n",
    "            if X[c].nunique(dropna=True) <= max_card: keep.append(c)\n",
    "        except Exception: pass\n",
    "    return keep\n",
    "\n",
    "def fast_corr_prefilter(X: pd.DataFrame, y: pd.Series, thr: float=LOW_CORR_THR) -> List[str]:\n",
    "    \"\"\"在训练集上用 Spearman 相关度筛掉与目标弱相关的数值特征\"\"\"\n",
    "    num_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
    "    low_cols = []\n",
    "    y_s = pd.to_numeric(y, errors=\"coerce\")\n",
    "    for c in num_cols:\n",
    "        try:\n",
    "            s = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "            corr = s.corr(y_s, method=\"spearman\")\n",
    "            if (corr is None) or (not np.isfinite(corr)) or (abs(corr) < thr): low_cols.append(c)\n",
    "        except Exception: continue\n",
    "    return low_cols\n",
    "\n",
    "def compute_high_vif_numeric(df: pd.DataFrame, thresh: float=VIF_THRESH) -> List[str]:\n",
    "    \"\"\"计算数值特征 VIF，剔除多重共线严重的列（、\"\"\"\n",
    "    try:\n",
    "        import statsmodels.api as sm\n",
    "        from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    except Exception:\n",
    "        return []\n",
    "    numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c]) and c not in (\"price\",\"rent\")]\n",
    "    if len(numeric_cols) < 2: return []\n",
    "    X = df[numeric_cols].copy().replace([np.inf,-np.inf], np.nan)\n",
    "    X = X.fillna(X.median(numeric_only=True))\n",
    "    Xc = sm.add_constant(X)\n",
    "    high = []\n",
    "    for i in range(1, Xc.shape[1]):\n",
    "        try:\n",
    "            vif = variance_inflation_factor(Xc.values, i)\n",
    "            if np.isfinite(vif) and vif >= thresh: high.append(X.columns[i-1])\n",
    "        except Exception: pass\n",
    "    return sorted(set(high))\n",
    "\n",
    "def make_ohe(max_cats=12):\n",
    "    \"\"\"兼容不同 sklearn 版本的 OHE；限制最大类别数以控制维度\"\"\"\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, max_categories=max_cats)\n",
    "    except TypeError:\n",
    "        # 旧版本退化为不设 max_categories\n",
    "        try:\n",
    "            return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "        except TypeError:\n",
    "            # 极旧版本\n",
    "            return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "def build_preprocessor(X_train: pd.DataFrame, use_poly: bool) -> ColumnTransformer:\n",
    "    \"\"\"构建列式预处理：数值（缺失填充→IQR截断→按需log→标准化）+ 低基数分类（OHE），最后方差过滤\"\"\"\n",
    "    num_cols = [c for c in X_train.columns if pd.api.types.is_numeric_dtype(X_train[c])]\n",
    "    cat_cols = select_low_card_cats(X_train, max_card=LOW_CARD_MAX)\n",
    "\n",
    "    num_steps = [(\"num_impute\", SimpleImputer(strategy=\"median\")),\n",
    "                 (\"num_clip\", IQRClipper()),\n",
    "                 (\"num_log\", AutoLogTransformer(skew_threshold=1.0))]\n",
    "    if use_poly:\n",
    "        num_steps.append((\"num_poly\", PolynomialFeatures(degree=2, include_bias=False)))\n",
    "    num_steps.append((\"num_scale\", StandardScaler()))\n",
    "    numeric_pipe = Pipeline(steps=num_steps)\n",
    "\n",
    "    cat_pipe = Pipeline(steps=[(\"cat_impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                               (\"cat_ohe\", make_ohe(max_cats=12))])\n",
    "\n",
    "    pre = ColumnTransformer(transformers=[(\"num\", numeric_pipe, num_cols),\n",
    "                                          (\"cat\", cat_pipe, cat_cols)],\n",
    "                            remainder=\"drop\")\n",
    "    # 方差过滤放在最后，进一步去除近似常量特征\n",
    "    preproc = Pipeline(steps=[(\"pre_cols\", pre),\n",
    "                              (\"variance_filter\", VarianceThreshold(VAR_THR))])\n",
    "    return preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "934c0b9f-1261-43b8-a72e-c2c33cb57247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ 训练 & 汇报 ------------------\n",
    "def _append_rmae_columns(df: pd.DataFrame, y_tr: pd.Series, y_te: pd.Series, cv_mae_col=\"Cross-validation\") -> pd.DataFrame:\n",
    "    \"\"\"在指标表中追加 RMAE（=MAE / mean(y)）\"\"\"\n",
    "    df = df.copy()\n",
    "    y_tr_mean = float(np.nanmean(y_tr))\n",
    "    y_te_mean = float(np.nanmean(y_te))\n",
    "    if not np.isfinite(y_te_mean): y_te_mean = y_tr_mean\n",
    "    df[\"In sample RMAE\"]      = df[\"In sample\"]       / y_tr_mean if y_tr_mean else np.nan\n",
    "    df[\"Out of sample RMAE\"]  = df[\"Out of sample\"]   / y_te_mean if y_te_mean else np.nan\n",
    "    df[\"CV RMAE\"]             = df[cv_mae_col]        / y_tr_mean if y_tr_mean else np.nan\n",
    "    cols = [\"Metrics\",\"In sample\",\"In sample RMAE\",\"Out of sample\",\"Out of sample RMAE\",\"Cross-validation\",\"CV RMAE\",\"Kaggle Score\"]\n",
    "    return df[cols]\n",
    "\n",
    "def _pretty_print_block(title_cn: str, metrics_df: pd.DataFrame):\n",
    "    \"\"\"美观打印指标块（带中文标题与分隔线）\"\"\"\n",
    "    line = \"=\" * 72\n",
    "    print(line)\n",
    "    print(title_cn)\n",
    "    print(line)\n",
    "    print(metrics_df.to_string(index=False))\n",
    "    print()\n",
    "\n",
    "def fit_and_report(df_raw: pd.DataFrame, dataset_name: str) -> pd.DataFrame:\n",
    "    \"\"\"对单个数据集执行：清洗→分割→筛特征→建模→评估→返回指标表\"\"\"\n",
    "    print(f\"\\n========== [{dataset_name}] 清洗 ==========\")\n",
    "    cleaned = clean_housing_df(df_raw, is_rent=(dataset_name==\"RENT\"))\n",
    "\n",
    "    # 识别目标列、去除缺失目标\n",
    "    target = identify_target(cleaned)\n",
    "    y_all_raw = pd.to_numeric(cleaned[target], errors=\"coerce\")\n",
    "    mask = y_all_raw.notna()\n",
    "    cleaned = cleaned.loc[mask].reset_index(drop=True)\n",
    "    y_all_raw = y_all_raw.loc[mask]\n",
    "\n",
    "    X_all = cleaned.drop(columns=[target])\n",
    "\n",
    "    # 防泄漏：按列名规则删除强疑似泄漏列\n",
    "    leak_drp = LeakageDropper(target=target).fit(X_all, None)\n",
    "    if leak_drp.to_drop_:\n",
    "        print(f\"[{dataset_name}] 删除疑似泄漏列: {leak_drp.to_drop_}\")\n",
    "        X_all = X_all.drop(columns=leak_drp.to_drop_, errors=\"ignore\")\n",
    "\n",
    "    # 80/20 切分train和validation\n",
    "    X_tr, X_te, y_tr_raw, y_te_raw = train_test_split(X_all, y_all_raw, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "    #  IQR 去异常值\n",
    "    q1, q3 = np.nanpercentile(y_tr_raw, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lo, hi = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "    keep = (y_tr_raw >= lo) & (y_tr_raw <= hi)\n",
    "    X_tr, y_tr_raw = X_tr.loc[keep], y_tr_raw.loc[keep]\n",
    "    print(f\"[{dataset_name}] IQR 剔除目标极端值: {int((~keep).sum())}；保留训练样本: {X_tr.shape[0]}\")\n",
    "    print(f\"[{dataset_name}] 验证集预测条数(Out-of-sample): {X_te.shape[0]}\")\n",
    "\n",
    "    # 低相关特征与高VIF共线特征\n",
    "    low_corr = fast_corr_prefilter(X_tr, y_tr_raw, thr=LOW_CORR_THR)\n",
    "    if low_corr:\n",
    "        print(f\"[{dataset_name}] 删除低相关数值列(|Spearman|<{LOW_CORR_THR}): {len(low_corr)} 列\")\n",
    "        X_tr = X_tr.drop(columns=low_corr, errors=\"ignore\")\n",
    "        X_te = X_te.drop(columns=low_corr, errors=\"ignore\")\n",
    "\n",
    "    high_vif = compute_high_vif_numeric(pd.concat([X_tr, y_tr_raw], axis=1), thresh=VIF_THRESH)\n",
    "    if high_vif:\n",
    "        print(f\"[{dataset_name}] 删除高VIF(≥{VIF_THRESH})列: {high_vif}\")\n",
    "        X_tr = X_tr.drop(columns=high_vif, errors=\"ignore\")\n",
    "        X_te = X_te.drop(columns=high_vif, errors=\"ignore\")\n",
    "\n",
    "    # 预处理流水线+ 方差过滤\n",
    "    preproc = build_preprocessor(X_tr, use_poly=USE_POLY)\n",
    "\n",
    "    # FAST_DEMO 模式下限制参与CV的样本规模\n",
    "    cv = KFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    X_cv, y_cv_raw = X_tr, y_tr_raw\n",
    "    if FAST_DEMO and X_tr.shape[0] > MAX_CV_ROWS:\n",
    "        rng = np.random.RandomState(RANDOM_STATE)\n",
    "        idx = rng.choice(np.arange(X_tr.shape[0]), size=MAX_CV_ROWS, replace=False)\n",
    "        X_cv, y_cv_raw = X_tr.iloc[idx], y_tr_raw.iloc[idx]\n",
    "        print(f\"[{dataset_name}] CV样本: {X_cv.shape[0]} / {X_tr.shape[0]} (FAST_DEMO)\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # ---- OLS ----\n",
    "    print(f\"[{dataset_name}] 训练：OLS\")\n",
    "    ols_pipe = Pipeline([(\"pre\", preproc), (\"reg\", LinearRegression())])\n",
    "    ols_ttr  = TransformedTargetRegressor(regressor=ols_pipe, func=np.log1p, inverse_func=np.expm1)\n",
    "    cv_mae_ols = -np.mean(cross_val_score(ols_ttr, X_cv, y_cv_raw, cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs=-1))\n",
    "    ols_ttr.fit(X_tr, y_tr_raw)\n",
    "    results.append({\"Metrics\":\"OLS\",\n",
    "                    \"In sample\": mean_absolute_error(y_tr_raw, ols_ttr.predict(X_tr)),\n",
    "                    \"Out of sample\": mean_absolute_error(y_te_raw, ols_ttr.predict(X_te)),\n",
    "                    \"Cross-validation\": cv_mae_ols,\n",
    "                    \"Kaggle Score\": \"待提交\"})\n",
    "\n",
    "    # ---- LASSO ----\n",
    "    print(f\"[{dataset_name}] 训练：LASSO\")\n",
    "    lasso_pipe = Pipeline([(\"pre\", preproc), (\"reg\", Lasso(max_iter=10000, random_state=RANDOM_STATE))])\n",
    "    lasso_ttr  = TransformedTargetRegressor(regressor=lasso_pipe, func=np.log1p, inverse_func=np.expm1)\n",
    "    # 覆盖较弱到中等的惩罚强度，以避免过度稀疏导致欠拟合\n",
    "    lasso_grid = {\n",
    "        \"regressor__reg__alpha\": (\n",
    "            np.r_[np.logspace(-4, -1, 5), np.logspace(-1, 2, 8)] if FAST_DEMO\n",
    "            else np.logspace(-4, 2, 20)\n",
    "        )\n",
    "    }\n",
    "    lasso_cv   = GridSearchCV(lasso_ttr, lasso_grid, scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=-1)\n",
    "    lasso_cv.fit(X_cv, y_cv_raw)\n",
    "    lasso_best = lasso_cv.best_estimator_\n",
    "    results.append({\"Metrics\":\"LASSO\",\n",
    "                    \"In sample\": mean_absolute_error(y_tr_raw, lasso_best.predict(X_tr)),\n",
    "                    \"Out of sample\": mean_absolute_error(y_te_raw, lasso_best.predict(X_te)),\n",
    "                    \"Cross-validation\": -lasso_cv.best_score_,\n",
    "                    \"Kaggle Score\": \"待提交\"})\n",
    "\n",
    "    # ---- Ridge ----\n",
    "    print(f\"[{dataset_name}] 训练：Ridge\")\n",
    "    ridge_pipe = Pipeline([(\"pre\", preproc), (\"reg\", Ridge())])\n",
    "    ridge_ttr  = TransformedTargetRegressor(regressor=ridge_pipe, func=np.log1p, inverse_func=np.expm1)\n",
    "    ridge_grid = {\"regressor__reg__alpha\": (np.logspace(0, 4, 6) if FAST_DEMO else np.logspace(-2, 5, 12))} # 1~1e4\n",
    "    ridge_cv   = GridSearchCV(ridge_ttr, ridge_grid, scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=-1)\n",
    "    ridge_cv.fit(X_cv, y_cv_raw)\n",
    "    ridge_best = ridge_cv.best_estimator_\n",
    "    results.append({\"Metrics\":\"Ridge\",\n",
    "                    \"In sample\": mean_absolute_error(y_tr_raw, ridge_best.predict(X_tr)),\n",
    "                    \"Out of sample\": mean_absolute_error(y_te_raw, ridge_best.predict(X_te)),\n",
    "                    \"Cross-validation\": -ridge_cv.best_score_,\n",
    "                    \"Kaggle Score\": \"待提交\"})\n",
    "\n",
    "    # ---- Elastic Net ----\n",
    "    print(f\"[{dataset_name}] 训练：Elastic Net\")\n",
    "    enet_pipe = Pipeline([(\"pre\", preproc), (\"reg\", ElasticNet(max_iter=10000, random_state=RANDOM_STATE))])\n",
    "    enet_ttr  = TransformedTargetRegressor(regressor=enet_pipe, func=np.log1p, inverse_func=np.expm1)\n",
    "    enet_grid = {\n",
    "        # 1e-4 ~ 1e+2，覆盖弱到中等惩罚\n",
    "        \"regressor__reg__alpha\": (\n",
    "            np.r_[np.logspace(-4, -1, 5), np.logspace(-1, 2, 8)] if FAST_DEMO\n",
    "            else np.logspace(-4, 2, 20)\n",
    "        ),\n",
    "        # 加入接近 Ridge 的比率，避免过度稀疏\n",
    "        \"regressor__reg__l1_ratio\": ([0.05, 0.2, 0.4, 0.6, 0.8] if FAST_DEMO\n",
    "                                     else [0.05, 0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "    }\n",
    "    enet_cv   = GridSearchCV(enet_ttr, enet_grid, scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=-1)\n",
    "    enet_cv.fit(X_cv, y_cv_raw)\n",
    "    enet_best = enet_cv.best_estimator_\n",
    "    results.append({\"Metrics\":\"Elastic Net\",\n",
    "                    \"In sample\": mean_absolute_error(y_tr_raw, enet_best.predict(X_tr)),\n",
    "                    \"Out of sample\": mean_absolute_error(y_te_raw, enet_best.predict(X_te)),\n",
    "                    \"Cross-validation\": -enet_cv.best_score_,\n",
    "                    \"Kaggle Score\": \"待提交\"})\n",
    "\n",
    "    # 最佳线性模型\n",
    "    metrics = pd.DataFrame(results).sort_values(\"Cross-validation\").reset_index(drop=True)\n",
    "    best_row = metrics.loc[0].copy()\n",
    "    best_row[\"Metrics\"] = \"Best Linear Model\"\n",
    "    metrics = pd.concat([metrics, pd.DataFrame([best_row])], ignore_index=True)\n",
    "\n",
    "    # 追加 RMAE 列\n",
    "    metrics = _append_rmae_columns(metrics, y_tr_raw, y_te_raw, cv_mae_col=\"Cross-validation\")\n",
    "    return metrics\n",
    "\n",
    "def _get_id_series(df_raw: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"拿到ID列（优先 'ID'，其次 'id'；若都没有则回退为顺序编号）\"\"\"\n",
    "    if \"ID\" in df_raw.columns: \n",
    "        return df_raw[\"ID\"]\n",
    "    if \"id\" in df_raw.columns:\n",
    "        return df_raw[\"id\"]\n",
    "    return pd.Series(np.arange(len(df_raw)), name=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd00f09c-c300-40f5-8c3c-933b4cc23bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ensure_required_columns_for_predict(fitted_ttr, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    根据已拟合的 TransformedTargetRegressor 内部 ColumnTransformer，补齐预测所需但缺失的列。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pre_pipe = fitted_ttr.regressor_[\"pre\"]\n",
    "        coltrans = pre_pipe.named_steps[\"pre_cols\"]\n",
    "    except Exception:\n",
    "        return df\n",
    "\n",
    "    required_cols = []\n",
    "    for name, trans, cols in getattr(coltrans, \"transformers_\", []):\n",
    "        if cols is None:\n",
    "            continue\n",
    "        if isinstance(cols, list):\n",
    "            required_cols.extend(cols)\n",
    "        else:\n",
    "            try:\n",
    "                required_cols.extend(list(cols))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    required_cols = [c for c in required_cols if isinstance(c, str)]\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    for c in missing:\n",
    "        df[c] = np.nan\n",
    "    return df\n",
    "\n",
    "def predict_to_csv(best_estimator, test_csv: Path, out_csv: Path, is_rent: bool):\n",
    "    \"\"\"用训练好的最佳模型对测试集预测，并导出为两列(ID, Price)的CSV\"\"\"\n",
    "    test_raw = pd.read_csv(test_csv, low_memory=False)\n",
    "    ids = _get_id_series(test_raw)\n",
    "    # 与训练一致的清洗；只做列转换，不删样本\n",
    "    test_clean = clean_housing_df(test_raw, is_rent=is_rent)\n",
    "    # 补齐训练所需但测试缺失的列\n",
    "    test_clean = _ensure_required_columns_for_predict(best_estimator, test_clean)\n",
    "    # 预测\n",
    "    preds = best_estimator.predict(test_clean)\n",
    "    pd.DataFrame({\"ID\": ids.values, \"Price\": preds}).to_csv(out_csv, index=False)\n",
    "\n",
    "def train_best_estimator(df_raw: pd.DataFrame, dataset_name: str):\n",
    "    \"\"\"\n",
    "    仅训练并返回“最佳线性模型”用于预测（与 fit_and_report 的模型与网格一致），\n",
    "    保持与上方训练流程一致，按CV MAE 最小选择 OLS/LASSO/Ridge/ENet 中的最佳者。\n",
    "    \"\"\"\n",
    "    # —— 以下基本复用在 fit_and_report 里的流程 ——\n",
    "    cleaned = clean_housing_df(df_raw, is_rent=(dataset_name==\"RENT\"))\n",
    "    target = identify_target(cleaned)\n",
    "    y_all_raw = pd.to_numeric(cleaned[target], errors=\"coerce\")\n",
    "    mask = y_all_raw.notna()\n",
    "    cleaned = cleaned.loc[mask].reset_index(drop=True)\n",
    "    y_all_raw = y_all_raw.loc[mask]\n",
    "    X_all = cleaned.drop(columns=[target])\n",
    "\n",
    "    # 防泄漏\n",
    "    leak_drp = LeakageDropper(target=target).fit(X_all, None)\n",
    "    X_all = X_all.drop(columns=leak_drp.to_drop_, errors=\"ignore\")\n",
    "\n",
    "    # 切分\n",
    "    X_tr, X_te, y_tr_raw, y_te_raw = train_test_split(X_all, y_all_raw, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "    # IQR 去极端\n",
    "    q1, q3 = np.nanpercentile(y_tr_raw, [25, 75]); iqr = q3 - q1\n",
    "    lo, hi = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "    keep = (y_tr_raw >= lo) & (y_tr_raw <= hi)\n",
    "    X_tr, y_tr_raw = X_tr.loc[keep], y_tr_raw.loc[keep]\n",
    "\n",
    "    # 低相关 / 高VIF\n",
    "    low_corr = fast_corr_prefilter(X_tr, y_tr_raw, thr=LOW_CORR_THR)\n",
    "    X_tr = X_tr.drop(columns=low_corr, errors=\"ignore\")\n",
    "    X_te = X_te.drop(columns=low_corr, errors=\"ignore\")\n",
    "    high_vif = compute_high_vif_numeric(pd.concat([X_tr, y_tr_raw], axis=1), thresh=VIF_THRESH)\n",
    "    X_tr = X_tr.drop(columns=high_vif, errors=\"ignore\")\n",
    "    X_te = X_te.drop(columns=high_vif, errors=\"ignore\")\n",
    "\n",
    "    # 预处理\n",
    "    preproc = build_preprocessor(X_tr, use_poly=USE_POLY)\n",
    "\n",
    "    # CV 与网格\n",
    "    cv = KFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    X_cv, y_cv_raw = X_tr, y_tr_raw\n",
    "    if FAST_DEMO and X_tr.shape[0] > MAX_CV_ROWS:\n",
    "        rng = np.random.RandomState(RANDOM_STATE)\n",
    "        idx = rng.choice(np.arange(X_tr.shape[0]), size=MAX_CV_ROWS, replace=False)\n",
    "        X_cv, y_cv_raw = X_tr.iloc[idx], y_tr_raw.iloc[idx]\n",
    "\n",
    "    candidates = {}\n",
    "\n",
    "    # OLS\n",
    "    ols_pipe = Pipeline([(\"pre\", preproc), (\"reg\", LinearRegression())])\n",
    "    ols = TransformedTargetRegressor(regressor=ols_pipe, func=np.log1p, inverse_func=np.expm1)\n",
    "    ols_cv_mae = -np.mean(cross_val_score(ols, X_cv, y_cv_raw, cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs=-1))\n",
    "    ols.fit(X_tr, y_tr_raw)\n",
    "    candidates[\"OLS\"] = (ols_cv_mae, ols)\n",
    "\n",
    "    # LASSO\n",
    "    lasso_pipe = Pipeline([(\"pre\", preproc), (\"reg\", Lasso(max_iter=10000, random_state=RANDOM_STATE))])\n",
    "    lasso = TransformedTargetRegressor(regressor=lasso_pipe, func=np.log1p, inverse_func=np.expm1)\n",
    "    lasso_grid = {\"regressor__reg__alpha\": (np.r_[np.logspace(-4, -1, 5), np.logspace(-1, 2, 8)] if FAST_DEMO else np.logspace(-4, 2, 20))}\n",
    "    lasso_cv = GridSearchCV(lasso, lasso_grid, scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=-1)\n",
    "    lasso_cv.fit(X_cv, y_cv_raw)\n",
    "    candidates[\"LASSO\"] = (-lasso_cv.best_score_, lasso_cv.best_estimator_)\n",
    "\n",
    "    # Ridge\n",
    "    ridge_pipe = Pipeline([(\"pre\", preproc), (\"reg\", Ridge())])\n",
    "    ridge = TransformedTargetRegressor(regressor=ridge_pipe, func=np.log1p, inverse_func=np.expm1)\n",
    "    ridge_grid = {\"regressor__reg__alpha\": (np.logspace(0, 4, 6) if FAST_DEMO else np.logspace(-2, 5, 12))}\n",
    "    ridge_cv = GridSearchCV(ridge, ridge_grid, scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=-1)\n",
    "    ridge_cv.fit(X_cv, y_cv_raw)\n",
    "    candidates[\"Ridge\"] = (-ridge_cv.best_score_, ridge_cv.best_estimator_)\n",
    "\n",
    "    # Elastic Net\n",
    "    enet_pipe = Pipeline([(\"pre\", preproc), (\"reg\", ElasticNet(max_iter=10000, random_state=RANDOM_STATE))])\n",
    "    enet = TransformedTargetRegressor(regressor=enet_pipe, func=np.log1p, inverse_func=np.expm1)\n",
    "    enet_grid = {\n",
    "        \"regressor__reg__alpha\": (np.r_[np.logspace(-4, -1, 5), np.logspace(-1, 2, 8)] if FAST_DEMO else np.logspace(-4, 2, 20)),\n",
    "        \"regressor__reg__l1_ratio\": ([0.05, 0.2, 0.4, 0.6, 0.8] if FAST_DEMO else [0.05, 0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "    }\n",
    "    enet_cv = GridSearchCV(enet, enet_grid, scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=-1)\n",
    "    enet_cv.fit(X_cv, y_cv_raw)\n",
    "    candidates[\"Elastic Net\"] = (-enet_cv.best_score_, enet_cv.best_estimator_)\n",
    "\n",
    "    # 选 CV MAE 最小者\n",
    "    best_name = min(candidates.items(), key=lambda kv: kv[1][0])[0]\n",
    "    best_est = candidates[best_name][1]\n",
    "    # 以全量训练集拟合一次最佳模型\n",
    "    return best_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3eaef0f-b3e0-4c6d-bf76-f17d568072fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== [PRICE] 清洗 ==========\n",
      "[PRICE] IQR 剔除目标极端值: 6312；保留训练样本: 76784\n",
      "[PRICE] 验证集预测条数(Out-of-sample): 20775\n",
      "[PRICE] 删除高VIF(≥15.0)列: ['coord_x', 'coord_y', 'lat', 'lon']\n",
      "[PRICE] CV样本: 30000 / 76784 (FAST_DEMO)\n",
      "[PRICE] 训练：OLS\n",
      "[PRICE] 训练：LASSO\n",
      "[PRICE] 训练：Ridge\n",
      "[PRICE] 训练：Elastic Net\n",
      "\n",
      "========== [RENT] 清洗 ==========\n",
      "[RENT] IQR 剔除目标极端值: 4392；保留训练样本: 74727\n",
      "[RENT] 验证集预测条数(Out-of-sample): 19780\n",
      "[RENT] 删除低相关数值列(|Spearman|<0.05): 1 列\n",
      "[RENT] 删除高VIF(≥15.0)列: ['coord_x', 'lon']\n",
      "[RENT] CV样本: 30000 / 74727 (FAST_DEMO)\n",
      "[RENT] 训练：OLS\n",
      "[RENT] 训练：LASSO\n",
      "[RENT] 训练：Ridge\n",
      "[RENT] 训练：Elastic Net\n",
      "\n",
      "======== PRICE Metrics (MAE) ========\n",
      "========================================================================\n",
      "价格  模型性能汇总：\n",
      "========================================================================\n",
      "          Metrics     In sample  In sample RMAE  Out of sample  Out of sample RMAE  Cross-validation  CV RMAE Kaggle Score\n",
      "            LASSO 264368.093750        0.154154  487137.596984            0.218064     265271.728779 0.154681          待提交\n",
      "      Elastic Net 267149.100409        0.155776  482963.737019            0.216196     268083.842920 0.156321          待提交\n",
      "            Ridge 304332.351388        0.177458  488157.436197            0.218521     300646.354675 0.175308          待提交\n",
      "              OLS 336124.716858        0.195996  513668.954146            0.229941     341350.976229 0.199043          待提交\n",
      "Best Linear Model 264368.093750        0.154154  487137.596984            0.218064     265271.728779 0.154681          待提交\n",
      "\n",
      "======== RENT Metrics (MAE) ========\n",
      "========================================================================\n",
      "租金  模型性能汇总：\n",
      "========================================================================\n",
      "          Metrics    In sample  In sample RMAE  Out of sample  Out of sample RMAE  Cross-validation  CV RMAE Kaggle Score\n",
      "      Elastic Net 68904.613870        0.145718  111989.082549            0.192458      68999.762421 0.145919          待提交\n",
      "            LASSO 69038.799461        0.146002  113373.982993            0.194838      69173.617374 0.146287          待提交\n",
      "            Ridge 74272.195431        0.157069  112957.155880            0.194122      72987.944734 0.154353          待提交\n",
      "              OLS 80876.692606        0.171036  119694.787245            0.205700      80570.832140 0.170390          待提交\n",
      "Best Linear Model 68904.613870        0.145718  111989.082549            0.192458      68999.762421 0.145919          待提交\n",
      "\n",
      "\n",
      "已导出：\n",
      "- /Users/Peiyao_Jin/Desktop/Code/midterm_exam/pred_test_price.csv\n",
      "- /Users/Peiyao_Jin/Desktop/Code/midterm_exam/pred_test_rent.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------ 主程序 ------------------\n",
    "def main():\n",
    "    \"\"\"读取数据→分别训练 PRICE/RENT→打印两块指标表\"\"\"\n",
    "    if not TRAIN_PRICE.exists() or not TRAIN_RENT.exists():\n",
    "        raise FileNotFoundError(f\"未找到训练数据：\\n- {TRAIN_PRICE}\\n- {TRAIN_RENT}\\n请检查 DATA_DIR 或文件名。\")\n",
    "\n",
    "    price_train = pd.read_csv(TRAIN_PRICE, low_memory=False)\n",
    "    rent_train  = pd.read_csv(TRAIN_RENT,  low_memory=False)\n",
    "\n",
    "    price_metrics = fit_and_report(price_train, dataset_name=\"PRICE\")\n",
    "    rent_metrics  = fit_and_report(rent_train,  dataset_name=\"RENT\")\n",
    "\n",
    "    print(\"\\n======== PRICE Metrics (MAE) ========\")\n",
    "    _pretty_print_block(\"价格  模型性能汇总：\", price_metrics)\n",
    "    print(\"======== RENT Metrics (MAE) ========\")\n",
    "    _pretty_print_block(\"租金  模型性能汇总：\", rent_metrics)\n",
    "\n",
    "    # ==== 导出 test 的两个 CSV ====\n",
    "    price_best = train_best_estimator(price_train, dataset_name=\"PRICE\")\n",
    "    rent_best  = train_best_estimator(rent_train,  dataset_name=\"RENT\")\n",
    "    predict_to_csv(price_best, TEST_PRICE, OUT_PRICE, is_rent=False)\n",
    "    predict_to_csv(rent_best,  TEST_RENT,  OUT_RENT,  is_rent=True)\n",
    "\n",
    "    print(f\"\\n已导出：\\n- {OUT_PRICE}\\n- {OUT_RENT}\\n\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf041da0-c71e-44d1-b49a-533a5db97626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
