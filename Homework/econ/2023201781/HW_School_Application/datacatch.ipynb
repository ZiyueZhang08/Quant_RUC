{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d0858b-7014-4ed9-83a9-1555c907e2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\31616\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\31616\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\31616\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\31616\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\31616\\anaconda3\\lib\\site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\31616\\anaconda3\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\31616\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b742605-9842-4f7e-a8af-9994b7533a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e9e430-b543-47dd-b2e3-8eaa5fbb0275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5af3d64b-4f2c-4694-956c-798e83e75edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 目标网站和基本设置 ---\n",
    "URL = \"https://ideas.repec.org/top/top.econdept.html\"\n",
    "# 设置请求头，模拟浏览器访问，避免被网站拦截\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c2f7ab3-60fd-4292-897a-db8bb54dcfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在访问目标网站...\n",
      "网站访问成功！\n"
     ]
    }
   ],
   "source": [
    "# --- 2. 发送请求，获取网页内容 ---\n",
    "print(\"正在访问目标网站...\")\n",
    "try:\n",
    "    response = requests.get(URL, headers=HEADERS)\n",
    "    response.raise_for_status() # 如果请求失败 (比如 404), 会抛出异常\n",
    "    print(\"网站访问成功！\")\n",
    "except requests.RequestException as e:\n",
    "    print(f\"访问网站失败: {e}\")\n",
    "    exit() # 如果网站访问不了，就退出程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc59eb9-5025-424f-a88c-f398f3c1d70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已找到排名表格，正在提取大学名称...\n",
      "成功提取了 338 所大学机构的名称。\n"
     ]
    }
   ],
   "source": [
    "# --- 3. 解析网页，提取大学名称 ---\n",
    "# 使用 BeautifulSoup 解析 HTML\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# 创建一个空列表来存放所有大学的名字\n",
    "all_universities = []\n",
    "\n",
    "# 首先，找到包含排名的那个大表格，它的 id 是 'ranklist'\n",
    "rank_table = soup.find('table', {'class': 'shorttop'})\n",
    "\n",
    "if rank_table:\n",
    "    print(\"已找到排名表格，正在提取大学名称...\")\n",
    "    # 找到表格中所有的行 <tr>\n",
    "    # 我们要跳过第一行，因为那是表头\n",
    "    rows = rank_table.find_all('tr')[1:] \n",
    "    \n",
    "    for row in rows:\n",
    "        # 每一行里有很多列 <td>，大学名称在第二列 (索引为 1)\n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) > 1:\n",
    "            # 提取第二列的文本，并用 .strip() 去掉前后的空格\n",
    "            university_name_raw = cols[1].text.strip()\n",
    "            \n",
    "            # 清洗数据：名字通常是 \"University Name - Department of...\" 的格式\n",
    "            # 我们只想要前半部分 \"University Name\"\n",
    "            university_name_clean = university_name_raw.split(' - ')[0]\n",
    "            \n",
    "            all_universities.append(university_name_clean)\n",
    "else:\n",
    "    print(\"错误：在页面上没有找到 id 为 'ranklist' 的表格。\")\n",
    "    exit()\n",
    "\n",
    "print(f\"成功提取了 {len(all_universities)} 所大学机构的名称。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01a41a4f-54df-4905-95c8-bf797fae7b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已按要求选取30所大学。\n"
     ]
    }
   ],
   "source": [
    "# --- 4. 按照你的要求选取30所大学 ---\n",
    "# 10 from top 30, 10 from top 60, 10 from top 90\n",
    "# 为了简单且符合要求，我们取 1-10名, 31-40名, 61-70名\n",
    "# 注意列表索引是从0开始的\n",
    "selected_universities = []\n",
    "if len(all_universities) >= 90:\n",
    "    group1 = all_universities[0:10]    # Top 10 (排名 1-10)\n",
    "    group2 = all_universities[30:40]   # (排名 31-40)\n",
    "    group3 = all_universities[60:70]   # (排名 61-70)\n",
    "    selected_universities = group1 + group2 + group3\n",
    "    print(\"已按要求选取30所大学。\")\n",
    "else:\n",
    "    print(\"警告：提取到的大学数量不足90所，将使用能获取到的最多的大学进行分组合并。\")\n",
    "    # 如果数量不够，就尽量取\n",
    "    selected_universities = all_universities[:10] + all_universities[30:min(40, len(all_universities))] + all_universities[60:min(70, len(all_universities))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ca4e281-da91-4abf-a48a-618600724d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 成功！大学列表已保存到 'universities_list.xlsx' 文件中。\n",
      "现在，请打开这个新文件，将大学名单复制到你的 `data.xlsx` 的 `Universities` 工作表中。\n"
     ]
    }
   ],
   "source": [
    "# --- 5. 保存到 Excel 文件 ---\n",
    "# 将列表转换为 pandas DataFrame\n",
    "df_to_save = pd.DataFrame(selected_universities, columns=['UniversityName'])\n",
    "\n",
    "# 保存为一个新的 Excel 文件，这样更安全，不会破坏你原来的 data.xlsx\n",
    "output_filename = \"universities_list.xlsx\"\n",
    "df_to_save.to_excel(output_filename, index=False)\n",
    "\n",
    "print(f\"\\n🎉 成功！大学列表已保存到 '{output_filename}' 文件中。\")\n",
    "print(\"现在，请打开这个新文件，将大学名单复制到你的 `data.xlsx` 的 `Universities` 工作表中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb63aec-1f22-49fa-ae45-c2503d687caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\31616\\zPython_econ\\Grad_Application_Generator\\HW_School_Application\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4fc37c-d1ae-42b6-a575-a4e7e572ab19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
