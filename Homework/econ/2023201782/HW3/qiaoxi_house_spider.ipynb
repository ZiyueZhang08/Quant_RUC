{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe80bc2a-8c07-48ba-8e80-54d2321fe60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common import NoSuchElementException, TimeoutException\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "\n",
    "class QiaoxiHouseSpider:\n",
    "    \"\"\"爬取桥西地区二手房和租房数据的爬虫类\"\"\"\n",
    "    \n",
    "    def __init__(self, max_pages=30):\n",
    "        \"\"\"初始化爬虫，设置URL、最大页数和数据保存路径\"\"\"\n",
    "        self.ershou_url = \"https://zhangjiakou.esf.fang.com/house-a014962\"  # 二手房URL\n",
    "        self.rent_url = \"https://zhangjiakou.zu.fang.com/house-a014962/\"  # 租房URL\n",
    "        self.max_pages = max_pages  # 最大爬取页数\n",
    "        self.area_name = \"桥西\"  # 目标区域\n",
    "        # 创建数据保存目录\n",
    "        self.data_dir = \"house_data\"\n",
    "        if not os.path.exists(self.data_dir):\n",
    "            os.makedirs(self.data_dir)\n",
    "        \n",
    "    def _get_driver(self):\n",
    "        \"\"\"配置并返回Edge浏览器驱动（无头模式）\"\"\"\n",
    "        edge_opts = Options()\n",
    "        edge_opts.add_argument(\"--headless=new\")  # 无头模式，不显示浏览器窗口\n",
    "        edge_opts.add_argument(\"--disable-gpu\")\n",
    "        edge_opts.add_argument(\"--no-sandbox\")\n",
    "        edge_opts.add_experimental_option(\"useAutomationExtension\", False)\n",
    "        edge_opts.add_argument(\"--ignore-certificate-errors\")\n",
    "        edge_opts.add_argument(\"--ignore-ssl-errors\")\n",
    "        return webdriver.Edge(options=edge_opts)\n",
    "    \n",
    "    def _parse_ershou_page(self, driver, wait):\n",
    "        \"\"\"解析二手房页面，提取房源信息\"\"\"\n",
    "        house_list = []\n",
    "        try:\n",
    "            # 等待房源列表加载完成\n",
    "            container = wait.until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"shop_list_4\"))\n",
    "            )\n",
    "            items = container.find_elements(By.XPATH, \".//dl[@dataflag='bg']\")\n",
    "            \n",
    "            for item in items:\n",
    "                house_info = {\"区域\": self.area_name}\n",
    "                \n",
    "                # 提取房源标题和小区名称\n",
    "                try:\n",
    "                    title_elem = item.find_element(By.CLASS_NAME, \"tit_shop\")\n",
    "                    title_text = title_elem.text.strip()\n",
    "                    house_info[\"房源标题\"] = title_text\n",
    "                    comm_match = re.search(r'^([^\\d]+?)[\\s\\-]', title_text)\n",
    "                    house_info[\"小区名称\"] = comm_match.group(1).strip() if comm_match else None\n",
    "                except:\n",
    "                    house_info[\"房源标题\"] = None\n",
    "                    house_info[\"小区名称\"] = None\n",
    "                \n",
    "                # 提取户型、面积、朝向等信息\n",
    "                try:\n",
    "                    info_text = item.find_element(By.CLASS_NAME, \"tel_shop\").text\n",
    "                    house_type = re.search(r\"\\d+室\\d+厅\", info_text)\n",
    "                    house_info[\"户型\"] = house_type.group() if house_type else None\n",
    "                    \n",
    "                    area_val = re.search(r\"\\d+\\.?\\d+㎡\", info_text)\n",
    "                    house_info[\"建筑面积\"] = area_val.group() if area_val else None\n",
    "                    \n",
    "                    direction = re.search(r\"[东南西北]+向\", info_text)\n",
    "                    house_info[\"朝向\"] = direction.group() if direction else None\n",
    "                    \n",
    "                    year = re.search(r\"\\d{4}年\", info_text)\n",
    "                    house_info[\"建造年份\"] = year.group() if year else None\n",
    "                    \n",
    "                    floor_match = re.search(r\"(高|中|低)层.*?共(\\d+)层\", info_text)\n",
    "                    if floor_match:\n",
    "                        house_info[\"楼层类型\"] = floor_match.group(1) + \"层\"\n",
    "                        house_info[\"总层数\"] = floor_match.group(2) + \"层\"\n",
    "                    else:\n",
    "                        house_info[\"楼层类型\"] = None\n",
    "                        house_info[\"总层数\"] = None\n",
    "                except:\n",
    "                    house_info[\"户型\"] = house_info[\"建筑面积\"] = house_info[\"朝向\"] = None\n",
    "                    house_info[\"建造年份\"] = house_info[\"楼层类型\"] = house_info[\"总层数\"] = None\n",
    "                \n",
    "                # 提取价格信息\n",
    "                try:\n",
    "                    total_price = item.find_element(By.XPATH, \".//dd[@class='price_right']/span[1]\").text\n",
    "                    house_info[\"总价\"] = total_price\n",
    "                except:\n",
    "                    house_info[\"总价\"] = None\n",
    "                    \n",
    "                try:\n",
    "                    unit_price = item.find_element(By.XPATH, \".//dd[@class='price_right']/span[2]\").text\n",
    "                    house_info[\"单价\"] = unit_price\n",
    "                except:\n",
    "                    house_info[\"单价\"] = None\n",
    "                \n",
    "                # 提取区域位置\n",
    "                try:\n",
    "                    area_pos = item.find_element(By.CLASS_NAME, \"add_shop\").text\n",
    "                    house_info[\"区域位置\"] = area_pos\n",
    "                except:\n",
    "                    house_info[\"区域位置\"] = None\n",
    "                \n",
    "                house_list.append(house_info)\n",
    "        except Exception as e:\n",
    "            print(f\"解析二手房页面出错: {str(e)}\")\n",
    "            \n",
    "        return house_list\n",
    "    \n",
    "    def crawl_ershou_data(self):\n",
    "        \"\"\"爬取二手房数据并保存为CSV文件\"\"\"\n",
    "        all_data = []\n",
    "        try:\n",
    "            with self._get_driver() as driver:\n",
    "                driver.get(self.ershou_url)\n",
    "                wait = WebDriverWait(driver, 5)\n",
    "                current_page = 1\n",
    "                \n",
    "                # 循环爬取多页\n",
    "                while current_page <= self.max_pages:\n",
    "                    print(f\"正在爬取桥西二手房第{current_page}页...\")\n",
    "                    page_data = self._parse_ershou_page(driver, wait)\n",
    "                    all_data.extend(page_data)\n",
    "                    \n",
    "                    # 翻页处理\n",
    "                    if current_page < self.max_pages:\n",
    "                        try:\n",
    "                            next_btn = wait.until(\n",
    "                                EC.element_to_be_clickable((By.XPATH, \"//a[text()='下一页']\"))\n",
    "                            )\n",
    "                            driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "                            time.sleep(2)  # 等待页面加载\n",
    "                            current_page += 1\n",
    "                        except (NoSuchElementException, TimeoutException):\n",
    "                            print(f\"第{current_page}页后无更多页面，终止爬取\")\n",
    "                            break\n",
    "        \n",
    "            # 保存数据到CSV\n",
    "            file_path = os.path.join(self.data_dir, f\"桥西二手房数据_{self.max_pages}页.csv\")\n",
    "            df = pd.DataFrame(all_data)\n",
    "            df.to_csv(file_path, index=False, encoding=\"utf-8-sig\")\n",
    "            print(f\"桥西二手房数据爬取完成，共{len(all_data)}条，已保存到 {file_path}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"二手房爬取过程出错: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def crawl_rent_data(self):\n",
    "        \"\"\"爬取租房数据并保存为CSV文件\"\"\"\n",
    "        all_data = []\n",
    "        try:\n",
    "            with self._get_driver() as driver:\n",
    "                driver.get(self.rent_url)\n",
    "                wait = WebDriverWait(driver, 5)\n",
    "                current_page = 1\n",
    "                \n",
    "                # 循环爬取多页\n",
    "                while current_page <= self.max_pages:\n",
    "                    print(f\"正在爬取桥西租房第{current_page}页...\")\n",
    "                    try:\n",
    "                        wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"houseList\")))\n",
    "                        items = driver.find_elements(\n",
    "                            By.XPATH, \"//div[@class='houseList']//dl[contains(@class, 'list')]\"\n",
    "                        )\n",
    "                        \n",
    "                        for item in items:\n",
    "                            rent_info = {\"区域\": self.area_name}\n",
    "                            \n",
    "                            # 提取房源标题和小区名称\n",
    "                            try:\n",
    "                                title_elem = item.find_element(By.XPATH, \".//dd//p[@class='title']/a\")\n",
    "                                title_text = title_elem.get_attribute(\"title\")\n",
    "                                rent_info[\"房源标题\"] = title_text\n",
    "                                comm_match = re.search(r'^([^\\d]+?)[\\s\\-]', title_text)\n",
    "                                rent_info[\"小区名称\"] = comm_match.group(1).strip() if comm_match else None\n",
    "                            except:\n",
    "                                continue\n",
    "                            \n",
    "                            # 提取户型、面积、朝向\n",
    "                            try:\n",
    "                                info_elem = item.find_element(By.XPATH, \".//dd//p[@class='font15 mt12']\")\n",
    "                                info_text = info_elem.text\n",
    "                                \n",
    "                                house_type = re.search(r\"\\d+室\\d+厅\", info_text)\n",
    "                                rent_info[\"户型\"] = house_type.group() if house_type else None\n",
    "                                \n",
    "                                area_val = re.search(r\"\\d+\\.?\\d+㎡\", info_text)\n",
    "                                rent_info[\"面积\"] = area_val.group() if area_val else None\n",
    "                                \n",
    "                                direction = re.search(r\"[东南西北]+向\", info_text)\n",
    "                                rent_info[\"朝向\"] = direction.group() if direction else None\n",
    "                            except:\n",
    "                                rent_info[\"户型\"] = rent_info[\"面积\"] = rent_info[\"朝向\"] = None\n",
    "                            \n",
    "                            # 提取租金\n",
    "                            try:\n",
    "                                price_elem = item.find_element(By.CLASS_NAME, \"price\")\n",
    "                                price_text = price_elem.text.strip()\n",
    "                                price_match = re.search(r\"\\d+\", price_text)\n",
    "                                rent_info[\"租金(元/月)\"] = int(price_match.group()) if price_match else None\n",
    "                            except:\n",
    "                                rent_info[\"租金(元/月)\"] = None\n",
    "                                \n",
    "                            # 判断是否业主直租\n",
    "                            try:\n",
    "                                item.find_element(By.XPATH, \".//span[contains(text(), '个人') or contains(text(), '业主')]\")\n",
    "                                rent_info[\"是否业主直租\"] = \"是\"\n",
    "                            except:\n",
    "                                rent_info[\"是否业主直租\"] = \"否\"\n",
    "                                \n",
    "                            all_data.append(rent_info)\n",
    "                        \n",
    "                        # 翻页处理\n",
    "                        if current_page < self.max_pages:\n",
    "                            try:\n",
    "                                next_btn = wait.until(\n",
    "                                    EC.element_to_be_clickable((By.XPATH, \"//a[contains(text(), '下一页')]\"))\n",
    "                                )\n",
    "                                driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "                                time.sleep(2)  # 等待页面加载\n",
    "                                current_page += 1\n",
    "                            except:\n",
    "                                print(f\"第{current_page}页后无更多页面，终止爬取\")\n",
    "                                break\n",
    "                    except Exception as e:\n",
    "                        print(f\"租房页面爬取错误: {str(e)}\")\n",
    "                        break\n",
    "        \n",
    "            # 保存数据到CSV\n",
    "            file_path = os.path.join(self.data_dir, f\"桥西租房数据_{self.max_pages}页.csv\")\n",
    "            df = pd.DataFrame(all_data)\n",
    "            df.to_csv(file_path, index=False, encoding=\"utf-8-sig\")\n",
    "            print(f\"桥西租房数据爬取完成，共{len(all_data)}条，已保存到 {file_path}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"租房爬取过程出错: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spider = QiaoxiHouseSpider(max_pages=30) # 初始化爬虫，最多爬取30页\n",
    "    # 爬取二手房数据\n",
    "    spider.crawl_ershou_data()  # 间隔3秒，避免请求过于频繁\n",
    "    time.sleep(3)\n",
    "    # 爬取租房数据\n",
    "    spider.crawl_rent_data()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa6bb1-5b61-460f-8240-d967e491c34a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
