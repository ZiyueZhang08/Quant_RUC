{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9631f980",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from docxtpl import DocxTemplate\n",
    "import os\n",
    "from docx2pdf import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31d22cd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def fetchUniversityList():\n",
    "    # 从网页读取学校列表信息\n",
    "    url = \"https://ideas.repec.org/top/top.econdept.html\"\n",
    "    resp = requests.get(url, timeout=20)\n",
    "    resp.encoding = resp.apparent_encoding or 'utf-8'\n",
    "    soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "    candidates = []\n",
    "    for li in soup.select(\"ol li\"):\n",
    "        txt = li.get_text(\" \", strip=True)\n",
    "        if txt:\n",
    "            candidates.append(txt)\n",
    "    if not candidates:\n",
    "        for tr in soup.select(\"table tr\"):\n",
    "            txt = tr.get_text(\" \", strip=True)\n",
    "            if txt:\n",
    "                candidates.append(txt)\n",
    "    if not candidates:\n",
    "        full = soup.get_text(\"\\n\")\n",
    "        candidates = re.findall(r'^\\s*\\d+\\..+$', full, flags=re.M)\n",
    "\n",
    "    # 提取网页的rank与institution部分\n",
    "    rows = []\n",
    "    for line in candidates:\n",
    "        m = re.search(r'^\\s*(\\d+)\\s+(.+?)\\s+(-?\\d+\\.\\d+)\\s+\\d+', line)\n",
    "        if m:\n",
    "            rank = int(m.group(1))\n",
    "            instRaw = m.group(2).strip()\n",
    "        else:\n",
    "            m2 = re.search(r'^\\s*(\\d+)\\s+(.+)$', line)\n",
    "            if not m2:\n",
    "                continue\n",
    "            rank = int(m2.group(1))\n",
    "            instRaw = m2.group(2).strip()\n",
    "        rows.append({\"rank\": rank, \"raw\": instRaw})\n",
    "\n",
    "    if not rows:\n",
    "        raise RuntimeError(\"未能从页面提取有效排名行，请检查页面结构。\")\n",
    "\n",
    "    # 关键词与国家表（用于排除仅为国家的错误结果）\n",
    "    instKeywords = [\n",
    "        \"University\", \"Institute\", \"College\", \"School\", \"Universiteit\", \"École\",\n",
    "        \"Business School\", \"School of Economics\", \"School of Management\", \"School of Arts and Sciences\"\n",
    "    ]\n",
    "    countries = {\n",
    "        \"netherlands\",\"italy\",\"france\",\"spain\",\"canada\",\"china\",\"germany\",\"united kingdom\",\n",
    "        \"united states\",\"usa\",\"australia\",\"brazil\",\"japan\"\n",
    "    }\n",
    "\n",
    "    # 用于从文本中提取完整机构名的正则（尽量包含 \"University of X\" 和带连字符的校名）\n",
    "    instPattern = re.compile(\n",
    "        r'(?i)(.+?(?:University(?: of [A-Za-z\\-\\s&]+|-[A-Za-z0-9]+)?|Institute(?: of [A-Za-z\\-\\s&]+)?|College(?: of [A-Za-z\\-\\s&]+)?|School(?: of [A-Za-z\\-\\s&]+)?|Business School|School of Economics|School of Management|School of Arts and Sciences))',\n",
    "        flags=re.I\n",
    "    )\n",
    "\n",
    "    def cleanInstitutionName(raw):\n",
    "        # 去括号和多余空格\n",
    "        s = re.sub(r'\\(.*?\\)', '', raw).strip()\n",
    "        s = re.sub(r'\\s{2,}', ' ', s)\n",
    "        # 先按逗号分段，从后向前找包含关键词的段落\n",
    "        parts = [p.strip() for p in s.split(',') if p.strip()]\n",
    "        for part in reversed(parts):\n",
    "            if any(kw.lower() in part.lower() for kw in instKeywords):\n",
    "                # 在该段内用正则抓取机构部分（优先最长匹配）\n",
    "                m = instPattern.search(part)\n",
    "                if m:\n",
    "                    candidate = m.group(1).strip().rstrip(' ,')\n",
    "                else:\n",
    "                    candidate = part\n",
    "                # 如果candidate仅为国家名或非常短，尝试回退到前一段\n",
    "                low = candidate.lower()\n",
    "                if low in countries or len(candidate.split()) <= 1:\n",
    "                    continue\n",
    "                return candidate\n",
    "        # 若逗号段未找到，尝试在整行匹配\n",
    "        m = instPattern.search(s)\n",
    "        if m:\n",
    "            candidate = m.group(1).strip().rstrip(' ,')\n",
    "            if candidate.lower() in countries or len(candidate.split()) <= 1:\n",
    "                # 回退：取去掉系/院前缀后的剩余\n",
    "                s2 = re.sub(r'^(Department of [^,]+,?|Economics Department,?|Dept\\. of [^,]+,?)\\s*', '', s, flags=re.I).strip()\n",
    "                s2 = re.sub(r'\\s*\\(.*?\\)', '', s2).strip()\n",
    "                return s2 if s2 and s2.lower() not in countries else candidate\n",
    "            return candidate\n",
    "        # 最后保底：去掉开头的系/院前缀并取第一段\n",
    "        s2 = re.sub(r'^(Department of [^,]+,?|Economics Department,?|Dept\\. of [^,]+,?)\\s*', '', s, flags=re.I).strip()\n",
    "        s2 = re.sub(r'\\s*\\(.*?\\)', '', s2).strip()\n",
    "        if ',' in s2:\n",
    "            s2 = s2.split(',')[0].strip()\n",
    "        # 如果仍然是国家名，返回空字符串以便后续过滤\n",
    "        if s2.lower() in countries:\n",
    "            return \"\"\n",
    "        return s2\n",
    "\n",
    "    df = pd.DataFrame(rows).drop_duplicates(subset=[\"rank\"]).sort_values(\"rank\").reset_index(drop=True)\n",
    "    df['clean'] = df['raw'].apply(cleanInstitutionName)\n",
    "\n",
    "    # 仅保留 1-90 且 clean 非空\n",
    "    df_1_90 = df[(df['rank'] >= 1) & (df['rank'] <= 90)].copy()\n",
    "    df_1_90 = df_1_90[df_1_90['clean'].str.strip() != \"\"].reset_index(drop=True)\n",
    "\n",
    "    # 选择：1-30 取 1-10，31-60 取 31-40，61-90 取 61-70\n",
    "    selectedRanks = list(range(1, 11)) + list(range(31, 41)) + list(range(61, 71))\n",
    "    dfSelected = df_1_90[df_1_90['rank'].isin(selectedRanks)].copy()\n",
    "    dfSelected = dfSelected.drop_duplicates(subset=[\"clean\"]).sort_values(\"rank\").reset_index(drop=True)\n",
    "\n",
    "    # 只保存最终选定的30所大学到universityList.xlsx\n",
    "    dfSelected[['clean']].rename(columns={'clean': 'University'}).to_excel(\"universityList.xlsx\", index=False)\n",
    "\n",
    "    # 控制台输出检查\n",
    "    print(f\"Total rows parsed: {len(df)}; kept 1-90 (non-empty): {len(df_1_90)}; selected final: {len(dfSelected)}\")\n",
    "    print(\"\\nSelected 30 universities:\")\n",
    "    for _, r in dfSelected.iterrows():\n",
    "        print(f\"{int(r['rank']):2d} - {r['clean']}\")\n",
    "\n",
    "    return dfSelected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb67bb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def createResearchData():\n",
    "    \n",
    "    # 创建研究数据Excel文件\n",
    "    # 研究方向和技术技能是预先手动从Glassdoor获取的\n",
    "\n",
    "    # 预先手动从Glassdoor获取的研究方向和技术技能\n",
    "    predefinedFieldsAndTechniques = {\n",
    "        \"Economics\": {\n",
    "            \"technique1\": \"Proficiency in Microsoft Office\",\n",
    "            \"technique2\": \"Highly developed analytical, research and written skills\", \n",
    "            \"technique3\": \"Advanced SQL skills\"\n",
    "        },\n",
    "        \"Finance\": {\n",
    "            \"technique1\": \"Ability to quickly learn new technology\",\n",
    "            \"technique2\": \"Excellent communication, time management skills\",\n",
    "            \"technique3\": \"Strong computer skills with emphasis in time series\"\n",
    "        },\n",
    "        \"Management\": {\n",
    "            \"technique1\": \"Interpersonal skills – ability to collaborate effectively in a team\",\n",
    "            \"technique2\": \"Relevant coursework, internships, or extracurricular leadership experience\",\n",
    "            \"technique3\": \"Excellent written and verbal communication\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"=== 预先定义的研究方向和技术技能 ===\")\n",
    "    for field, techniques in predefinedFieldsAndTechniques.items():\n",
    "        print(f\"{field}: {list(techniques.values())}\")\n",
    "    \n",
    "    # 从网页爬取顶级期刊\n",
    "    print(\"\\n=== 开始从网页爬取顶级期刊 ===\")\n",
    "    journalsData = scrapeJournalsFromWeb()\n",
    "    \n",
    "    # 将期刊数据与预定义的研究方向和技能合并\n",
    "    researchData = mergeJournalsWithFields(journalsData, predefinedFieldsAndTechniques)\n",
    "    \n",
    "    # 创建DataFrame并保存到Excel\n",
    "    dataFrame = pd.DataFrame(researchData)\n",
    "    outputFile = 'researchData.xlsx'\n",
    "    dataFrame.to_excel(outputFile, index=False)\n",
    "    \n",
    "    print(f\"\\n=== 最终生成的研究数据 ===\")\n",
    "    print(dataFrame)\n",
    "    print(f\"\\n数据已保存到 {outputFile}\")\n",
    "    \n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078420c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def scrapeJournalsFromWeb():\n",
    "    # 从指定网页爬取顶级期刊信息\n",
    "    \n",
    "    url = \"https://www.scmor.com/view/10554\"\n",
    "    \n",
    "    try:\n",
    "        # 发送HTTP请求\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        response.encoding = 'utf-8'\n",
    "        \n",
    "        # 解析HTML内容\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        print(f\"网页标题: {soup.title.string if soup.title else '无标题'}\")\n",
    "        \n",
    "        # 查找所有可能的期刊列表\n",
    "        journalElements = soup.find_all(['p', 'li', 'div', 'td'])\n",
    "        \n",
    "        # 提取所有可能的期刊名称\n",
    "        possibleJournals = []\n",
    "        for element in journalElements:\n",
    "            text = element.get_text(strip=True)\n",
    "            # 期刊名称通常包含\"Journal\"、\"Review\"等关键词，且长度适中\n",
    "            if (len(text) > 5 and len(text) < 100 and \n",
    "                any(keyword in text.lower() for keyword in ['journal', 'review', 'economics', 'finance', 'management', 'accounting'])):\n",
    "                possibleJournals.append(text)\n",
    "        \n",
    "        print(f\"找到 {len(possibleJournals)} 个可能的期刊名称\")\n",
    "        \n",
    "        # 按研究领域分类期刊\n",
    "        categorizedJournals = categorizeJournals(possibleJournals)\n",
    "        \n",
    "        return categorizedJournals\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"爬取网页时出错: {e}\")\n",
    "        # 如果爬取失败，返回空数据\n",
    "        return {\n",
    "            \"Economics\": [\"\", \"\", \"\"],\n",
    "            \"Finance\": [\"\", \"\", \"\"],\n",
    "            \"Management\": [\"\", \"\", \"\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d9bd7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def categorizeJournals(journals):\n",
    "    # 将期刊按研究领域分类\n",
    "    \n",
    "    # 定义研究领域和对应的关键词\n",
    "    fieldKeywords = {\n",
    "        \"Economics\": [\"economic\", \"econometric\", \"economy\", \"economic review\", \"political economy\"],\n",
    "        \"Finance\": [\"finance\", \"financial\", \"investment\", \"banking\", \"capital\", \"portfolio\"],\n",
    "        \"Management\": [\"management\", \"administrative\", \"strategic\", \"organization\", \"business\", \"leadership\"]\n",
    "    }\n",
    "    \n",
    "    categorizedJournals = {}\n",
    "    \n",
    "    for field, keywords in fieldKeywords.items():\n",
    "        fieldJournals = []\n",
    "        \n",
    "        # 从网页期刊中匹配当前领域的期刊\n",
    "        for journal in journals:\n",
    "            # 检查期刊是否包含该领域的关键词\n",
    "            if any(keyword in journal.lower() for keyword in keywords):\n",
    "                # 避免重复添加\n",
    "                if journal not in fieldJournals:\n",
    "                    fieldJournals.append(journal)\n",
    "        \n",
    "        # 取前3个匹配的期刊，如果不足3个则用空字符串填充\n",
    "        topJournals = fieldJournals[:3] if len(fieldJournals) >= 3 else fieldJournals + [\"\"] * (3 - len(fieldJournals))\n",
    "        \n",
    "        categorizedJournals[field] = topJournals\n",
    "        print(f\"领域 '{field}' 匹配到 {len(fieldJournals)} 个期刊: {topJournals}\")\n",
    "    \n",
    "    return categorizedJournals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee174d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def mergeJournalsWithFields(journalsData, fieldsAndTechniques):\n",
    "    \"\"\"\n",
    "    将期刊数据与预定义的研究方向和技能合并\n",
    "    \"\"\"\n",
    "    researchData = []\n",
    "    \n",
    "    for field, techniques in fieldsAndTechniques.items():\n",
    "        # 获取该领域的期刊\n",
    "        fieldJournals = journalsData.get(field, [\"\", \"\", \"\"])\n",
    "        \n",
    "        researchData.append({\n",
    "            \"field\": field,\n",
    "            \"journal1\": fieldJournals[0] if len(fieldJournals) > 0 else \"\",\n",
    "            \"journal2\": fieldJournals[1] if len(fieldJournals) > 1 else \"\",\n",
    "            \"journal3\": fieldJournals[2] if len(fieldJournals) > 2 else \"\",\n",
    "            \"technique1\": techniques[\"technique1\"],\n",
    "            \"technique2\": techniques[\"technique2\"],\n",
    "            \"technique3\": techniques[\"technique3\"]\n",
    "        })\n",
    "    \n",
    "    return researchData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c78fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 主函数部分\n",
    "\n",
    "    fetchUniversityList()\n",
    "    createResearchData()\n",
    "    # 读取学校数据\n",
    "    universityDf = pd.read_excel('universityList.xlsx')\n",
    "    universities = universityDf['University'].tolist()\n",
    "    \n",
    "    # 读取研究领域数据\n",
    "    researchDf = pd.read_excel('researchData.xlsx')\n",
    "    print(f\"读取到 {len(researchDf)} 个研究领域\")\n",
    "    \n",
    "    # 创建输出目录\n",
    "    outputDir = 'AdmissionLetters'\n",
    "    if not os.path.exists(outputDir):\n",
    "        os.makedirs(outputDir)\n",
    "        print(f\"创建目录: {outputDir}\")\n",
    "    else:\n",
    "        print(f\"目录已存在: {outputDir}\")\n",
    "    \n",
    "    # 加载模板\n",
    "    template = DocxTemplate('admissionTemplate.docx')\n",
    "    print(\"模板加载成功\")\n",
    "    \n",
    "    # 外层循环 - 遍历大学\n",
    "    i = 0\n",
    "    while i < len(universities):\n",
    "        university = universities[i]\n",
    "        \n",
    "        # 内层循环 - 遍历研究领域\n",
    "        j = 0\n",
    "        while j < len(researchDf):\n",
    "            researchRow = researchDf.iloc[j]\n",
    "            \n",
    "            # 准备替换数据\n",
    "            context = {\n",
    "                'university': university,\n",
    "                'field': researchRow['field'],\n",
    "                'journal1': researchRow['journal1'],\n",
    "                'journal2': researchRow['journal2'],\n",
    "                'journal3': researchRow['journal3'],\n",
    "                'technique1': researchRow['technique1'],\n",
    "                'technique2': researchRow['technique2'],\n",
    "                'technique3': researchRow['technique3']\n",
    "            }\n",
    "            \n",
    "            # 生成文件名 - 修正这里\n",
    "            safeUniversity = ''.join(c for c in university if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "            safeField = ''.join(c for c in researchRow['field'] if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "            filename = f\"{safeUniversity}_{safeField}\"\n",
    "            docxPath = os.path.join(outputDir, f\"{filename}.docx\")  # 去掉filename中的.docx\n",
    "            pdfPath = os.path.join(outputDir, f\"{filename}.pdf\")    # 去掉filename中的.pdf\n",
    "            \n",
    "            # 渲染并保存Word文档\n",
    "            template.render(context)\n",
    "            template.save(docxPath)\n",
    "            \n",
    "            # 立即导出PDF版本\n",
    "            try:\n",
    "                convert(docxPath, pdfPath)\n",
    "                print(f\"生成第 {i*len(researchDf) + j + 1} 封: {filename}.docx 和 {filename}.pdf\")\n",
    "            except Exception as e:\n",
    "                print(f\"生成第 {i*len(researchDf) + j + 1} 封: {filename}.docx (PDF转换失败: {e})\")\n",
    "            \n",
    "            j += 1\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    print(\"\\n生成完成\")\n",
    "    print(f\"成功生成 {len(universities) * len(researchDf)} 封申请信\")\n",
    "    print(f\"文件保存在: {outputDir} 目录\")\n",
    "    print(\"\\n注意: Glassdoor有Cloudflare反爬机制,所以technique字段是手动搜索的.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
