{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438ff02-e8e8-4c1e-9833-866f93e5c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install html5lib\n",
    "%pip install webdriver-manager\n",
    "%pip install selenium\n",
    "%pip install selenium webdriver-manager pandas matplotlib -q\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"‚úÖ Environment ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a5fd894-bc3a-46b6-92e1-2b4768c8e026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chrome started\n"
     ]
    }
   ],
   "source": [
    "# Start Chrome browser via webdriver-manager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.maximize_window()\n",
    "print(\"‚úÖ Chrome started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02b250d7-d19d-4aae-b8c2-17702265240a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Opening https://esf.fang.com/house-a010-b05048/\n",
      "‚úÖ Page loaded and listing container detected.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define start URL\n",
    "START_URL = \"https://esf.fang.com/house-a010-b05048/\"\n",
    "\n",
    "# Safely quit an existing driver if it still exists\n",
    "def safe_quit(drv):\n",
    "    \"\"\"Try to quit an existing driver safely.\"\"\"\n",
    "    try:\n",
    "        drv.quit()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Check and clean up any old driver instance\n",
    "try:\n",
    "    _ = driver.current_url  # Test if the driver is still alive\n",
    "except Exception:\n",
    "    try:\n",
    "        driver  # If the variable exists but is broken\n",
    "        safe_quit(driver)\n",
    "    except NameError:\n",
    "        pass  # Driver not defined yet\n",
    "\n",
    "# Start a new Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.maximize_window()\n",
    "\n",
    "print(f\"üåê Opening {START_URL}\")\n",
    "driver.get(START_URL)\n",
    "\n",
    "# Wait for the listing container to ensure the page is ready\n",
    "WebDriverWait(driver, 12).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, \"div.shop_list.shop_list_4, #listBox\"))\n",
    ")\n",
    "print(\"‚úÖ Page loaded and listing container detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d515f3c2-e1f1-469b-a56b-d9771bfe25cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1: 60 rows | https://esf.fang.com/house-a010-b05048/\n",
      "Page 2: 60 rows | https://esf.fang.com/house-a010-b05048/i32/\n",
      "Page 3: 60 rows | https://esf.fang.com/house-a010-b05048/i33/\n",
      "Page 4: 60 rows | https://esf.fang.com/house-a010-b05048/i34/\n",
      "Page 5: 60 rows | https://esf.fang.com/house-a010-b05048/i35/\n",
      "Page 6: 60 rows | https://esf.fang.com/house-a010-b05048/i36/\n",
      "Page 7: 60 rows | https://esf.fang.com/house-a010-b05048/i37/\n",
      "Page 8: 60 rows | https://esf.fang.com/house-a010-b05048/i38/\n",
      "Page 9: 60 rows | https://esf.fang.com/house-a010-b05048/i39/\n",
      "Page 10: 60 rows | https://esf.fang.com/house-a010-b05048/i310/\n",
      "Page 11: 60 rows | https://esf.fang.com/house-a010-b05048/i311/\n",
      "Page 12: 60 rows | https://esf.fang.com/house-a010-b05048/i312/\n",
      "Page 13: 60 rows | https://esf.fang.com/house-a010-b05048/i313/\n",
      "Page 14: 60 rows | https://esf.fang.com/house-a010-b05048/i314/\n",
      "Page 15: 60 rows | https://esf.fang.com/house-a010-b05048/i315/\n",
      "Page 16: 60 rows | https://esf.fang.com/house-a010-b05048/i316/\n",
      "Page 17: 60 rows | https://esf.fang.com/house-a010-b05048/i317/\n",
      "Page 18: 60 rows | https://esf.fang.com/house-a010-b05048/i318/\n",
      "Page 19: 60 rows | https://esf.fang.com/house-a010-b05048/i319/\n",
      "Page 20: 60 rows | https://esf.fang.com/house-a010-b05048/i320/\n",
      "Reached max_pages, stop.\n",
      "TOTAL rows (first 20 pages): 1200\n",
      "üíæ Saved: majiaoqiao_first20pages_area_unit.csv\n",
      "Head:\n",
      "  area_sqm unit_price_yuan_per_sqm\n",
      "0       87                   36436\n",
      "1    88.13                   29274\n",
      "2    86.97                   25066\n",
      "3    89.26                   30136\n",
      "4   236.05                   27536\n",
      "5    78.73                   33024\n",
      "6   109.21                   30033\n",
      "7    94.09                   35923\n",
      "Tail:\n",
      "     area_sqm unit_price_yuan_per_sqm\n",
      "1192    71.58                   46801\n",
      "1193    85.88                   24453\n",
      "1194   109.89                   49687\n",
      "1195    89.21                   19617\n",
      "1196   112.24                   30115\n",
      "1197    70.58                   10202\n",
      "1198    79.03                   26193\n",
      "1199    88.49                   23619\n"
     ]
    }
   ],
   "source": [
    "# Crawl first 20 pages (from page 1) for Tongzhou ¬∑ Majuqiao on Fang.com\n",
    "# Fields:\n",
    "# - area_sqm: strictly from <p class=\"tel_shop\"> ... „é° ... -> e.g., \"94.09\"\n",
    "# - unit_price_yuan_per_sqm: from <dd class=\"price_right\"> <span> ... ÂÖÉ/„é° </span> -> e.g., \"31402\"\n",
    "\n",
    "import re, time, pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# ---------- Config ----------\n",
    "START_URL = \"https://esf.fang.com/house-a010-b05048/\"  # page 1 (Majuqiao)\n",
    "MAX_PAGES = 20\n",
    "SLEEP_SEC = 0.4\n",
    "CSV_PATH = \"majiaoqiao_first20pages_area_unit.csv\"\n",
    "BASE = \"https://esf.fang.com\"\n",
    "\n",
    "# ---------- Regex helpers ----------\n",
    "AREA_PATTERN = re.compile(r\"(\\d+(?:\\.\\d+)?)\\s*[„é°m¬≤]\")\n",
    "NUM_PATTERN  = re.compile(r\"(\\d+(?:\\.\\d+)?)\")\n",
    "\n",
    "def num_first(text: str) -> str:\n",
    "    \"\"\"Return the first decimal number in text, else ''.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    m = NUM_PATTERN.search(text.replace(\",\", \"\"))\n",
    "    return m.group(1) if m else \"\"\n",
    "\n",
    "# ---------- Driver helpers ----------\n",
    "def ensure_driver():\n",
    "    \"\"\"Return a usable Selenium Chrome driver, recreating if needed.\"\"\"\n",
    "    global driver\n",
    "    try:\n",
    "        _ = driver.current_url  # raises if window is gone\n",
    "        return driver\n",
    "    except Exception:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except Exception:\n",
    "            pass\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "        driver.maximize_window()\n",
    "        return driver\n",
    "\n",
    "def wait_list_loaded(drv, timeout=12):\n",
    "    \"\"\"Wait until listing container exists on the page.\"\"\"\n",
    "    WebDriverWait(drv, timeout).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"div.shop_list.shop_list_4, #listBox\"))\n",
    "    )\n",
    "\n",
    "# ---------- Scraping helpers ----------\n",
    "def area_from_tel_shop(card_el) -> str:\n",
    "    \"\"\"Extract area strictly from <p class='tel_shop'> ... „é° ...\"\"\"\n",
    "    try:\n",
    "        tel_text = card_el.find_element(By.CSS_SELECTOR, \"p.tel_shop\").text\n",
    "        tel_text = \" \".join(tel_text.replace(\"\\xa0\", \" \").split())  # normalize whitespace\n",
    "        m = AREA_PATTERN.search(tel_text)\n",
    "        return m.group(1) if m else \"\"\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def scrape_current_page_tel_area(drv):\n",
    "    \"\"\"Scrape all listings on current page (area from tel_shop; unit price from price_right).\"\"\"\n",
    "    # locate container\n",
    "    container = None\n",
    "    for sel in [\"div.shop_list.shop_list_4\", \"#listBox\"]:\n",
    "        els = drv.find_elements(By.CSS_SELECTOR, sel)\n",
    "        if els:\n",
    "            container = els[0]\n",
    "            break\n",
    "    if container is None:\n",
    "        return []\n",
    "\n",
    "    # each listing card\n",
    "    cards = container.find_elements(By.CSS_SELECTOR, \"dl.clearfix\")\n",
    "    if not cards:\n",
    "        cards = container.find_elements(By.CSS_SELECTOR, \"dl\")\n",
    "\n",
    "    out = []\n",
    "    for it in cards:\n",
    "        # area from tel_shop\n",
    "        area_num = area_from_tel_shop(it)\n",
    "\n",
    "        # unit price from price_right \"... ÂÖÉ/„é°\"\n",
    "        unit_num = \"\"\n",
    "        try:\n",
    "            up_text = it.find_element(\n",
    "                By.XPATH, \".//dd[contains(@class,'price_right')]//span[contains(text(),'ÂÖÉ/„é°')]\"\n",
    "            ).text.strip()\n",
    "            unit_num = num_first(up_text)\n",
    "        except Exception:\n",
    "            try:\n",
    "                up_text2 = it.find_element(By.XPATH, \".//*[contains(text(),'ÂÖÉ/„é°')]\").text.strip()\n",
    "                unit_num = num_first(up_text2)\n",
    "            except Exception:\n",
    "                unit_num = \"\"\n",
    "\n",
    "        if area_num or unit_num:\n",
    "            out.append({\"area_sqm\": area_num, \"unit_price_yuan_per_sqm\": unit_num})\n",
    "    return out\n",
    "\n",
    "def get_next_href(drv) -> str:\n",
    "    \"\"\"Return absolute href of the '‰∏ã‰∏ÄÈ°µ' link, or '' if none.\"\"\"\n",
    "    try:\n",
    "        a = drv.find_element(By.XPATH, \"//a[normalize-space(text())='‰∏ã‰∏ÄÈ°µ']\")\n",
    "        href = (a.get_attribute(\"href\") or \"\").strip()\n",
    "        if href.startswith(\"/\"):\n",
    "            href = BASE + href\n",
    "        return href\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def crawl_all_pages(drv, start_url: str, max_pages: int = 20, sleep_sec: float = 0.4):\n",
    "    \"\"\"Paginate until '‰∏ã‰∏ÄÈ°µ' missing or reaching max_pages; return all rows.\"\"\"\n",
    "    all_rows, seen = [], set()\n",
    "    drv.get(start_url)\n",
    "    wait_list_loaded(drv, 12)\n",
    "\n",
    "    page_idx = 1\n",
    "    while True:\n",
    "        cur = drv.current_url\n",
    "        if cur in seen:\n",
    "            print(\"‚ö†Ô∏è Repeat URL, stop:\", cur)\n",
    "            break\n",
    "        seen.add(cur)\n",
    "\n",
    "        rows = scrape_current_page_tel_area(drv)\n",
    "        print(f\"Page {page_idx}: {len(rows)} rows | {cur}\")\n",
    "        all_rows.extend(rows)\n",
    "\n",
    "        if page_idx >= max_pages:\n",
    "            print(\"Reached max_pages, stop.\"); break\n",
    "\n",
    "        nxt = get_next_href(drv)\n",
    "        if not nxt or nxt == cur:\n",
    "            print(\"No further '‰∏ã‰∏ÄÈ°µ', stop.\"); break\n",
    "\n",
    "        drv.get(nxt)\n",
    "        page_idx += 1\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return all_rows\n",
    "\n",
    "# ---------- RUN ----------\n",
    "driver = ensure_driver()\n",
    "records_20 = crawl_all_pages(driver, START_URL, max_pages=MAX_PAGES, sleep_sec=SLEEP_SEC)\n",
    "print(f\"TOTAL rows (first {MAX_PAGES} pages): {len(records_20)}\")\n",
    "\n",
    "df = pd.DataFrame(records_20)\n",
    "df.to_csv(CSV_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"üíæ Saved:\", CSV_PATH)\n",
    "\n",
    "# quick preview\n",
    "print(\"Head:\")\n",
    "print(df.head(8))\n",
    "print(\"Tail:\")\n",
    "print(df.tail(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "906dceac-f6cf-4278-ad7f-5bfbbfaab8a2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1: 60 rows | https://zu.fang.com/house-a010-b05048/\n",
      "Page 2: 60 rows | https://zu.fang.com/house-a010-b05048/i32/\n",
      "Page 3: 60 rows | https://zu.fang.com/house-a010-b05048/i33/\n",
      "Page 4: 60 rows | https://zu.fang.com/house-a010-b05048/i34/\n",
      "Page 5: 60 rows | https://zu.fang.com/house-a010-b05048/i35/\n",
      "Page 6: 60 rows | https://zu.fang.com/house-a010-b05048/i36/\n",
      "Page 7: 60 rows | https://zu.fang.com/house-a010-b05048/i37/\n",
      "Page 8: 60 rows | https://zu.fang.com/house-a010-b05048/i38/\n",
      "Page 9: 60 rows | https://zu.fang.com/house-a010-b05048/i39/\n",
      "Page 10: 60 rows | https://zu.fang.com/house-a010-b05048/i310/\n",
      "Page 11: 60 rows | https://zu.fang.com/house-a010-b05048/i311/\n",
      "Page 12: 60 rows | https://zu.fang.com/house-a010-b05048/i312/\n",
      "Page 13: 29 rows | https://zu.fang.com/house-a010-b05048/i313/\n",
      "No further '‰∏ã‰∏ÄÈ°µ', stop.\n",
      "TOTAL rows: 749\n",
      "üíæ Saved: majiaoqiao_rent_all_pages_area_rent.csv\n",
      "Head:\n",
      "  area_sqm rent_yuan_per_month\n",
      "0       52                3000\n",
      "1       60                3000\n",
      "2      118                6500\n",
      "3       85                3700\n",
      "4       88                5200\n",
      "5       90                1800\n",
      "6      102                4300\n",
      "7       86                4200\n",
      "Tail:\n",
      "    area_sqm rent_yuan_per_month\n",
      "741       81                4740\n",
      "742      160               10000\n",
      "743       90                4800\n",
      "744       88                2800\n",
      "745      210                9000\n",
      "746      114                4500\n",
      "747       10                1550\n",
      "748      114                5800\n"
     ]
    }
   ],
   "source": [
    "# Crawl ALL rental pages for Tongzhou ¬∑ Majuqiao on zu.fang.com\n",
    "# Fields:\n",
    "# - area_sqm: from <p class=\"font15 mt12 bold\"> ... „é° ... </p> -> e.g., \"52\"\n",
    "# - rent_yuan_per_month: from <div class=\"moreInfo\"><span class=\"price\">3000</span>ÂÖÉ/Êúà</div> -> \"3000\"\n",
    "# Pagination:\n",
    "# - Click/visit the anchor whose text is exactly \"‰∏ã‰∏ÄÈ°µ\" until it disappears.\n",
    "\n",
    "import re, time, pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "START_URL = \"https://zu.fang.com/house-a010-b05048/\"\n",
    "BASE      = \"https://zu.fang.com\"\n",
    "CSV_PATH  = \"majiaoqiao_rent_all_pages_area_rent.csv\"\n",
    "\n",
    "AREA_RE = re.compile(r\"(\\d+(?:\\.\\d+)?)\\s*[„é°m¬≤]\")\n",
    "NUM_RE  = re.compile(r\"(\\d+(?:\\.\\d+)?)\")\n",
    "\n",
    "def ensure_driver():\n",
    "    \"\"\"Return a usable Selenium Chrome driver, recreating if needed.\"\"\"\n",
    "    global driver\n",
    "    try:\n",
    "        _ = driver.current_url\n",
    "        return driver\n",
    "    except Exception:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except Exception:\n",
    "            pass\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "        driver.maximize_window()\n",
    "        return driver\n",
    "\n",
    "def wait_list_loaded(drv, timeout=12):\n",
    "    \"\"\"Wait until listing container exists on the page.\"\"\"\n",
    "    WebDriverWait(drv, timeout).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"div.shop_list.shop_list_4, #listBox\"))\n",
    "    )\n",
    "\n",
    "def area_from_rent_header(card_el) -> str:\n",
    "    \"\"\"Extract area from <p class='font15 mt12 bold'> ... „é° ...>.\"\"\"\n",
    "    try:\n",
    "        p = card_el.find_element(By.CSS_SELECTOR, \"p.font15.mt12.bold\")\n",
    "        txt = \" \".join(p.text.replace(\"\\xa0\", \" \").split())\n",
    "        m = AREA_RE.search(txt)\n",
    "        return m.group(1) if m else \"\"\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def rent_from_moreinfo(card_el) -> str:\n",
    "    \"\"\"Extract monthly rent from <div class='moreInfo'><span class='price'>..</span>ÂÖÉ/Êúà</div>.\"\"\"\n",
    "    # primary\n",
    "    try:\n",
    "        price_span = card_el.find_element(By.CSS_SELECTOR, \"div.moreInfo span.price\")\n",
    "        txt = price_span.text.strip()\n",
    "        m = NUM_RE.search(txt.replace(\",\", \"\"))\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # fallback within the card\n",
    "    try:\n",
    "        txt2 = card_el.find_element(By.XPATH, \".//*[contains(text(),'ÂÖÉ/Êúà')]\").text.strip()\n",
    "        m2 = NUM_RE.search(txt2.replace(\",\", \"\"))\n",
    "        return m2.group(1) if m2 else \"\"\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def scrape_rent_current_page(drv):\n",
    "    \"\"\"Scrape all rental listings on the current page.\"\"\"\n",
    "    # locate container\n",
    "    container = None\n",
    "    for sel in [\"div.shop_list.shop_list_4\", \"#listBox\"]:\n",
    "        els = drv.find_elements(By.CSS_SELECTOR, sel)\n",
    "        if els:\n",
    "            container = els[0]; break\n",
    "    if container is None:\n",
    "        return []\n",
    "\n",
    "    # each listing card (dl)\n",
    "    cards = container.find_elements(By.CSS_SELECTOR, \"dl.clearfix\") or container.find_elements(By.CSS_SELECTOR, \"dl\")\n",
    "\n",
    "    out = []\n",
    "    for it in cards:\n",
    "        area_num = area_from_rent_header(it)\n",
    "        rent_num = rent_from_moreinfo(it)\n",
    "        if area_num or rent_num:\n",
    "            out.append({\"area_sqm\": area_num, \"rent_yuan_per_month\": rent_num})\n",
    "    return out\n",
    "\n",
    "def get_next_href(drv) -> str:\n",
    "    \"\"\"Return absolute href of the '‰∏ã‰∏ÄÈ°µ' link, or '' if none.\"\"\"\n",
    "    try:\n",
    "        a = drv.find_element(By.XPATH, \"//a[normalize-space(text())='‰∏ã‰∏ÄÈ°µ']\")\n",
    "        href = (a.get_attribute(\"href\") or \"\").strip()\n",
    "        if href.startswith(\"/\"):\n",
    "            href = BASE + href\n",
    "        return href\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def crawl_all_pages(drv, start_url: str, sleep_sec: float = 0.4, max_pages: int = 1000):\n",
    "    \"\"\"Paginate until no '‰∏ã‰∏ÄÈ°µ' or reaching max_pages; return all rows.\"\"\"\n",
    "    all_rows, seen = [], set()\n",
    "    drv.get(start_url)\n",
    "    wait_list_loaded(drv, 12)\n",
    "\n",
    "    page_idx = 1\n",
    "    while True:\n",
    "        cur = drv.current_url\n",
    "        if cur in seen:\n",
    "            print(\"‚ö†Ô∏è Repeat URL, stop:\", cur); break\n",
    "        seen.add(cur)\n",
    "\n",
    "        rows = scrape_rent_current_page(drv)\n",
    "        print(f\"Page {page_idx}: {len(rows)} rows | {cur}\")\n",
    "        all_rows.extend(rows)\n",
    "\n",
    "        if page_idx >= max_pages:\n",
    "            print(\"Reached max_pages, stop.\"); break\n",
    "\n",
    "        nxt = get_next_href(drv)\n",
    "        if not nxt or nxt == cur:\n",
    "            print(\"No further '‰∏ã‰∏ÄÈ°µ', stop.\"); break\n",
    "\n",
    "        drv.get(nxt)\n",
    "        page_idx += 1\n",
    "        time.sleep(sleep_sec)\n",
    "\n",
    "    return all_rows\n",
    "\n",
    "# ---- RUN: paginate all pages ----\n",
    "driver = ensure_driver()\n",
    "records = crawl_all_pages(driver, START_URL, sleep_sec=0.4, max_pages=1000)\n",
    "print(f\"TOTAL rows: {len(records)}\")\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(CSV_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"üíæ Saved:\", CSV_PATH)\n",
    "\n",
    "# quick preview\n",
    "print(\"Head:\")\n",
    "print(df.head(8))\n",
    "print(\"Tail:\")\n",
    "print(df.tail(8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcbf4bb-de1a-4c13-9394-bb7376e1c352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
